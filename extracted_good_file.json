[["daf81b989f81c7a0dd654d4b0bea5f08", {"code_string": "def get_UB(config):\n    sample, geometry, detector, engines = new_hkl_diffractometer(config)\n    return hkl_matrix_to_numpy(sample.UB_get())\n", "code_toks_joined": "def get_UB ( config ) : <NEWLINE> <INDENT> sample , geometry , detector , engines = new_hkl_diffractometer ( config ) <NEWLINE> return hkl_matrix_to_numpy ( sample . UB_get ( ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["1bdd18d071e2bd423a7f43edaf2bede6", {"code_string": "\"\"\"Helper functions\"\"\"\nimport datetime\nimport math\nimport pytz\nimport random\nimport re\n", "code_toks_joined": "<STRING> <NEWLINE> import datetime <NEWLINE> import math <NEWLINE> import pytz <NEWLINE> import random <NEWLINE> import re <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Helper functions\"\"\""]}}], ["19a7ddc668b47aa6e8920230c4449c3d", {"code_string": "class IWikiPageManipulator(Interface):\n    \"\"\"Components that need to do specific pre- and post- processing of\"\"\"\n    def prepare_wiki_page(req, page, fields):\n        \"\"\"Validate a wiki page before rendering it.\"\"\"\n    def validate_wiki_page(req, page):\n        \"\"\"Validate a wiki page after it's been populated from user input.\"\"\"\n", "code_toks_joined": "class IWikiPageManipulator ( Interface ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def prepare_wiki_page ( req , page , fields ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> <DEDENT> def validate_wiki_page ( req , page ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Components that need to do specific pre- and post- processing of\"\"\"", "\"\"\"Validate a wiki page before rendering it.\"\"\"", "\"\"\"Validate a wiki page after it's been populated from user input.\"\"\""]}}], ["cf05ae72a078a5f69f8d9b2042d30eb7", {"code_string": "def test_local():\n    src = urllib.urlopen(url)\n    with open(local, 'w') as f:\n        f.write(src.read())\n    with open(local, 'r') as source:\n        forum_topics(source)\n", "code_toks_joined": "def test_local ( ) : <NEWLINE> <INDENT> src = urllib . urlopen ( url ) <NEWLINE> with open ( local , <STRING> ) as f : <NEWLINE> <INDENT> f . write ( src . read ( ) ) <NEWLINE> <DEDENT> with open ( local , <STRING> ) as source : <NEWLINE> <INDENT> forum_topics ( source ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'w'", "'r'"]}}], ["ecb37c8fc54b681c15fe049a262a9c98", {"code_string": "class install(_install):\n    def run(self):\n        super().run()\n        self.execute(\n            make_shortcut,\n            (self.install_scripts, ),\n            msg = \"Creating desktop shortcut\"\n        )\n", "code_toks_joined": "class install ( _install ) : <NEWLINE> <INDENT> def run ( self ) : <NEWLINE> <INDENT> super ( ) . run ( ) <NEWLINE> self . execute ( <NEWLINE> <INDENT> make_shortcut , <NEWLINE> ( self . install_scripts , ) , <NEWLINE> msg = <STRING> <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Creating desktop shortcut\""]}}], ["b47c55ba94147d42cb0a53d075091091", {"code_string": "def main():\n    actions = log_collection.find(\n        {},\n        {'action': True}\n    ).distinct(\n        'action'\n    )\n    for action in actions:\n        analyze_log_action(action)\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> actions = log_collection . find ( <NEWLINE> <INDENT> { } , <NEWLINE> { <STRING> : True } <NEWLINE> <DEDENT> ) . distinct ( <NEWLINE> <INDENT> <STRING> <NEWLINE> <DEDENT> ) <NEWLINE> for action in actions : <NEWLINE> <INDENT> analyze_log_action ( action ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'action'", "'action'"]}}], ["af9c36fb7057d165ef5b72739ebc59d3", {"code_string": "class InteractionStyle(Enum):\n    SYNCHRONOUS = auto()\n    ASYNCHRONOUS = auto()\n", "code_toks_joined": "class InteractionStyle ( Enum ) : <NEWLINE> <INDENT> SYNCHRONOUS = auto ( ) <NEWLINE> ASYNCHRONOUS = auto ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["c6b9c8abf69f9f1c769d2e8cbf15d0b6", {"code_string": "def main():\n    input_length = 100\n    hidden_cnt = 50\n    nn = NeuralNetwork(RNN(input_length, hidden_cnt))\n    data = get_test_data(input_length)\n    print(\"TRAIN\")\n    nn.train(data)\n    print(\"TEST\")\n    nn.test(data)\n    print(\"TRAIN WITH CROSS-VALIDATION\")\n    nn.run_with_cross_validation(data, 2)\n    print(\"FEATURE SELECTION\")\n    features = nn.feature_selection(data)\n    print(\"Selected features: {0}\".format(features))\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> input_length = 100 <NEWLINE> hidden_cnt = 50 <NEWLINE> nn = NeuralNetwork ( RNN ( input_length , hidden_cnt ) ) <NEWLINE> data = get_test_data ( input_length ) <NEWLINE> print ( <STRING> ) <NEWLINE> nn . train ( data ) <NEWLINE> print ( <STRING> ) <NEWLINE> nn . test ( data ) <NEWLINE> print ( <STRING> ) <NEWLINE> nn . run_with_cross_validation ( data , 2 ) <NEWLINE> print ( <STRING> ) <NEWLINE> features = nn . feature_selection ( data ) <NEWLINE> print ( <STRING> . format ( features ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"TRAIN\"", "\"TEST\"", "\"TRAIN WITH CROSS-VALIDATION\"", "\"FEATURE SELECTION\"", "\"Selected features: {0}\""]}}], ["4c3136a028dfb95cc6c127e9a1b1b00c", {"code_string": "class Maker(FileSystemEventHandler):\n    def on_modified(self, _):\n        Maker.lock = True\n        print('make')\n        p = subprocess.Popen('make')\n        p.wait()\n", "code_toks_joined": "class Maker ( FileSystemEventHandler ) : <NEWLINE> <INDENT> def on_modified ( self , _ ) : <NEWLINE> <INDENT> Maker . lock = True <NEWLINE> print ( <STRING> ) <NEWLINE> p = subprocess . Popen ( <STRING> ) <NEWLINE> p . wait ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'make'", "'make'"]}}], ["421649ab584e74bab3657a2c0883bfea", {"code_string": "def test_t17():\n    lines = run_test('t17').split('\\n')\n    assert(lines[1] == '3141')\n", "code_toks_joined": "def test_t17 ( ) : <NEWLINE> <INDENT> lines = run_test ( <STRING> ) . split ( <STRING> ) <NEWLINE> assert ( lines [ 1 ] == <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'t17'", "'\\n'", "'3141'"]}}], ["9f3eb39ca1b9df49de3166048228c5ce", {"code_string": "def log_exception():\n    if not enabled:\n        logger.warning('Sentry called to log exception, but is not active')\n        return None\n    return sentry.captureException(extra = {\n        'session': get_session_data(),\n    })\n", "code_toks_joined": "def log_exception ( ) : <NEWLINE> <INDENT> if not enabled : <NEWLINE> <INDENT> logger . warning ( <STRING> ) <NEWLINE> return None <NEWLINE> <DEDENT> return sentry . captureException ( extra = { <NEWLINE> <INDENT> <STRING> : get_session_data ( ) , <NEWLINE> <DEDENT> } ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Sentry called to log exception, but is not active'", "'session'"]}}], ["8a2949d6d5d0d7d85a1f3b19a6f6abc6", {"code_string": "import base64\nfrom binascii import hexlify\nfrom enum import Enum\n", "code_toks_joined": "import base64 <NEWLINE> from binascii import hexlify <NEWLINE> from enum import Enum <NEWLINE>", "anonymize_dict": {}}], ["bbbf1f99efebe4f75882b835059229b6", {"code_string": "from __future__ import unicode_literals\nimport re\nimport base64\nfrom.common import InfoExtractor\nfrom..utils import(\n    ExtractorError,\n    compat_urllib_request,\n    compat_urllib_parse,\n    int_or_none,\n)\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> import re <NEWLINE> import base64 <NEWLINE> from . common import InfoExtractor <NEWLINE> from . . utils import ( <NEWLINE> <INDENT> ExtractorError , <NEWLINE> compat_urllib_request , <NEWLINE> compat_urllib_parse , <NEWLINE> int_or_none , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {}}], ["92965b73fe3e4f8a8a1ac6a606e68bb5", {"code_string": "class FingerprintTest(unittest.TestCase):\n    def test_name(self):\n        fp2 = chemkit.Fingerprint.create(\"fp2\")\n        self.assertEqual(fp2.name(), \"fp2\")\n", "code_toks_joined": "class FingerprintTest ( unittest . TestCase ) : <NEWLINE> <INDENT> def test_name ( self ) : <NEWLINE> <INDENT> fp2 = chemkit . Fingerprint . create ( <STRING> ) <NEWLINE> self . assertEqual ( fp2 . name ( ) , <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"fp2\"", "\"fp2\""]}}], ["76a08dcc4a7c735f5867ee664eb37103", {"code_string": "def to_xml(self):\n    tmpl = \"<item>\" \"<Title><![CDATA[$title]]></Title>\" \"<Description><![CDATA[$description]]></Description>\" \"<PicUrl><![CDATA[$pic_url]]></PicUrl>\" \"<Url><![CDATA[$url]]></Url>\" \"</item>\"\n    xml_item = Template(tmpl).safe_substitute(title = self.title,\n        description = self.description,\n        pic_url = self.pic_url,\n        url = self.url)\n    return xml_item\n", "code_toks_joined": "def to_xml ( self ) : <NEWLINE> <INDENT> tmpl = <STRING> <STRING> <STRING> <STRING> <STRING> <STRING> <NEWLINE> xml_item = Template ( tmpl ) . safe_substitute ( title = self . title , <NEWLINE> <INDENT> description = self . description , <NEWLINE> pic_url = self . pic_url , <NEWLINE> url = self . url ) <NEWLINE> <DEDENT> return xml_item <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"<item>\"", "\"<Title><![CDATA[$title]]></Title>\"", "\"<Description><![CDATA[$description]]></Description>\"", "\"<PicUrl><![CDATA[$pic_url]]></PicUrl>\"", "\"<Url><![CDATA[$url]]></Url>\"", "\"</item>\""]}}], ["19e3caf301c3a8a9089c03c234f5b79a", {"code_string": "def test_instance_has_valid_construction(self):\n    instance = self._makeOne()\n    self.assertEqual(instance.title, u'title')\n    self.assertEqual(instance.text, u'text')\n    self.assertEqual(instance.creator, u'admin')\n    self.assertEqual(instance.modified_by, u'admin')\n    self.assertEqual(instance.caption, u'caption')\n    self.failUnless('attachments' in instance)\n    from zope.interface.verify import verifyObject\n    from karl.models.interfaces import IAttachmentsFolder\n    verifyObject(IAttachmentsFolder, instance['attachments'])\n", "code_toks_joined": "def test_instance_has_valid_construction ( self ) : <NEWLINE> <INDENT> instance = self . _makeOne ( ) <NEWLINE> self . assertEqual ( instance . title , <STRING> ) <NEWLINE> self . assertEqual ( instance . text , <STRING> ) <NEWLINE> self . assertEqual ( instance . creator , <STRING> ) <NEWLINE> self . assertEqual ( instance . modified_by , <STRING> ) <NEWLINE> self . assertEqual ( instance . caption , <STRING> ) <NEWLINE> self . failUnless ( <STRING> in instance ) <NEWLINE> from zope . interface . verify import verifyObject <NEWLINE> from karl . models . interfaces import IAttachmentsFolder <NEWLINE> verifyObject ( IAttachmentsFolder , instance [ <STRING> ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["u'title'", "u'text'", "u'admin'", "u'admin'", "u'caption'", "'attachments'", "'attachments'"]}}], ["e9f2c593780591f5221fc43e687cec36", {"code_string": "def _get_section_bars(self):\n    self.sec_bars = self.uicore.core.cmd_str('S=')\n    if self.sec_bars:\n        self._parse_ascii_bars()\n", "code_toks_joined": "def _get_section_bars ( self ) : <NEWLINE> <INDENT> self . sec_bars = self . uicore . core . cmd_str ( <STRING> ) <NEWLINE> if self . sec_bars : <NEWLINE> <INDENT> self . _parse_ascii_bars ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'S='"]}}], ["250a652587745d7131ccb8fb4ccc4046", {"code_string": "def test_12_failmissingcluster(self):\n    command = [\"add_allowed_personality\", \"--archetype\", \"vmhost\",\n        \"--personality=vulcan-1g-desktop-prod\", \"--cluster=does-not-exist\"]\n    out = self.notfoundtest(command)\n    self.matchoutput(out,\n        \"Cluster does-not-exist not found.\",\n        command)\n", "code_toks_joined": "def test_12_failmissingcluster ( self ) : <NEWLINE> <INDENT> command = [ <STRING> , <STRING> , <STRING> , <NEWLINE> <INDENT> <STRING> , <STRING> ] <NEWLINE> <DEDENT> out = self . notfoundtest ( command ) <NEWLINE> self . matchoutput ( out , <NEWLINE> <INDENT> <STRING> , <NEWLINE> command ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"add_allowed_personality\"", "\"--archetype\"", "\"vmhost\"", "\"--personality=vulcan-1g-desktop-prod\"", "\"--cluster=does-not-exist\"", "\"Cluster does-not-exist not found.\""]}}], ["b5eb5ef609993f17becc77317fbe8f6b", {"code_string": "def enum(typename, field_names):\n    \"\"\"Create a new enumeration type\"\"\"\n    if isinstance(field_names, str):\n        field_names = field_names.replace(',', ' ').split()\n    d = dict((reversed(nv) for nv in enumerate(field_names)), __slots__ = ())\n    return type(typename, (object, ), d)()\n", "code_toks_joined": "def enum ( typename , field_names ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if isinstance ( field_names , str ) : <NEWLINE> <INDENT> field_names = field_names . replace ( <STRING> , <STRING> ) . split ( ) <NEWLINE> <DEDENT> d = dict ( ( reversed ( nv ) for nv in enumerate ( field_names ) ) , __slots__ = ( ) ) <NEWLINE> return type ( typename , ( object , ) , d ) ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Create a new enumeration type\"\"\"", "','", "' '"]}}], ["929bc97ade1cb77990fd7651ffbf3c9e", {"code_string": "def teardown(self):\n    if os.path.exists(self.dbfile):\n        os.unlink(self.dbfile)\n    if os.path.exists(self.inifile):\n        os.unlink(self.inifile)\n", "code_toks_joined": "def teardown ( self ) : <NEWLINE> <INDENT> if os . path . exists ( self . dbfile ) : <NEWLINE> <INDENT> os . unlink ( self . dbfile ) <NEWLINE> <DEDENT> if os . path . exists ( self . inifile ) : <NEWLINE> <INDENT> os . unlink ( self . inifile ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["eae72ff6ba26cab40191608647258aa5", {"code_string": "def extract_length(length_string):\n    l3 = string.split(length_string, \"...\")\n    n1 = string.atoi(l3[0])\n    n2 = string.atoi(l3[1])\n    length = n2 - n1\n    return(length)\n", "code_toks_joined": "def extract_length ( length_string ) : <NEWLINE> <INDENT> l3 = string . split ( length_string , <STRING> ) <NEWLINE> n1 = string . atoi ( l3 [ 0 ] ) <NEWLINE> n2 = string . atoi ( l3 [ 1 ] ) <NEWLINE> length = n2 - n1 <NEWLINE> return ( length ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"...\""]}}], ["5d890a2fc31070093fc5aabf97d1ca4e", {"code_string": "class UserManager(BaseUserManager):\n    STAFF = ('MANAGER', 'WAITER', 'BARTENDER')\n    def create_superuser(self, role, email, password):\n        user = self.create_user(email, password = password, role = role)\n        user.is_admin = True\n        user.save(using = self._db)\n        return user\n", "code_toks_joined": "class UserManager ( BaseUserManager ) : <NEWLINE> <INDENT> STAFF = ( <STRING> , <STRING> , <STRING> ) <NEWLINE> def create_superuser ( self , role , email , password ) : <NEWLINE> <INDENT> user = self . create_user ( email , password = password , role = role ) <NEWLINE> user . is_admin = True <NEWLINE> user . save ( using = self . _db ) <NEWLINE> return user <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'MANAGER'", "'WAITER'", "'BARTENDER'"]}}], ["7e2ea927a85845ddff950a8fe60147b6", {"code_string": "import blinker\n_signals = blinker.Namespace()\nrepository_created = _signals.signal('repository-created')\nrepository_updated = _signals.signal('repository-updated')\nrepository_deleted = _signals.signal('repository-deleted')\ntag_created = _signals.signal('tag-created')\ntag_deleted = _signals.signal('tag-deleted')\n", "code_toks_joined": "import blinker <NEWLINE> _signals = blinker . Namespace ( ) <NEWLINE> repository_created = _signals . signal ( <STRING> ) <NEWLINE> repository_updated = _signals . signal ( <STRING> ) <NEWLINE> repository_deleted = _signals . signal ( <STRING> ) <NEWLINE> tag_created = _signals . signal ( <STRING> ) <NEWLINE> tag_deleted = _signals . signal ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'repository-created'", "'repository-updated'", "'repository-deleted'", "'tag-created'", "'tag-deleted'"]}}], ["aef7e1fa1145630ebb64a9806a12afef", {"code_string": "def test_id(self):\n    assert self.task.id == test_id\n    assert self.task['_id'] == test_id\n", "code_toks_joined": "def test_id ( self ) : <NEWLINE> <INDENT> assert self . task . id == test_id <NEWLINE> assert self . task [ <STRING> ] == test_id <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'_id'"]}}], ["0364e44bb727f72a010398f52eab4041", {"code_string": "def refreshCanvas(self):\n    if not self.dirty: return\n    self.screen.clear()\n    self.dirty = False\n", "code_toks_joined": "def refreshCanvas ( self ) : <NEWLINE> <INDENT> if not self . dirty : return <NEWLINE> self . screen . clear ( ) <NEWLINE> self . dirty = False <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["2ff256fbccf101260c2ed9f570e6aa61", {"code_string": "r\"\"\":Copyright:\"\"\"\nif __doc__:\n    __doc__ = __doc__.encode('ascii').decode('unicode_escape')\n__author__ = r\"Andr\\xe9 Malo\".encode('ascii').decode('unicode_escape')\n__docformat__ = \"restructuredtext en\"\nimport types as _types\nfrom gensaschema import _util\n", "code_toks_joined": "<STRING> <NEWLINE> if __doc__ : <NEWLINE> <INDENT> __doc__ = __doc__ . encode ( <STRING> ) . decode ( <STRING> ) <NEWLINE> <DEDENT> __author__ = <STRING> . encode ( <STRING> ) . decode ( <STRING> ) <NEWLINE> __docformat__ = <STRING> <NEWLINE> import types as _types <NEWLINE> from gensaschema import _util <NEWLINE>", "anonymize_dict": {"<STRING>": ["r\"\"\":Copyright:\"\"\"", "'ascii'", "'unicode_escape'", "r\"Andr\\xe9 Malo\"", "'ascii'", "'unicode_escape'", "\"restructuredtext en\""]}}], ["5874dd913d53927f2361ee32786f34b7", {"code_string": "'''name:face.py'''\nimport sys\nimport cv2\nimggray = cv2.imread('../../public/images/skew-linedetection.png');\ncv2.imshow('1', imggray)\nimgbw = cv2.im2bw(imggray, 0.5)\ncv2.subplot(222)\ncv2.imshow(imgbw)\nimgbw = cv2.im2bw(imggray, 0.25)\ncv2.subplot(223)\ncv2.imshow(imgbw)\nlevel = cv2.graythresh(imggray)\nimgbw = cv2.im2bw(imggray, level)\ncv2.subplot(224)\ncv2.imshow(imgbw)\n", "code_toks_joined": "<STRING> <NEWLINE> import sys <NEWLINE> import cv2 <NEWLINE> imggray = cv2 . imread ( <STRING> ) ; <NEWLINE> cv2 . imshow ( <STRING> , imggray ) <NEWLINE> imgbw = cv2 . im2bw ( imggray , 0.5 ) <NEWLINE> cv2 . subplot ( 222 ) <NEWLINE> cv2 . imshow ( imgbw ) <NEWLINE> imgbw = cv2 . im2bw ( imggray , 0.25 ) <NEWLINE> cv2 . subplot ( 223 ) <NEWLINE> cv2 . imshow ( imgbw ) <NEWLINE> level = cv2 . graythresh ( imggray ) <NEWLINE> imgbw = cv2 . im2bw ( imggray , level ) <NEWLINE> cv2 . subplot ( 224 ) <NEWLINE> cv2 . imshow ( imgbw ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''name:face.py'''", "'../../public/images/skew-linedetection.png'", "'1'"]}}], ["88f196d9354d7d6f4c4e68c5f4df6512", {"code_string": "import forwarding_protocol\nimport forwarding_buffer\nimport forwarding_buffer_composite\nimport functools\nimport collections\nimport copy\nimport random\n", "code_toks_joined": "import forwarding_protocol <NEWLINE> import forwarding_buffer <NEWLINE> import forwarding_buffer_composite <NEWLINE> import functools <NEWLINE> import collections <NEWLINE> import copy <NEWLINE> import random <NEWLINE>", "anonymize_dict": {}}], ["df38cb6f3158606fd631832579f76834", {"code_string": "def get_details(cand):\n    '''Obtains the candidate detailed description'''\n    headline = [cand.get('Profesi\u00f3n', ''),\n        cand.get('Edad', ''),\n        cand.get('Ciudad', ''), ]\n    headline = [el for el in headline if el != '']\n    return '<p>%s.</p> <p>%s</p>' %(\n        ', '.join(headline),\n        cand.get('Texto presentaci\u00f3n', '').replace('   ', '</p><p>').replace('.  ', '</p><p>'))\n", "code_toks_joined": "def get_details ( cand ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> headline = [ cand . get ( <STRING> , <STRING> ) , <NEWLINE> <INDENT> cand . get ( <STRING> , <STRING> ) , <NEWLINE> cand . get ( <STRING> , <STRING> ) , ] <NEWLINE> <DEDENT> headline = [ el for el in headline if el != <STRING> ] <NEWLINE> return <STRING> % ( <NEWLINE> <INDENT> <STRING> . join ( headline ) , <NEWLINE> cand . get ( <STRING> , <STRING> ) . replace ( <STRING> , <STRING> ) . replace ( <STRING> , <STRING> ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Obtains the candidate detailed description'''", "'Profesi\u00f3n'", "''", "'Edad'", "''", "'Ciudad'", "''", "''", "'<p>%s.</p> <p>%s</p>'", "', '", "'Texto presentaci\u00f3n'", "''", "'   '", "'</p><p>'", "'.  '", "'</p><p>'"]}}], ["605435fbbaf20f4e24d9373fc7d7c3ec", {"code_string": "def _end_planet_source(self):\n    self._end_source()\n    context = self._getContext()\n    if not context.has_key('sources'): context['sources'] = []\n    context.sources.append(context.source)\n    del context['source']\n", "code_toks_joined": "def _end_planet_source ( self ) : <NEWLINE> <INDENT> self . _end_source ( ) <NEWLINE> context = self . _getContext ( ) <NEWLINE> if not context . has_key ( <STRING> ) : context [ <STRING> ] = [ ] <NEWLINE> context . sources . append ( context . source ) <NEWLINE> del context [ <STRING> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'sources'", "'sources'", "'source'"]}}], ["39503f68e4a323bcfe7524d9765ac46e", {"code_string": "def upgrade():\n    op.add_column(\n        'cloud',\n        sa.Column('architecture', sa.String(length = 40), nullable = True))\n", "code_toks_joined": "def upgrade ( ) : <NEWLINE> <INDENT> op . add_column ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> sa . Column ( <STRING> , sa . String ( length = 40 ) , nullable = True ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'cloud'", "'architecture'"]}}], ["5542cdb9f81ef750110a0cf9e3cb4e7a", {"code_string": "\"\"\"WSGI config for project.\"\"\"\nimport os\nimport sys\nPATH = os.path.abspath(os.path.dirname(__file__))\nsys.path.insert(0, PATH)\nactivate_this = os.path.join(PATH, '.env/bin/activate_this.py')\nif os.path.exists(activate_this):\n    execfile(activate_this, dict(__file__ = activate_this))\nfrom app import app as application\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> import sys <NEWLINE> PATH = os . path . abspath ( os . path . dirname ( __file__ ) ) <NEWLINE> sys . path . insert ( 0 , PATH ) <NEWLINE> activate_this = os . path . join ( PATH , <STRING> ) <NEWLINE> if os . path . exists ( activate_this ) : <NEWLINE> <INDENT> execfile ( activate_this , dict ( __file__ = activate_this ) ) <NEWLINE> <DEDENT> from app import app as application <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"WSGI config for project.\"\"\"", "'.env/bin/activate_this.py'"]}}], ["66ee0a6e5741262b2b878525a46684e4", {"code_string": "def test_ndimiterator_yields_same_numpy_array():\n    from numpy import all, ndarray\n    from pylada.decorations._cutilities import NDimIterator\n    from itertools import product\n    previous = None\n    for expected in NDimIterator(2, 2, 3):\n        if previous is None:\n            previous = expected\n        assert isinstance(expected, ndarray)\n        assert expected.dtype == 'intc'\n        assert previous is expected\n", "code_toks_joined": "def test_ndimiterator_yields_same_numpy_array ( ) : <NEWLINE> <INDENT> from numpy import all , ndarray <NEWLINE> from pylada . decorations . _cutilities import NDimIterator <NEWLINE> from itertools import product <NEWLINE> previous = None <NEWLINE> for expected in NDimIterator ( 2 , 2 , 3 ) : <NEWLINE> <INDENT> if previous is None : <NEWLINE> <INDENT> previous = expected <NEWLINE> <DEDENT> assert isinstance ( expected , ndarray ) <NEWLINE> assert expected . dtype == <STRING> <NEWLINE> assert previous is expected <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'intc'"]}}], ["23a108323fea262001f2d26ba3da4029", {"code_string": "from opentrons_sdk.drivers import motor\n__all__ = [motor]\n", "code_toks_joined": "from opentrons_sdk . drivers import motor <NEWLINE> __all__ = [ motor ] <NEWLINE>", "anonymize_dict": {}}], ["9edebf98fcc612179a9261d3b0132dcf", {"code_string": "def generate_idl(self):\n    return{\n        'features': self._features,\n    }\n", "code_toks_joined": "def generate_idl ( self ) : <NEWLINE> <INDENT> return { <NEWLINE> <INDENT> <STRING> : self . _features , <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'features'"]}}], ["79df1dc02a607c22ec5d39f7c22055cc", {"code_string": "def test_summarize_alad_results():\n    datasets = get_test_datasets()\n    for dataset in datasets:\n        args = get_command_args(debug = False, debug_args = None)\n        configure_logger(args)\n        opts = Opts(args)\n        logger.debug(opts.str_opts())\n        set_seed(args.randseed)\n        summarize_alad_to_csv(opts = opts)\n        print(\"completed result summary %s for %s\" %(opts.detector_type_str(), opts.dataset, ))\n", "code_toks_joined": "def test_summarize_alad_results ( ) : <NEWLINE> <INDENT> datasets = get_test_datasets ( ) <NEWLINE> for dataset in datasets : <NEWLINE> <INDENT> args = get_command_args ( debug = False , debug_args = None ) <NEWLINE> configure_logger ( args ) <NEWLINE> opts = Opts ( args ) <NEWLINE> logger . debug ( opts . str_opts ( ) ) <NEWLINE> set_seed ( args . randseed ) <NEWLINE> summarize_alad_to_csv ( opts = opts ) <NEWLINE> print ( <STRING> % ( opts . detector_type_str ( ) , opts . dataset , ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"completed result summary %s for %s\""]}}], ["21dc7cf7407a45009ce66c9c404a8bcb", {"code_string": "def test_join_user_with_bogus_id(self):\n    try:\n        self._service.join('test.example.com', uuid.UUID(int = 99))\n    except MissingUserError as exc:\n        self.assertEqual(exc.user_id, uuid.UUID(int = 99))\n    else:\n        raise AssertionError('MissingUserError expected')\n", "code_toks_joined": "def test_join_user_with_bogus_id ( self ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> self . _service . join ( <STRING> , uuid . UUID ( int = 99 ) ) <NEWLINE> <DEDENT> except MissingUserError as exc : <NEWLINE> <INDENT> self . assertEqual ( exc . user_id , uuid . UUID ( int = 99 ) ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> raise AssertionError ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'test.example.com'", "'MissingUserError expected'"]}}], ["cb4d3d39d0ad7211f1ad25dd9bf51c02", {"code_string": "class ConstantSpectrumGenerator(SpectrumGenerator):\n    \"\"\"Generates a Spectrum whose data is a sequence of constant samples with the\"\"\"\n    def __init__(self, value = 1.0, resolution = None, length = None):\n        \"\"\"@param value: the constant float value of each sample\"\"\"\n        SpectrumGenerator.__init__(self, resolution = resolution, length = length)\n        self.__value = value\n    @ sumpf.Input(float, \"GetSpectrum\")\n    def SetValue(self, value):\n        \"\"\"Sets the constant value.\"\"\"\n        self.__value = value\n    def _GetSample(self, f):\n        \"\"\"Defines the value for each sample\"\"\"\n        return self.__value\n    def _GetLabel(self):\n        \"\"\"Defines the label.\"\"\"\n        return \"Constant\"\n", "code_toks_joined": "class ConstantSpectrumGenerator ( SpectrumGenerator ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , value = 1.0 , resolution = None , length = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> SpectrumGenerator . __init__ ( self , resolution = resolution , length = length ) <NEWLINE> self . __value = value <NEWLINE> <DEDENT> @ sumpf . Input ( float , <STRING> ) <NEWLINE> def SetValue ( self , value ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . __value = value <NEWLINE> <DEDENT> def _GetSample ( self , f ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . __value <NEWLINE> <DEDENT> def _GetLabel ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Generates a Spectrum whose data is a sequence of constant samples with the\"\"\"", "\"\"\"@param value: the constant float value of each sample\"\"\"", "\"GetSpectrum\"", "\"\"\"Sets the constant value.\"\"\"", "\"\"\"Defines the value for each sample\"\"\"", "\"\"\"Defines the label.\"\"\"", "\"Constant\""]}}], ["709909cedc495c41d9ec8f2f62bdc846", {"code_string": "\"\"\"HEPData Dashboard API.\"\"\"\nfrom collections import OrderedDict\nfrom flask.ext.login import current_user\nfrom invenio_accounts.models import User\nfrom sqlalchemy import and_, or_\nfrom hepdata.modules.permissions.models import SubmissionParticipant\nfrom hepdata.modules.records.utils.common import get_record_by_id, decode_string\nfrom hepdata.modules.submission.api import get_latest_hepsubmission\nfrom hepdata.modules.records.utils.users import has_role\nfrom hepdata.modules.submission.models import HEPSubmission, DataReview\nfrom hepdata.utils.users import get_user_from_id\n", "code_toks_joined": "<STRING> <NEWLINE> from collections import OrderedDict <NEWLINE> from flask . ext . login import current_user <NEWLINE> from invenio_accounts . models import User <NEWLINE> from sqlalchemy import and_ , or_ <NEWLINE> from hepdata . modules . permissions . models import SubmissionParticipant <NEWLINE> from hepdata . modules . records . utils . common import get_record_by_id , decode_string <NEWLINE> from hepdata . modules . submission . api import get_latest_hepsubmission <NEWLINE> from hepdata . modules . records . utils . users import has_role <NEWLINE> from hepdata . modules . submission . models import HEPSubmission , DataReview <NEWLINE> from hepdata . utils . users import get_user_from_id <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"HEPData Dashboard API.\"\"\""]}}], ["6f28a8eebacb74814c1c4f52488020c1", {"code_string": "from django.http import HttpResponse\nfrom django.core.urlresolvers import reverse\nfrom django.shortcuts import render_to_response\nimport pymongo\nconn = pymongo.Connection()\ndb = conn.debug_test\n", "code_toks_joined": "from django . http import HttpResponse <NEWLINE> from django . core . urlresolvers import reverse <NEWLINE> from django . shortcuts import render_to_response <NEWLINE> import pymongo <NEWLINE> conn = pymongo . Connection ( ) <NEWLINE> db = conn . debug_test <NEWLINE>", "anonymize_dict": {}}], ["58f1ff0b7e5bb340931a90842eb5f360", {"code_string": "def dump_counts(counts):\n    for k, v in enumerate(counts):\n        kmer = indexToKmer(k, K)\n        sv = ';'.join(['%s=%d' %(x, y) for x, y in v.iteritems()])\n        print('%s\\t%s' %(kmer, sv))\n", "code_toks_joined": "def dump_counts ( counts ) : <NEWLINE> <INDENT> for k , v in enumerate ( counts ) : <NEWLINE> <INDENT> kmer = indexToKmer ( k , K ) <NEWLINE> sv = <STRING> . join ( [ <STRING> % ( x , y ) for x , y in v . iteritems ( ) ] ) <NEWLINE> print ( <STRING> % ( kmer , sv ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["';'", "'%s=%d'", "'%s\\t%s'"]}}], ["e46b0afa8961aa02489b2ce066ca4be5", {"code_string": "import logging\nfrom dart.context.database import db\nfrom dart.model.orm import TriggerDao\nfrom dart.model.trigger import Trigger\nfrom dart.service.patcher import patch_difference\nfrom dart.tool.tool_runner import Tool\n_logger = logging.getLogger(__name__)\n", "code_toks_joined": "import logging <NEWLINE> from dart . context . database import db <NEWLINE> from dart . model . orm import TriggerDao <NEWLINE> from dart . model . trigger import Trigger <NEWLINE> from dart . service . patcher import patch_difference <NEWLINE> from dart . tool . tool_runner import Tool <NEWLINE> _logger = logging . getLogger ( __name__ ) <NEWLINE>", "anonymize_dict": {}}], ["2b42df7a2634c7260069d0333e88d6b5", {"code_string": "import urllib, urllib2, re, xbmcplugin, xbmcgui, sys, xbmcaddon, socket\nsocket.setdefaulttimeout(30)\npluginhandle = int(sys.argv[1])\naddon = xbmcaddon.Addon(id = 'plugin.video.sueddeutsche_de')\ntranslation = addon.getLocalizedString\nforceViewMode = addon.getSetting(\"forceViewMode\")\nif forceViewMode == \"true\":\n    forceViewMode = True\nelse:\n    forceViewMode = False\nviewMode = str(addon.getSetting(\"viewMode\"))\n", "code_toks_joined": "import urllib , urllib2 , re , xbmcplugin , xbmcgui , sys , xbmcaddon , socket <NEWLINE> socket . setdefaulttimeout ( 30 ) <NEWLINE> pluginhandle = int ( sys . argv [ 1 ] ) <NEWLINE> addon = xbmcaddon . Addon ( id = <STRING> ) <NEWLINE> translation = addon . getLocalizedString <NEWLINE> forceViewMode = addon . getSetting ( <STRING> ) <NEWLINE> if forceViewMode == <STRING> : <NEWLINE> <INDENT> forceViewMode = True <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> forceViewMode = False <NEWLINE> <DEDENT> viewMode = str ( addon . getSetting ( <STRING> ) ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'plugin.video.sueddeutsche_de'", "\"forceViewMode\"", "\"true\"", "\"viewMode\""]}}], ["c47f692f4d725e989f00d6bd64616d30", {"code_string": "from datetime import datetime\nfrom corpusbuilder import CorpusBuilder\nimport config\n", "code_toks_joined": "from datetime import datetime <NEWLINE> from corpusbuilder import CorpusBuilder <NEWLINE> import config <NEWLINE>", "anonymize_dict": {}}], ["ff09ce866a75d83238b7d0403ee0c7cb", {"code_string": "from pyglet.gl import *\nfrom pyglet import window, image\nimport shader\n__all__ = ['wired']\ntest_v = '''varying vec3 position;'''\ntest_f = '''uniform vec4 color;'''\n", "code_toks_joined": "from pyglet . gl import * <NEWLINE> from pyglet import window , image <NEWLINE> import shader <NEWLINE> __all__ = [ <STRING> ] <NEWLINE> test_v = <STRING> <NEWLINE> test_f = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'wired'", "'''varying vec3 position;'''", "'''uniform vec4 color;'''"]}}], ["f4cb1aa588e0d9fa15a89ebc2aa06a4a", {"code_string": "def capillary_volume(self):\n    '''Return the volume of the capillary'''\n    return self.capillary.capillary_volume()\n", "code_toks_joined": "def capillary_volume ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . capillary . capillary_volume ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Return the volume of the capillary'''"]}}], ["f71a0c2d733fe60164ebc59a0a1379fd", {"code_string": "def forwards(self, orm):\n    db.add_column(u'physical_plan', 'engine_equivalent_plan',\n        self.gf('django.db.models.fields.related.ForeignKey')(blank = True, related_name = u'backwards_plan', null = True, on_delete = models.SET_NULL, to = orm['physical.Plan']),\n        keep_default = False)\n", "code_toks_joined": "def forwards ( self , orm ) : <NEWLINE> <INDENT> db . add_column ( <STRING> , <STRING> , <NEWLINE> <INDENT> self . gf ( <STRING> ) ( blank = True , related_name = <STRING> , null = True , on_delete = models . SET_NULL , to = orm [ <STRING> ] ) , <NEWLINE> keep_default = False ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["u'physical_plan'", "'engine_equivalent_plan'", "'django.db.models.fields.related.ForeignKey'", "u'backwards_plan'", "'physical.Plan'"]}}], ["e01288497448d18775c457f1fabff227", {"code_string": "from django.shortcuts import render, render_to_response\nfrom django.views.generic import ListView\nfrom django.core.context_processors import request\nfrom django.http.response import HttpResponse\nfrom django.template import RequestContext\n", "code_toks_joined": "from django . shortcuts import render , render_to_response <NEWLINE> from django . views . generic import ListView <NEWLINE> from django . core . context_processors import request <NEWLINE> from django . http . response import HttpResponse <NEWLINE> from django . template import RequestContext <NEWLINE>", "anonymize_dict": {}}], ["6d694f608707f470ffbbb17303464b2b", {"code_string": "def _repo(self, config):\n    \"\"\"Private method that validates that the config is properly formed.\"\"\"\n    if not isinstance(config['yumrepomap'], list):\n        raise SystemError('`yumrepomap` must be a list!')\n", "code_toks_joined": "def _repo ( self , config ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if not isinstance ( config [ <STRING> ] , list ) : <NEWLINE> <INDENT> raise SystemError ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Private method that validates that the config is properly formed.\"\"\"", "'yumrepomap'", "'`yumrepomap` must be a list!'"]}}], ["3e0d2251e0c72c4fed7053fdf53d6e41", {"code_string": "\"\"\"Basic building blocks for generic class based views.\"\"\"\nfrom __future__ import unicode_literals\nfrom django.http import Http404\nfrom rest_framework import status\nfrom rest_framework.response import Response\nfrom rest_framework.request import clone_request\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import unicode_literals <NEWLINE> from django . http import Http404 <NEWLINE> from rest_framework import status <NEWLINE> from rest_framework . response import Response <NEWLINE> from rest_framework . request import clone_request <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Basic building blocks for generic class based views.\"\"\""]}}], ["cbb7e8c898737b5f76f8ee860807b4da", {"code_string": "def analyze_dell_status(arr, server, community, config):\n    st = arr[0][1]\n    if st != 3:\n        return oids.dell_status_standard[st], True\n    return oids.dell_status_standard[st], False\n", "code_toks_joined": "def analyze_dell_status ( arr , server , community , config ) : <NEWLINE> <INDENT> st = arr [ 0 ] [ 1 ] <NEWLINE> if st != 3 : <NEWLINE> <INDENT> return oids . dell_status_standard [ st ] , True <NEWLINE> <DEDENT> return oids . dell_status_standard [ st ] , False <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["4a11e49e4aeeba386c3d2d1cf50b296f", {"code_string": "def convertBlockquote(line):\n    line = re.sub(r'>(.*\\n.*)', r'<blockquote>\\1</blockquote>', line)\n    return line\n", "code_toks_joined": "def convertBlockquote ( line ) : <NEWLINE> <INDENT> line = re . sub ( <STRING> , <STRING> , line ) <NEWLINE> return line <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["r'>(.*\\n.*)'", "r'<blockquote>\\1</blockquote>'"]}}], ["3b265ce48ab1d189f7a5c24ee4199180", {"code_string": "def test_delete_vm(self):\n    tenant = fakes.tenants[\"foo\"]\n    app = self.get_app()\n    for s in fakes.servers[tenant[\"id\"]]:\n        req = self._build_req(\"/compute/%s\" % s[\"id\"],\n            tenant[\"id\"], method = \"DELETE\")\n        resp = req.get_response(app)\n        self.assertContentType(resp)\n        self.assertEqual(204, resp.status_code)\n", "code_toks_joined": "def test_delete_vm ( self ) : <NEWLINE> <INDENT> tenant = fakes . tenants [ <STRING> ] <NEWLINE> app = self . get_app ( ) <NEWLINE> for s in fakes . servers [ tenant [ <STRING> ] ] : <NEWLINE> <INDENT> req = self . _build_req ( <STRING> % s [ <STRING> ] , <NEWLINE> <INDENT> tenant [ <STRING> ] , method = <STRING> ) <NEWLINE> <DEDENT> resp = req . get_response ( app ) <NEWLINE> self . assertContentType ( resp ) <NEWLINE> self . assertEqual ( 204 , resp . status_code ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"foo\"", "\"id\"", "\"/compute/%s\"", "\"id\"", "\"id\"", "\"DELETE\""]}}], ["a19a7c1ade0f9353dcabf7e0a78db311", {"code_string": "from unittest import TestCase\nfrom unittest.mock import patch, call\nimport rancon\nfrom rancon.backends import consul\nfrom.test_data import TEST_SERVICES\n", "code_toks_joined": "from unittest import TestCase <NEWLINE> from unittest . mock import patch , call <NEWLINE> import rancon <NEWLINE> from rancon . backends import consul <NEWLINE> from . test_data import TEST_SERVICES <NEWLINE>", "anonymize_dict": {}}], ["ef3949926923fe5e00a03a8665d0635f", {"code_string": "import marzipan_io\nimport config\nimport cc\nimport pycurl\nms = open(\"magnetic_stripe\", \"r\").read().rstrip().lstrip(\"%\")\ncard = cc.parse_magstripe(ms)\n(xid, status) = marzipan_io.send_tnbci_request(0.01, card)\nprint(xid)\nprint(status)\n", "code_toks_joined": "import marzipan_io <NEWLINE> import config <NEWLINE> import cc <NEWLINE> import pycurl <NEWLINE> ms = open ( <STRING> , <STRING> ) . read ( ) . rstrip ( ) . lstrip ( <STRING> ) <NEWLINE> card = cc . parse_magstripe ( ms ) <NEWLINE> ( xid , status ) = marzipan_io . send_tnbci_request ( 0.01 , card ) <NEWLINE> print ( xid ) <NEWLINE> print ( status ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"magnetic_stripe\"", "\"r\"", "\"%\""]}}], ["cbc1987fe5aa72a8b9204bbeff3deaa5", {"code_string": "def test_create_nova_probe_external(self):\n    self._test_create_probe_external(\n        debug_agent.DEVICE_OWNER_COMPUTE_PROBE)\n", "code_toks_joined": "def test_create_nova_probe_external ( self ) : <NEWLINE> <INDENT> self . _test_create_probe_external ( <NEWLINE> <INDENT> debug_agent . DEVICE_OWNER_COMPUTE_PROBE ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["81a564803df1a2466f6e763e27baa136", {"code_string": "class Team(models.Model):\n    name = models.CharField('\u540d\u524d', default = '', max_length = 32)\n    def __str__(self):\n        return self.name\n", "code_toks_joined": "class Team ( models . Model ) : <NEWLINE> <INDENT> name = models . CharField ( <STRING> , default = <STRING> , max_length = 32 ) <NEWLINE> def __str__ ( self ) : <NEWLINE> <INDENT> return self . name <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'\u540d\u524d'", "''"]}}], ["80e25c1c76d311f4f74c2bee9b159567", {"code_string": "class build_py(_build_py):\n    \"\"\"Specialized source builder required to compile and update CUDA kernels.\"\"\"\n    def run(self):\n        sts = Popen(\"make kernels\", shell = True, cwd = this_dir).wait()\n        if sts != 0:\n            raise OSError(sts, 'Problems compiling kernels')\n        _build_py.run(self)\n", "code_toks_joined": "class build_py ( _build_py ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def run ( self ) : <NEWLINE> <INDENT> sts = Popen ( <STRING> , shell = True , cwd = this_dir ) . wait ( ) <NEWLINE> if sts != 0 : <NEWLINE> <INDENT> raise OSError ( sts , <STRING> ) <NEWLINE> <DEDENT> _build_py . run ( self ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Specialized source builder required to compile and update CUDA kernels.\"\"\"", "\"make kernels\"", "'Problems compiling kernels'"]}}], ["3de5ef261f578173a03fc7b2944e12f4", {"code_string": "import os\nimport sys\nimport math\nimport copy\nif sys.platform == \"cygwin\":\n    from cyglibra_core import *\nelif sys.platform == \"linux\" or sys.platform == \"linux2\":\n    from liblibra_core import *\nfrom libra_py import *\nfrom create_input_gms import *\nfrom create_input_qe import *\nfrom x_to_libra_gms import *\nfrom x_to_libra_qe import *\nfrom hamiltonian_vib import *\nimport print_results\nimport include_mm\n", "code_toks_joined": "import os <NEWLINE> import sys <NEWLINE> import math <NEWLINE> import copy <NEWLINE> if sys . platform == <STRING> : <NEWLINE> <INDENT> from cyglibra_core import * <NEWLINE> <DEDENT> elif sys . platform == <STRING> or sys . platform == <STRING> : <NEWLINE> <INDENT> from liblibra_core import * <NEWLINE> <DEDENT> from libra_py import * <NEWLINE> from create_input_gms import * <NEWLINE> from create_input_qe import * <NEWLINE> from x_to_libra_gms import * <NEWLINE> from x_to_libra_qe import * <NEWLINE> from hamiltonian_vib import * <NEWLINE> import print_results <NEWLINE> import include_mm <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"cygwin\"", "\"linux\"", "\"linux2\""]}}], ["f1df6773933d21374bd01d76ee4a46ff", {"code_string": "from brewmachine import *\nimport json\nstate_list = [Maischen, Beta, Alpha, Leutern, Kochen, Kochen]\nstate_list.reverse()\nio = open(\"recipe.json\").read()\nrezept = json.loads(io)\nfoo = BrewMachine(state_list, rezept)\nfor _ in range(0, len(state_list) - 1):\n    foo.next()\n    print(foo.run())\n", "code_toks_joined": "from brewmachine import * <NEWLINE> import json <NEWLINE> state_list = [ Maischen , Beta , Alpha , Leutern , Kochen , Kochen ] <NEWLINE> state_list . reverse ( ) <NEWLINE> io = open ( <STRING> ) . read ( ) <NEWLINE> rezept = json . loads ( io ) <NEWLINE> foo = BrewMachine ( state_list , rezept ) <NEWLINE> for _ in range ( 0 , len ( state_list ) - 1 ) : <NEWLINE> <INDENT> foo . next ( ) <NEWLINE> print ( foo . run ( ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"recipe.json\""]}}], ["a72808c6ee02a9f24f25dcc9500c47af", {"code_string": "import discord\nfrom bot import i18n\nfrom bot.commands.command import Command\nimport random\n", "code_toks_joined": "import discord <NEWLINE> from bot import i18n <NEWLINE> from bot . commands . command import Command <NEWLINE> import random <NEWLINE>", "anonymize_dict": {}}], ["16cf2aff1202cc064c390c187a263926", {"code_string": "from setuptools import setup, find_packages\nsetup(\n    name = 'verge-python',\n    version = '0.1.3',\n    description = 'Friendly VERGE JSON-RPC API binding for Python',\n    long_description = 'This package allows performing commands such as listing the current balance'\n    ' and sending coins to the original client from Python. The communication with the'\n    ' client happens over JSON-RPC.',\n    url = 'https://github.com/vergecurrency/verge-python',\n    classifiers = [\n        'Development Status :: 4 - Beta',\n        'Environment :: Console',\n        'Environment :: Web Environment',\n        'Intended Audience :: Developers',\n        'Programming Language :: Python',\n        'License :: OSI Approved :: MIT License',\n        'Topic :: Office/Business :: Financial'\n    ],\n    packages = find_packages(\"src\"),\n    package_dir = {'': 'src'}\n)\n", "code_toks_joined": "from setuptools import setup , find_packages <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> long_description = <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> , <NEWLINE> url = <STRING> , <NEWLINE> classifiers = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> <NEWLINE> <DEDENT> ] , <NEWLINE> packages = find_packages ( <STRING> ) , <NEWLINE> package_dir = { <STRING> : <STRING> } <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'verge-python'", "'0.1.3'", "'Friendly VERGE JSON-RPC API binding for Python'", "'This package allows performing commands such as listing the current balance'", "' and sending coins to the original client from Python. The communication with the'", "' client happens over JSON-RPC.'", "'https://github.com/vergecurrency/verge-python'", "'Development Status :: 4 - Beta'", "'Environment :: Console'", "'Environment :: Web Environment'", "'Intended Audience :: Developers'", "'Programming Language :: Python'", "'License :: OSI Approved :: MIT License'", "'Topic :: Office/Business :: Financial'", "\"src\"", "''", "'src'"]}}], ["8556e078742f2b0bf05caba27157e011", {"code_string": "def make_text(s):\n    if s.startswith('\\n'):\n        s = s[1: ]\n    return textwrap.dedent(s)\n", "code_toks_joined": "def make_text ( s ) : <NEWLINE> <INDENT> if s . startswith ( <STRING> ) : <NEWLINE> <INDENT> s = s [ 1 : ] <NEWLINE> <DEDENT> return textwrap . dedent ( s ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'\\n'"]}}], ["b53d27376b43b8f4ac0e7934ce50bfd0", {"code_string": "def main():\n    optlist, infiles = getopt.gnu_getopt(sys.argv[1: ], '')\n    if not infiles:\n        print('No input file.')\n        return\n    InFileName = infiles[0]\n    err = open(InFileName, 'rb').read()\n    err = re.sub('\\r', '', err)\n    out_err = handle_err(err)\n    print(out_err)\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> optlist , infiles = getopt . gnu_getopt ( sys . argv [ 1 : ] , <STRING> ) <NEWLINE> if not infiles : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> return <NEWLINE> <DEDENT> InFileName = infiles [ 0 ] <NEWLINE> err = open ( InFileName , <STRING> ) . read ( ) <NEWLINE> err = re . sub ( <STRING> , <STRING> , err ) <NEWLINE> out_err = handle_err ( err ) <NEWLINE> print ( out_err ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["''", "'No input file.'", "'rb'", "'\\r'", "''"]}}], ["8acfd158d7ee8f30321184deaaf9fa60", {"code_string": "def main():\n    \"\"\"Create a drmaa session and exit\"\"\"\n    s = drmaa.Session()\n    s.initialize()\n    print('A session was started successfully')\n    s.exit()\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> s = drmaa . Session ( ) <NEWLINE> s . initialize ( ) <NEWLINE> print ( <STRING> ) <NEWLINE> s . exit ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Create a drmaa session and exit\"\"\"", "'A session was started successfully'"]}}], ["66e2b33b7afb64cdfae59ce013c1a1b9", {"code_string": "def decimal_dec(hdu_str):\n    val_list = [float(n) for n in hdu_str.split(':')]\n    if str(val_list[0])[0] == '-':\n        sng = - 1\n        val_list[0] = sng * val_list[0]\n    else:\n        sng = 1\n    val_deci = sng *(val_list[0] +((val_list[1] +(val_list[2] / 60.0)) / 60.0))\n    return val_deci\n", "code_toks_joined": "def decimal_dec ( hdu_str ) : <NEWLINE> <INDENT> val_list = [ float ( n ) for n in hdu_str . split ( <STRING> ) ] <NEWLINE> if str ( val_list [ 0 ] ) [ 0 ] == <STRING> : <NEWLINE> <INDENT> sng = - 1 <NEWLINE> val_list [ 0 ] = sng * val_list [ 0 ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> sng = 1 <NEWLINE> <DEDENT> val_deci = sng * ( val_list [ 0 ] + ( ( val_list [ 1 ] + ( val_list [ 2 ] / 60.0 ) ) / 60.0 ) ) <NEWLINE> return val_deci <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["':'", "'-'"]}}], ["ecdd3b5c4e2524f9e431ae8584276827", {"code_string": "def match_pattern(dna, pattern):\n    dna = dna.upper()\n    pattern = pattern.upper()\n    locations = []\n    for index in range(len(dna) - len(pattern) + 1):\n        s = dna[index: index + len(pattern)]\n        if s == pattern:\n            locations.append(str(index))\n    return locations\n", "code_toks_joined": "def match_pattern ( dna , pattern ) : <NEWLINE> <INDENT> dna = dna . upper ( ) <NEWLINE> pattern = pattern . upper ( ) <NEWLINE> locations = [ ] <NEWLINE> for index in range ( len ( dna ) - len ( pattern ) + 1 ) : <NEWLINE> <INDENT> s = dna [ index : index + len ( pattern ) ] <NEWLINE> if s == pattern : <NEWLINE> <INDENT> locations . append ( str ( index ) ) <NEWLINE> <DEDENT> <DEDENT> return locations <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["27035f6bcadcad4299d99dd3327b8622", {"code_string": "import json\nfrom.import basetests\nfrom spark_app import app\n", "code_toks_joined": "import json <NEWLINE> from . import basetests <NEWLINE> from spark_app import app <NEWLINE>", "anonymize_dict": {}}], ["edc3441c38430ceacc604429445f8182", {"code_string": "class event(plugin):\n    def __init__(self):\n        self.observers = []\n    def register_observer(self, func):\n        self.observers.append(func)\n    def print_observers(self):\n        for observer in self.observers:\n            print(observer)\n", "code_toks_joined": "class event ( plugin ) : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> self . observers = [ ] <NEWLINE> <DEDENT> def register_observer ( self , func ) : <NEWLINE> <INDENT> self . observers . append ( func ) <NEWLINE> <DEDENT> def print_observers ( self ) : <NEWLINE> <INDENT> for observer in self . observers : <NEWLINE> <INDENT> print ( observer ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["18103f5c91653596c523ff16b244a385", {"code_string": "def activate_user(self, activation_key):\n    \"\"\"Validate an activation key and activate the corresponding\"\"\"\n    if SHA1_RE.search(activation_key):\n        try:\n            profile = self.get(activation_key = activation_key)\n        except self.model.DoesNotExist:\n            return False\n        if not profile.activation_key_expired():\n            user = profile.user\n            user.is_active = True\n            user.save()\n            profile.activation_key = self.model.ACTIVATED\n            profile.save()\n            return user\n    return False\n", "code_toks_joined": "def activate_user ( self , activation_key ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if SHA1_RE . search ( activation_key ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> profile = self . get ( activation_key = activation_key ) <NEWLINE> <DEDENT> except self . model . DoesNotExist : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> if not profile . activation_key_expired ( ) : <NEWLINE> <INDENT> user = profile . user <NEWLINE> user . is_active = True <NEWLINE> user . save ( ) <NEWLINE> profile . activation_key = self . model . ACTIVATED <NEWLINE> profile . save ( ) <NEWLINE> return user <NEWLINE> <DEDENT> <DEDENT> return False <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Validate an activation key and activate the corresponding\"\"\""]}}], ["78b050e2825b0544dbb85c579a0f1e9a", {"code_string": "class SxxExxKennung(object):\n    PATTERN = re.compile(r'S(\\d{1,2})E(\\d{1,2})')\n    @ classmethod\n    def parse(cls, title):\n        target = cls.PATTERN.findall(_normalize(title))\n        if target:\n            return \"S%02dE%02d\" %(int(target[0][0]), int(target[0][1]))\n        return None\n", "code_toks_joined": "class SxxExxKennung ( object ) : <NEWLINE> <INDENT> PATTERN = re . compile ( <STRING> ) <NEWLINE> @ classmethod <NEWLINE> def parse ( cls , title ) : <NEWLINE> <INDENT> target = cls . PATTERN . findall ( _normalize ( title ) ) <NEWLINE> if target : <NEWLINE> <INDENT> return <STRING> % ( int ( target [ 0 ] [ 0 ] ) , int ( target [ 0 ] [ 1 ] ) ) <NEWLINE> <DEDENT> return None <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["r'S(\\d{1,2})E(\\d{1,2})'", "\"S%02dE%02d\""]}}], ["2a6a8633f0f38279e38db28f356db85a", {"code_string": "def convertKeyframePlan(self, keyframeMsg):\n    msg = lcmdrc.robot_plan_t()\n    msg.utime = keyframeMsg.utime\n    msg.robot_name = keyframeMsg.robot_name\n    msg.num_states = keyframeMsg.num_states\n    msg.plan = keyframeMsg.plan\n    msg.plan_info = keyframeMsg.plan_info\n    msg.num_bytes = keyframeMsg.num_bytes\n    msg.matlab_data = keyframeMsg.matlab_data\n    msg.num_grasp_transitions = keyframeMsg.num_grasp_transitions\n    msg.left_arm_control_type = msg.NONE\n    msg.right_arm_control_type = msg.NONE\n    msg.left_leg_control_type = msg.NONE\n    msg.right_leg_control_type = msg.NONE\n    return msg\n", "code_toks_joined": "def convertKeyframePlan ( self , keyframeMsg ) : <NEWLINE> <INDENT> msg = lcmdrc . robot_plan_t ( ) <NEWLINE> msg . utime = keyframeMsg . utime <NEWLINE> msg . robot_name = keyframeMsg . robot_name <NEWLINE> msg . num_states = keyframeMsg . num_states <NEWLINE> msg . plan = keyframeMsg . plan <NEWLINE> msg . plan_info = keyframeMsg . plan_info <NEWLINE> msg . num_bytes = keyframeMsg . num_bytes <NEWLINE> msg . matlab_data = keyframeMsg . matlab_data <NEWLINE> msg . num_grasp_transitions = keyframeMsg . num_grasp_transitions <NEWLINE> msg . left_arm_control_type = msg . NONE <NEWLINE> msg . right_arm_control_type = msg . NONE <NEWLINE> msg . left_leg_control_type = msg . NONE <NEWLINE> msg . right_leg_control_type = msg . NONE <NEWLINE> return msg <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["78ea86656319839ce662ef30fbbe0f1a", {"code_string": "def get_matching_options(self, obs, a):\n    '''return indices of options that  select a given phi'''\n    mask = np.array([(o.can_init(obs) and o.pi(obs) == a) for o in self.options])\n    return np.arange(self.n_options)[mask]\n", "code_toks_joined": "def get_matching_options ( self , obs , a ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> mask = np . array ( [ ( o . can_init ( obs ) and o . pi ( obs ) == a ) for o in self . options ] ) <NEWLINE> return np . arange ( self . n_options ) [ mask ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''return indices of options that  select a given phi'''"]}}], ["f36c5853775b01d28175d2ae826281e1", {"code_string": "class EnhancedThreadedCommentFlag(models.Model, Auditable):\n    comment = models.ForeignKey(EnhancedThreadedComment)\n    user = models.ForeignKey(settings.AUTH_USER_MODEL)\n    flagged_at = models.DateTimeField(auto_now_add = True)\n    hidden = models.BooleanField(default = False)\n    class Meta:\n        app_label = 'otm_comments'\n", "code_toks_joined": "class EnhancedThreadedCommentFlag ( models . Model , Auditable ) : <NEWLINE> <INDENT> comment = models . ForeignKey ( EnhancedThreadedComment ) <NEWLINE> user = models . ForeignKey ( settings . AUTH_USER_MODEL ) <NEWLINE> flagged_at = models . DateTimeField ( auto_now_add = True ) <NEWLINE> hidden = models . BooleanField ( default = False ) <NEWLINE> class Meta : <NEWLINE> <INDENT> app_label = <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'otm_comments'"]}}], ["fb259ae5c5381f91f35e49736ab60cdd", {"code_string": "from django.conf.urls import url\nfrom subprocuraduria.views import CreateSubprocuraduriaView, CreateDireccionView, SubprocuraduriaListView, DireccionListView, EditSubprocuraduriaView\nurlpatterns = [\n    url(r'crear-subprocuraduria/$', CreateSubprocuraduriaView.as_view(), name = 'crear_subprocuraduria'),\n    url(r'editar-subprocuraduria/(?P<pk>[0-9]+)/$', EditSubprocuraduriaView.as_view(), name = 'editar_subprocuraduria'),\n    url(r'listado-subprocuradurias/$', SubprocuraduriaListView.as_view(), name = 'listado_subprocuradurias'),\n    url(r'crear-direccion/$', CreateDireccionView.as_view(), name = 'crear_direccion'),\n    url(r'listado-direcciones/$', DireccionListView.as_view(), name = 'listado_direcciones'),\n]\n", "code_toks_joined": "from django . conf . urls import url <NEWLINE> from subprocuraduria . views import CreateSubprocuraduriaView , CreateDireccionView , SubprocuraduriaListView , DireccionListView , EditSubprocuraduriaView <NEWLINE> urlpatterns = [ <NEWLINE> <INDENT> url ( <STRING> , CreateSubprocuraduriaView . as_view ( ) , name = <STRING> ) , <NEWLINE> url ( <STRING> , EditSubprocuraduriaView . as_view ( ) , name = <STRING> ) , <NEWLINE> url ( <STRING> , SubprocuraduriaListView . as_view ( ) , name = <STRING> ) , <NEWLINE> url ( <STRING> , CreateDireccionView . as_view ( ) , name = <STRING> ) , <NEWLINE> url ( <STRING> , DireccionListView . as_view ( ) , name = <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["r'crear-subprocuraduria/$'", "'crear_subprocuraduria'", "r'editar-subprocuraduria/(?P<pk>[0-9]+)/$'", "'editar_subprocuraduria'", "r'listado-subprocuradurias/$'", "'listado_subprocuradurias'", "r'crear-direccion/$'", "'crear_direccion'", "r'listado-direcciones/$'", "'listado_direcciones'"]}}], ["822a9cae7c37d1821520f38db542c488", {"code_string": "def test_prepare_rollout(self):\n    expected_logs = \"Preparing rollout for bug 50000.\\nUpdating working directory\\n\"\n    self.assert_execute_outputs(PrepareRollout(), [852, \"Reason\"], options = self._default_options(), expected_logs = expected_logs)\n", "code_toks_joined": "def test_prepare_rollout ( self ) : <NEWLINE> <INDENT> expected_logs = <STRING> <NEWLINE> self . assert_execute_outputs ( PrepareRollout ( ) , [ 852 , <STRING> ] , options = self . _default_options ( ) , expected_logs = expected_logs ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Preparing rollout for bug 50000.\\nUpdating working directory\\n\"", "\"Reason\""]}}], ["e2eaa842d7d6ab682d72d9e3c34c9319", {"code_string": "def render(filename, UserContext = {}, path = CConf['path']['template']):\n    context.update(UserContext)\n    from os.path import join, dirname\n    if filename.startswith('CumulusBuiltins/'):\n        filename = filename.replace('CumulusBuiltins/', '', 1)\n        path = join(dirname(__file__), 'builtins', 'template')\n    from jinja2 import Environment, FileSystemLoader\n    env = Environment(loader = FileSystemLoader(path))\n    return env.get_template(filename).render(context)\n", "code_toks_joined": "def render ( filename , UserContext = { } , path = CConf [ <STRING> ] [ <STRING> ] ) : <NEWLINE> <INDENT> context . update ( UserContext ) <NEWLINE> from os . path import join , dirname <NEWLINE> if filename . startswith ( <STRING> ) : <NEWLINE> <INDENT> filename = filename . replace ( <STRING> , <STRING> , 1 ) <NEWLINE> path = join ( dirname ( __file__ ) , <STRING> , <STRING> ) <NEWLINE> <DEDENT> from jinja2 import Environment , FileSystemLoader <NEWLINE> env = Environment ( loader = FileSystemLoader ( path ) ) <NEWLINE> return env . get_template ( filename ) . render ( context ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'path'", "'template'", "'CumulusBuiltins/'", "'CumulusBuiltins/'", "''", "'builtins'", "'template'"]}}], ["6c72a8b8e270f8efb625c0d386034022", {"code_string": "def _setup_helpers(self):\n    \"\"\"Initializes protocol-specific NAS drivers.\"\"\"\n    self._helpers = {}\n    for helper_str in self.configuration.lvm_share_helpers:\n        share_proto, _, import_str = helper_str.partition('=')\n        helper = importutils.import_class(import_str)\n        self._helpers[share_proto.upper()] = helper(\n            self._execute, self._ssh_exec_as_root, self.configuration)\n", "code_toks_joined": "def _setup_helpers ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . _helpers = { } <NEWLINE> for helper_str in self . configuration . lvm_share_helpers : <NEWLINE> <INDENT> share_proto , _ , import_str = helper_str . partition ( <STRING> ) <NEWLINE> helper = importutils . import_class ( import_str ) <NEWLINE> self . _helpers [ share_proto . upper ( ) ] = helper ( <NEWLINE> <INDENT> self . _execute , self . _ssh_exec_as_root , self . configuration ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Initializes protocol-specific NAS drivers.\"\"\"", "'='"]}}], ["fcc878a3dba2490df1128b9e88200f71", {"code_string": "import pkg_resources\nfrom disq.client import DisqueAlpha\nfrom redis.exceptions import(\n    ConnectionError,\n    RedisError,\n    ResponseError,\n    TimeoutError,\n)\nDisque = DisqueAlpha\n__all__ = ['DisqueAlpha',\n    'Disque',\n    'ConnectionError',\n    'RedisError',\n    'ResponseError',\n    'TimeoutError',\n    ]\n__version__ = pkg_resources.get_distribution('disq').version\n", "code_toks_joined": "import pkg_resources <NEWLINE> from disq . client import DisqueAlpha <NEWLINE> from redis . exceptions import ( <NEWLINE> <INDENT> ConnectionError , <NEWLINE> RedisError , <NEWLINE> ResponseError , <NEWLINE> TimeoutError , <NEWLINE> <DEDENT> ) <NEWLINE> Disque = DisqueAlpha <NEWLINE> __all__ = [ <STRING> , <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> ] <NEWLINE> <DEDENT> __version__ = pkg_resources . get_distribution ( <STRING> ) . version <NEWLINE>", "anonymize_dict": {"<STRING>": ["'DisqueAlpha'", "'Disque'", "'ConnectionError'", "'RedisError'", "'ResponseError'", "'TimeoutError'", "'disq'"]}}], ["69ea6fc95a28797f210160c52288f836", {"code_string": "class OAuthRequestToken(models.Model):\n    \"\"\"OAuth Request Token.\"\"\"\n    session_key = models.CharField(max_length = 250)\n    ft_token = models.CharField(max_length = 250)\n    ft_token_secret = models.CharField(max_length = 250)\n    created = models.DateTimeField(auto_now_add = True)\n    def is_complete(self):\n        if self.ft_token and self.md_token:\n            return True\n", "code_toks_joined": "class OAuthRequestToken ( models . Model ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> session_key = models . CharField ( max_length = 250 ) <NEWLINE> ft_token = models . CharField ( max_length = 250 ) <NEWLINE> ft_token_secret = models . CharField ( max_length = 250 ) <NEWLINE> created = models . DateTimeField ( auto_now_add = True ) <NEWLINE> def is_complete ( self ) : <NEWLINE> <INDENT> if self . ft_token and self . md_token : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"OAuth Request Token.\"\"\""]}}], ["3f14564524c60b8594780b022e67bcca", {"code_string": "def add_arguments(self):\n    self.argparser.add_argument('-n', '--names', dest = 'names_only', action = 'store_true',\n        help = 'Display column names and indices from the input CSV and exit.')\n    self.argparser.add_argument('-c', '--columns', dest = 'columns',\n        help = 'A comma separated list of column indices or names to be extracted. Defaults to all columns.')\n    self.argparser.add_argument('-C', '--not-columns', dest = 'not_columns',\n        help = 'A comma separated list of column indices or names to be excluded. Defaults to no columns.')\n    self.argparser.add_argument('-x', '--delete-empty-rows', dest = 'delete_empty', action = 'store_true',\n        help = 'After cutting, delete rows which are completely empty.')\n    ColumnSelectorMixin.add_arguments(self)\n", "code_toks_joined": "def add_arguments ( self ) : <NEWLINE> <INDENT> self . argparser . add_argument ( <STRING> , <STRING> , dest = <STRING> , action = <STRING> , <NEWLINE> <INDENT> help = <STRING> ) <NEWLINE> <DEDENT> self . argparser . add_argument ( <STRING> , <STRING> , dest = <STRING> , <NEWLINE> <INDENT> help = <STRING> ) <NEWLINE> <DEDENT> self . argparser . add_argument ( <STRING> , <STRING> , dest = <STRING> , <NEWLINE> <INDENT> help = <STRING> ) <NEWLINE> <DEDENT> self . argparser . add_argument ( <STRING> , <STRING> , dest = <STRING> , action = <STRING> , <NEWLINE> <INDENT> help = <STRING> ) <NEWLINE> <DEDENT> ColumnSelectorMixin . add_arguments ( self ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'-n'", "'--names'", "'names_only'", "'store_true'", "'Display column names and indices from the input CSV and exit.'", "'-c'", "'--columns'", "'columns'", "'A comma separated list of column indices or names to be extracted. Defaults to all columns.'", "'-C'", "'--not-columns'", "'not_columns'", "'A comma separated list of column indices or names to be excluded. Defaults to no columns.'", "'-x'", "'--delete-empty-rows'", "'delete_empty'", "'store_true'", "'After cutting, delete rows which are completely empty.'"]}}], ["252163e15333b85bb5f9d3c81b6f3793", {"code_string": "def third_party_tracking_ids(request):\n    \"\"\"Retrieve 3rd-party tracking IDs from the settings file and add them to the\"\"\"\n    return{\n        'google_analytics_tracking_id': settings.GOOGLE_ANALYTICS_TRACKING_ID,\n        'addthis_publisher_id': settings.ADDTHIS_PUBLISHER_ID,\n    }\n", "code_toks_joined": "def third_party_tracking_ids ( request ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return { <NEWLINE> <INDENT> <STRING> : settings . GOOGLE_ANALYTICS_TRACKING_ID , <NEWLINE> <STRING> : settings . ADDTHIS_PUBLISHER_ID , <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Retrieve 3rd-party tracking IDs from the settings file and add them to the\"\"\"", "'google_analytics_tracking_id'", "'addthis_publisher_id'"]}}], ["6f2d3f5324225c3e6498185e90d86e6d", {"code_string": "\"\"\"Server URL Configuration\"\"\"\nfrom django.conf.urls import include, url\nfrom django.contrib import admin\nimport settings\nfrom django.conf.urls.static import static\nurlpatterns = [\n    url(r'^admin/', include(admin.site.urls)),\n    url(r'^media/(?P<path>.*)$', 'django.views.static.serve', {\n        'document_root': settings.MEDIA_ROOT,\n        }),\n    url(r'', include('layouts.urls'))\n] + static(settings.MEDIA_URL, document_root = settings.MEDIA_ROOT)\n", "code_toks_joined": "<STRING> <NEWLINE> from django . conf . urls import include , url <NEWLINE> from django . contrib import admin <NEWLINE> import settings <NEWLINE> from django . conf . urls . static import static <NEWLINE> urlpatterns = [ <NEWLINE> <INDENT> url ( <STRING> , include ( admin . site . urls ) ) , <NEWLINE> url ( <STRING> , <STRING> , { <NEWLINE> <INDENT> <STRING> : settings . MEDIA_ROOT , <NEWLINE> } ) , <NEWLINE> <DEDENT> url ( <STRING> , include ( <STRING> ) ) <NEWLINE> <DEDENT> ] + static ( settings . MEDIA_URL , document_root = settings . MEDIA_ROOT ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Server URL Configuration\"\"\"", "r'^admin/'", "r'^media/(?P<path>.*)$'", "'django.views.static.serve'", "'document_root'", "r''", "'layouts.urls'"]}}], ["41a1df73e0379a877067f2b3cb933e58", {"code_string": "def test_sync_image_failed(self):\n    def f():\n        mv = VNXMirrorView.get(t_cli(), 'mv0')\n        mv.sync_image()\n    assert_that(f, raises(VNXMirrorSyncImageError, 'failed'))\n", "code_toks_joined": "def test_sync_image_failed ( self ) : <NEWLINE> <INDENT> def f ( ) : <NEWLINE> <INDENT> mv = VNXMirrorView . get ( t_cli ( ) , <STRING> ) <NEWLINE> mv . sync_image ( ) <NEWLINE> <DEDENT> assert_that ( f , raises ( VNXMirrorSyncImageError , <STRING> ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'mv0'", "'failed'"]}}], ["cb3873e6d9ed9e1afb2e3f4200031eab", {"code_string": "def OnSliderScroll(self, event):\n    obj = event.GetEventObject()\n    val = obj.GetValue()\n    self.val = float(val) / 100\n    Publisher().sendMessage((\"layers.channel\"), (self.val, self.id))\n", "code_toks_joined": "def OnSliderScroll ( self , event ) : <NEWLINE> <INDENT> obj = event . GetEventObject ( ) <NEWLINE> val = obj . GetValue ( ) <NEWLINE> self . val = float ( val ) / 100 <NEWLINE> Publisher ( ) . sendMessage ( ( <STRING> ) , ( self . val , self . id ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"layers.channel\""]}}], ["608d55bec74f76372fcf86365ba2dc7a", {"code_string": "import urllib2\nimport os\nimport datetime\nfrom targetexplorer.flaskapp import models, db\nimport pandas as pd\n", "code_toks_joined": "import urllib2 <NEWLINE> import os <NEWLINE> import datetime <NEWLINE> from targetexplorer . flaskapp import models , db <NEWLINE> import pandas as pd <NEWLINE>", "anonymize_dict": {}}], ["74e25e40cbf2a1ecc9718e4896c5d4b1", {"code_string": "def test_execute(self, mock_exec_file, mock_get_files_in_dir):\n    mock_service = mock.MagicMock()\n    fake_path = os.path.join('fake', 'path')\n    mock_get_files_in_dir.return_value = [fake_path]\n    response = self._localscripts.execute(mock_service, shared_data = None)\n    mock_get_files_in_dir.assert_called_once_with(\n        mock.sentinel.mock_local_scripts_path)\n    mock_exec_file.assert_called_once_with(fake_path)\n    self.assertEqual((base.PLUGIN_EXECUTION_DONE, False), response)\n", "code_toks_joined": "def test_execute ( self , mock_exec_file , mock_get_files_in_dir ) : <NEWLINE> <INDENT> mock_service = mock . MagicMock ( ) <NEWLINE> fake_path = os . path . join ( <STRING> , <STRING> ) <NEWLINE> mock_get_files_in_dir . return_value = [ fake_path ] <NEWLINE> response = self . _localscripts . execute ( mock_service , shared_data = None ) <NEWLINE> mock_get_files_in_dir . assert_called_once_with ( <NEWLINE> <INDENT> mock . sentinel . mock_local_scripts_path ) <NEWLINE> <DEDENT> mock_exec_file . assert_called_once_with ( fake_path ) <NEWLINE> self . assertEqual ( ( base . PLUGIN_EXECUTION_DONE , False ) , response ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'fake'", "'path'"]}}], ["1941ef637b43ebb42e94feb3f0fd3eb1", {"code_string": "def test_None_count(self):\n    nacolcount = self._test_dc.nacolcount()\n    self.assertEqual(nacolcount.loc['None_100', 'Napercentage'], 0.1)\n    self.assertEqual(nacolcount.loc['None_100', 'Nanumber'], 100)\n    self.assertEqual(nacolcount.loc['None_na_200', 'Napercentage'], 0.2)\n    self.assertEqual(nacolcount.loc['None_na_200', 'Nanumber'], 200)\n", "code_toks_joined": "def test_None_count ( self ) : <NEWLINE> <INDENT> nacolcount = self . _test_dc . nacolcount ( ) <NEWLINE> self . assertEqual ( nacolcount . loc [ <STRING> , <STRING> ] , 0.1 ) <NEWLINE> self . assertEqual ( nacolcount . loc [ <STRING> , <STRING> ] , 100 ) <NEWLINE> self . assertEqual ( nacolcount . loc [ <STRING> , <STRING> ] , 0.2 ) <NEWLINE> self . assertEqual ( nacolcount . loc [ <STRING> , <STRING> ] , 200 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'None_100'", "'Napercentage'", "'None_100'", "'Nanumber'", "'None_na_200'", "'Napercentage'", "'None_na_200'", "'Nanumber'"]}}], ["7663c09ad2e2cabde1b92c99578c5c20", {"code_string": "import random\na = random.randint(1, 2)\nif a == 1:\n    w = \"\u0421\u0435\u0440\u0433\u0435\u0439 \u0411\u0440\u0438\u043d\"\nelif a == 2:\n    w = \"\u041b\u0430\u0440\u0440\u0438 \u041f\u0435\u0439\u0434\u0436\"\nprint(\"\u041e\u0441\u043d\u043e\u0432\u0430\u0442\u0435\u043b\u044c \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 Google: \")\notvet = input(\"\\n\u0412\u0432\u0435\u0434\u0438\u0442\u0435 \u0438\u043c\u044f: \")\nwhile(otvet != w):\n    print(\"\\n\u041d\u0435\u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e. \u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0439 \u0435\u0449\u0435 \u0440\u0430\u0437\")\n    otvet = input(\"\\n\u0412\u0432\u0435\u0434\u0438\u0442\u0435 \u0438\u043c\u044f: \")\nprint(\"\u041f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e!\", w, \"!\")\ninput(\"\u041d\u0430\u0436\u043c\u0438\u0442\u0435 ENTER \u0434\u043b\u044f \u043f\u0440\u043e\u0434\u043e\u043b\u0436\u0435\u043d\u0438\u044f\")\n", "code_toks_joined": "import random <NEWLINE> a = random . randint ( 1 , 2 ) <NEWLINE> if a == 1 : <NEWLINE> <INDENT> w = <STRING> <NEWLINE> <DEDENT> elif a == 2 : <NEWLINE> <INDENT> w = <STRING> <NEWLINE> <DEDENT> print ( <STRING> ) <NEWLINE> otvet = input ( <STRING> ) <NEWLINE> while ( otvet != w ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> otvet = input ( <STRING> ) <NEWLINE> <DEDENT> print ( <STRING> , w , <STRING> ) <NEWLINE> input ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\u0421\u0435\u0440\u0433\u0435\u0439 \u0411\u0440\u0438\u043d\"", "\"\u041b\u0430\u0440\u0440\u0438 \u041f\u0435\u0439\u0434\u0436\"", "\"\u041e\u0441\u043d\u043e\u0432\u0430\u0442\u0435\u043b\u044c \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 Google: \"", "\"\\n\u0412\u0432\u0435\u0434\u0438\u0442\u0435 \u0438\u043c\u044f: \"", "\"\\n\u041d\u0435\u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e. \u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0439 \u0435\u0449\u0435 \u0440\u0430\u0437\"", "\"\\n\u0412\u0432\u0435\u0434\u0438\u0442\u0435 \u0438\u043c\u044f: \"", "\"\u041f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e!\"", "\"!\"", "\"\u041d\u0430\u0436\u043c\u0438\u0442\u0435 ENTER \u0434\u043b\u044f \u043f\u0440\u043e\u0434\u043e\u043b\u0436\u0435\u043d\u0438\u044f\""]}}], ["c7a6ddc36fdd9e4a8bc0bface1815573", {"code_string": "import re\nfrom django.middleware.locale import LocaleMiddleware\nfrom django.utils import translation\nfrom django.conf import settings\nfrom utilities.models import UserLanguageProfile\nfrom django.core.exceptions import ObjectDoesNotExist\n", "code_toks_joined": "import re <NEWLINE> from django . middleware . locale import LocaleMiddleware <NEWLINE> from django . utils import translation <NEWLINE> from django . conf import settings <NEWLINE> from utilities . models import UserLanguageProfile <NEWLINE> from django . core . exceptions import ObjectDoesNotExist <NEWLINE>", "anonymize_dict": {}}], ["c22467ffbe20ec146687eb1aea60b213", {"code_string": "from django.shortcuts import render, render_to_response\nfrom django.http import HttpResponse\nfrom.models import FAQ\n", "code_toks_joined": "from django . shortcuts import render , render_to_response <NEWLINE> from django . http import HttpResponse <NEWLINE> from . models import FAQ <NEWLINE>", "anonymize_dict": {}}], ["cf303528838a111595cb88ff57a17fe8", {"code_string": "class md_model3(Model):\n    _name = 'md.model3'\n    _description = 'General model'\n    _columns = OrderedDict([\n    ('md_group_model_id', fields.many2one(obj = 'md.group.model', label = 'Model Group', manual = u\"\u042d\u0442\u043e \u0441\u0432\u0437\u044f\u0437\u044c \u0441 \u0433\u0440\u0443\u043f\u043f\u043e\u0439 \u0438\u043e\u0434\u0435\u043b\u0435\u0439\")),\n    ('name', fields.varchar(label = 'Name')),\n    ('note', fields.text(label = 'Note'))\n    ])\n", "code_toks_joined": "class md_model3 ( Model ) : <NEWLINE> <INDENT> _name = <STRING> <NEWLINE> _description = <STRING> <NEWLINE> _columns = OrderedDict ( [ <NEWLINE> ( <STRING> , fields . many2one ( obj = <STRING> , label = <STRING> , manual = <STRING> ) ) , <NEWLINE> ( <STRING> , fields . varchar ( label = <STRING> ) ) , <NEWLINE> ( <STRING> , fields . text ( label = <STRING> ) ) <NEWLINE> ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'md.model3'", "'General model'", "'md_group_model_id'", "'md.group.model'", "'Model Group'", "u\"\u042d\u0442\u043e \u0441\u0432\u0437\u044f\u0437\u044c \u0441 \u0433\u0440\u0443\u043f\u043f\u043e\u0439 \u0438\u043e\u0434\u0435\u043b\u0435\u0439\"", "'name'", "'Name'", "'note'", "'Note'"]}}], ["7550e5c8a477a30e0f783c712a9b9d0c", {"code_string": "class ChargeFilterSettings(base.BaseSettings):\n    \"\"\"Settings for the charge filter\"\"\"\n    def __init__(self):\n        super(ChargeFilterSettings, self).__init__()\n        self.registerSetting(\"minCharge\", default = - 100.0)\n        self.registerSetting(\"maxCharge\", default = 100.0)\n", "code_toks_joined": "class ChargeFilterSettings ( base . BaseSettings ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self ) : <NEWLINE> <INDENT> super ( ChargeFilterSettings , self ) . __init__ ( ) <NEWLINE> self . registerSetting ( <STRING> , default = - 100.0 ) <NEWLINE> self . registerSetting ( <STRING> , default = 100.0 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Settings for the charge filter\"\"\"", "\"minCharge\"", "\"maxCharge\""]}}], ["fb8aa5d91a4e8da39069890ccf40e7a5", {"code_string": "def delete_alarms(self, alarms):\n    \"\"\"Deletes all specified alarms. In the event of an error, no\"\"\"\n    params = {}\n    self.build_list_params(params, alarms, 'AlarmNames.member.%s')\n    return self.get_status('DeleteAlarms', params)\n", "code_toks_joined": "def delete_alarms ( self , alarms ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> params = { } <NEWLINE> self . build_list_params ( params , alarms , <STRING> ) <NEWLINE> return self . get_status ( <STRING> , params ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Deletes all specified alarms. In the event of an error, no\"\"\"", "'AlarmNames.member.%s'", "'DeleteAlarms'"]}}], ["7d4061e5deb69416609f5322c04ccab6", {"code_string": "def parse_args(local_argv = None):\n    \"\"\"Parse Arguments to find File Options and working directory\"\"\"\n    if local_argv is None:\n        local_argv = sys.argv\n    c_filename = local_argv[1]\n    moduleName = local_argv[2]\n    localDirectory = local_argv[3]\n    try:\n        c_filename\n    except:\n        print(\"No c file specified\")\n    try:\n        moduleName\n    except:\n        print(\"No module specified\")\n    try:\n        localDirectory\n    except:\n        print(\"No local directory specified\")\n    return(c_filename, moduleName, localDirectory)\n", "code_toks_joined": "def parse_args ( local_argv = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if local_argv is None : <NEWLINE> <INDENT> local_argv = sys . argv <NEWLINE> <DEDENT> c_filename = local_argv [ 1 ] <NEWLINE> moduleName = local_argv [ 2 ] <NEWLINE> localDirectory = local_argv [ 3 ] <NEWLINE> try : <NEWLINE> <INDENT> c_filename <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> try : <NEWLINE> <INDENT> moduleName <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> try : <NEWLINE> <INDENT> localDirectory <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> return ( c_filename , moduleName , localDirectory ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Parse Arguments to find File Options and working directory\"\"\"", "\"No c file specified\"", "\"No module specified\"", "\"No local directory specified\""]}}], ["ddd70ca13c843cbb70de39d0151ae8fc", {"code_string": "def test_list_tags(self):\n    response = self.client.get('/tags/')\n    self.assertTrue('tags' in response.context)\n    self.assertTrue(len(response.context['tags']) > 0)\n", "code_toks_joined": "def test_list_tags ( self ) : <NEWLINE> <INDENT> response = self . client . get ( <STRING> ) <NEWLINE> self . assertTrue ( <STRING> in response . context ) <NEWLINE> self . assertTrue ( len ( response . context [ <STRING> ] ) > 0 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/tags/'", "'tags'", "'tags'"]}}], ["632da173ce19fd530792e459b2b1443e", {"code_string": "from.home import HomeHandler\nfrom.quiz import QuizHandler\nfrom.modify import ModifyHandler\n__all__ = ['HomeHandler', 'QuizHandler', 'ModifyHandler']\n", "code_toks_joined": "from . home import HomeHandler <NEWLINE> from . quiz import QuizHandler <NEWLINE> from . modify import ModifyHandler <NEWLINE> __all__ = [ <STRING> , <STRING> , <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'HomeHandler'", "'QuizHandler'", "'ModifyHandler'"]}}], ["e8dd4757ef898e24a92f10f5c220de5c", {"code_string": "def _create_roles_dirs(self):\n    if self.mode == 'full':\n        role_struct = self.full_role_structure\n    else:\n        role_struct = self.default_role_structure\n    for k in self.roles:\n        path = os.path.join(self.path, self.name, 'roles', k)\n        self._dirs_create(path, * role_struct)\n", "code_toks_joined": "def _create_roles_dirs ( self ) : <NEWLINE> <INDENT> if self . mode == <STRING> : <NEWLINE> <INDENT> role_struct = self . full_role_structure <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> role_struct = self . default_role_structure <NEWLINE> <DEDENT> for k in self . roles : <NEWLINE> <INDENT> path = os . path . join ( self . path , self . name , <STRING> , k ) <NEWLINE> self . _dirs_create ( path , * role_struct ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'full'", "'roles'"]}}], ["3348e0fa12d0166c8dd966a2416ab4c9", {"code_string": "def prompt_password(prompt, confirm = True):\n    import getpass\n    if sys.stdin.isatty():\n        password = getpass.getpass(prompt)\n        if password and confirm:\n            password2 = getpass.getpass(\"Confirm: \")\n            if password != password2:\n                sys.exit(\"Error: Passwords do not match.\")\n    else:\n        password = raw_input(prompt)\n    if not password:\n        password = None\n    return password\n", "code_toks_joined": "def prompt_password ( prompt , confirm = True ) : <NEWLINE> <INDENT> import getpass <NEWLINE> if sys . stdin . isatty ( ) : <NEWLINE> <INDENT> password = getpass . getpass ( prompt ) <NEWLINE> if password and confirm : <NEWLINE> <INDENT> password2 = getpass . getpass ( <STRING> ) <NEWLINE> if password != password2 : <NEWLINE> <INDENT> sys . exit ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> password = raw_input ( prompt ) <NEWLINE> <DEDENT> if not password : <NEWLINE> <INDENT> password = None <NEWLINE> <DEDENT> return password <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Confirm: \"", "\"Error: Passwords do not match.\""]}}], ["c626d4654d363e8d6b444da1ca0f9917", {"code_string": "def is_thread_waiting_for_me(self, checked_thread):\n    my_thread = threading.currentThread()\n    threading.main_thread()\n", "code_toks_joined": "def is_thread_waiting_for_me ( self , checked_thread ) : <NEWLINE> <INDENT> my_thread = threading . currentThread ( ) <NEWLINE> threading . main_thread ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["30d9b45e50734d5db9abdf777550c157", {"code_string": "import gevent\nfrom gevent import socket\nfrom gevent import monkey\nmonkey.patch_socket()\nfrom dnslib import A, AAAA, CNAME, MX, RR, TXT\nfrom dnslib import DNSHeader, DNSRecord, QTYPE\nAF_INET = 2\nSOCK_DGRAM = 2\ns = socket.socket(AF_INET, SOCK_DGRAM)\ns.bind(('', 53))\nIP = \"127.0.0.1\"\nIPV6 = (0, ) * 16\nMSG = \"gevent_server.py\"\n", "code_toks_joined": "import gevent <NEWLINE> from gevent import socket <NEWLINE> from gevent import monkey <NEWLINE> monkey . patch_socket ( ) <NEWLINE> from dnslib import A , AAAA , CNAME , MX , RR , TXT <NEWLINE> from dnslib import DNSHeader , DNSRecord , QTYPE <NEWLINE> AF_INET = 2 <NEWLINE> SOCK_DGRAM = 2 <NEWLINE> s = socket . socket ( AF_INET , SOCK_DGRAM ) <NEWLINE> s . bind ( ( <STRING> , 53 ) ) <NEWLINE> IP = <STRING> <NEWLINE> IPV6 = ( 0 , ) * 16 <NEWLINE> MSG = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["''", "\"127.0.0.1\"", "\"gevent_server.py\""]}}], ["2a25c90dd2bdc3389eb25e4db76d7a55", {"code_string": "class LogTest(ExtendedTestCase):\n    def test_enums(self):\n        self.assertEnumIsFullyDefined(MessageLevelEnum, \"message_level_type\", \"lib/include/ert/util/log.h\")\n", "code_toks_joined": "class LogTest ( ExtendedTestCase ) : <NEWLINE> <INDENT> def test_enums ( self ) : <NEWLINE> <INDENT> self . assertEnumIsFullyDefined ( MessageLevelEnum , <STRING> , <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"message_level_type\"", "\"lib/include/ert/util/log.h\""]}}], ["45e55d2b23794586fc037bbaa257c6ae", {"code_string": "\"\"\"This script exists to work around severe performane problems when WPA or other\"\"\"\nfrom __future__ import print_function\nimport os\nimport sys\nimport re\nimport tempfile\nimport shutil\nimport subprocess\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import print_function <NEWLINE> import os <NEWLINE> import sys <NEWLINE> import re <NEWLINE> import tempfile <NEWLINE> import shutil <NEWLINE> import subprocess <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"This script exists to work around severe performane problems when WPA or other\"\"\""]}}], ["84be723ccfeef6fa20633727df01c608", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('registration', '0018_auto_20150904_0703'),\n    ]\n    operations = [\n        migrations.AlterField(\n            model_name = 'participant',\n            name = 'bill_id',\n            field = models.BigIntegerField(default = None, null = True),\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . AlterField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . BigIntegerField ( default = None , null = True ) , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'registration'", "'0018_auto_20150904_0703'", "'participant'", "'bill_id'"]}}], ["b08cf78fac54dbcd44097a5cca1a0b50", {"code_string": "from oslo_log import log\nfrom oslo_utils import timeutils\nfrom manila import exception\nfrom manila.share import api\nfrom manila.share import hook\nfrom manila.share.hooks import zaqarclientwrapper\nCONF = zaqarclientwrapper.CONF\nLOG = log.getLogger(__name__)\nZAQARCLIENT = zaqarclientwrapper.ZAQARCLIENT\n", "code_toks_joined": "from oslo_log import log <NEWLINE> from oslo_utils import timeutils <NEWLINE> from manila import exception <NEWLINE> from manila . share import api <NEWLINE> from manila . share import hook <NEWLINE> from manila . share . hooks import zaqarclientwrapper <NEWLINE> CONF = zaqarclientwrapper . CONF <NEWLINE> LOG = log . getLogger ( __name__ ) <NEWLINE> ZAQARCLIENT = zaqarclientwrapper . ZAQARCLIENT <NEWLINE>", "anonymize_dict": {}}], ["ef9da196b05bcd3c9f7a47c50f584ea9", {"code_string": "from formalchemy.tests import *\nfrom formalchemy.fields import PasswordFieldRenderer\ntry:\n    import json\nexcept ImportError:\n    import simplejson as json\n", "code_toks_joined": "from formalchemy . tests import * <NEWLINE> from formalchemy . fields import PasswordFieldRenderer <NEWLINE> try : <NEWLINE> <INDENT> import json <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> import simplejson as json <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["0fb96abc1ab5d47c1ec57a8027e07f68", {"code_string": "def register():\n    bpy.utils.register_class(AppleseedMatLayerProps)\n    bpy.utils.register_class(AppleseedMatProps)\n    bpy.types.Material.appleseed = bpy.props.PointerProperty(type = AppleseedMatProps)\n", "code_toks_joined": "def register ( ) : <NEWLINE> <INDENT> bpy . utils . register_class ( AppleseedMatLayerProps ) <NEWLINE> bpy . utils . register_class ( AppleseedMatProps ) <NEWLINE> bpy . types . Material . appleseed = bpy . props . PointerProperty ( type = AppleseedMatProps ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["d6cec97f63ef570208e2e07ddaca8230", {"code_string": "botellas = 99\nwhile(botellas > 0):\n    print(botellas, \"bottles of beer on the wall,\", botellas, \"bottles of beer.\")\n    botellas = botellas - 1\n    print(\"Take one down, pass it around,\", botellas, \"bottles of beer on the wall.\")\n    print(\" \")\nprint(\"se acabo\")\n", "code_toks_joined": "botellas = 99 <NEWLINE> while ( botellas > 0 ) : <NEWLINE> <INDENT> print ( botellas , <STRING> , botellas , <STRING> ) <NEWLINE> botellas = botellas - 1 <NEWLINE> print ( <STRING> , botellas , <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> <DEDENT> print ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"bottles of beer on the wall,\"", "\"bottles of beer.\"", "\"Take one down, pass it around,\"", "\"bottles of beer on the wall.\"", "\" \"", "\"se acabo\""]}}], ["7acbd471bf69cf36867f86ab12221c9f", {"code_string": "from toontown.classicchars import DistributedGoofySpeedwayAI\nfrom toontown.dna.DNAParser import DNAGroup, DNAVisGroup\nfrom toontown.hood import HoodAI\nfrom toontown.hood import ZoneUtil\nfrom toontown.racing import RaceGlobals\nfrom toontown.racing.DistributedRacePadAI import DistributedRacePadAI\nfrom toontown.racing.DistributedStartingBlockAI import DistributedStartingBlockAI\nfrom toontown.racing.DistributedViewPadAI import DistributedViewPadAI\nfrom toontown.racing.DistributedStartingBlockAI import DistributedViewingBlockAI\nfrom toontown.toonbase import ToontownGlobals\n", "code_toks_joined": "from toontown . classicchars import DistributedGoofySpeedwayAI <NEWLINE> from toontown . dna . DNAParser import DNAGroup , DNAVisGroup <NEWLINE> from toontown . hood import HoodAI <NEWLINE> from toontown . hood import ZoneUtil <NEWLINE> from toontown . racing import RaceGlobals <NEWLINE> from toontown . racing . DistributedRacePadAI import DistributedRacePadAI <NEWLINE> from toontown . racing . DistributedStartingBlockAI import DistributedStartingBlockAI <NEWLINE> from toontown . racing . DistributedViewPadAI import DistributedViewPadAI <NEWLINE> from toontown . racing . DistributedStartingBlockAI import DistributedViewingBlockAI <NEWLINE> from toontown . toonbase import ToontownGlobals <NEWLINE>", "anonymize_dict": {}}], ["60aa21820d2fc9baf6bacc3adb2c27e9", {"code_string": "from vt_manager.controller.MacAllocator import MACallocator\nfrom vt_manager.controller.SlotAllocator import SlotAllocator\nfrom vt_manager.models.Slot import Slot\nfrom vt_manager.models.Mac import Mac\nsa = SlotAllocator()\nma = MACallocator()\ns = sa.acquire(\"projecto\", \"agg\", \"slice2\")\nm = ma.acquire(\"projecto\", \"agg\", \"slice2\")\nprint(m)\n", "code_toks_joined": "from vt_manager . controller . MacAllocator import MACallocator <NEWLINE> from vt_manager . controller . SlotAllocator import SlotAllocator <NEWLINE> from vt_manager . models . Slot import Slot <NEWLINE> from vt_manager . models . Mac import Mac <NEWLINE> sa = SlotAllocator ( ) <NEWLINE> ma = MACallocator ( ) <NEWLINE> s = sa . acquire ( <STRING> , <STRING> , <STRING> ) <NEWLINE> m = ma . acquire ( <STRING> , <STRING> , <STRING> ) <NEWLINE> print ( m ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"projecto\"", "\"agg\"", "\"slice2\"", "\"projecto\"", "\"agg\"", "\"slice2\""]}}], ["65da23fb1b7436b33a5bc1ca1f0de88a", {"code_string": "import os\nimport sys\nimport getopt\nimport subprocess\nimport tempfile\nimport re\nimport shutil\n", "code_toks_joined": "import os <NEWLINE> import sys <NEWLINE> import getopt <NEWLINE> import subprocess <NEWLINE> import tempfile <NEWLINE> import re <NEWLINE> import shutil <NEWLINE>", "anonymize_dict": {}}], ["fcdc1a057f1030310dbc4a1bc67ac66b", {"code_string": "def create_playlist(self, name, tracks):\n    me = self._client.get_me()\n    playlist = self._client.create_playlist(me['id'], name)\n    for c in self._create_chunks(tracks, 50):\n        self._client.add_playlist_tracks(me['id'], playlist['id'], c)\n", "code_toks_joined": "def create_playlist ( self , name , tracks ) : <NEWLINE> <INDENT> me = self . _client . get_me ( ) <NEWLINE> playlist = self . _client . create_playlist ( me [ <STRING> ] , name ) <NEWLINE> for c in self . _create_chunks ( tracks , 50 ) : <NEWLINE> <INDENT> self . _client . add_playlist_tracks ( me [ <STRING> ] , playlist [ <STRING> ] , c ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'id'", "'id'", "'id'"]}}], ["10f419d238eb93706e5ee0af7d70943d", {"code_string": "\"\"\"Stochastic Model VSHP\"\"\"\n__author__ = 'krishnab'\n__version__ = '0.1.0'\nfrom operator import neg, truediv\nimport numpy as np\nimport pandas as pd\nfrom numpy.random import binomial\nfrom pyugend.Models import Base_model\n", "code_toks_joined": "<STRING> <NEWLINE> __author__ = <STRING> <NEWLINE> __version__ = <STRING> <NEWLINE> from operator import neg , truediv <NEWLINE> import numpy as np <NEWLINE> import pandas as pd <NEWLINE> from numpy . random import binomial <NEWLINE> from pyugend . Models import Base_model <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Stochastic Model VSHP\"\"\"", "'krishnab'", "'0.1.0'"]}}], ["94c2a21e8d7ffeff09e4a1cd6488cfb7", {"code_string": "\"\"\"This tries to do more or less the same thing as CutyCapt, but as a\"\"\"\nimport sys\nfrom PyQt4 import QtCore, QtGui, QtWebKit\n", "code_toks_joined": "<STRING> <NEWLINE> import sys <NEWLINE> from PyQt4 import QtCore , QtGui , QtWebKit <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"This tries to do more or less the same thing as CutyCapt, but as a\"\"\""]}}], ["e5b731b2ddaff3d761a3c6964590e543", {"code_string": "import commands\nfrom datetime import datetime\nimport functools\nfrom time import mktime, sleep, time\nimport pytz\n", "code_toks_joined": "import commands <NEWLINE> from datetime import datetime <NEWLINE> import functools <NEWLINE> from time import mktime , sleep , time <NEWLINE> import pytz <NEWLINE>", "anonymize_dict": {}}], ["946979bc7f20dca18d9bd44febba86fe", {"code_string": "def entropy(img):\n    histogram = img.histogram()\n    histogram_length = sum(histogram)\n    samples_probability = [float(h) / histogram_length for h in histogram]\n    return - sum([p * math.log(p, 2) for p in samples_probability if p != 0])\n", "code_toks_joined": "def entropy ( img ) : <NEWLINE> <INDENT> histogram = img . histogram ( ) <NEWLINE> histogram_length = sum ( histogram ) <NEWLINE> samples_probability = [ float ( h ) / histogram_length for h in histogram ] <NEWLINE> return - sum ( [ p * math . log ( p , 2 ) for p in samples_probability if p != 0 ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["b511388e21e67b09d3bed1d9da4fb1a9", {"code_string": "def load_yaml_config(filepath):\n    \"\"\"Load yaml config file at the given path.\"\"\"\n    with open(filepath) as f:\n        return yaml.load(f)\n", "code_toks_joined": "def load_yaml_config ( filepath ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> with open ( filepath ) as f : <NEWLINE> <INDENT> return yaml . load ( f ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Load yaml config file at the given path.\"\"\""]}}], ["c2dcbb5b397223a1800bb42a1f89fcc1", {"code_string": "class Solution:\n    def removeElement(self, A, elem):\n        p1 = 0\n        p2 = 0\n        while p2 < len(A):\n            if A[p2] != elem:\n                A[p1] = A[p2]\n                p1 += 1\n            p2 += 1\n        return p1\n", "code_toks_joined": "class Solution : <NEWLINE> <INDENT> def removeElement ( self , A , elem ) : <NEWLINE> <INDENT> p1 = 0 <NEWLINE> p2 = 0 <NEWLINE> while p2 < len ( A ) : <NEWLINE> <INDENT> if A [ p2 ] != elem : <NEWLINE> <INDENT> A [ p1 ] = A [ p2 ] <NEWLINE> p1 += 1 <NEWLINE> <DEDENT> p2 += 1 <NEWLINE> <DEDENT> return p1 <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["29daf4bce0aa124496918a323e586fc6", {"code_string": "from oslo_config import cfg\nfrom keystoneclient.auth.identity.v3 import base\n__all__ = ['TokenMethod', 'Token']\n", "code_toks_joined": "from oslo_config import cfg <NEWLINE> from keystoneclient . auth . identity . v3 import base <NEWLINE> __all__ = [ <STRING> , <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'TokenMethod'", "'Token'"]}}], ["1469f46ecaec74c42a75e1d08711be0c", {"code_string": "def main():\n    \"\"\"\u4e3b\u7a0b\u5e8f\u5165\u53e3\"\"\"\n    ctypes.windll.shell32.SetCurrentProcessExplicitAppUserModelID('vn.py demo')\n    app = QtGui.QApplication(sys.argv)\n    app.setWindowIcon(QtGui.QIcon('vnpy.ico'))\n    me = MainEngine()\n    mw = MainWindow(me.ee, me)\n    mw.showMaximized()\n    sys.exit(app.exec_())\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> ctypes . windll . shell32 . SetCurrentProcessExplicitAppUserModelID ( <STRING> ) <NEWLINE> app = QtGui . QApplication ( sys . argv ) <NEWLINE> app . setWindowIcon ( QtGui . QIcon ( <STRING> ) ) <NEWLINE> me = MainEngine ( ) <NEWLINE> mw = MainWindow ( me . ee , me ) <NEWLINE> mw . showMaximized ( ) <NEWLINE> sys . exit ( app . exec_ ( ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"\u4e3b\u7a0b\u5e8f\u5165\u53e3\"\"\"", "'vn.py demo'", "'vnpy.ico'"]}}], ["9f84037e0dc48decac813b0dc12f1bbf", {"code_string": "import os\nimport logging\nfrom logging.handlers import RotatingFileHandler\nfrom constants import HOME, LOG_DIR, LOG_FILE, MAX_LOG_SIZE\n", "code_toks_joined": "import os <NEWLINE> import logging <NEWLINE> from logging . handlers import RotatingFileHandler <NEWLINE> from constants import HOME , LOG_DIR , LOG_FILE , MAX_LOG_SIZE <NEWLINE>", "anonymize_dict": {}}], ["0019e709ab479c58b5c4138bc66db5bf", {"code_string": "import os\nimport dynamixel\nimport time\nimport random\nimport sys\nimport subprocess\nimport optparse\nimport yaml\nimport numpy as np\nimport hubo_ach as ha\nimport ach\n", "code_toks_joined": "import os <NEWLINE> import dynamixel <NEWLINE> import time <NEWLINE> import random <NEWLINE> import sys <NEWLINE> import subprocess <NEWLINE> import optparse <NEWLINE> import yaml <NEWLINE> import numpy as np <NEWLINE> import hubo_ach as ha <NEWLINE> import ach <NEWLINE>", "anonymize_dict": {}}], ["aa11202a176dfcd77b7cc4397783f8f1", {"code_string": "def test_file_passing_blob_from_gzip():\n    import gzip\n    src = get_fn('tz2_2.pdb.gz')\n    blob = gzip.open(src).read()\n    fm = FileManager(blob)\n    assert not fm.is_filename\n    with pytest.raises(ValueError):\n        fm.ext\n", "code_toks_joined": "def test_file_passing_blob_from_gzip ( ) : <NEWLINE> <INDENT> import gzip <NEWLINE> src = get_fn ( <STRING> ) <NEWLINE> blob = gzip . open ( src ) . read ( ) <NEWLINE> fm = FileManager ( blob ) <NEWLINE> assert not fm . is_filename <NEWLINE> with pytest . raises ( ValueError ) : <NEWLINE> <INDENT> fm . ext <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'tz2_2.pdb.gz'"]}}], ["85cdcf8156bfcc741367615aed725094", {"code_string": "def rho(n, f = f1):\n    x = 2\n    y = 2\n    d = 1\n    while d == 1:\n        x = f(x, n)\n        y = f(f(y, n), n)\n        d = gcd(abs(x - y), n)\n    if d == n:\n        return False\n    return d\n", "code_toks_joined": "def rho ( n , f = f1 ) : <NEWLINE> <INDENT> x = 2 <NEWLINE> y = 2 <NEWLINE> d = 1 <NEWLINE> while d == 1 : <NEWLINE> <INDENT> x = f ( x , n ) <NEWLINE> y = f ( f ( y , n ) , n ) <NEWLINE> d = gcd ( abs ( x - y ) , n ) <NEWLINE> <DEDENT> if d == n : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> return d <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["c0ed5846f89c01bfddbcd8d17808c589", {"code_string": "def _populate_with_data(self):\n    self._populate_freedesktop_attributes()\n    number_of_files = self._wrapper.number_of_files\n    self._statusbar.pop(1)\n    if 1 < number_of_files:\n        self._statusbar.push(1, '{0} Dateien ge\u00f6ffnet.'.format(number_of_files))\n    elif 1 == number_of_files:\n        file_name = self._wrapper.file_names[0]\n        self._statusbar.push(1, '{0} ge\u00f6ffnet.'.format(file_name))\n", "code_toks_joined": "def _populate_with_data ( self ) : <NEWLINE> <INDENT> self . _populate_freedesktop_attributes ( ) <NEWLINE> number_of_files = self . _wrapper . number_of_files <NEWLINE> self . _statusbar . pop ( 1 ) <NEWLINE> if 1 < number_of_files : <NEWLINE> <INDENT> self . _statusbar . push ( 1 , <STRING> . format ( number_of_files ) ) <NEWLINE> <DEDENT> elif 1 == number_of_files : <NEWLINE> <INDENT> file_name = self . _wrapper . file_names [ 0 ] <NEWLINE> self . _statusbar . push ( 1 , <STRING> . format ( file_name ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'{0} Dateien ge\u00f6ffnet.'", "'{0} ge\u00f6ffnet.'"]}}], ["3496950b323e164d838615d05ec91a0d", {"code_string": "def cb():\n    from.GeventWSFactory import GeventWSFactory\n    return GeventWSFactory()\n", "code_toks_joined": "def cb ( ) : <NEWLINE> <INDENT> from . GeventWSFactory import GeventWSFactory <NEWLINE> return GeventWSFactory ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["14d5821eedb90c2aacc6c43330a53de6", {"code_string": "def lca(node_0, node_1):\n    iter_0, iter_1 = node_0, node_1\n    nodes_on_path_to_root = set()\n    while iter_0 or iter_1:\n        if iter_0:\n            if iter_0 in nodes_on_path_to_root:\n                return iter_0\n            nodes_on_path_to_root.add(iter_0)\n            iter_0 = iter_0.parent\n        if iter_1:\n            if iter_1 in nodes_on_path_to_root:\n                return iter_1\n            nodes_on_path_to_root.add(iter_1)\n            iter_1 = iter_1.parent\n    raise ValueError('node_0 and node_1 are not in the same tree')\n", "code_toks_joined": "def lca ( node_0 , node_1 ) : <NEWLINE> <INDENT> iter_0 , iter_1 = node_0 , node_1 <NEWLINE> nodes_on_path_to_root = set ( ) <NEWLINE> while iter_0 or iter_1 : <NEWLINE> <INDENT> if iter_0 : <NEWLINE> <INDENT> if iter_0 in nodes_on_path_to_root : <NEWLINE> <INDENT> return iter_0 <NEWLINE> <DEDENT> nodes_on_path_to_root . add ( iter_0 ) <NEWLINE> iter_0 = iter_0 . parent <NEWLINE> <DEDENT> if iter_1 : <NEWLINE> <INDENT> if iter_1 in nodes_on_path_to_root : <NEWLINE> <INDENT> return iter_1 <NEWLINE> <DEDENT> nodes_on_path_to_root . add ( iter_1 ) <NEWLINE> iter_1 = iter_1 . parent <NEWLINE> <DEDENT> <DEDENT> raise ValueError ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'node_0 and node_1 are not in the same tree'"]}}], ["e63407b5cce1a47e065ba4ea95d1973d", {"code_string": "def flatten_gender(row):\n    g = 'unknown'\n    if not pd.isnull(row['Q4-t']):\n        g = 't'\n    elif not pd.isnull(row['Q4-gq']):\n        g = 't'\n    elif not pd.isnull(row['Q4-i']):\n        g = 't'\n    elif not pd.isnull(row['Q4-m']):\n        g = 'm'\n    elif not pd.isnull(row['Q4-f']):\n        g = 'f'\n    return g\n", "code_toks_joined": "def flatten_gender ( row ) : <NEWLINE> <INDENT> g = <STRING> <NEWLINE> if not pd . isnull ( row [ <STRING> ] ) : <NEWLINE> <INDENT> g = <STRING> <NEWLINE> <DEDENT> elif not pd . isnull ( row [ <STRING> ] ) : <NEWLINE> <INDENT> g = <STRING> <NEWLINE> <DEDENT> elif not pd . isnull ( row [ <STRING> ] ) : <NEWLINE> <INDENT> g = <STRING> <NEWLINE> <DEDENT> elif not pd . isnull ( row [ <STRING> ] ) : <NEWLINE> <INDENT> g = <STRING> <NEWLINE> <DEDENT> elif not pd . isnull ( row [ <STRING> ] ) : <NEWLINE> <INDENT> g = <STRING> <NEWLINE> <DEDENT> return g <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'unknown'", "'Q4-t'", "'t'", "'Q4-gq'", "'t'", "'Q4-i'", "'t'", "'Q4-m'", "'m'", "'Q4-f'", "'f'"]}}], ["a9a85a47ba8861190d02c1e55aef00fc", {"code_string": "def add_lift(self, axis = \"vertical\", type_ = \"normal\"):\n    Element.add_lift(self, axis, type_)\n    self._has_lift = True\n", "code_toks_joined": "def add_lift ( self , axis = <STRING> , type_ = <STRING> ) : <NEWLINE> <INDENT> Element . add_lift ( self , axis , type_ ) <NEWLINE> self . _has_lift = True <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"vertical\"", "\"normal\""]}}], ["a11dd1177e15fa57d67177ff16c7c158", {"code_string": "import os\nimport subprocess\nimport sys\nprog, path = sys.argv\ndirname, basename = os.path.split(path)\ntry:\n    subprocess.call([sys.executable, basename], cwd = dirname)\nexcept KeyboardInterrupt:\n    pass\nprint()\nprint(\"--------------------------\")\nprint(\"Your program exited. Press Enter to close this window...\")\ninput()\n", "code_toks_joined": "import os <NEWLINE> import subprocess <NEWLINE> import sys <NEWLINE> prog , path = sys . argv <NEWLINE> dirname , basename = os . path . split ( path ) <NEWLINE> try : <NEWLINE> <INDENT> subprocess . call ( [ sys . executable , basename ] , cwd = dirname ) <NEWLINE> <DEDENT> except KeyboardInterrupt : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> print ( ) <NEWLINE> print ( <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> input ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"--------------------------\"", "\"Your program exited. Press Enter to close this window...\""]}}], ["756362fcde23e46f113f0dde8a0831e2", {"code_string": "def _run_server():\n    host = cfg.CONF.api.host\n    port = cfg.CONF.api.port\n    LOG.info('(PID=%s) ST2 API is serving on http://%s:%s.', os.getpid(), host, port)\n    max_pool_size = eventlet.wsgi.DEFAULT_MAX_SIMULTANEOUS_REQUESTS\n    worker_pool = eventlet.GreenPool(max_pool_size)\n    sock = eventlet.listen((host, port))\n    wsgi.server(sock, app.setup_app(), custom_pool = worker_pool, log = LOG, log_output = False)\n    return 0\n", "code_toks_joined": "def _run_server ( ) : <NEWLINE> <INDENT> host = cfg . CONF . api . host <NEWLINE> port = cfg . CONF . api . port <NEWLINE> LOG . info ( <STRING> , os . getpid ( ) , host , port ) <NEWLINE> max_pool_size = eventlet . wsgi . DEFAULT_MAX_SIMULTANEOUS_REQUESTS <NEWLINE> worker_pool = eventlet . GreenPool ( max_pool_size ) <NEWLINE> sock = eventlet . listen ( ( host , port ) ) <NEWLINE> wsgi . server ( sock , app . setup_app ( ) , custom_pool = worker_pool , log = LOG , log_output = False ) <NEWLINE> return 0 <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'(PID=%s) ST2 API is serving on http://%s:%s.'"]}}], ["bd92763279dfd05a77d94e589a1f1e9d", {"code_string": "from __future__ import absolute_import, unicode_literals\nimport unittest\nimport json\nfrom base64 import b64encode\nfrom flask import current_app, url_for\nfrom app import create_app, db\nfrom app.models import Role, User, RawCourse, Course\nstudent_id = '4140206139'\nother_student_id = '4140206109'\nold_student_id = '4120206101'\n", "code_toks_joined": "from __future__ import absolute_import , unicode_literals <NEWLINE> import unittest <NEWLINE> import json <NEWLINE> from base64 import b64encode <NEWLINE> from flask import current_app , url_for <NEWLINE> from app import create_app , db <NEWLINE> from app . models import Role , User , RawCourse , Course <NEWLINE> student_id = <STRING> <NEWLINE> other_student_id = <STRING> <NEWLINE> old_student_id = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'4140206139'", "'4140206109'", "'4120206101'"]}}], ["3db1f722eac60ddca0c90cd721cab0ae", {"code_string": "from unittest import TestCase\nfrom cartodb_services.refactor.storage.null_config import NullConfigStorage\nfrom cartodb_services.refactor.core.interfaces import ConfigBackendInterface\n", "code_toks_joined": "from unittest import TestCase <NEWLINE> from cartodb_services . refactor . storage . null_config import NullConfigStorage <NEWLINE> from cartodb_services . refactor . core . interfaces import ConfigBackendInterface <NEWLINE>", "anonymize_dict": {}}], ["fa530639077cb6eb3c2266149e17f244", {"code_string": "'''Little tool that converts the cube generated by'''\nfrom wand.image import Image\npix = 0\nwith Image(filename = 'textures/earth_night.png') as a:\n    for i in range(6):\n        with a.clone() as img:\n            print(pix)\n            img.crop(top = pix, height = 1024)\n            img.save(filename = 'textures/earth_night_' + str(i) + '.png')\n        pix += 1024\n", "code_toks_joined": "<STRING> <NEWLINE> from wand . image import Image <NEWLINE> pix = 0 <NEWLINE> with Image ( filename = <STRING> ) as a : <NEWLINE> <INDENT> for i in range ( 6 ) : <NEWLINE> <INDENT> with a . clone ( ) as img : <NEWLINE> <INDENT> print ( pix ) <NEWLINE> img . crop ( top = pix , height = 1024 ) <NEWLINE> img . save ( filename = <STRING> + str ( i ) + <STRING> ) <NEWLINE> <DEDENT> pix += 1024 <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Little tool that converts the cube generated by'''", "'textures/earth_night.png'", "'textures/earth_night_'", "'.png'"]}}], ["5703432ad631e4197ffafbd043e7eae1", {"code_string": "def isOnTextBorder(self, sender):\n    twX = self.richText.getAbsoluteLeft()\n    twY = self.richText.getAbsoluteTop()\n    x = event.getClientX() - twX\n    y = event.getClientY() - twY\n    width = self.richText.getOffsetWidth()\n    height = self.richText.getOffsetHeight()\n    return((sender == self.richText) and\n        ((x <= 0) or(x >= width) or\n        (y <= 0) or(y >= height)))\n", "code_toks_joined": "def isOnTextBorder ( self , sender ) : <NEWLINE> <INDENT> twX = self . richText . getAbsoluteLeft ( ) <NEWLINE> twY = self . richText . getAbsoluteTop ( ) <NEWLINE> x = event . getClientX ( ) - twX <NEWLINE> y = event . getClientY ( ) - twY <NEWLINE> width = self . richText . getOffsetWidth ( ) <NEWLINE> height = self . richText . getOffsetHeight ( ) <NEWLINE> return ( ( sender == self . richText ) and <NEWLINE> <INDENT> ( ( x <= 0 ) or ( x >= width ) or <NEWLINE> ( y <= 0 ) or ( y >= height ) ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["7ff8b5859a55141016b41219d583aae6", {"code_string": "def test_basic_queue(self):\n    \"\"\"Test basic QUEUE publish and retrieve.\"\"\"\n    q = self.ps.queue(\"testqueue\")\n    self.assertEqual(q.__class__, Queue)\n    q.put(\"10\")\n    q.put(\"20\")\n    q.put(\"30\")\n    q.put(\"40\")\n    r = []\n    for x in range(0, 4):\n        r.append(q.get(timeout = 2))\n    self.assertEqual(r, [\"10\", \"20\", \"30\", \"40\"], \"Queue results did not match publish.\")\n", "code_toks_joined": "def test_basic_queue ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> q = self . ps . queue ( <STRING> ) <NEWLINE> self . assertEqual ( q . __class__ , Queue ) <NEWLINE> q . put ( <STRING> ) <NEWLINE> q . put ( <STRING> ) <NEWLINE> q . put ( <STRING> ) <NEWLINE> q . put ( <STRING> ) <NEWLINE> r = [ ] <NEWLINE> for x in range ( 0 , 4 ) : <NEWLINE> <INDENT> r . append ( q . get ( timeout = 2 ) ) <NEWLINE> <DEDENT> self . assertEqual ( r , [ <STRING> , <STRING> , <STRING> , <STRING> ] , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test basic QUEUE publish and retrieve.\"\"\"", "\"testqueue\"", "\"10\"", "\"20\"", "\"30\"", "\"40\"", "\"10\"", "\"20\"", "\"30\"", "\"40\"", "\"Queue results did not match publish.\""]}}], ["5b94e87ffceba7c5d47c6551be71ea24", {"code_string": "def __init__(self, info_hash):\n    self.info = redis.hgetall(info_hash)\n    self.info_hash = info_hash\n", "code_toks_joined": "def __init__ ( self , info_hash ) : <NEWLINE> <INDENT> self . info = redis . hgetall ( info_hash ) <NEWLINE> self . info_hash = info_hash <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["59739024f0389a179ff05ff1e4494cfc", {"code_string": "import re\nimport platform\nfrom decimal import Decimal\nfrom urllib import quote\nfrom PyQt4.QtGui import *\nfrom PyQt4.QtCore import *\nimport PyQt4.QtCore as QtCore\nimport PyQt4.QtGui as QtGui\nfrom electrum_boli_gui.qt.qrcodewidget import QRCodeWidget\nfrom electrum_boli.i18n import _\nif platform.system() == 'Windows':\n    MONOSPACE_FONT = 'Lucida Console'\nelif platform.system() == 'Darwin':\n    MONOSPACE_FONT = 'Monaco'\nelse:\n    MONOSPACE_FONT = 'monospace'\ncolumn_index = 4\n", "code_toks_joined": "import re <NEWLINE> import platform <NEWLINE> from decimal import Decimal <NEWLINE> from urllib import quote <NEWLINE> from PyQt4 . QtGui import * <NEWLINE> from PyQt4 . QtCore import * <NEWLINE> import PyQt4 . QtCore as QtCore <NEWLINE> import PyQt4 . QtGui as QtGui <NEWLINE> from electrum_boli_gui . qt . qrcodewidget import QRCodeWidget <NEWLINE> from electrum_boli . i18n import _ <NEWLINE> if platform . system ( ) == <STRING> : <NEWLINE> <INDENT> MONOSPACE_FONT = <STRING> <NEWLINE> <DEDENT> elif platform . system ( ) == <STRING> : <NEWLINE> <INDENT> MONOSPACE_FONT = <STRING> <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> MONOSPACE_FONT = <STRING> <NEWLINE> <DEDENT> column_index = 4 <NEWLINE>", "anonymize_dict": {"<STRING>": ["'Windows'", "'Lucida Console'", "'Darwin'", "'Monaco'", "'monospace'"]}}], ["65489258a65549bb0e718bc9fbdb356f", {"code_string": "\"\"\"homeassistant.bootstrap\"\"\"\nimport os\nimport configparser\nimport logging\nfrom collections import defaultdict\nimport homeassistant\nimport homeassistant.loader as loader\nimport homeassistant.components as core_components\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> import configparser <NEWLINE> import logging <NEWLINE> from collections import defaultdict <NEWLINE> import homeassistant <NEWLINE> import homeassistant . loader as loader <NEWLINE> import homeassistant . components as core_components <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"homeassistant.bootstrap\"\"\""]}}], ["e17b64c2ec5f4234b76b14bf94245fa5", {"code_string": "def extract_images(article_content):\n    \"\"\"Extract the sources of all images in the article.\"\"\"\n    extractor = ImageExtractor()\n    extractor.feed(article_content)\n    return extractor.images\n", "code_toks_joined": "def extract_images ( article_content ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> extractor = ImageExtractor ( ) <NEWLINE> extractor . feed ( article_content ) <NEWLINE> return extractor . images <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Extract the sources of all images in the article.\"\"\""]}}], ["115ec0a6b76499285d20af3c4be1891e", {"code_string": "def read(self, qid):\n    '''Read indices for a given QID'''\n    indexfilepath = glob.glob(os.path.join(self.indexdir, '*%s*' % qid))\n    if len(indexfilepath) == 0:\n        raise Exception('Index file not found: %s', qid)\n    if len(indexfilepath) > 1:\n        raise Exception('Duplicate index files: %s', str(indexfilepath))\n    indexfilepath = indexfilepath[0]\n    indices = self._read_index(qid, indexfilepath)\n    return indices\n", "code_toks_joined": "def read ( self , qid ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> indexfilepath = glob . glob ( os . path . join ( self . indexdir , <STRING> % qid ) ) <NEWLINE> if len ( indexfilepath ) == 0 : <NEWLINE> <INDENT> raise Exception ( <STRING> , qid ) <NEWLINE> <DEDENT> if len ( indexfilepath ) > 1 : <NEWLINE> <INDENT> raise Exception ( <STRING> , str ( indexfilepath ) ) <NEWLINE> <DEDENT> indexfilepath = indexfilepath [ 0 ] <NEWLINE> indices = self . _read_index ( qid , indexfilepath ) <NEWLINE> return indices <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Read indices for a given QID'''", "'*%s*'", "'Index file not found: %s'", "'Duplicate index files: %s'"]}}], ["99993a5993ff44257a4905bb083609f4", {"code_string": "def redirect(self, f = None, args = [], vars = {}, flash = None):\n    \"\"\"self.redirect('name', [], {}, 'message') is a shortcut for\"\"\"\n    if flash:\n        self.session.flash = flash\n    redirect(self.action(f, args, vars))\n", "code_toks_joined": "def redirect ( self , f = None , args = [ ] , vars = { } , flash = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if flash : <NEWLINE> <INDENT> self . session . flash = flash <NEWLINE> <DEDENT> redirect ( self . action ( f , args , vars ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"self.redirect('name', [], {}, 'message') is a shortcut for\"\"\""]}}], ["a5aaa70b7d6be2bbc3175f8bbb66fc8b", {"code_string": "class FeedbackUploadForm(forms.Form):\n    file_upload = forms.FileField(\n        widget = forms.FileInput(\n            attrs = {\n                'class': 'form-control'\n            }\n        )\n    )\n", "code_toks_joined": "class FeedbackUploadForm ( forms . Form ) : <NEWLINE> <INDENT> file_upload = forms . FileField ( <NEWLINE> <INDENT> widget = forms . FileInput ( <NEWLINE> <INDENT> attrs = { <NEWLINE> <INDENT> <STRING> : <STRING> <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'class'", "'form-control'"]}}], ["0f9fd36c256db98de49deecf2cbba40a", {"code_string": "\"\"\"Test helper functions.\"\"\"\nfrom __future__ import absolute_import, print_function\nfrom flask import Blueprint, abort, jsonify, request, session, url_for\nfrom flask_oauthlib.client import OAuth, prepare_request\nfrom mock import MagicMock\nfrom six.moves.urllib.parse import urlparse\nfrom werkzeug.urls import url_decode, url_parse, url_unparse\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import absolute_import , print_function <NEWLINE> from flask import Blueprint , abort , jsonify , request , session , url_for <NEWLINE> from flask_oauthlib . client import OAuth , prepare_request <NEWLINE> from mock import MagicMock <NEWLINE> from six . moves . urllib . parse import urlparse <NEWLINE> from werkzeug . urls import url_decode , url_parse , url_unparse <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Test helper functions.\"\"\""]}}], ["3fa81ad7c9a2349fcaf43300593d83fe", {"code_string": "from soap.semantics.functions.arithmetic import arith_eval, error_eval\nfrom soap.semantics.functions.boolean import bool_eval\nfrom soap.semantics.functions.fixpoint import(\n    fixpoint_eval, unroll_fix_expr, fix_expr_eval\n)\nfrom soap.semantics.functions.label import label, luts, resource_eval\nfrom soap.semantics.functions.meta import expand_expr, expand_meta_state\n", "code_toks_joined": "from soap . semantics . functions . arithmetic import arith_eval , error_eval <NEWLINE> from soap . semantics . functions . boolean import bool_eval <NEWLINE> from soap . semantics . functions . fixpoint import ( <NEWLINE> <INDENT> fixpoint_eval , unroll_fix_expr , fix_expr_eval <NEWLINE> <DEDENT> ) <NEWLINE> from soap . semantics . functions . label import label , luts , resource_eval <NEWLINE> from soap . semantics . functions . meta import expand_expr , expand_meta_state <NEWLINE>", "anonymize_dict": {}}], ["49f2317f1792f40fea34b19ff22ce023", {"code_string": "class Plugin(PluginBase):\n    name = 'plugins'\n    doc = 'Reuturns list of all loaded plugins'\n    methods_subclass = {}\n    def handle_input(self, term_system, term_globals, exec_locals, text):\n        fname, method, args = self.get_method_args(text)\n        ret = list(term_system.plugins)\n        return ret\n", "code_toks_joined": "class Plugin ( PluginBase ) : <NEWLINE> <INDENT> name = <STRING> <NEWLINE> doc = <STRING> <NEWLINE> methods_subclass = { } <NEWLINE> def handle_input ( self , term_system , term_globals , exec_locals , text ) : <NEWLINE> <INDENT> fname , method , args = self . get_method_args ( text ) <NEWLINE> ret = list ( term_system . plugins ) <NEWLINE> return ret <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'plugins'", "'Reuturns list of all loaded plugins'"]}}], ["2812c83ffb93436b4272a1565f73ee17", {"code_string": "class MentalUsException(Exception):\n    code = 0\n    def to_json(self):\n        return dict(code = self.code, msg = self.msg)\n", "code_toks_joined": "class MentalUsException ( Exception ) : <NEWLINE> <INDENT> code = 0 <NEWLINE> def to_json ( self ) : <NEWLINE> <INDENT> return dict ( code = self . code , msg = self . msg ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["8fab92fcdfd95f86e4d4d5a8742a09ba", {"code_string": "class OpenID(object):\n    GOOGLE = 1\n    FACEBOOK = 2\n    TWITTER = 3\n    FRIENDFEED = 4\n    NAME = {GOOGLE: \"Google\", FACEBOOK: \"Facebook\",\n        TWITTER: \"Twitter\", FRIENDFEED: \"Friendfeed\"}\n", "code_toks_joined": "class OpenID ( object ) : <NEWLINE> <INDENT> GOOGLE = 1 <NEWLINE> FACEBOOK = 2 <NEWLINE> TWITTER = 3 <NEWLINE> FRIENDFEED = 4 <NEWLINE> NAME = { GOOGLE : <STRING> , FACEBOOK : <STRING> , <NEWLINE> <INDENT> TWITTER : <STRING> , FRIENDFEED : <STRING> } <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Google\"", "\"Facebook\"", "\"Twitter\"", "\"Friendfeed\""]}}], ["1c15ab65cc2ce8b378b8198e8ad17080", {"code_string": "import optparse\nfrom django.core.management.base import BaseCommand\nfrom cumulus.authentication import Auth\n", "code_toks_joined": "import optparse <NEWLINE> from django . core . management . base import BaseCommand <NEWLINE> from cumulus . authentication import Auth <NEWLINE>", "anonymize_dict": {}}], ["1b730f53a8d703167edae3b6b8ac74c1", {"code_string": "class MissingPackage(ConnectorException):\n    def __init__(self, driver, supported_packages):\n        if not isinstance(supported_packages, list):\n            supported_packages = [supported_packages]\n        message = 'Driver \"%s\" requires ' % driver\n        if len(supported_packages) == 1:\n            message += '\"%s\" package' % supported_packages[0]\n        else:\n            message += 'one of the following packages: \"%s\"' %('\", \"'.join(supported_packages))\n        super(MissingPackage, self).__init__(message)\n", "code_toks_joined": "class MissingPackage ( ConnectorException ) : <NEWLINE> <INDENT> def __init__ ( self , driver , supported_packages ) : <NEWLINE> <INDENT> if not isinstance ( supported_packages , list ) : <NEWLINE> <INDENT> supported_packages = [ supported_packages ] <NEWLINE> <DEDENT> message = <STRING> % driver <NEWLINE> if len ( supported_packages ) == 1 : <NEWLINE> <INDENT> message += <STRING> % supported_packages [ 0 ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> message += <STRING> % ( <STRING> . join ( supported_packages ) ) <NEWLINE> <DEDENT> super ( MissingPackage , self ) . __init__ ( message ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Driver \"%s\" requires '", "'\"%s\" package'", "'one of the following packages: \"%s\"'", "'\", \"'"]}}], ["30d947baddda256634fc455b8c6ef81b", {"code_string": "def generate_search_index(self):\n    \"\"\"python to json conversion\"\"\"\n    page_dicts = {\n        'docs': self._entries,\n    }\n    return json.dumps(page_dicts, sort_keys = True, indent = 4)\n", "code_toks_joined": "def generate_search_index ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> page_dicts = { <NEWLINE> <INDENT> <STRING> : self . _entries , <NEWLINE> <DEDENT> } <NEWLINE> return json . dumps ( page_dicts , sort_keys = True , indent = 4 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"python to json conversion\"\"\"", "'docs'"]}}], ["1c8151e7828758d6953769080498ebc7", {"code_string": "class Lungs(object):\n    def __init__(self, msml_filename, p):\n        self.app = App(exporter = 'nsofa', output_dir = 'batchedPressureNew' + str(p), executor = 'sequential')\n        self.mf = self.app._load_msml_file(msml_filename)\n        self._surface_pressure = p\n    def __call__(self):\n        self.app.memory_init_file = {\n            \"surface_pressure\": self._surface_pressure\n        }\n        mem = self.app.execute_msml(self.mf, )\n        return mem._internal['volumeMeasure']['volume']\n", "code_toks_joined": "class Lungs ( object ) : <NEWLINE> <INDENT> def __init__ ( self , msml_filename , p ) : <NEWLINE> <INDENT> self . app = App ( exporter = <STRING> , output_dir = <STRING> + str ( p ) , executor = <STRING> ) <NEWLINE> self . mf = self . app . _load_msml_file ( msml_filename ) <NEWLINE> self . _surface_pressure = p <NEWLINE> <DEDENT> def __call__ ( self ) : <NEWLINE> <INDENT> self . app . memory_init_file = { <NEWLINE> <INDENT> <STRING> : self . _surface_pressure <NEWLINE> <DEDENT> } <NEWLINE> mem = self . app . execute_msml ( self . mf , ) <NEWLINE> return mem . _internal [ <STRING> ] [ <STRING> ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'nsofa'", "'batchedPressureNew'", "'sequential'", "\"surface_pressure\"", "'volumeMeasure'", "'volume'"]}}], ["e720004a73450334d2d972e14b73638c", {"code_string": "def test_instance_type_extra_specs_update(self):\n    self.specs[\"cpu_model\"] = \"Sandy Bridge\"\n    db.flavor_extra_specs_update_or_create(\n        self.context,\n        self.flavorid,\n        dict(cpu_model = \"Sandy Bridge\"))\n    actual_specs = db.flavor_extra_specs_get(\n        self.context,\n        self.flavorid)\n    self.assertEqual(self.specs, actual_specs)\n", "code_toks_joined": "def test_instance_type_extra_specs_update ( self ) : <NEWLINE> <INDENT> self . specs [ <STRING> ] = <STRING> <NEWLINE> db . flavor_extra_specs_update_or_create ( <NEWLINE> <INDENT> self . context , <NEWLINE> self . flavorid , <NEWLINE> dict ( cpu_model = <STRING> ) ) <NEWLINE> <DEDENT> actual_specs = db . flavor_extra_specs_get ( <NEWLINE> <INDENT> self . context , <NEWLINE> self . flavorid ) <NEWLINE> <DEDENT> self . assertEqual ( self . specs , actual_specs ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"cpu_model\"", "\"Sandy Bridge\"", "\"Sandy Bridge\""]}}], ["ebadbf5ac1345191abdc9a00c3ae90fb", {"code_string": "'''Created by Daniel Sindhikara, sindhikara@gmail.com'''\nfrom __future__ import division\nimport grid.grid as grid\nimport sys\nimport argparse\nimport os\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import division <NEWLINE> import grid . grid as grid <NEWLINE> import sys <NEWLINE> import argparse <NEWLINE> import os <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Created by Daniel Sindhikara, sindhikara@gmail.com'''"]}}], ["e58fce67f97359b3b88908b76804ffdd", {"code_string": "def makeHeader(resultList, path, timestep, name, units):\n    resultList.Add(\"key:location/dataType/units/frequency/startsAt/endsAt\", GH_Path(path))\n    resultList.Add(location, GH_Path(path))\n    resultList.Add(name, GH_Path(path))\n    resultList.Add(units, GH_Path(path))\n    resultList.Add(timestep, GH_Path(path))\n    resultList.Add(start, GH_Path(path))\n    resultList.Add(end, GH_Path(path))\n", "code_toks_joined": "def makeHeader ( resultList , path , timestep , name , units ) : <NEWLINE> <INDENT> resultList . Add ( <STRING> , GH_Path ( path ) ) <NEWLINE> resultList . Add ( location , GH_Path ( path ) ) <NEWLINE> resultList . Add ( name , GH_Path ( path ) ) <NEWLINE> resultList . Add ( units , GH_Path ( path ) ) <NEWLINE> resultList . Add ( timestep , GH_Path ( path ) ) <NEWLINE> resultList . Add ( start , GH_Path ( path ) ) <NEWLINE> resultList . Add ( end , GH_Path ( path ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"key:location/dataType/units/frequency/startsAt/endsAt\""]}}], ["415cdc96d4a5b7bfd21927d83e42f205", {"code_string": "def buildCircle(name):\n    cmds.circle(name = name, c = (0, 0, 0), nr = (0, 1, 0), sw = 360, r = 1, d = 3, ut = 0, tol = 0.0001, s = 8, ch = False)\n    getShape = cmds.listRelatives(name, shapes = True)\n    cmds.rename(getShape[0], '{}Shape'.format(name))\n    return name\n", "code_toks_joined": "def buildCircle ( name ) : <NEWLINE> <INDENT> cmds . circle ( name = name , c = ( 0 , 0 , 0 ) , nr = ( 0 , 1 , 0 ) , sw = 360 , r = 1 , d = 3 , ut = 0 , tol = 0.0001 , s = 8 , ch = False ) <NEWLINE> getShape = cmds . listRelatives ( name , shapes = True ) <NEWLINE> cmds . rename ( getShape [ 0 ] , <STRING> . format ( name ) ) <NEWLINE> return name <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'{}Shape'"]}}], ["5695791d07f56108585d50b0e4dadd31", {"code_string": "if __name__ == \"__main__\":\n    f = open('access.log', 'w');\n    for i in range(2048):\n        s = \"element \" + str(i) + \" on file\\n\"\n        f.write(s)\n    f.close()\n", "code_toks_joined": "if __name__ == <STRING> : <NEWLINE> <INDENT> f = open ( <STRING> , <STRING> ) ; <NEWLINE> for i in range ( 2048 ) : <NEWLINE> <INDENT> s = <STRING> + str ( i ) + <STRING> <NEWLINE> f . write ( s ) <NEWLINE> <DEDENT> f . close ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"__main__\"", "'access.log'", "'w'", "\"element \"", "\" on file\\n\""]}}], ["630b3ff3173cce580c831a6ca2d7d196", {"code_string": "import datetime\nimport logging\nimport random\nfrom mixer.backend.flask import Mixer\nimport mixer.fakers as mxfake\nimport mixer.generators as mxgen\nimport pytz\nfrom six.moves import range\nfrom trafficdb.models import *\nlog = logging.getLogger(__name__)\nDEFAULT_START = datetime.datetime(2013, 4, 29, tzinfo = pytz.utc)\n", "code_toks_joined": "import datetime <NEWLINE> import logging <NEWLINE> import random <NEWLINE> from mixer . backend . flask import Mixer <NEWLINE> import mixer . fakers as mxfake <NEWLINE> import mixer . generators as mxgen <NEWLINE> import pytz <NEWLINE> from six . moves import range <NEWLINE> from trafficdb . models import * <NEWLINE> log = logging . getLogger ( __name__ ) <NEWLINE> DEFAULT_START = datetime . datetime ( 2013 , 4 , 29 , tzinfo = pytz . utc ) <NEWLINE>", "anonymize_dict": {}}], ["403afe41c6c222a25926017a4248d479", {"code_string": "class GridSearch(GridSearchCV):\n    \"\"\"Wrapper around GridSearchCV; workaround for scikit-learn issue #3484.\"\"\"\n    def decision_function(self, X):\n        return super(GridSearch, self).decision_function(X)\n    def predict(self, X):\n        return super(GridSearch, self).predict(X)\n", "code_toks_joined": "class GridSearch ( GridSearchCV ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def decision_function ( self , X ) : <NEWLINE> <INDENT> return super ( GridSearch , self ) . decision_function ( X ) <NEWLINE> <DEDENT> def predict ( self , X ) : <NEWLINE> <INDENT> return super ( GridSearch , self ) . predict ( X ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Wrapper around GridSearchCV; workaround for scikit-learn issue #3484.\"\"\""]}}], ["730996c00f7cc337a4d4dd5d085d3023", {"code_string": "from.import timers\nfrom.time_zone import TimeZone\n__all__ = ['TimeZone',\n    'timers']\n", "code_toks_joined": "from . import timers <NEWLINE> from . time_zone import TimeZone <NEWLINE> __all__ = [ <STRING> , <NEWLINE> <INDENT> <STRING> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'TimeZone'", "'timers'"]}}], ["294e03e704138bce62470673ca1ae2f6", {"code_string": "a, b = 2, 2\nprint('% 8d' % a)\nprint('x% 7d' % b)\nc = b\nprint('-' * 8)\ni = 8\nwhile c > 0:\n    print('% *d' %(i, (c % 10) * a))\n    c = c / 10\n    i -= 1\nif i == 7:\n    print('*' * 20)\nelse:\n    print('-' * 8)\n    print('% 8d' %(a * b))\n    print('*' * 20)\n", "code_toks_joined": "a , b = 2 , 2 <NEWLINE> print ( <STRING> % a ) <NEWLINE> print ( <STRING> % b ) <NEWLINE> c = b <NEWLINE> print ( <STRING> * 8 ) <NEWLINE> i = 8 <NEWLINE> while c > 0 : <NEWLINE> <INDENT> print ( <STRING> % ( i , ( c % 10 ) * a ) ) <NEWLINE> c = c / 10 <NEWLINE> i -= 1 <NEWLINE> <DEDENT> if i == 7 : <NEWLINE> <INDENT> print ( <STRING> * 20 ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> print ( <STRING> * 8 ) <NEWLINE> print ( <STRING> % ( a * b ) ) <NEWLINE> print ( <STRING> * 20 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'% 8d'", "'x% 7d'", "'-'", "'% *d'", "'*'", "'-'", "'% 8d'", "'*'"]}}], ["dc7f0e4066cdec4585a40926249f5f43", {"code_string": "import os\nimport pytest\nfrom contextlib import contextmanager\nfrom twitter.common.contextutil import temporary_dir\nfrom twitter.common.dirutil import Fileset as RealFileset, touch\n", "code_toks_joined": "import os <NEWLINE> import pytest <NEWLINE> from contextlib import contextmanager <NEWLINE> from twitter . common . contextutil import temporary_dir <NEWLINE> from twitter . common . dirutil import Fileset as RealFileset , touch <NEWLINE>", "anonymize_dict": {}}], ["d83c7eae034597e96a190faac548d3ec", {"code_string": "def checkTraficLightBH(self):\n    self.activityTimer.callback.remove(self.checkTraficLightBH)\n    self.activityTimer.start(100, False)\n    self.startActualUpdate(True)\n", "code_toks_joined": "def checkTraficLightBH ( self ) : <NEWLINE> <INDENT> self . activityTimer . callback . remove ( self . checkTraficLightBH ) <NEWLINE> self . activityTimer . start ( 100 , False ) <NEWLINE> self . startActualUpdate ( True ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["a41b1b6e4cc7400a06775e64721a6c05", {"code_string": "\"\"\"@name:      PyHouse/src/Modules/families/UPB/test/test_UPB_device.py\"\"\"\n__updated__ = '2017-01-19'\nimport xml.etree.ElementTree as ET\nfrom twisted.trial import unittest\nfrom Modules.Families.UPB.UPB_device import API as upbDeviceAPI\nfrom test.xml_data import XML_LONG, TESTING_PYHOUSE\nfrom test.testing_mixin import SetupPyHouseObj\n", "code_toks_joined": "<STRING> <NEWLINE> __updated__ = <STRING> <NEWLINE> import xml . etree . ElementTree as ET <NEWLINE> from twisted . trial import unittest <NEWLINE> from Modules . Families . UPB . UPB_device import API as upbDeviceAPI <NEWLINE> from test . xml_data import XML_LONG , TESTING_PYHOUSE <NEWLINE> from test . testing_mixin import SetupPyHouseObj <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"@name:      PyHouse/src/Modules/families/UPB/test/test_UPB_device.py\"\"\"", "'2017-01-19'"]}}], ["57c9db6d27ceb633573fb2f65e58c706", {"code_string": "import W\nfrom Carbon import Windows\nw = W.ModalDialog((100, 100))\nw.ed = W.EditText((10, 10, 80, 50))\nw.ok = W.Button((10, 70, 80, 16), \"Ok\", w.close)\nw.setdefaultbutton(w.ok)\nw.open()\n", "code_toks_joined": "import W <NEWLINE> from Carbon import Windows <NEWLINE> w = W . ModalDialog ( ( 100 , 100 ) ) <NEWLINE> w . ed = W . EditText ( ( 10 , 10 , 80 , 50 ) ) <NEWLINE> w . ok = W . Button ( ( 10 , 70 , 80 , 16 ) , <STRING> , w . close ) <NEWLINE> w . setdefaultbutton ( w . ok ) <NEWLINE> w . open ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"Ok\""]}}], ["2b76b5edcefc3208ec765778481f92c4", {"code_string": "def test_write_to_completion_cache(self):\n    manager = base.Manager()\n    manager.write_to_completion_cache(\"non-exist\", \"val\")\n    manager._mock_cache = mock.Mock()\n    manager._mock_cache.write = mock.Mock(return_value = None)\n    manager.write_to_completion_cache(\"mock\", \"val\")\n    self.assertEqual(1, manager._mock_cache.write.call_count)\n", "code_toks_joined": "def test_write_to_completion_cache ( self ) : <NEWLINE> <INDENT> manager = base . Manager ( ) <NEWLINE> manager . write_to_completion_cache ( <STRING> , <STRING> ) <NEWLINE> manager . _mock_cache = mock . Mock ( ) <NEWLINE> manager . _mock_cache . write = mock . Mock ( return_value = None ) <NEWLINE> manager . write_to_completion_cache ( <STRING> , <STRING> ) <NEWLINE> self . assertEqual ( 1 , manager . _mock_cache . write . call_count ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"non-exist\"", "\"val\"", "\"mock\"", "\"val\""]}}], ["eb35d8a6cdf91cefe20039e5c7e19665", {"code_string": "from django.conf import settings\nfrom django.contrib import messages\nfrom django.contrib.auth.models import User\nfrom django.core.urlresolvers import reverse\nfrom django.db.models.signals import post_save, pre_save, post_delete, pre_delete\nfrom django.dispatch import receiver\nfrom django.http import HttpResponse, HttpResponseRedirect, Http404\nfrom django.shortcuts import render, get_object_or_404, redirect\nfrom django.utils.translation import ugettext as _\n", "code_toks_joined": "from django . conf import settings <NEWLINE> from django . contrib import messages <NEWLINE> from django . contrib . auth . models import User <NEWLINE> from django . core . urlresolvers import reverse <NEWLINE> from django . db . models . signals import post_save , pre_save , post_delete , pre_delete <NEWLINE> from django . dispatch import receiver <NEWLINE> from django . http import HttpResponse , HttpResponseRedirect , Http404 <NEWLINE> from django . shortcuts import render , get_object_or_404 , redirect <NEWLINE> from django . utils . translation import ugettext as _ <NEWLINE>", "anonymize_dict": {}}], ["5e43b1ec071376e981b9511f11a5372a", {"code_string": "def print_anagrams(sorted_words, all_words):\n    match_count = 0\n    valid_set = set(all_words)\n    matches = defaultdict(list)\n    for word in sorted_words:\n        if word in valid_set:\n            sorted_letters = ''.join(sorted(word))\n            matching_words = matches[sorted_letters]\n            matching_words.append(word)\n            if len(matching_words) > 1:\n                print('\\n'.join(matching_words))\n                print\n                match_count += 1\n                if match_count > 100:\n                    return\n", "code_toks_joined": "def print_anagrams ( sorted_words , all_words ) : <NEWLINE> <INDENT> match_count = 0 <NEWLINE> valid_set = set ( all_words ) <NEWLINE> matches = defaultdict ( list ) <NEWLINE> for word in sorted_words : <NEWLINE> <INDENT> if word in valid_set : <NEWLINE> <INDENT> sorted_letters = <STRING> . join ( sorted ( word ) ) <NEWLINE> matching_words = matches [ sorted_letters ] <NEWLINE> matching_words . append ( word ) <NEWLINE> if len ( matching_words ) > 1 : <NEWLINE> <INDENT> print ( <STRING> . join ( matching_words ) ) <NEWLINE> print <NEWLINE> match_count += 1 <NEWLINE> if match_count > 100 : <NEWLINE> <INDENT> return <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["''", "'\\n'"]}}], ["a957db4fda10e3e086f1f7f971a2b81e", {"code_string": "\"\"\"Created on Sun Jan 29 20:44:27 2017\"\"\"\nimport cv2\nimport sys\nimport cvutil as u\ncap = u.source_video(sys.argv)\ncount = 0\nwhile(count < 10):\n    count += 1\n    _, frame = cap.read()\n    cv2.imshow('frame', frame)\n    cv2.imwrite(\"../videos/frames/frame_{0}.png\".format(count), frame)\ncv2.destroyAllWindows()\n", "code_toks_joined": "<STRING> <NEWLINE> import cv2 <NEWLINE> import sys <NEWLINE> import cvutil as u <NEWLINE> cap = u . source_video ( sys . argv ) <NEWLINE> count = 0 <NEWLINE> while ( count < 10 ) : <NEWLINE> <INDENT> count += 1 <NEWLINE> _ , frame = cap . read ( ) <NEWLINE> cv2 . imshow ( <STRING> , frame ) <NEWLINE> cv2 . imwrite ( <STRING> . format ( count ) , frame ) <NEWLINE> <DEDENT> cv2 . destroyAllWindows ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Created on Sun Jan 29 20:44:27 2017\"\"\"", "'frame'", "\"../videos/frames/frame_{0}.png\""]}}], ["be2c0a2a6ed6d73f907f8b30c79c55a9", {"code_string": "def add_pilot_from_values(self, pilot_name, aircraft, livery):\n    pilot = Roster.Pilot(pilot_name, aircraft, livery)\n    self.add_pilot_object(pilot)\n", "code_toks_joined": "def add_pilot_from_values ( self , pilot_name , aircraft , livery ) : <NEWLINE> <INDENT> pilot = Roster . Pilot ( pilot_name , aircraft , livery ) <NEWLINE> self . add_pilot_object ( pilot ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["6bc91922fbeed883b51e8f26470af6db", {"code_string": "def decrypt(test_key):\n    cnt = Counter(test_key)\n    return ''.join(str(cnt[a]) for a in ascii_lowercase)\n", "code_toks_joined": "def decrypt ( test_key ) : <NEWLINE> <INDENT> cnt = Counter ( test_key ) <NEWLINE> return <STRING> . join ( str ( cnt [ a ] ) for a in ascii_lowercase ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["''"]}}], ["a772579154781a72a22ccfa4a1b7b656", {"code_string": "class DynamicExtended(OneOf):\n    '''Container that provides mutations based on the dynamic value,'''\n    def __init__(self, key, value, additional_field, fuzzable = True, name = None):\n        ''':param key: key for data in the session information'''\n        if name is None:\n            name = key\n        fields = [\n            Dynamic(key = key, default_value = value, length = len(value), fuzzable = True, name = _join_name(name, 'dynamic')),\n            additional_field\n        ]\n        super(DynamicExtended, self).__init__(fields = fields, fuzzable = fuzzable, name = name)\n", "code_toks_joined": "class DynamicExtended ( OneOf ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , key , value , additional_field , fuzzable = True , name = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if name is None : <NEWLINE> <INDENT> name = key <NEWLINE> <DEDENT> fields = [ <NEWLINE> <INDENT> Dynamic ( key = key , default_value = value , length = len ( value ) , fuzzable = True , name = _join_name ( name , <STRING> ) ) , <NEWLINE> additional_field <NEWLINE> <DEDENT> ] <NEWLINE> super ( DynamicExtended , self ) . __init__ ( fields = fields , fuzzable = fuzzable , name = name ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Container that provides mutations based on the dynamic value,'''", "''':param key: key for data in the session information'''", "'dynamic'"]}}], ["f2ef87edb7ece37436a416cdb097c0db", {"code_string": "def test_safedata(self):\n    \"\"\"Tests that a message containing SafeData is keeping its safe status when\"\"\"\n    def encode_decode(data):\n        message = Message(constants.DEBUG, data)\n        encoded = storage._encode(message)\n        decoded = storage._decode(encoded)\n        return decoded.message\n    storage = self.get_storage()\n    self.assertIsInstance(\n        encode_decode(mark_safe(\"<b>Hello Django!</b>\")), SafeData)\n    self.assertNotIsInstance(\n        encode_decode(\"<b>Hello Django!</b>\"), SafeData)\n", "code_toks_joined": "def test_safedata ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def encode_decode ( data ) : <NEWLINE> <INDENT> message = Message ( constants . DEBUG , data ) <NEWLINE> encoded = storage . _encode ( message ) <NEWLINE> decoded = storage . _decode ( encoded ) <NEWLINE> return decoded . message <NEWLINE> <DEDENT> storage = self . get_storage ( ) <NEWLINE> self . assertIsInstance ( <NEWLINE> <INDENT> encode_decode ( mark_safe ( <STRING> ) ) , SafeData ) <NEWLINE> <DEDENT> self . assertNotIsInstance ( <NEWLINE> <INDENT> encode_decode ( <STRING> ) , SafeData ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Tests that a message containing SafeData is keeping its safe status when\"\"\"", "\"<b>Hello Django!</b>\"", "\"<b>Hello Django!</b>\""]}}], ["6a5fe842dda45c964f8e0bd05420704a", {"code_string": "def is_demo(self):\n    \"\"\"Whether the collection is one of the demo collections.\"\"\"\n    return self.is_demo_collection_id(self.id)\n", "code_toks_joined": "def is_demo ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . is_demo_collection_id ( self . id ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Whether the collection is one of the demo collections.\"\"\""]}}], ["31b3839c0431e61f3116120f9b0bd441", {"code_string": "import pytest\nfrom tests.globals import local_filepath, remote_filepath\nfrom xsdtocls.tools import cli\n", "code_toks_joined": "import pytest <NEWLINE> from tests . globals import local_filepath , remote_filepath <NEWLINE> from xsdtocls . tools import cli <NEWLINE>", "anonymize_dict": {}}], ["ebeea34de350f922243c5de93f3ef56e", {"code_string": "def test_countdown_after_start_returns_countdown_to_end(self, event):\n    event.end = arrow.utcnow().replace(minutes = + 5, seconds = + 1)\n    countdown = event.countdown()\n    expected = \"00:05:00 until the end of {0}\".format(event.summary)\n    assert countdown == expected\n", "code_toks_joined": "def test_countdown_after_start_returns_countdown_to_end ( self , event ) : <NEWLINE> <INDENT> event . end = arrow . utcnow ( ) . replace ( minutes = + 5 , seconds = + 1 ) <NEWLINE> countdown = event . countdown ( ) <NEWLINE> expected = <STRING> . format ( event . summary ) <NEWLINE> assert countdown == expected <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"00:05:00 until the end of {0}\""]}}], ["3b21b98be5da3d31e6152deb18a2c549", {"code_string": "def delete_tag(self, context, resource, resource_id, tag):\n    res = self._get_resource(context, resource, resource_id)\n    with context.session.begin(subtransactions = True):\n        query = context.session.query(tag_model.Tag)\n        query = query.filter_by(tag = tag,\n            standard_attr_id = res.standard_attr_id)\n        if not query.delete():\n            raise tag_ext.TagNotFound(tag = tag)\n", "code_toks_joined": "def delete_tag ( self , context , resource , resource_id , tag ) : <NEWLINE> <INDENT> res = self . _get_resource ( context , resource , resource_id ) <NEWLINE> with context . session . begin ( subtransactions = True ) : <NEWLINE> <INDENT> query = context . session . query ( tag_model . Tag ) <NEWLINE> query = query . filter_by ( tag = tag , <NEWLINE> <INDENT> standard_attr_id = res . standard_attr_id ) <NEWLINE> <DEDENT> if not query . delete ( ) : <NEWLINE> <INDENT> raise tag_ext . TagNotFound ( tag = tag ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["14c22de79e477da7e1d1d98d48938552", {"code_string": "def get_url(s):\n    m = _re_match_url.search(s)\n    if not m:\n        return None\n    return m.group(1)\n", "code_toks_joined": "def get_url ( s ) : <NEWLINE> <INDENT> m = _re_match_url . search ( s ) <NEWLINE> if not m : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> return m . group ( 1 ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["f055806018f88278aa378af7a7ec5c7f", {"code_string": "\"\"\"__init__.py\"\"\"\nfrom hashdd import hashdd\n", "code_toks_joined": "<STRING> <NEWLINE> from hashdd import hashdd <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"__init__.py\"\"\""]}}], ["452b7468a32da7a42ef53e332cb97769", {"code_string": "def filter_dict_by_keys(dict_, field_names):\n    \"\"\" Returns a copy of `dict_` with only the fields in `field_names`\"\"\"\n    return{key: value for(key, value) in dict_.items()\n        if key in field_names}\n", "code_toks_joined": "def filter_dict_by_keys ( dict_ , field_names ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return { key : value for ( key , value ) in dict_ . items ( ) <NEWLINE> <INDENT> if key in field_names } <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Returns a copy of `dict_` with only the fields in `field_names`\"\"\""]}}], ["75a6a88cfd5d3a6d8b51260a50b8859c", {"code_string": "def valid_low_rate(self, device):\n    \"\"\"set the rate to the lowest supported audio rate.\"\"\"\n    for testrate in[25000]:\n        if self.valid_test(device, testrate):\n            return testrate\n    print(\"SOMETHING'S WRONG! I can't figure out how to use DEV\", device)\n    return None\n", "code_toks_joined": "def valid_low_rate ( self , device ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> for testrate in [ 25000 ] : <NEWLINE> <INDENT> if self . valid_test ( device , testrate ) : <NEWLINE> <INDENT> return testrate <NEWLINE> <DEDENT> <DEDENT> print ( <STRING> , device ) <NEWLINE> return None <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"set the rate to the lowest supported audio rate.\"\"\"", "\"SOMETHING'S WRONG! I can't figure out how to use DEV\""]}}], ["a6740ce33a2fc43a63e09718cfebb292", {"code_string": "def _get_url(self, resource):\n    if is_collection(resource):\n        resource = map(str, resource)\n        resource = '/'.join(resource)\n    return resource\n", "code_toks_joined": "def _get_url ( self , resource ) : <NEWLINE> <INDENT> if is_collection ( resource ) : <NEWLINE> <INDENT> resource = map ( str , resource ) <NEWLINE> resource = <STRING> . join ( resource ) <NEWLINE> <DEDENT> return resource <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/'"]}}], ["fd3eb4d74a27d43471c4202d6d0089fa", {"code_string": "def get_match(self, pattern, source, default = ''):\n    res = re.findall(pattern, source)\n    if len(res) > 0:\n        return res[0]\n    else:\n        return default\n", "code_toks_joined": "def get_match ( self , pattern , source , default = <STRING> ) : <NEWLINE> <INDENT> res = re . findall ( pattern , source ) <NEWLINE> if len ( res ) > 0 : <NEWLINE> <INDENT> return res [ 0 ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return default <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["''"]}}], ["e923b99729fedcac51c1cbf45fac79fc", {"code_string": "def dumps(* args, ** kwargs):\n    kwargs['default'] = Processor()\n    return json.dumps(* args, ** kwargs)\n", "code_toks_joined": "def dumps ( * args , ** kwargs ) : <NEWLINE> <INDENT> kwargs [ <STRING> ] = Processor ( ) <NEWLINE> return json . dumps ( * args , ** kwargs ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'default'"]}}], ["6dfd9be0eed44a31bb5cce3e1cb48d90", {"code_string": "def tearDown(self):\n    tablet.Tablet.check_vttablet_count()\n    for t in[master_tablet, replica_tablet]:\n        t.reset_replication()\n        t.set_semi_sync_enabled(master = False)\n        t.clean_dbs()\n", "code_toks_joined": "def tearDown ( self ) : <NEWLINE> <INDENT> tablet . Tablet . check_vttablet_count ( ) <NEWLINE> for t in [ master_tablet , replica_tablet ] : <NEWLINE> <INDENT> t . reset_replication ( ) <NEWLINE> t . set_semi_sync_enabled ( master = False ) <NEWLINE> t . clean_dbs ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["a1559aeb1de837cc50fa1374444154f2", {"code_string": "from django.conf.urls import *\nfrom localwiki.utils.views import GetCSRFCookieView\nurlpatterns = patterns('',\n    url(r'^pages/suggest/?$', 'pages.views.suggest'),\n    url(r'^regions/suggest/?$', 'regions.views.suggest'),\n    url(r'^tags/suggest/?$', 'tags.views.suggest_tags'),\n    url(r'^users/suggest/(?P<region>[^/]+?)/?$', 'users.views.suggest_users'),\n    url(r'^_get/csrf_cookie/?$', GetCSRFCookieView.as_view(), name = 'get_csrf_cookie'),\n)\n", "code_toks_joined": "from django . conf . urls import * <NEWLINE> from localwiki . utils . views import GetCSRFCookieView <NEWLINE> urlpatterns = patterns ( <STRING> , <NEWLINE> <INDENT> url ( <STRING> , <STRING> ) , <NEWLINE> url ( <STRING> , <STRING> ) , <NEWLINE> url ( <STRING> , <STRING> ) , <NEWLINE> url ( <STRING> , <STRING> ) , <NEWLINE> url ( <STRING> , GetCSRFCookieView . as_view ( ) , name = <STRING> ) , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["''", "r'^pages/suggest/?$'", "'pages.views.suggest'", "r'^regions/suggest/?$'", "'regions.views.suggest'", "r'^tags/suggest/?$'", "'tags.views.suggest_tags'", "r'^users/suggest/(?P<region>[^/]+?)/?$'", "'users.views.suggest_users'", "r'^_get/csrf_cookie/?$'", "'get_csrf_cookie'"]}}], ["b1183d1e7fb817ef9dcd2b786b9fcdf9", {"code_string": "def get_similar(asin):\n    baseurl = r'http://webservices.amazon.com/onca/xml?'\n    service = r'Service=AWSECommerceService'\n    amazonid = '1THTW69EYJTSND8GNA02'\n    access = r'&AWSAccessKeyId=' + amazonid\n    operation = r'&Operation=SimilarityLookup&ItemId=' + asin\n    r = urllib.urlopen(baseurl + service + access + operation)\n    return r\n", "code_toks_joined": "def get_similar ( asin ) : <NEWLINE> <INDENT> baseurl = <STRING> <NEWLINE> service = <STRING> <NEWLINE> amazonid = <STRING> <NEWLINE> access = <STRING> + amazonid <NEWLINE> operation = <STRING> + asin <NEWLINE> r = urllib . urlopen ( baseurl + service + access + operation ) <NEWLINE> return r <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["r'http://webservices.amazon.com/onca/xml?'", "r'Service=AWSECommerceService'", "'1THTW69EYJTSND8GNA02'", "r'&AWSAccessKeyId='", "r'&Operation=SimilarityLookup&ItemId='"]}}], ["700ee9f236d6195e8de975e3ce36f905", {"code_string": "from arduino import *\nmyservo = Servo()\npos = 0\npin = 11\nmyservo.attach(pin)\n", "code_toks_joined": "from arduino import * <NEWLINE> myservo = Servo ( ) <NEWLINE> pos = 0 <NEWLINE> pin = 11 <NEWLINE> myservo . attach ( pin ) <NEWLINE>", "anonymize_dict": {}}], ["7f71387277b3ff3ed137b06779746516", {"code_string": "from aux.system.base import BaseSystem\nfrom aux.authentication import BaseCredentials\nfrom aux.api import ssh\n", "code_toks_joined": "from aux . system . base import BaseSystem <NEWLINE> from aux . authentication import BaseCredentials <NEWLINE> from aux . api import ssh <NEWLINE>", "anonymize_dict": {}}], ["5f9a85c844fc4773efe244707418bfe8", {"code_string": "def __init__(self, method, start_response, context):\n    self.method = method\n    self.start_response = start_response\n    self.context = context\n    self._write_buffer = []\n    self._finished = False\n    self._expected_content_remaining = None\n    self._error = None\n", "code_toks_joined": "def __init__ ( self , method , start_response , context ) : <NEWLINE> <INDENT> self . method = method <NEWLINE> self . start_response = start_response <NEWLINE> self . context = context <NEWLINE> self . _write_buffer = [ ] <NEWLINE> self . _finished = False <NEWLINE> self . _expected_content_remaining = None <NEWLINE> self . _error = None <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["1503d108764c66588dc6210643ca8415", {"code_string": "from openerp.tools.translate import _\nfrom openerp.osv import fields, osv\nimport openerp.addons.decimal_precision as dp\n", "code_toks_joined": "from openerp . tools . translate import _ <NEWLINE> from openerp . osv import fields , osv <NEWLINE> import openerp . addons . decimal_precision as dp <NEWLINE>", "anonymize_dict": {}}], ["69170dea4259215f68015f4b27da90c7", {"code_string": "def __str__(self):\n    '''retourne le checkFile sous une forme lisible pour l'humain.'''\n    return \"CheckFile de chemin : {} et avec champs : {} \".format(self.pathField, self.fieldList)\n", "code_toks_joined": "def __str__ ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return <STRING> . format ( self . pathField , self . fieldList ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''retourne le checkFile sous une forme lisible pour l'humain.'''", "\"CheckFile de chemin : {} et avec champs : {} \""]}}], ["37ea5d2ff1809c3afee28282bd39bd55", {"code_string": "class MainConfigDirectory(ConfigDirectory):\n    \"\"\"ConfigDirectory with name set to a default name for configuration.\"\"\"\n    __pathname__ = CONFIG_DIR_PATHNAME\n", "code_toks_joined": "class MainConfigDirectory ( ConfigDirectory ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> __pathname__ = CONFIG_DIR_PATHNAME <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"ConfigDirectory with name set to a default name for configuration.\"\"\""]}}], ["796d5e2058402b44421a750a05505c9d", {"code_string": "def true_pos_handler(msg):\n    true_pos[0] = msg.pose.position.x\n    true_pos[1] = msg.pose.position.y\n    true_pos[2] = msg.pose.position.z\n", "code_toks_joined": "def true_pos_handler ( msg ) : <NEWLINE> <INDENT> true_pos [ 0 ] = msg . pose . position . x <NEWLINE> true_pos [ 1 ] = msg . pose . position . y <NEWLINE> true_pos [ 2 ] = msg . pose . position . z <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["18ff5aea829e4b8c44a9c385fa6dbeab", {"code_string": "from django.contrib.auth.mixins import LoginRequiredMixin\nfrom django.core.exceptions import PermissionDenied\nfrom django.shortcuts import get_object_or_404, redirect\nfrom django.urls import reverse\nfrom django.views.generic.base import TemplateView\nfrom projects.models import Project\n", "code_toks_joined": "from django . contrib . auth . mixins import LoginRequiredMixin <NEWLINE> from django . core . exceptions import PermissionDenied <NEWLINE> from django . shortcuts import get_object_or_404 , redirect <NEWLINE> from django . urls import reverse <NEWLINE> from django . views . generic . base import TemplateView <NEWLINE> from projects . models import Project <NEWLINE>", "anonymize_dict": {}}], ["f92873324de7e4e58539400a414f028e", {"code_string": "from unittest import TestCase\ntry:\n    from unittest import mock\nexcept ImportError:\n    import mock\nfrom bettercache.middleware import BetterCacheMiddleware\n", "code_toks_joined": "from unittest import TestCase <NEWLINE> try : <NEWLINE> <INDENT> from unittest import mock <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> import mock <NEWLINE> <DEDENT> from bettercache . middleware import BetterCacheMiddleware <NEWLINE>", "anonymize_dict": {}}], ["6182348c9eb132ed6b26f4083b56a2b1", {"code_string": "import shutil\nimport sys\nimport os\nimport re\nfrom optparse import OptionParser\n", "code_toks_joined": "import shutil <NEWLINE> import sys <NEWLINE> import os <NEWLINE> import re <NEWLINE> from optparse import OptionParser <NEWLINE>", "anonymize_dict": {}}], ["6c5f9f2570514145c6070a50afcb4b4c", {"code_string": "class TestLogin(unittest.TestCase):\n    def testmadison(self):\n        f = open(\"librarybot/fixtures/koha/madison-login.htm\", \"r\")\n        html = f.read()\n        page = koha.LoginPage(None, html)\n        action, data = page.createPost(\"myuser\", \"mypassword\")\n", "code_toks_joined": "class TestLogin ( unittest . TestCase ) : <NEWLINE> <INDENT> def testmadison ( self ) : <NEWLINE> <INDENT> f = open ( <STRING> , <STRING> ) <NEWLINE> html = f . read ( ) <NEWLINE> page = koha . LoginPage ( None , html ) <NEWLINE> action , data = page . createPost ( <STRING> , <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"librarybot/fixtures/koha/madison-login.htm\"", "\"r\"", "\"myuser\"", "\"mypassword\""]}}], ["993e1634c87b083ea32f9fa574dd7b06", {"code_string": "__all__ = ['Parser']\nimport struct\nimport logging\nimport core\nlog = logging.getLogger('metadata')\n", "code_toks_joined": "__all__ = [ <STRING> ] <NEWLINE> import struct <NEWLINE> import logging <NEWLINE> import core <NEWLINE> log = logging . getLogger ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'Parser'", "'metadata'"]}}], ["327ff5b8d2bc6cdb893c8af4f60a9b6d", {"code_string": "from setuptools import setup\nsetup(name = 'keras_squeezenet',\n    version = '0.3',\n    description = 'Squeezenet implementation with Keras framework',\n    url = 'https://github.com/rcmalli/keras-squeezenet',\n    author = 'Refik Can MALLI',\n    author_email = \"mallir@itu.edu.tr\",\n    license = 'MIT',\n    packages = ['keras_squeezenet'],\n    zip_safe = False,\n    install_requires = ['keras', 'tensorflow', 'pillow', 'numpy'])\n", "code_toks_joined": "from setuptools import setup <NEWLINE> setup ( name = <STRING> , <NEWLINE> <INDENT> version = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> url = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> license = <STRING> , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> zip_safe = False , <NEWLINE> install_requires = [ <STRING> , <STRING> , <STRING> , <STRING> ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'keras_squeezenet'", "'0.3'", "'Squeezenet implementation with Keras framework'", "'https://github.com/rcmalli/keras-squeezenet'", "'Refik Can MALLI'", "\"mallir@itu.edu.tr\"", "'MIT'", "'keras_squeezenet'", "'keras'", "'tensorflow'", "'pillow'", "'numpy'"]}}], ["6e267e6ac4f33cf74772fac54447211f", {"code_string": "def test_run_extra_args(self):\n    self.add_new('New-HOWTO', example.ex_linuxdoc)\n    fullpath = opj(self.tempdir, 'sources', 'New-HOWTO.sgml')\n    argv = self.argv\n    argv.extend(['--build', 'stale', 'Orphan-HOWTO', fullpath, 'extra'])\n    val = tldp.driver.run(argv)\n    self.assertTrue('Unknown arguments' in val)\n", "code_toks_joined": "def test_run_extra_args ( self ) : <NEWLINE> <INDENT> self . add_new ( <STRING> , example . ex_linuxdoc ) <NEWLINE> fullpath = opj ( self . tempdir , <STRING> , <STRING> ) <NEWLINE> argv = self . argv <NEWLINE> argv . extend ( [ <STRING> , <STRING> , <STRING> , fullpath , <STRING> ] ) <NEWLINE> val = tldp . driver . run ( argv ) <NEWLINE> self . assertTrue ( <STRING> in val ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'New-HOWTO'", "'sources'", "'New-HOWTO.sgml'", "'--build'", "'stale'", "'Orphan-HOWTO'", "'extra'", "'Unknown arguments'"]}}], ["abbbd4519f642e374399cf6f1de48cae", {"code_string": "def memset(ptr, value, byte_count):\n    \"\"\"Set some bytes to a specific value in the memory of the FT800.\"\"\"\n    ret = _LIB.eve_click_memset(ptr, value, byte_count)\n    if ret < 0:\n        raise Exception(\"eve click memset failed\")\n", "code_toks_joined": "def memset ( ptr , value , byte_count ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> ret = _LIB . eve_click_memset ( ptr , value , byte_count ) <NEWLINE> if ret < 0 : <NEWLINE> <INDENT> raise Exception ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Set some bytes to a specific value in the memory of the FT800.\"\"\"", "\"eve click memset failed\""]}}], ["0be5493143865f0cec7ee45d804fffdc", {"code_string": "class MockIngester(object):\n    def __init__(self, stream):\n        self.data = stream.read()\n    def next(self):\n        if len(self.data) == 0:\n            raise StopIteration()\n        return self.data.pop()\n", "code_toks_joined": "class MockIngester ( object ) : <NEWLINE> <INDENT> def __init__ ( self , stream ) : <NEWLINE> <INDENT> self . data = stream . read ( ) <NEWLINE> <DEDENT> def next ( self ) : <NEWLINE> <INDENT> if len ( self . data ) == 0 : <NEWLINE> <INDENT> raise StopIteration ( ) <NEWLINE> <DEDENT> return self . data . pop ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["a549d607b7ff890dbe13efdfbaa4cd20", {"code_string": "from indivo.lib import iso8601\nfrom indivo.models import MedicationFill\nXML = 'xml'\nDOM = 'dom'\n", "code_toks_joined": "from indivo . lib import iso8601 <NEWLINE> from indivo . models import MedicationFill <NEWLINE> XML = <STRING> <NEWLINE> DOM = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'xml'", "'dom'"]}}], ["1995b2d7c9db5529cc109675b33b6ab4", {"code_string": "\"\"\"Usage: manage.py {lms|cms} [--settings env] ...\"\"\"\nimport os\nimport sys\nimport importlib\nfrom argparse import ArgumentParser\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> import sys <NEWLINE> import importlib <NEWLINE> from argparse import ArgumentParser <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Usage: manage.py {lms|cms} [--settings env] ...\"\"\""]}}], ["8aa16aadcd7d9b3d788c090e126000ed", {"code_string": "def __init__(self, zookeepers = None):\n    if zookeepers is None:\n        zookeepers = self._extract_zookeepers()\n    self.zookeepers = zookeepers\n    self._connection = _connection(zookeepers)\n    self._connection.open()\n", "code_toks_joined": "def __init__ ( self , zookeepers = None ) : <NEWLINE> <INDENT> if zookeepers is None : <NEWLINE> <INDENT> zookeepers = self . _extract_zookeepers ( ) <NEWLINE> <DEDENT> self . zookeepers = zookeepers <NEWLINE> self . _connection = _connection ( zookeepers ) <NEWLINE> self . _connection . open ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["4f64260eaf7b056341fb172096c628d5", {"code_string": "def check_credentials(request, username, password):\n    \"\"\"Check user submitted username and pw against stored pw to determine authentication state.\"\"\"\n    gotten_usernames = request.dbsession.query(User).all()\n    is_authenticated = False\n    if gotten_usernames:\n        if any(d.username == username for d in gotten_usernames):\n            db_pw = request.dbsession.query(User).filter(User.username == username).first()\n            try:\n                is_authenticated = pwd_context.verify(password, db_pw.password)\n            except ValueError:\n                pass\n    return is_authenticated\n", "code_toks_joined": "def check_credentials ( request , username , password ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> gotten_usernames = request . dbsession . query ( User ) . all ( ) <NEWLINE> is_authenticated = False <NEWLINE> if gotten_usernames : <NEWLINE> <INDENT> if any ( d . username == username for d in gotten_usernames ) : <NEWLINE> <INDENT> db_pw = request . dbsession . query ( User ) . filter ( User . username == username ) . first ( ) <NEWLINE> try : <NEWLINE> <INDENT> is_authenticated = pwd_context . verify ( password , db_pw . password ) <NEWLINE> <DEDENT> except ValueError : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT> <DEDENT> return is_authenticated <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Check user submitted username and pw against stored pw to determine authentication state.\"\"\""]}}], ["283ae625ee6d75a5e909f13ee091a901", {"code_string": "def test_client_returning_same_for_relative_and_absolute_queries():\n    given_rest_client()\n    shop_relative = client.get(\"/\")\n    shop_absolute = client.get(API_URL)\n    assert unicode(shop_relative) == unicode(shop_absolute)\n", "code_toks_joined": "def test_client_returning_same_for_relative_and_absolute_queries ( ) : <NEWLINE> <INDENT> given_rest_client ( ) <NEWLINE> shop_relative = client . get ( <STRING> ) <NEWLINE> shop_absolute = client . get ( API_URL ) <NEWLINE> assert unicode ( shop_relative ) == unicode ( shop_absolute ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"/\""]}}], ["28903f40835f4fb873704e5f054b2c89", {"code_string": "def __truediv__(self, other):\n    assert isinstance(other, (numbers.Number, SymbolNUMBER))\n    if isinstance(other, SymbolNUMBER):\n        return SymbolNUMBER(self.value / other.value, self.lineno)\n    return SymbolNUMBER(self.value / other, self.lineno)\n", "code_toks_joined": "def __truediv__ ( self , other ) : <NEWLINE> <INDENT> assert isinstance ( other , ( numbers . Number , SymbolNUMBER ) ) <NEWLINE> if isinstance ( other , SymbolNUMBER ) : <NEWLINE> <INDENT> return SymbolNUMBER ( self . value / other . value , self . lineno ) <NEWLINE> <DEDENT> return SymbolNUMBER ( self . value / other , self . lineno ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["4fdd7255081b35ba0dcb2f24dc43592e", {"code_string": "import pickle, random, itertools, copy\nfilenames = pickle.load(open('filenames.pickle'))\nsubjects = sorted(filenames.keys())\n", "code_toks_joined": "import pickle , random , itertools , copy <NEWLINE> filenames = pickle . load ( open ( <STRING> ) ) <NEWLINE> subjects = sorted ( filenames . keys ( ) ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'filenames.pickle'"]}}], ["32442d9ed5bc4336258ec669521ed709", {"code_string": "def from_args(cls, args, arg_prefix):\n    \"\"\"Create a :class:`~.ParallelTestRunner` from command-line arguments.\"\"\"\n    initializer_spec = args.process_init\n    if initializer_spec is None:\n        initializer = None\n    else:\n        module_name, initializer_name = initializer_spec.rsplit('.', 1)\n        init_module = get_module_by_name(module_name)\n        initializer = getattr(init_module, initializer_name)\n    return cls(process_count = args.processes, initializer = initializer,\n        maxtasksperchild = args.process_max_tasks)\n", "code_toks_joined": "def from_args ( cls , args , arg_prefix ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> initializer_spec = args . process_init <NEWLINE> if initializer_spec is None : <NEWLINE> <INDENT> initializer = None <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> module_name , initializer_name = initializer_spec . rsplit ( <STRING> , 1 ) <NEWLINE> init_module = get_module_by_name ( module_name ) <NEWLINE> initializer = getattr ( init_module , initializer_name ) <NEWLINE> <DEDENT> return cls ( process_count = args . processes , initializer = initializer , <NEWLINE> <INDENT> maxtasksperchild = args . process_max_tasks ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Create a :class:`~.ParallelTestRunner` from command-line arguments.\"\"\"", "'.'"]}}], ["a597676d682049dcdc5cbbfe74616c61", {"code_string": "import TCP\nimport Motor\nimport Steering\nimport Status\nimport time\nimport Cameras\nimport Lights\nimport Modes\nimport os\ntry:\n    trip_meter = Motor.TripMeter()\n    motors = Motor.Motor(trip_meter)\n    follow_line = Steering.FollowLine(motors, start_speed = 20)\n    while True:\n        time.sleep(10)\nexcept:\n    print(\"except\")\n    motors.turn_off()\n    follow_line.stop()\n", "code_toks_joined": "import TCP <NEWLINE> import Motor <NEWLINE> import Steering <NEWLINE> import Status <NEWLINE> import time <NEWLINE> import Cameras <NEWLINE> import Lights <NEWLINE> import Modes <NEWLINE> import os <NEWLINE> try : <NEWLINE> <INDENT> trip_meter = Motor . TripMeter ( ) <NEWLINE> motors = Motor . Motor ( trip_meter ) <NEWLINE> follow_line = Steering . FollowLine ( motors , start_speed = 20 ) <NEWLINE> while True : <NEWLINE> <INDENT> time . sleep ( 10 ) <NEWLINE> <DEDENT> <DEDENT> except : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> motors . turn_off ( ) <NEWLINE> follow_line . stop ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"except\""]}}], ["3696152ce5f56e99e37bd487d9f1c569", {"code_string": "import string\nprint(\" ____       _      ____    ____    _____    ____   _   _   ____    _____ \")\nprint(\"|  _ \\     / \\    / ___|  / ___|  | ____|  / ___| | | | | |  _ \\  | ____|\")\nprint(\"| |_) |   / _ \\   \\___ \\  \\___ \\  |  _|   | |     | | | | | |_) | |  _|\")\nprint(\"|  __/   / ___ \\   ___) |  ___) | | |___  | |___  | |_| | |  _ <  | |___\")\nprint(\"|_|     /_/   \\_\\ |____/  |____/  |_____|  \\____|  \\___/  |_| \\_\\ |_____|\")\nprint(\"******************************by n0ipr0cs*********************************\")\nprint(\"\")\nfrom random import *\ncharacters = string.ascii_letters + string.punctuation + string.digits\npassword = \"\".join(choice(characters) for x in range(randint(8, 16)))\nprint(\"Tu password es:\")\nprint(password)\nprint(\"Ya tienes un password fuerte\")\n", "code_toks_joined": "import string <NEWLINE> print ( <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> from random import * <NEWLINE> characters = string . ascii_letters + string . punctuation + string . digits <NEWLINE> password = <STRING> . join ( choice ( characters ) for x in range ( randint ( 8 , 16 ) ) ) <NEWLINE> print ( <STRING> ) <NEWLINE> print ( password ) <NEWLINE> print ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\" ____       _      ____    ____    _____    ____   _   _   ____    _____ \"", "\"|  _ \\     / \\    / ___|  / ___|  | ____|  / ___| | | | | |  _ \\  | ____|\"", "\"| |_) |   / _ \\   \\___ \\  \\___ \\  |  _|   | |     | | | | | |_) | |  _|\"", "\"|  __/   / ___ \\   ___) |  ___) | | |___  | |___  | |_| | |  _ <  | |___\"", "\"|_|     /_/   \\_\\ |____/  |____/  |_____|  \\____|  \\___/  |_| \\_\\ |_____|\"", "\"******************************by n0ipr0cs*********************************\"", "\"\"", "\"\"", "\"Tu password es:\"", "\"Ya tienes un password fuerte\""]}}], ["6f72beb7313f4a6f9da72dfa46ad8ba1", {"code_string": "def numeric(self, values):\n    \"\"\"Reshape the value.\"\"\"\n    return np.reshape(values[0], (self.rows, self.cols), \"F\")\n", "code_toks_joined": "def numeric ( self , values ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return np . reshape ( values [ 0 ] , ( self . rows , self . cols ) , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Reshape the value.\"\"\"", "\"F\""]}}], ["eadb7ac2e36d42f5bfb6cf810a0fa924", {"code_string": "def db_purge(self, purge_time, purge_id):\n    total_rows_deleted = 0\n    if(purge_time != None):\n        total_rows_deleted = self.purge_old_data(purge_id, purge_time)\n        if(total_rows_deleted != - 1):\n            self._update_analytics_start_time(int(purge_time))\n    return total_rows_deleted\n", "code_toks_joined": "def db_purge ( self , purge_time , purge_id ) : <NEWLINE> <INDENT> total_rows_deleted = 0 <NEWLINE> if ( purge_time != None ) : <NEWLINE> <INDENT> total_rows_deleted = self . purge_old_data ( purge_id , purge_time ) <NEWLINE> if ( total_rows_deleted != - 1 ) : <NEWLINE> <INDENT> self . _update_analytics_start_time ( int ( purge_time ) ) <NEWLINE> <DEDENT> <DEDENT> return total_rows_deleted <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["f550d72d44cfcd469491ced01b1f20d7", {"code_string": "def destination(self, dest):\n    self.cmd['dest'] = dest\n    return(self)\n", "code_toks_joined": "def destination ( self , dest ) : <NEWLINE> <INDENT> self . cmd [ <STRING> ] = dest <NEWLINE> return ( self ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'dest'"]}}], ["63c1ab629a2cbd148a1651043d343349", {"code_string": "def move_data(apps, schema_editor):\n    CSWRecord = apps.get_model(\"core\", \"cswrecord\")\n    TopicCategory = apps.get_model(\"base\", \"topiccategory\")\n    for record in CSWRecord.objects.all():\n        try:\n            record.topic_category = TopicCategory.objects.filter(identifier__iexact = record.category, is_choice = True)[0]\n            record.save()\n        except:\n            pass\n", "code_toks_joined": "def move_data ( apps , schema_editor ) : <NEWLINE> <INDENT> CSWRecord = apps . get_model ( <STRING> , <STRING> ) <NEWLINE> TopicCategory = apps . get_model ( <STRING> , <STRING> ) <NEWLINE> for record in CSWRecord . objects . all ( ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> record . topic_category = TopicCategory . objects . filter ( identifier__iexact = record . category , is_choice = True ) [ 0 ] <NEWLINE> record . save ( ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"core\"", "\"cswrecord\"", "\"base\"", "\"topiccategory\""]}}], ["b56efd58ace3847b78a017ac0b17c1d9", {"code_string": "def get_instance_id(self):\n    \"\"\"Instance name of the virtual machine.\"\"\"\n    return self._get_cache_data('instance-id')\n", "code_toks_joined": "def get_instance_id ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . _get_cache_data ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Instance name of the virtual machine.\"\"\"", "'instance-id'"]}}], ["8206d4584d3212e4a11031eecb79b888", {"code_string": "import os\nimport sys\nif os.name == 'nt':\n    if 'scripts' not in sys.executable.lower():\n        VIRTUALENV = os.path.dirname(sys.executable)\n    else:\n        VIRTUALENV = os.path.dirname(os.path.dirname(sys.executable))\nelse:\n    VIRTUALENV = os.path.dirname(os.path.dirname(sys.executable))\n", "code_toks_joined": "import os <NEWLINE> import sys <NEWLINE> if os . name == <STRING> : <NEWLINE> <INDENT> if <STRING> not in sys . executable . lower ( ) : <NEWLINE> <INDENT> VIRTUALENV = os . path . dirname ( sys . executable ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> VIRTUALENV = os . path . dirname ( os . path . dirname ( sys . executable ) ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> VIRTUALENV = os . path . dirname ( os . path . dirname ( sys . executable ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'nt'", "'scripts'"]}}], ["cfd67cb21ecb64cb55ff7c4487587865", {"code_string": "\"\"\"An interpreted text role to link docs to Trac tickets.\"\"\"\nfrom docutils import nodes, utils\nfrom docutils.parsers.rst import roles\n", "code_toks_joined": "<STRING> <NEWLINE> from docutils import nodes , utils <NEWLINE> from docutils . parsers . rst import roles <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"An interpreted text role to link docs to Trac tickets.\"\"\""]}}], ["b3bb341955447cbe3683b4bbbfea6cc6", {"code_string": "def VerifyFields(self, Mail):\n    '''Verifies passed fields to follow requirements of Gmail'''\n    To_Email = Mail['To_Email']\n    if len(To_Email) != 0:\n        status = True\n    else:\n        return False\n    Message = Mail['Message']\n    Message = Message.strip()\n    if len(Message) != 0:\n        status = True\n    else:\n        return False\n    return status\n", "code_toks_joined": "def VerifyFields ( self , Mail ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> To_Email = Mail [ <STRING> ] <NEWLINE> if len ( To_Email ) != 0 : <NEWLINE> <INDENT> status = True <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> Message = Mail [ <STRING> ] <NEWLINE> Message = Message . strip ( ) <NEWLINE> if len ( Message ) != 0 : <NEWLINE> <INDENT> status = True <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> return status <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Verifies passed fields to follow requirements of Gmail'''", "'To_Email'", "'Message'"]}}], ["0500ddda464c6f573e54fe1c56380756", {"code_string": "def export_set(dataset, ** kwargs):\n    \"\"\"Returns CSV representation of Dataset.\"\"\"\n    stream = StringIO()\n    kwargs.setdefault('delimiter', DEFAULT_DELIMITER)\n    if not is_py3:\n        kwargs.setdefault('encoding', DEFAULT_ENCODING)\n    _csv = csv.writer(stream, ** kwargs)\n    for row in dataset._package(dicts = False):\n        _csv.writerow(row)\n    return stream.getvalue()\n", "code_toks_joined": "def export_set ( dataset , ** kwargs ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> stream = StringIO ( ) <NEWLINE> kwargs . setdefault ( <STRING> , DEFAULT_DELIMITER ) <NEWLINE> if not is_py3 : <NEWLINE> <INDENT> kwargs . setdefault ( <STRING> , DEFAULT_ENCODING ) <NEWLINE> <DEDENT> _csv = csv . writer ( stream , ** kwargs ) <NEWLINE> for row in dataset . _package ( dicts = False ) : <NEWLINE> <INDENT> _csv . writerow ( row ) <NEWLINE> <DEDENT> return stream . getvalue ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Returns CSV representation of Dataset.\"\"\"", "'delimiter'", "'encoding'"]}}], ["bdc6fd79425366eaf151be043ee33c4b", {"code_string": "from pyramid.compat import(\n    text_type,\n    binary_type\n    )\nfrom sqlalchemy.ext.hybrid import(\n    hybrid_property,\n    Comparator,\n    )\n", "code_toks_joined": "from pyramid . compat import ( <NEWLINE> <INDENT> text_type , <NEWLINE> binary_type <NEWLINE> ) <NEWLINE> <DEDENT> from sqlalchemy . ext . hybrid import ( <NEWLINE> <INDENT> hybrid_property , <NEWLINE> Comparator , <NEWLINE> ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["a016cd875b1be681c203bd4e241e8aa8", {"code_string": "from django.contrib import admin\nfrom core.models import Hackaton\nadmin.site.register(Hackaton)\n", "code_toks_joined": "from django . contrib import admin <NEWLINE> from core . models import Hackaton <NEWLINE> admin . site . register ( Hackaton ) <NEWLINE>", "anonymize_dict": {}}], ["1c0ba8635c7c73f1740743e40258cfd7", {"code_string": "def main():\n    \"\"\"Main\"\"\"\n    time1 = Time()\n    print(\"Military time is\", time1.print_military())\n    print(\"Standard time is\", time1.print_standard())\n    time1.set_time(13, 27, 6)\n    print(time1.print_military())\n    print(time1.print_standard())\n    time1.set_hour(4)\n    time1.set_minute(3)\n    time1.set_second(34)\n    print(time1.print_military())\n    print(time1.print_standard())\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> time1 = Time ( ) <NEWLINE> print ( <STRING> , time1 . print_military ( ) ) <NEWLINE> print ( <STRING> , time1 . print_standard ( ) ) <NEWLINE> time1 . set_time ( 13 , 27 , 6 ) <NEWLINE> print ( time1 . print_military ( ) ) <NEWLINE> print ( time1 . print_standard ( ) ) <NEWLINE> time1 . set_hour ( 4 ) <NEWLINE> time1 . set_minute ( 3 ) <NEWLINE> time1 . set_second ( 34 ) <NEWLINE> print ( time1 . print_military ( ) ) <NEWLINE> print ( time1 . print_standard ( ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Main\"\"\"", "\"Military time is\"", "\"Standard time is\""]}}], ["3ef029f26b30e54f0b0e57416885274b", {"code_string": "def __enter__(self):\n    with FileLock(self.lock_path):\n        self.read()\n        return self\n", "code_toks_joined": "def __enter__ ( self ) : <NEWLINE> <INDENT> with FileLock ( self . lock_path ) : <NEWLINE> <INDENT> self . read ( ) <NEWLINE> return self <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["2c515bf6235d6739e4904bb2c513952d", {"code_string": "class ClientNotifier(Session):\n    all_clients = []\n    def __init__(self, * args, ** kwargs):\n        Session.__init__(self, * args, ** kwargs)\n    def on_open(self):\n        self.all_clients.append(self)\n        print(self.all_clients)\n        pass\n    def on_message(self, message):\n        pass\n    def on_close(self):\n        self.all_clients.remove(self)\n        pass\n", "code_toks_joined": "class ClientNotifier ( Session ) : <NEWLINE> <INDENT> all_clients = [ ] <NEWLINE> def __init__ ( self , * args , ** kwargs ) : <NEWLINE> <INDENT> Session . __init__ ( self , * args , ** kwargs ) <NEWLINE> <DEDENT> def on_open ( self ) : <NEWLINE> <INDENT> self . all_clients . append ( self ) <NEWLINE> print ( self . all_clients ) <NEWLINE> pass <NEWLINE> <DEDENT> def on_message ( self , message ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def on_close ( self ) : <NEWLINE> <INDENT> self . all_clients . remove ( self ) <NEWLINE> pass <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["5ec9f4d9cc43acdec5a55505d6f73251", {"code_string": "def tweet(self, text):\n    text = self.clean_text(text)\n    api = self.get_api()\n    api.update_status(status = text)\n", "code_toks_joined": "def tweet ( self , text ) : <NEWLINE> <INDENT> text = self . clean_text ( text ) <NEWLINE> api = self . get_api ( ) <NEWLINE> api . update_status ( status = text ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["97de921828288611c67c03fb1776b4cf", {"code_string": "class Disk():\n    '''Methods relating to disk usage, dca disk policy etc'''\n    def __init__(self):\n        pass\n    def get_disk_usage(self, hostname, partition = '/data'):\n        '''Returns the disk usage of individual hosts'''\n        cmd_str = \"ssh %s df %s | grep -v Filesystem |awk \\'{print $4}\\'\" %(hostname, partition)\n        results = {'rc': 0, 'stdout': '', 'stderr': ''}\n        run_shell_command(cmd_str, results = results)\n        return results1['rc'], results1['stdout']\n", "code_toks_joined": "class Disk ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def get_disk_usage ( self , hostname , partition = <STRING> ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> cmd_str = <STRING> % ( hostname , partition ) <NEWLINE> results = { <STRING> : 0 , <STRING> : <STRING> , <STRING> : <STRING> } <NEWLINE> run_shell_command ( cmd_str , results = results ) <NEWLINE> return results1 [ <STRING> ] , results1 [ <STRING> ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Methods relating to disk usage, dca disk policy etc'''", "'/data'", "'''Returns the disk usage of individual hosts'''", "\"ssh %s df %s | grep -v Filesystem |awk \\'{print $4}\\'\"", "'rc'", "'stdout'", "''", "'stderr'", "''", "'rc'", "'stdout'"]}}], ["c497c4fb8fa38406690f3d412f30b0ce", {"code_string": "def max_sum_in_lst(lst):\n    cur_sum, max_sum = 0, 0\n    for i in lst:\n        cur_sum = i if i > cur_sum + i else cur_sum + i\n        max_sum = cur_sum if cur_sum > max_sum else max_sum\n    return max_sum\n", "code_toks_joined": "def max_sum_in_lst ( lst ) : <NEWLINE> <INDENT> cur_sum , max_sum = 0 , 0 <NEWLINE> for i in lst : <NEWLINE> <INDENT> cur_sum = i if i > cur_sum + i else cur_sum + i <NEWLINE> max_sum = cur_sum if cur_sum > max_sum else max_sum <NEWLINE> <DEDENT> return max_sum <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["5f16f2424b1303db84e937b234d28206", {"code_string": "import datetime\nimport hashlib\nimport random\nimport re\nfrom django.conf import settings\nfrom django.contrib.auth.models import User\nfrom django.db import models\nfrom django.db import transaction\nfrom django.template.loader import render_to_string\nfrom django.utils.translation import ugettext_lazy as _\nUser = settings.AUTH_USER_MODEL\ntry:\n    from django.utils.timezone import now as datetime_now\nexcept ImportError:\n    datetime_now = datetime.datetime.now\nSHA1_RE = re.compile('^[a-f0-9]{40}$')\n", "code_toks_joined": "import datetime <NEWLINE> import hashlib <NEWLINE> import random <NEWLINE> import re <NEWLINE> from django . conf import settings <NEWLINE> from django . contrib . auth . models import User <NEWLINE> from django . db import models <NEWLINE> from django . db import transaction <NEWLINE> from django . template . loader import render_to_string <NEWLINE> from django . utils . translation import ugettext_lazy as _ <NEWLINE> User = settings . AUTH_USER_MODEL <NEWLINE> try : <NEWLINE> <INDENT> from django . utils . timezone import now as datetime_now <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> datetime_now = datetime . datetime . now <NEWLINE> <DEDENT> SHA1_RE = re . compile ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'^[a-f0-9]{40}$'"]}}], ["fe5fd61939d3752cfabc7ecdc97d2850", {"code_string": "def lookup(table, ip):\n    i = bisect.bisect_right(table, (ip, None, None))\n    (low, hi, isp) = table[i - 1]\n    if low <= ip <= hi:\n        return isp\n", "code_toks_joined": "def lookup ( table , ip ) : <NEWLINE> <INDENT> i = bisect . bisect_right ( table , ( ip , None , None ) ) <NEWLINE> ( low , hi , isp ) = table [ i - 1 ] <NEWLINE> if low <= ip <= hi : <NEWLINE> <INDENT> return isp <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["0e2bb815fb46ac90c0bd1139c9c4b8ae", {"code_string": "def testHighLowEvent(self):\n    with self.assertRaises(ValueError):\n        GPIO.add_event_detect(LOOP_IN, GPIO.LOW)\n    with self.assertRaises(ValueError):\n        GPIO.add_event_detect(LOOP_IN, GPIO.HIGH)\n", "code_toks_joined": "def testHighLowEvent ( self ) : <NEWLINE> <INDENT> with self . assertRaises ( ValueError ) : <NEWLINE> <INDENT> GPIO . add_event_detect ( LOOP_IN , GPIO . LOW ) <NEWLINE> <DEDENT> with self . assertRaises ( ValueError ) : <NEWLINE> <INDENT> GPIO . add_event_detect ( LOOP_IN , GPIO . HIGH ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["64161d561d24c368c06723fc43a2f927", {"code_string": "def pop(self, key, alt = None, callback = None):\n    return self.__jobRunner.run(\n        self.__pop, self.__rlock, callback, key, alt\n    )\n", "code_toks_joined": "def pop ( self , key , alt = None , callback = None ) : <NEWLINE> <INDENT> return self . __jobRunner . run ( <NEWLINE> <INDENT> self . __pop , self . __rlock , callback , key , alt <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["cd36ab24277caf283eeac01bb295a9eb", {"code_string": "def test_mail_notification_url_no_partner(self):\n    mail = self.env['mail.mail'].create({'state': 'exception'})\n    url = mail._get_partner_access_link()\n    self.assertEqual(url, None)\n", "code_toks_joined": "def test_mail_notification_url_no_partner ( self ) : <NEWLINE> <INDENT> mail = self . env [ <STRING> ] . create ( { <STRING> : <STRING> } ) <NEWLINE> url = mail . _get_partner_access_link ( ) <NEWLINE> self . assertEqual ( url , None ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'mail.mail'", "'state'", "'exception'"]}}], ["3c1916e4c74284bc2f44ca911c5fb986", {"code_string": "def serialization_path(self):\n    \"\"\"Generate the full path at which this envelope should be serialized.\"\"\"\n    envelope_filename = urllib.parse.quote(self.content_id, safe = '') + '.json'\n    return path.join(self.deconst_config.envelope_dir, envelope_filename)\n", "code_toks_joined": "def serialization_path ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> envelope_filename = urllib . parse . quote ( self . content_id , safe = <STRING> ) + <STRING> <NEWLINE> return path . join ( self . deconst_config . envelope_dir , envelope_filename ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Generate the full path at which this envelope should be serialized.\"\"\"", "''", "'.json'"]}}], ["35d90f58eef71f69167f63fc5aa79884", {"code_string": "from dolfin import *\nimport sys\nN = 256\nsigma = 0.9\nepsilon = 1.25\nT = 1\nc = 0.5\nh = 1.0 / N\ndt = h * 0.0001\niteration = 0\ninfo(\"Initial parameters: N = {0}; sigma = {1}; epsilon = {2}; h = {3}; dt = {4}\".format(N, sigma, epsilon, h, dt))\nmesh = UnitIntervalMesh(N)\nV = FunctionSpace(mesh, 'Lagrange', 2)\nu0 = Expression('(0.25 < x[0] && x[0] < 0.75) ? 1 : 0')\n", "code_toks_joined": "from dolfin import * <NEWLINE> import sys <NEWLINE> N = 256 <NEWLINE> sigma = 0.9 <NEWLINE> epsilon = 1.25 <NEWLINE> T = 1 <NEWLINE> c = 0.5 <NEWLINE> h = 1.0 / N <NEWLINE> dt = h * 0.0001 <NEWLINE> iteration = 0 <NEWLINE> info ( <STRING> . format ( N , sigma , epsilon , h , dt ) ) <NEWLINE> mesh = UnitIntervalMesh ( N ) <NEWLINE> V = FunctionSpace ( mesh , <STRING> , 2 ) <NEWLINE> u0 = Expression ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"Initial parameters: N = {0}; sigma = {1}; epsilon = {2}; h = {3}; dt = {4}\"", "'Lagrange'", "'(0.25 < x[0] && x[0] < 0.75) ? 1 : 0'"]}}], ["0879052067e0f95c24744783432ced0f", {"code_string": "\"\"\"black_rhino is a multi-agent simulator for financial network analysis\"\"\"\nfrom abm_template.src.basemodel import BaseModel\nfrom src.agent import Agent\n", "code_toks_joined": "<STRING> <NEWLINE> from abm_template . src . basemodel import BaseModel <NEWLINE> from src . agent import Agent <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"black_rhino is a multi-agent simulator for financial network analysis\"\"\""]}}], ["634e0c057315825ead218cb7bfb1dd72", {"code_string": "def test_process_translations(self):\n    fr_article1 = get_article(lang = 'fr', slug = 'yay', title = 'Un titre',\n        content = 'en fran\u00e7ais')\n    en_article1 = get_article(lang = 'en', slug = 'yay', title = 'A title',\n        content = 'in english')\n    articles = [fr_article1, en_article1]\n    index, trans = utils.process_translations(articles)\n    self.assertIn(en_article1, index)\n    self.assertIn(fr_article1, trans)\n    self.assertNotIn(en_article1, trans)\n    self.assertNotIn(fr_article1, index)\n", "code_toks_joined": "def test_process_translations ( self ) : <NEWLINE> <INDENT> fr_article1 = get_article ( lang = <STRING> , slug = <STRING> , title = <STRING> , <NEWLINE> <INDENT> content = <STRING> ) <NEWLINE> <DEDENT> en_article1 = get_article ( lang = <STRING> , slug = <STRING> , title = <STRING> , <NEWLINE> <INDENT> content = <STRING> ) <NEWLINE> <DEDENT> articles = [ fr_article1 , en_article1 ] <NEWLINE> index , trans = utils . process_translations ( articles ) <NEWLINE> self . assertIn ( en_article1 , index ) <NEWLINE> self . assertIn ( fr_article1 , trans ) <NEWLINE> self . assertNotIn ( en_article1 , trans ) <NEWLINE> self . assertNotIn ( fr_article1 , index ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'fr'", "'yay'", "'Un titre'", "'en fran\u00e7ais'", "'en'", "'yay'", "'A title'", "'in english'"]}}], ["13fc85d041ffd993147249118d2f3fc0", {"code_string": "class Bar(Foo1):\n    def test(self):\n        print('Bar')\n", "code_toks_joined": "class Bar ( Foo1 ) : <NEWLINE> <INDENT> def test ( self ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Bar'"]}}], ["f349c4f1f1cebb6f1c47f36ff3d10ced", {"code_string": "class Color(_Color):\n    \"\"\"(r, g, b, a) namedtuple for 8-bit RGB color with alpha channel.\"\"\"\n    def __new__(cls, r, g, b, a = 0):\n        for value in r, g, b, a:\n            if value not in range(256):\n                raise ValueError(\"Color channels must have values 0-255\")\n        return _Color.__new__(cls, r, g, b, a)\n", "code_toks_joined": "class Color ( _Color ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __new__ ( cls , r , g , b , a = 0 ) : <NEWLINE> <INDENT> for value in r , g , b , a : <NEWLINE> <INDENT> if value not in range ( 256 ) : <NEWLINE> <INDENT> raise ValueError ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT> return _Color . __new__ ( cls , r , g , b , a ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"(r, g, b, a) namedtuple for 8-bit RGB color with alpha channel.\"\"\"", "\"Color channels must have values 0-255\""]}}], ["77ba206767e29f04f520e7b8416293ae", {"code_string": "def bar_handler(args):\n    \"\"\"usage: {program} {command} <name>\"\"\"\n    print(\"Bar, {}\".format(args['<name>']))\n", "code_toks_joined": "def bar_handler ( args ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> print ( <STRING> . format ( args [ <STRING> ] ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"usage: {program} {command} <name>\"\"\"", "\"Bar, {}\"", "'<name>'"]}}], ["c7228286cd837cca4b9e45bef8ff65fb", {"code_string": "def end_synchro(self):\n    \"\"\" Declare as SILENT the AddressStatus that are still not responsive\"\"\"\n    map(self.invalid, filter(lambda x: x.state == AddressStates.UNKNOWN,\n        self.addresses.values()))\n", "code_toks_joined": "def end_synchro ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> map ( self . invalid , filter ( lambda x : x . state == AddressStates . UNKNOWN , <NEWLINE> <INDENT> self . addresses . values ( ) ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Declare as SILENT the AddressStatus that are still not responsive\"\"\""]}}], ["377313243f7d2f432ac31d8b29d7ca07", {"code_string": "def allTests():\n    \"\"\"This function returns a list of tests.\"\"\"\n    tests = make_tests(\"type_inference/positive\", True, [\"--emit-annotated\"])\n    for test in tests:\n        if test.getName() in optionals:\n            test.opt()\n    return tests\n", "code_toks_joined": "def allTests ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> tests = make_tests ( <STRING> , True , [ <STRING> ] ) <NEWLINE> for test in tests : <NEWLINE> <INDENT> if test . getName ( ) in optionals : <NEWLINE> <INDENT> test . opt ( ) <NEWLINE> <DEDENT> <DEDENT> return tests <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"This function returns a list of tests.\"\"\"", "\"type_inference/positive\"", "\"--emit-annotated\""]}}], ["0c8bca1496384f380b8a5cca3ed83138", {"code_string": "\"\"\"This module provides a widget with the full description of the plugin.\"\"\"\n__docformat__ = 'restructuredtext'\nimport os.path\nfrom qtpy import QtGui\nfrom qtpy.uic import loadUiType\nfrom qtpy import QtWidgets\nfrom vitables.vtsite import PLUGINSDIR\ntranslate = QtWidgets.QApplication.translate\nUi_AboutPage = loadUiType(os.path.join(PLUGINSDIR, 'about_page.ui'))[0]\n", "code_toks_joined": "<STRING> <NEWLINE> __docformat__ = <STRING> <NEWLINE> import os . path <NEWLINE> from qtpy import QtGui <NEWLINE> from qtpy . uic import loadUiType <NEWLINE> from qtpy import QtWidgets <NEWLINE> from vitables . vtsite import PLUGINSDIR <NEWLINE> translate = QtWidgets . QApplication . translate <NEWLINE> Ui_AboutPage = loadUiType ( os . path . join ( PLUGINSDIR , <STRING> ) ) [ 0 ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"This module provides a widget with the full description of the plugin.\"\"\"", "'restructuredtext'", "'about_page.ui'"]}}], ["94d35e504fa5624b8f0d5085c3f2382b", {"code_string": "def ensureDirExists(path):\n    if not os.path.exists(path) and not os.path.isdir(path):\n        os.mkdir(path)\n    elif not os.path.isdir(path):\n        raise IOError(\"Path exists and is not a directory: %s\" % path)\n", "code_toks_joined": "def ensureDirExists ( path ) : <NEWLINE> <INDENT> if not os . path . exists ( path ) and not os . path . isdir ( path ) : <NEWLINE> <INDENT> os . mkdir ( path ) <NEWLINE> <DEDENT> elif not os . path . isdir ( path ) : <NEWLINE> <INDENT> raise IOError ( <STRING> % path ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Path exists and is not a directory: %s\""]}}], ["0ef9018cfa161de799ca4ee8c4c356dc", {"code_string": "def calc_weights(pscore, D):\n    N = pscore.shape[0]\n    weights = np.empty(N)\n    weights[D == 0] = 1 /(1 - pscore[D == 0])\n    weights[D == 1] = 1 / pscore[D == 1]\n    return weights\n", "code_toks_joined": "def calc_weights ( pscore , D ) : <NEWLINE> <INDENT> N = pscore . shape [ 0 ] <NEWLINE> weights = np . empty ( N ) <NEWLINE> weights [ D == 0 ] = 1 / ( 1 - pscore [ D == 0 ] ) <NEWLINE> weights [ D == 1 ] = 1 / pscore [ D == 1 ] <NEWLINE> return weights <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["81380d29dee4cff5d7b6405707feef95", {"code_string": "\"\"\"This file is part of python-lightblueclient.\"\"\"\nfrom setuptools import setup, find_packages\nsetup(\n    name = 'lightblueclient',\n    version = '0.1.0',\n    packages = find_packages(),\n    author = 'Kevin Howell',\n    author_email = 'khowell@redhat.com',\n    url = 'https://github.com/kahowell/python-lightblueclient'\n)\n", "code_toks_joined": "<STRING> <NEWLINE> from setuptools import setup , find_packages <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> packages = find_packages ( ) , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> url = <STRING> <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"This file is part of python-lightblueclient.\"\"\"", "'lightblueclient'", "'0.1.0'", "'Kevin Howell'", "'khowell@redhat.com'", "'https://github.com/kahowell/python-lightblueclient'"]}}], ["bda963bd945fc40012355991d91ba99d", {"code_string": "def register():\n    Pool.register(\n        account.AccountTemplate,\n        account.BEVATCustomer,\n        account.BEVATCustomerContext,\n        module = 'account_be', type_ = 'model')\n", "code_toks_joined": "def register ( ) : <NEWLINE> <INDENT> Pool . register ( <NEWLINE> <INDENT> account . AccountTemplate , <NEWLINE> account . BEVATCustomer , <NEWLINE> account . BEVATCustomerContext , <NEWLINE> module = <STRING> , type_ = <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'account_be'", "'model'"]}}], ["08a11aadf156586cdcf3210c1ad6416c", {"code_string": "def __isub__(self, v2):\n    if hasattr(v2, \"x\"):\n        self.x -= v2.x\n        self.y -= v2.y\n        self.z -= v2.z\n    else:\n        self.x -= v2\n        self.y -= v2\n        self.z -= v2\n    return self\n", "code_toks_joined": "def __isub__ ( self , v2 ) : <NEWLINE> <INDENT> if hasattr ( v2 , <STRING> ) : <NEWLINE> <INDENT> self . x -= v2 . x <NEWLINE> self . y -= v2 . y <NEWLINE> self . z -= v2 . z <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . x -= v2 <NEWLINE> self . y -= v2 <NEWLINE> self . z -= v2 <NEWLINE> <DEDENT> return self <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"x\""]}}], ["198466c7c13b1bc10263224a8bbc3d34", {"code_string": "def user_json(user):\n    return{\n        'id': user.pk,\n        'profile': reverse('view_profile', args = (user.pk, )),\n        'name': user.get_full_name(),\n        'link': get_template('links/user_link.html').render(Context({'user': user})),\n        'autocomplete_entry': get_template('autocomplete/user.html').render(Context({'user': user})),\n    }\n", "code_toks_joined": "def user_json ( user ) : <NEWLINE> <INDENT> return { <NEWLINE> <INDENT> <STRING> : user . pk , <NEWLINE> <STRING> : reverse ( <STRING> , args = ( user . pk , ) ) , <NEWLINE> <STRING> : user . get_full_name ( ) , <NEWLINE> <STRING> : get_template ( <STRING> ) . render ( Context ( { <STRING> : user } ) ) , <NEWLINE> <STRING> : get_template ( <STRING> ) . render ( Context ( { <STRING> : user } ) ) , <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'id'", "'profile'", "'view_profile'", "'name'", "'link'", "'links/user_link.html'", "'user'", "'autocomplete_entry'", "'autocomplete/user.html'", "'user'"]}}], ["cae35587c196c499c8ff24db7a38f4af", {"code_string": "def helper_test_http_method_and_keys(client, method, url, data, users, after_each_request = None):\n    responses = _helper_test_http_method_responses(client, method, url, data, users, after_each_request)\n    return list(map(lambda r: (r.status_code, set(r.data.keys() if isinstance(r.data, dict) and 200 <= r.status_code < 300 else[])), responses))\n", "code_toks_joined": "def helper_test_http_method_and_keys ( client , method , url , data , users , after_each_request = None ) : <NEWLINE> <INDENT> responses = _helper_test_http_method_responses ( client , method , url , data , users , after_each_request ) <NEWLINE> return list ( map ( lambda r : ( r . status_code , set ( r . data . keys ( ) if isinstance ( r . data , dict ) and 200 <= r . status_code < 300 else [ ] ) ) , responses ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["5d88345a9230be59744c1a634af372c4", {"code_string": "def setUp(self):\n    super(TestConfigViews, self).setUp()\n    self.mock_about = mock.patch.object(\n        GoogleDriveClient,\n        'about'\n    )\n    self.mock_about.return_value = {'rootFolderId': '24601'}\n    self.mock_about.start()\n    self.mock_fetch = mock.patch.object(\n        self.node_settings.__class__,\n        'fetch_access_token'\n    )\n    self.mock_fetch.return_value = self.external_account.oauth_key\n    self.mock_fetch.start()\n", "code_toks_joined": "def setUp ( self ) : <NEWLINE> <INDENT> super ( TestConfigViews , self ) . setUp ( ) <NEWLINE> self . mock_about = mock . patch . object ( <NEWLINE> <INDENT> GoogleDriveClient , <NEWLINE> <STRING> <NEWLINE> <DEDENT> ) <NEWLINE> self . mock_about . return_value = { <STRING> : <STRING> } <NEWLINE> self . mock_about . start ( ) <NEWLINE> self . mock_fetch = mock . patch . object ( <NEWLINE> <INDENT> self . node_settings . __class__ , <NEWLINE> <STRING> <NEWLINE> <DEDENT> ) <NEWLINE> self . mock_fetch . return_value = self . external_account . oauth_key <NEWLINE> self . mock_fetch . start ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'about'", "'rootFolderId'", "'24601'", "'fetch_access_token'"]}}], ["ed4cc77f50fb01441efb41b6b35ec656", {"code_string": "def boundary(A, x, y):\n    \"\"\"Set up boundary conditions\"\"\"\n    Nx = A.shape[1]\n    Ny = A.shape[0]\n    Lx = x[Nx - 1]\n    Ly = x[Nx - 1]\n    A[: , 0] = 100 * numpy.sin(math.pi * x / Lx)\n    A[: , Nx - 1] = - 100 * numpy.sin(math.pi * x / Lx)\n    A[0, : ] = 0.0\n    A[Ny - 1, : ] = 0.0\n", "code_toks_joined": "def boundary ( A , x , y ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> Nx = A . shape [ 1 ] <NEWLINE> Ny = A . shape [ 0 ] <NEWLINE> Lx = x [ Nx - 1 ] <NEWLINE> Ly = x [ Nx - 1 ] <NEWLINE> A [ : , 0 ] = 100 * numpy . sin ( math . pi * x / Lx ) <NEWLINE> A [ : , Nx - 1 ] = - 100 * numpy . sin ( math . pi * x / Lx ) <NEWLINE> A [ 0 , : ] = 0.0 <NEWLINE> A [ Ny - 1 , : ] = 0.0 <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Set up boundary conditions\"\"\""]}}], ["47241a5b73245d5f15d1999020b0e130", {"code_string": "def _live_lint(self, cmd, code):\n    print('gometalinter: live linting {}'.format(self.filename))\n    files = [f for f in os.listdir(os.path.dirname(self.filename)) if f.endswith('.go')]\n    return self.tmpdir(cmd, files, code)\n", "code_toks_joined": "def _live_lint ( self , cmd , code ) : <NEWLINE> <INDENT> print ( <STRING> . format ( self . filename ) ) <NEWLINE> files = [ f for f in os . listdir ( os . path . dirname ( self . filename ) ) if f . endswith ( <STRING> ) ] <NEWLINE> return self . tmpdir ( cmd , files , code ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'gometalinter: live linting {}'", "'.go'"]}}], ["5ebc05191a9b4b846163b47117869afc", {"code_string": "import youtube_edits as youtube_edits_module\nedits = youtube_edits_module.edits\nmapping = get_video_excerpts_map(edits)\nprint(mapping)\nurl = get_youtube_url_from('gz5TPI2sSTo')\nfor key, value in mapping.items():\n    display(HTML(get_embed_string_from(value, url)))\n", "code_toks_joined": "import youtube_edits as youtube_edits_module <NEWLINE> edits = youtube_edits_module . edits <NEWLINE> mapping = get_video_excerpts_map ( edits ) <NEWLINE> print ( mapping ) <NEWLINE> url = get_youtube_url_from ( <STRING> ) <NEWLINE> for key , value in mapping . items ( ) : <NEWLINE> <INDENT> display ( HTML ( get_embed_string_from ( value , url ) ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'gz5TPI2sSTo'"]}}], ["88654d164a2f31a528607fe180d8b45c", {"code_string": "class GdbThread(Thread):\n    def __init__(self, inferior, gdb_thread):\n        super(GdbThread, self).__init__(inferior)\n        self._gdb_thread = gdb_thread\n    def name(self):\n        return self._gdb_thread.name\n    def id(self):\n        return self._gdb_thread.num\n    def is_valid(self):\n        return self._gdb_thread.is_valid()\n", "code_toks_joined": "class GdbThread ( Thread ) : <NEWLINE> <INDENT> def __init__ ( self , inferior , gdb_thread ) : <NEWLINE> <INDENT> super ( GdbThread , self ) . __init__ ( inferior ) <NEWLINE> self . _gdb_thread = gdb_thread <NEWLINE> <DEDENT> def name ( self ) : <NEWLINE> <INDENT> return self . _gdb_thread . name <NEWLINE> <DEDENT> def id ( self ) : <NEWLINE> <INDENT> return self . _gdb_thread . num <NEWLINE> <DEDENT> def is_valid ( self ) : <NEWLINE> <INDENT> return self . _gdb_thread . is_valid ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["2b9f59aa97594536e128a92be67e7650", {"code_string": "def predict(self, sequence, batch_size = 32, verbose = 0):\n    \"\"\"Apply pre-trained labeling to sequences\"\"\"\n    return self.labeling_.predict(\n        sequence, batch_size = batch_size, verbose = verbose)\n", "code_toks_joined": "def predict ( self , sequence , batch_size = 32 , verbose = 0 ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . labeling_ . predict ( <NEWLINE> <INDENT> sequence , batch_size = batch_size , verbose = verbose ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Apply pre-trained labeling to sequences\"\"\""]}}], ["8c3c858d2cf901ec8da88a182c812e58", {"code_string": "def __init__(self, * args, ** kwds):\n    \"\"\"Constructor. Any message fields that are implicitly/explicitly\"\"\"\n    if args or kwds:\n        super(AddTwoIntsResponse, self).__init__(* args, ** kwds)\n        if self.sum is None:\n            self.sum = 0\n    else:\n        self.sum = 0\n", "code_toks_joined": "def __init__ ( self , * args , ** kwds ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if args or kwds : <NEWLINE> <INDENT> super ( AddTwoIntsResponse , self ) . __init__ ( * args , ** kwds ) <NEWLINE> if self . sum is None : <NEWLINE> <INDENT> self . sum = 0 <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> self . sum = 0 <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Constructor. Any message fields that are implicitly/explicitly\"\"\""]}}], ["73de33304a8d68a46aa31924d68e78ed", {"code_string": "def __init__(self, nn, validation_split = 0.25, batch_size = 128, nb_epoch = 10, show_accuracy = True):\n    self.show_accuracy = show_accuracy\n    self.nb_epoch = nb_epoch\n    self.batch_size = batch_size\n    self.validation_split = validation_split\n    self.nn = nn\n    self.model = nn.get_model()\n", "code_toks_joined": "def __init__ ( self , nn , validation_split = 0.25 , batch_size = 128 , nb_epoch = 10 , show_accuracy = True ) : <NEWLINE> <INDENT> self . show_accuracy = show_accuracy <NEWLINE> self . nb_epoch = nb_epoch <NEWLINE> self . batch_size = batch_size <NEWLINE> self . validation_split = validation_split <NEWLINE> self . nn = nn <NEWLINE> self . model = nn . get_model ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["374744a695c450612f78819c5378b16d", {"code_string": "class OggifyOSXAppDelegate(NSObject):\n    def applicationDidFinishLaunching_(self, sender):\n        NSLog(\"Application did finish launching.\")\n", "code_toks_joined": "class OggifyOSXAppDelegate ( NSObject ) : <NEWLINE> <INDENT> def applicationDidFinishLaunching_ ( self , sender ) : <NEWLINE> <INDENT> NSLog ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Application did finish launching.\""]}}], ["2e528d92811dccd6d86dfc763a68c6c5", {"code_string": "from __future__ import absolute_import\nfrom.kafka import KafkaProducer\nfrom.simple import SimpleProducer\nfrom.keyed import KeyedProducer\n__all__ = [\n    'KafkaProducer',\n    'SimpleProducer', 'KeyedProducer'\n]\n", "code_toks_joined": "from __future__ import absolute_import <NEWLINE> from . kafka import KafkaProducer <NEWLINE> from . simple import SimpleProducer <NEWLINE> from . keyed import KeyedProducer <NEWLINE> __all__ = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <STRING> <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'KafkaProducer'", "'SimpleProducer'", "'KeyedProducer'"]}}], ["481666b520cf5c026c282a4681ce97aa", {"code_string": "def BuildNotifyMessage(m_ptr, src, dst_ptr):\n    m_ptr['m_type'] = NOTIFY_MESSAGE\n    m_ptr['NOTIFY_TIMESTAMP'] = get_monotonic()\n    if src == HARDWARE:\n        m_ptr['NOTIFY_TAG'] = dst_ptr['s_int_pending']\n        dst_ptr['s_int_pending'] = 0\n    elif src == SYSTEM:\n        m_ptr['NOTIFY_TAG'] = dst_ptr['s_sig_pending']\n        dst_ptr['s_sig_pending'] = 0\n", "code_toks_joined": "def BuildNotifyMessage ( m_ptr , src , dst_ptr ) : <NEWLINE> <INDENT> m_ptr [ <STRING> ] = NOTIFY_MESSAGE <NEWLINE> m_ptr [ <STRING> ] = get_monotonic ( ) <NEWLINE> if src == HARDWARE : <NEWLINE> <INDENT> m_ptr [ <STRING> ] = dst_ptr [ <STRING> ] <NEWLINE> dst_ptr [ <STRING> ] = 0 <NEWLINE> <DEDENT> elif src == SYSTEM : <NEWLINE> <INDENT> m_ptr [ <STRING> ] = dst_ptr [ <STRING> ] <NEWLINE> dst_ptr [ <STRING> ] = 0 <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'m_type'", "'NOTIFY_TIMESTAMP'", "'NOTIFY_TAG'", "'s_int_pending'", "'s_int_pending'", "'NOTIFY_TAG'", "'s_sig_pending'", "'s_sig_pending'"]}}], ["fab5fb6d59e9c8faefef768fa8050490", {"code_string": "\"\"\"Funciones para obtener datos de Apis Abiertas de gobierno\"\"\"\nimport json\nimport urllib2\nimport pandas as pn\n", "code_toks_joined": "<STRING> <NEWLINE> import json <NEWLINE> import urllib2 <NEWLINE> import pandas as pn <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Funciones para obtener datos de Apis Abiertas de gobierno\"\"\""]}}], ["8e3178682be14f221c1385ed241eea9f", {"code_string": "from.constructors import(\n    is_rule,\n    Production,\n    Rule,\n    OrRule,\n    ExtendedRule,\n    OptionalRule,\n    RepeatableRule,\n    RepeatableOptionalRule,\n    NamedRule,\n    InterpretationRule,\n    ForwardRule,\n    EmptyRule\n)\n", "code_toks_joined": "from . constructors import ( <NEWLINE> <INDENT> is_rule , <NEWLINE> Production , <NEWLINE> Rule , <NEWLINE> OrRule , <NEWLINE> ExtendedRule , <NEWLINE> OptionalRule , <NEWLINE> RepeatableRule , <NEWLINE> RepeatableOptionalRule , <NEWLINE> NamedRule , <NEWLINE> InterpretationRule , <NEWLINE> ForwardRule , <NEWLINE> EmptyRule <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {}}], ["c91ccec1e41ac38ae14ebca5902099e7", {"code_string": "def accueil(self):\n    \"\"\"Message d'accueil de l'\u00e9diteur.\"\"\"\n    identifiant = self.identifiant\n    noms_types = tuple(\n        type(self).importeur.navigation.types_elements.keys())\n    noms_types = sorted(noms_types)\n    return \"|tit|Cr\u00e9ation du prototype {}|ff|\\n\\n\".format(identifiant) + \"Entrez |cmd|le type d'\u00e9l\u00e9ment|ff| que vous souhaitez cr\u00e9er \" \"ou |cmd|a|ff| pour annuler.\\n\" \"Le type choisi ne pourra pas \u00eatre modifi\u00e9 par la suite, \" \"soyez prudent.\\n\\n\" \"Liste des types existants : |cmd|\" + \"|ff|, |cmd|\".join(\n        noms_types) + \"|ff|\"\n", "code_toks_joined": "def accueil ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> identifiant = self . identifiant <NEWLINE> noms_types = tuple ( <NEWLINE> <INDENT> type ( self ) . importeur . navigation . types_elements . keys ( ) ) <NEWLINE> <DEDENT> noms_types = sorted ( noms_types ) <NEWLINE> return <STRING> . format ( identifiant ) + <STRING> <STRING> <STRING> <STRING> <STRING> + <STRING> . join ( <NEWLINE> <INDENT> noms_types ) + <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Message d'accueil de l'\u00e9diteur.\"\"\"", "\"|tit|Cr\u00e9ation du prototype {}|ff|\\n\\n\"", "\"Entrez |cmd|le type d'\u00e9l\u00e9ment|ff| que vous souhaitez cr\u00e9er \"", "\"ou |cmd|a|ff| pour annuler.\\n\"", "\"Le type choisi ne pourra pas \u00eatre modifi\u00e9 par la suite, \"", "\"soyez prudent.\\n\\n\"", "\"Liste des types existants : |cmd|\"", "\"|ff|, |cmd|\"", "\"|ff|\""]}}], ["50e9b6f9a32becea97ade585addedafa", {"code_string": "from distutils.core import setup\nsetup(\n    name = 'pyamaha',\n    packages = ['pyamaha'],\n    version = '0.3',\n    description = 'Python implementation of Yamaha Extended Control API Specification.',\n    author = 'Radoslaw Matusiak',\n    author_email = 'radoslaw.matusiak@gmail.com',\n    url = 'https://github.com/rsc-dev/pyamaha',\n    download_url = 'https://github.com/rsc-dev/pyamaha/releases/tag/0.3',\n    keywords = ['Yamaha', 'API', 'Yamaha Extended Control'],\n    classifiers = [\n        'Development Status :: 4 - Beta',\n        'Environment :: Console',\n        'License :: OSI Approved :: MIT License',\n        'Natural Language :: English',\n        'Operating System :: OS Independent',\n        'Programming Language :: Python',\n        'Topic :: Software Development :: Libraries :: Python Modules'\n    ],\n    install_requires = [\n        'requests',\n    ],\n)\n", "code_toks_joined": "from distutils . core import setup <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> version = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> url = <STRING> , <NEWLINE> download_url = <STRING> , <NEWLINE> keywords = [ <STRING> , <STRING> , <STRING> ] , <NEWLINE> classifiers = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> <NEWLINE> <DEDENT> ] , <NEWLINE> install_requires = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <DEDENT> ] , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'pyamaha'", "'pyamaha'", "'0.3'", "'Python implementation of Yamaha Extended Control API Specification.'", "'Radoslaw Matusiak'", "'radoslaw.matusiak@gmail.com'", "'https://github.com/rsc-dev/pyamaha'", "'https://github.com/rsc-dev/pyamaha/releases/tag/0.3'", "'Yamaha'", "'API'", "'Yamaha Extended Control'", "'Development Status :: 4 - Beta'", "'Environment :: Console'", "'License :: OSI Approved :: MIT License'", "'Natural Language :: English'", "'Operating System :: OS Independent'", "'Programming Language :: Python'", "'Topic :: Software Development :: Libraries :: Python Modules'", "'requests'"]}}], ["1f79da0155ad9990227d83892c2719a0", {"code_string": "def get(self, t, token_or_tag):\n    if t == 0:\n        return get_token(token_or_tag)\n    elif t == 1:\n        return get_tag(token_or_tag)\n", "code_toks_joined": "def get ( self , t , token_or_tag ) : <NEWLINE> <INDENT> if t == 0 : <NEWLINE> <INDENT> return get_token ( token_or_tag ) <NEWLINE> <DEDENT> elif t == 1 : <NEWLINE> <INDENT> return get_tag ( token_or_tag ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["c159abb56e8409248877d7759d57b4f0", {"code_string": "class Board(Model, Base):\n    host = Column(String)\n    alias = Column(String, index = True)\n    __table_args__ = (UniqueConstraint('host', 'alias'), )\n", "code_toks_joined": "class Board ( Model , Base ) : <NEWLINE> <INDENT> host = Column ( String ) <NEWLINE> alias = Column ( String , index = True ) <NEWLINE> __table_args__ = ( UniqueConstraint ( <STRING> , <STRING> ) , ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'host'", "'alias'"]}}], ["81433767221157d7cad847d13a1ddfc6", {"code_string": "\"\"\"[summary]\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport os\nimport sys\nfrom os.path import join as join\nfrom shutil import copyfile\nimport ebf\nimport numpy as np\nimport ConfigParser\nimport skysurvey\nfrom.new_config import SYS_CFG_FNAME\n__all__ = ['fsinit']\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import absolute_import <NEWLINE> from __future__ import division <NEWLINE> from __future__ import print_function <NEWLINE> import os <NEWLINE> import sys <NEWLINE> from os . path import join as join <NEWLINE> from shutil import copyfile <NEWLINE> import ebf <NEWLINE> import numpy as np <NEWLINE> import ConfigParser <NEWLINE> import skysurvey <NEWLINE> from . new_config import SYS_CFG_FNAME <NEWLINE> __all__ = [ <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"[summary]\"\"\"", "'fsinit'"]}}], ["37d2037fde8bf0e0c96a384d64f4156a", {"code_string": "import matplotlib\nimport pandas\nimport re\nfrom matplotlib2tikz import save as tikz_save\nimport numpy\nfrom matplotlib import pyplot\nmatplotlib.style.use('ggplot')\npyplot.interactive(False)\n", "code_toks_joined": "import matplotlib <NEWLINE> import pandas <NEWLINE> import re <NEWLINE> from matplotlib2tikz import save as tikz_save <NEWLINE> import numpy <NEWLINE> from matplotlib import pyplot <NEWLINE> matplotlib . style . use ( <STRING> ) <NEWLINE> pyplot . interactive ( False ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'ggplot'"]}}], ["39ac9fe3ffbece126bfcaa13f0990e74", {"code_string": "def __init__(self, config, url):\n    BaseSiteAdapter.__init__(self, config, url)\n    query_data = urlparse.parse_qs(self.parsedUrl.query)\n    story_id = query_data['sid'][0]\n    self.story.setMetadata('storyId', story_id)\n    self._setURL(self._VIEW_STORY_URL_TEMPLATE % story_id)\n    self.story.setMetadata('siteabbrev', self._SITE_DOMAIN)\n    self.story.setMetadata('language', self._SITE_LANGUAGE)\n", "code_toks_joined": "def __init__ ( self , config , url ) : <NEWLINE> <INDENT> BaseSiteAdapter . __init__ ( self , config , url ) <NEWLINE> query_data = urlparse . parse_qs ( self . parsedUrl . query ) <NEWLINE> story_id = query_data [ <STRING> ] [ 0 ] <NEWLINE> self . story . setMetadata ( <STRING> , story_id ) <NEWLINE> self . _setURL ( self . _VIEW_STORY_URL_TEMPLATE % story_id ) <NEWLINE> self . story . setMetadata ( <STRING> , self . _SITE_DOMAIN ) <NEWLINE> self . story . setMetadata ( <STRING> , self . _SITE_LANGUAGE ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'sid'", "'storyId'", "'siteabbrev'", "'language'"]}}], ["d765c048b5309841321c9033c497e841", {"code_string": "class ProcurementOrder(models.Model):\n    _inherit = 'procurement.order'\n    lot_id = fields.Many2one('stock.production.lot', 'Lot')\n    @ api.model\n    def _get_stock_move_values(self):\n        res = super(\n            ProcurementOrder, self)._get_stock_move_values()\n        res['restrict_lot_id'] = self.lot_id.id\n        return res\n", "code_toks_joined": "class ProcurementOrder ( models . Model ) : <NEWLINE> <INDENT> _inherit = <STRING> <NEWLINE> lot_id = fields . Many2one ( <STRING> , <STRING> ) <NEWLINE> @ api . model <NEWLINE> def _get_stock_move_values ( self ) : <NEWLINE> <INDENT> res = super ( <NEWLINE> <INDENT> ProcurementOrder , self ) . _get_stock_move_values ( ) <NEWLINE> <DEDENT> res [ <STRING> ] = self . lot_id . id <NEWLINE> return res <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'procurement.order'", "'stock.production.lot'", "'Lot'", "'restrict_lot_id'"]}}], ["2e2741c2996adaec10e1c02b4512f0c3", {"code_string": "import xml.etree.ElementTree as ET\nfrom src.element.Card import Card\nfrom src.element.ResourceType import ResourceType\nfrom src.element.Tile import Tile\nfrom src.game.GameState import GameState\nfrom src.mvc.EventType import EventType\n", "code_toks_joined": "import xml . etree . ElementTree as ET <NEWLINE> from src . element . Card import Card <NEWLINE> from src . element . ResourceType import ResourceType <NEWLINE> from src . element . Tile import Tile <NEWLINE> from src . game . GameState import GameState <NEWLINE> from src . mvc . EventType import EventType <NEWLINE>", "anonymize_dict": {}}], ["8144979ae2f93349324c04ae453eda80", {"code_string": "def upgrade():\n    upgrade_table('requests')\n    upgrade_table('assessments')\n", "code_toks_joined": "def upgrade ( ) : <NEWLINE> <INDENT> upgrade_table ( <STRING> ) <NEWLINE> upgrade_table ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'requests'", "'assessments'"]}}], ["112babe1572c1181e278e5baf46c8617", {"code_string": "def test_revision_unit_updater_update(store0):\n    updater_class = revision_updater.get(Unit)\n    updater = updater_class(object_list = store0.units)\n    _test_revision_updater(updater)\n", "code_toks_joined": "def test_revision_unit_updater_update ( store0 ) : <NEWLINE> <INDENT> updater_class = revision_updater . get ( Unit ) <NEWLINE> updater = updater_class ( object_list = store0 . units ) <NEWLINE> _test_revision_updater ( updater ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["183f970be8e3debf0afbd70212215c57", {"code_string": "def clean(self):\n    \"\"\"Validaci\u00f3n de new_email y re_new_email.\"\"\"\n    cleaned_data = super().clean()\n    new_email = cleaned_data.get('new_email')\n    re_new_email = cleaned_data.get('re_new_email')\n    if new_email and new_email != re_new_email:\n        raise forms.ValidationError(ugettext('Los emails no coinciden'))\n    return cleaned_data\n", "code_toks_joined": "def clean ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> cleaned_data = super ( ) . clean ( ) <NEWLINE> new_email = cleaned_data . get ( <STRING> ) <NEWLINE> re_new_email = cleaned_data . get ( <STRING> ) <NEWLINE> if new_email and new_email != re_new_email : <NEWLINE> <INDENT> raise forms . ValidationError ( ugettext ( <STRING> ) ) <NEWLINE> <DEDENT> return cleaned_data <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Validaci\u00f3n de new_email y re_new_email.\"\"\"", "'new_email'", "'re_new_email'", "'Los emails no coinciden'"]}}], ["e8b6fc6122dddd11ad5cfcfcb960b853", {"code_string": "class Trigger():\n    def __init__(self):\n        self.key = \"\"\n        self.handler = 0\n        self.priority = 1\n        self.active = False\n        self.type = 0\n        self.classtxt = \"\"\n", "code_toks_joined": "class Trigger ( ) : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> self . key = <STRING> <NEWLINE> self . handler = 0 <NEWLINE> self . priority = 1 <NEWLINE> self . active = False <NEWLINE> self . type = 0 <NEWLINE> self . classtxt = <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"", "\"\""]}}], ["f992424f9e199d04f72636f63659fb9f", {"code_string": "def process(self):\n    if hasattr(self, '_process') and self._process is not None:\n        return self._process\n", "code_toks_joined": "def process ( self ) : <NEWLINE> <INDENT> if hasattr ( self , <STRING> ) and self . _process is not None : <NEWLINE> <INDENT> return self . _process <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'_process'"]}}], ["71071d315e978ee4ce12dafaf1e8ba88", {"code_string": "def modified(self):\n    try:\n        return self.pod.file_modified(self.pod_path)\n    except OSError:\n        return None\n", "code_toks_joined": "def modified ( self ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> return self . pod . file_modified ( self . pod_path ) <NEWLINE> <DEDENT> except OSError : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["813675aebe929715150e12e086893748", {"code_string": "from __future__ import absolute_import, print_function, unicode_literals, division\nimport itertools\nfrom jormungandr.realtime_schedule.realtime_proxy import RealtimeProxy\nfrom jormungandr.schedule import RealTimePassage\nimport xml.etree.ElementTree as et\nfrom jormungandr.interfaces.parsers import date_time_format\nimport pytz\nfrom flask import logging\nimport pybreaker\nimport requests as requests\nfrom jormungandr import cache, app\nfrom datetime import datetime, time\nfrom jormungandr.utils import timestamp_to_datetime\nfrom navitiacommon.ratelimit import RateLimiter, FakeRateLimiter\nfrom navitiacommon import type_pb2\nimport redis\n", "code_toks_joined": "from __future__ import absolute_import , print_function , unicode_literals , division <NEWLINE> import itertools <NEWLINE> from jormungandr . realtime_schedule . realtime_proxy import RealtimeProxy <NEWLINE> from jormungandr . schedule import RealTimePassage <NEWLINE> import xml . etree . ElementTree as et <NEWLINE> from jormungandr . interfaces . parsers import date_time_format <NEWLINE> import pytz <NEWLINE> from flask import logging <NEWLINE> import pybreaker <NEWLINE> import requests as requests <NEWLINE> from jormungandr import cache , app <NEWLINE> from datetime import datetime , time <NEWLINE> from jormungandr . utils import timestamp_to_datetime <NEWLINE> from navitiacommon . ratelimit import RateLimiter , FakeRateLimiter <NEWLINE> from navitiacommon import type_pb2 <NEWLINE> import redis <NEWLINE>", "anonymize_dict": {}}], ["1b3f64719c66ce28ebd9a3ca02493fa3", {"code_string": "import json\nimport os\nimport os.path\nimport shutil\nimport tornado.web\nfrom base import BaseHandler\nfrom logic import media\nfrom logic import url_factory\n", "code_toks_joined": "import json <NEWLINE> import os <NEWLINE> import os . path <NEWLINE> import shutil <NEWLINE> import tornado . web <NEWLINE> from base import BaseHandler <NEWLINE> from logic import media <NEWLINE> from logic import url_factory <NEWLINE>", "anonymize_dict": {}}], ["351f3740d2e0824112c737f9d319c3c7", {"code_string": "def _auth(self):\n    cmd = (\"oc login %s:%s -u%s -p%s --insecure-skip-tls-verify=True 2>&1 > /dev/null\"\n        %(self.host, self.port, self.username, self.password))\n    subprocess.check_output(cmd, shell = True)\n    cmd = \"oc whoami -t\"\n    stdout = subprocess.check_output(cmd, shell = True)\n    return stdout.strip()\n", "code_toks_joined": "def _auth ( self ) : <NEWLINE> <INDENT> cmd = ( <STRING> <NEWLINE> <INDENT> % ( self . host , self . port , self . username , self . password ) ) <NEWLINE> <DEDENT> subprocess . check_output ( cmd , shell = True ) <NEWLINE> cmd = <STRING> <NEWLINE> stdout = subprocess . check_output ( cmd , shell = True ) <NEWLINE> return stdout . strip ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"oc login %s:%s -u%s -p%s --insecure-skip-tls-verify=True 2>&1 > /dev/null\"", "\"oc whoami -t\""]}}], ["56480f0aad158cced73e20cd2414aef4", {"code_string": "def from_ranges(cls, ranges_list, pattern_creator = None, pattern = None, is_param = False):\n    spans = SpanList(\n        [\n            Span(\n                start,\n                end,\n                pattern_creator = pattern_creator,\n                pattern = pattern,\n                is_param = is_param\n            ) for start, end in ranges_list\n        ]\n    )\n    return spans\n", "code_toks_joined": "def from_ranges ( cls , ranges_list , pattern_creator = None , pattern = None , is_param = False ) : <NEWLINE> <INDENT> spans = SpanList ( <NEWLINE> <INDENT> [ <NEWLINE> <INDENT> Span ( <NEWLINE> <INDENT> start , <NEWLINE> end , <NEWLINE> pattern_creator = pattern_creator , <NEWLINE> pattern = pattern , <NEWLINE> is_param = is_param <NEWLINE> <DEDENT> ) for start , end in ranges_list <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT> ) <NEWLINE> return spans <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["7952d979e96dfa30a41b311fd4b0e8ee", {"code_string": "def test_wildcard():\n    eq_(str(Q('lol*', wildcard = True)), 'lol*')\n    eq_(str(Q('field_with_*', 'some query')), 'field_with_*:(\"some query\")')\n    eq_(str(Q('field_with_*', 'some*query', wildcard = True)), 'field_with_*:(some*query)')\n", "code_toks_joined": "def test_wildcard ( ) : <NEWLINE> <INDENT> eq_ ( str ( Q ( <STRING> , wildcard = True ) ) , <STRING> ) <NEWLINE> eq_ ( str ( Q ( <STRING> , <STRING> ) ) , <STRING> ) <NEWLINE> eq_ ( str ( Q ( <STRING> , <STRING> , wildcard = True ) ) , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'lol*'", "'lol*'", "'field_with_*'", "'some query'", "'field_with_*:(\"some query\")'", "'field_with_*'", "'some*query'", "'field_with_*:(some*query)'"]}}], ["f90dd04e30758abb4e0ab73cf17e1669", {"code_string": "class Gui(base.Gui):\n    \"\"\"Special functions for Konqueror.\"\"\"\n    def reset_browser(self):\n        \"\"\"Delete browser cache.\"\"\"\n        home = os.environ['HOME']\n        self.delete_if_exists(os.path.join(home, '.kde', 'cache-*'))\n", "code_toks_joined": "class Gui ( base . Gui ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def reset_browser ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> home = os . environ [ <STRING> ] <NEWLINE> self . delete_if_exists ( os . path . join ( home , <STRING> , <STRING> ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Special functions for Konqueror.\"\"\"", "\"\"\"Delete browser cache.\"\"\"", "'HOME'", "'.kde'", "'cache-*'"]}}], ["57788f17f90bc240f7b9dc2aa5125922", {"code_string": "def psnr(img1, img2):\n    mse = numpy.mean((img1 - img2) ** 2)\n    if mse == 0:\n        return 100\n    PIXEL_MAX = 255.0\n    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n", "code_toks_joined": "def psnr ( img1 , img2 ) : <NEWLINE> <INDENT> mse = numpy . mean ( ( img1 - img2 ) ** 2 ) <NEWLINE> if mse == 0 : <NEWLINE> <INDENT> return 100 <NEWLINE> <DEDENT> PIXEL_MAX = 255.0 <NEWLINE> return 20 * math . log10 ( PIXEL_MAX / math . sqrt ( mse ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["1463e7f8aad585d3c3f1820e22fc481f", {"code_string": "def send_mail(email_from, email_to, subject, text_content, html_content):\n    mail = EmailMultiAlternatives(\n        subject = subject,\n        body = text_content,\n        from_email = email_from,\n        to = [email_to]\n    )\n    mail.attach_alternative(html_content, \"text/html\")\n    mail.send()\n", "code_toks_joined": "def send_mail ( email_from , email_to , subject , text_content , html_content ) : <NEWLINE> <INDENT> mail = EmailMultiAlternatives ( <NEWLINE> <INDENT> subject = subject , <NEWLINE> body = text_content , <NEWLINE> from_email = email_from , <NEWLINE> to = [ email_to ] <NEWLINE> <DEDENT> ) <NEWLINE> mail . attach_alternative ( html_content , <STRING> ) <NEWLINE> mail . send ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"text/html\""]}}], ["f009a9a3eed03cc91a075253f23151b7", {"code_string": "def p_range(stop, start = 0, step = 1):\n    if start != 0 or step < 0 or stop < 0:\n        stop, start = start, stop\n    p_list = []\n    if step > 0:\n        while start < stop:\n            p_list.append(start)\n            start += step\n    if step < 0:\n        while start > stop:\n            p_list.append(start)\n            start += step\n    return p_list\n", "code_toks_joined": "def p_range ( stop , start = 0 , step = 1 ) : <NEWLINE> <INDENT> if start != 0 or step < 0 or stop < 0 : <NEWLINE> <INDENT> stop , start = start , stop <NEWLINE> <DEDENT> p_list = [ ] <NEWLINE> if step > 0 : <NEWLINE> <INDENT> while start < stop : <NEWLINE> <INDENT> p_list . append ( start ) <NEWLINE> start += step <NEWLINE> <DEDENT> <DEDENT> if step < 0 : <NEWLINE> <INDENT> while start > stop : <NEWLINE> <INDENT> p_list . append ( start ) <NEWLINE> start += step <NEWLINE> <DEDENT> <DEDENT> return p_list <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["143a63f704ac40e0b3e7c880288a4332", {"code_string": "import re\nfrom livestreamer.plugin import Plugin\nfrom livestreamer.stream import HLSStream\nPLAYLIST_URL = \"http://x{0}x.api.channel.livestream.com/3.0/playlist.m3u8\"\n_url_re = re.compile(\"http(s)?://(www\\.)?livestream.com/(?P<channel>[^&?/]+)\")\n", "code_toks_joined": "import re <NEWLINE> from livestreamer . plugin import Plugin <NEWLINE> from livestreamer . stream import HLSStream <NEWLINE> PLAYLIST_URL = <STRING> <NEWLINE> _url_re = re . compile ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"http://x{0}x.api.channel.livestream.com/3.0/playlist.m3u8\"", "\"http(s)?://(www\\.)?livestream.com/(?P<channel>[^&?/]+)\""]}}], ["8d6e52e6ea20082ce209781c2e1b2fa0", {"code_string": "'''Created on 11.04.2016'''\nimport random\nfrom materials.amaterial import AMaterial\n", "code_toks_joined": "<STRING> <NEWLINE> import random <NEWLINE> from materials . amaterial import AMaterial <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Created on 11.04.2016'''"]}}], ["70a40d9302f2465d648bcb5b0e6d6f49", {"code_string": "\"\"\"raas_v2.controllers.exchange_rates_controller\"\"\"\nimport logging\nfrom.base_controller import BaseController\nfrom..api_helper import APIHelper\nfrom..configuration import Configuration\nfrom..http.auth.basic_auth import BasicAuth\n", "code_toks_joined": "<STRING> <NEWLINE> import logging <NEWLINE> from . base_controller import BaseController <NEWLINE> from . . api_helper import APIHelper <NEWLINE> from . . configuration import Configuration <NEWLINE> from . . http . auth . basic_auth import BasicAuth <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"raas_v2.controllers.exchange_rates_controller\"\"\""]}}], ["81afdf13ecbd47104e2aa54885110b50", {"code_string": "import subprocess\nimport sys\nif len(sys.argv) != 3:\n    print(\"Need two arguments\")\n    sys.exit(1)\nresult = subprocess.check_output([sys.argv[1], sys.argv[2]]).strip()\nprint('\"' + result + '\"')\n", "code_toks_joined": "import subprocess <NEWLINE> import sys <NEWLINE> if len ( sys . argv ) != 3 : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> sys . exit ( 1 ) <NEWLINE> <DEDENT> result = subprocess . check_output ( [ sys . argv [ 1 ] , sys . argv [ 2 ] ] ) . strip ( ) <NEWLINE> print ( <STRING> + result + <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"Need two arguments\"", "'\"'", "'\"'"]}}], ["2b80b5a980d56bed95e5e3a74c3f39a5", {"code_string": "def ask(request):\n    if request.method == \"POST\":\n        form = QuestionForm(request.POST)\n        try:\n            question = form.save(commit = False)\n            question.user = request.user\n            question.save()\n            return redirect(question)\n        except ValueError:\n            return render(request, \"qna/ask.html\", {\"error\": True})\n    else:\n        c = {}\n        return render(request, \"qna/ask.html\", c)\n", "code_toks_joined": "def ask ( request ) : <NEWLINE> <INDENT> if request . method == <STRING> : <NEWLINE> <INDENT> form = QuestionForm ( request . POST ) <NEWLINE> try : <NEWLINE> <INDENT> question = form . save ( commit = False ) <NEWLINE> question . user = request . user <NEWLINE> question . save ( ) <NEWLINE> return redirect ( question ) <NEWLINE> <DEDENT> except ValueError : <NEWLINE> <INDENT> return render ( request , <STRING> , { <STRING> : True } ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> c = { } <NEWLINE> return render ( request , <STRING> , c ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"POST\"", "\"qna/ask.html\"", "\"error\"", "\"qna/ask.html\""]}}], ["88ebcb9970542b908167bcfcb06b7045", {"code_string": "\"\"\"Blocking and non-blocking HTTP client interfaces.\"\"\"\nfrom __future__ import absolute_import, division, print_function, with_statement\nimport functools\nimport time\nimport weakref\nfrom tornado.concurrent import TracebackFuture\nfrom tornado.escape import utf8, native_str\nfrom tornado import httputil, stack_context\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import absolute_import , division , print_function , with_statement <NEWLINE> import functools <NEWLINE> import time <NEWLINE> import weakref <NEWLINE> from tornado . concurrent import TracebackFuture <NEWLINE> from tornado . escape import utf8 , native_str <NEWLINE> from tornado import httputil , stack_context <NEWLINE> from tornado . ioloop import IOLoop <NEWLINE> from tornado . util import Configurable <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Blocking and non-blocking HTTP client interfaces.\"\"\""]}}], ["e487bc0751d06c7a95c11ece5b7705c8", {"code_string": "class Solution:\n    def isValidSerialization(self, preorder):\n        preorder = preorder.split(\",\")\n        return self.is_valid_serialization(preorder)\n    def is_valid_serialization(self, preorder):\n        edge_count = 1\n        for node in preorder:\n            if edge_count == 0:\n                return False\n            edge_count -= 1\n            if node != \"#\":\n                edge_count += 2\n        if edge_count != 0:\n            return False\n        return True\n", "code_toks_joined": "class Solution : <NEWLINE> <INDENT> def isValidSerialization ( self , preorder ) : <NEWLINE> <INDENT> preorder = preorder . split ( <STRING> ) <NEWLINE> return self . is_valid_serialization ( preorder ) <NEWLINE> <DEDENT> def is_valid_serialization ( self , preorder ) : <NEWLINE> <INDENT> edge_count = 1 <NEWLINE> for node in preorder : <NEWLINE> <INDENT> if edge_count == 0 : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> edge_count -= 1 <NEWLINE> if node != <STRING> : <NEWLINE> <INDENT> edge_count += 2 <NEWLINE> <DEDENT> <DEDENT> if edge_count != 0 : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> return True <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\",\"", "\"#\""]}}], ["5da9ae237c46b57474153932ef14a3c5", {"code_string": "def get_paper_name_by_issn(issue_df, issn):\n    \"\"\"Return paper name, based on its' ISSN number\"\"\"\n    try:\n        paper = issue_df.loc[issue_df['issn'] == issn]['paper'].iloc[0]\n        return paper\n    except IndexError:\n        log.error('ISSN Number not found: %s' % issn)\n        return False\n", "code_toks_joined": "def get_paper_name_by_issn ( issue_df , issn ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> try : <NEWLINE> <INDENT> paper = issue_df . loc [ issue_df [ <STRING> ] == issn ] [ <STRING> ] . iloc [ 0 ] <NEWLINE> return paper <NEWLINE> <DEDENT> except IndexError : <NEWLINE> <INDENT> log . error ( <STRING> % issn ) <NEWLINE> return False <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Return paper name, based on its' ISSN number\"\"\"", "'issn'", "'paper'", "'ISSN Number not found: %s'"]}}], ["4153f76581062b7767a0a7a0a1ebbdd1", {"code_string": "import data.APIs as apis\napis.deathrate.run()\nimport data.settings as settings\nimport data.generate as generate\nimport data.block as block\nimport data.control as control\nimport data.imageUtils as imageUtils\nimport data.utils as utisls\nimport data.entities as entitites\ngenerate.maze.loadMap()\n", "code_toks_joined": "import data . APIs as apis <NEWLINE> apis . deathrate . run ( ) <NEWLINE> import data . settings as settings <NEWLINE> import data . generate as generate <NEWLINE> import data . block as block <NEWLINE> import data . control as control <NEWLINE> import data . imageUtils as imageUtils <NEWLINE> import data . utils as utisls <NEWLINE> import data . entities as entitites <NEWLINE> generate . maze . loadMap ( ) <NEWLINE>", "anonymize_dict": {}}], ["2cc5696c60cb6cfcb6f0649835ed495f", {"code_string": "\"\"\"\u68c0\u67e5\u56fe\u7247\u94fe\u63a5\uff0c\u6253\u5370\u65e0\u6548\u94fe\u63a5\"\"\"\nimport requests\nfrom pymongo import MongoClient\ncollection = MongoClient(host = 'mongodb').bastogne.movie\nmovie = collection.find()\nwith open('image.txt', 'ab') as f:\n    for mv in movie:\n        try:\n            r = requests.get(mv['image'])\n            if r.status_code != 200:\n                f.write((mv['image'] + '\\n').encode())\n            else:\n                print(mv['id'])\n        except Exception as e:\n            continue\n", "code_toks_joined": "<STRING> <NEWLINE> import requests <NEWLINE> from pymongo import MongoClient <NEWLINE> collection = MongoClient ( host = <STRING> ) . bastogne . movie <NEWLINE> movie = collection . find ( ) <NEWLINE> with open ( <STRING> , <STRING> ) as f : <NEWLINE> <INDENT> for mv in movie : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> r = requests . get ( mv [ <STRING> ] ) <NEWLINE> if r . status_code != 200 : <NEWLINE> <INDENT> f . write ( ( mv [ <STRING> ] + <STRING> ) . encode ( ) ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> print ( mv [ <STRING> ] ) <NEWLINE> <DEDENT> <DEDENT> except Exception as e : <NEWLINE> <INDENT> continue <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"\u68c0\u67e5\u56fe\u7247\u94fe\u63a5\uff0c\u6253\u5370\u65e0\u6548\u94fe\u63a5\"\"\"", "'mongodb'", "'image.txt'", "'ab'", "'image'", "'image'", "'\\n'", "'id'"]}}], ["52594c88ebc49b634f18ae6b1522cef1", {"code_string": "def createLD(language):\n    languageDict = {'french': '584'}\n    langNum = languageDict[language]\n    LD = []\n    with open('EngFrJapGerm.txt', 'r') as infoFile:\n        for line in infoFile:\n            [grammStr, inflStr, sentenceStr] = line.split(\"\\t\")\n            sentenceStr = sentenceStr.rstrip()\n            s = Sentence([grammStr, inflStr, sentenceStr])\n            if grammStr == langNum:\n                LD.append(s)\n    return LD\n", "code_toks_joined": "def createLD ( language ) : <NEWLINE> <INDENT> languageDict = { <STRING> : <STRING> } <NEWLINE> langNum = languageDict [ language ] <NEWLINE> LD = [ ] <NEWLINE> with open ( <STRING> , <STRING> ) as infoFile : <NEWLINE> <INDENT> for line in infoFile : <NEWLINE> <INDENT> [ grammStr , inflStr , sentenceStr ] = line . split ( <STRING> ) <NEWLINE> sentenceStr = sentenceStr . rstrip ( ) <NEWLINE> s = Sentence ( [ grammStr , inflStr , sentenceStr ] ) <NEWLINE> if grammStr == langNum : <NEWLINE> <INDENT> LD . append ( s ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> return LD <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'french'", "'584'", "'EngFrJapGerm.txt'", "'r'", "\"\\t\""]}}], ["221d845bc56c5ea703c6f02c317e3ea9", {"code_string": "def import_object(name, current_module = None):\n    \"\"\"Import an object at \"dotted path\".\"\"\"\n    if '.' not in name:\n        return __import__(name)\n    else:\n        if name.startswith('.'):\n            name = current_module.rsplit('.', 1)[0] + name\n        (modpath, objname) = name.rsplit('.', 1)\n        module = __import__(modpath, fromlist = [objname])\n        return getattr(module, objname)\n", "code_toks_joined": "def import_object ( name , current_module = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if <STRING> not in name : <NEWLINE> <INDENT> return __import__ ( name ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> if name . startswith ( <STRING> ) : <NEWLINE> <INDENT> name = current_module . rsplit ( <STRING> , 1 ) [ 0 ] + name <NEWLINE> <DEDENT> ( modpath , objname ) = name . rsplit ( <STRING> , 1 ) <NEWLINE> module = __import__ ( modpath , fromlist = [ objname ] ) <NEWLINE> return getattr ( module , objname ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Import an object at \"dotted path\".\"\"\"", "'.'", "'.'", "'.'", "'.'"]}}], ["9bd1c175a796407661cb5d9717aebc41", {"code_string": "from distutils.core import setup\n__version__ = \"0.1\"\nsetup(name = \"twisted_hang\",\n    version = __version__,\n    description = \"Figure out if the main thread is hanging, and if so, what's causing it to hang.\",\n    author = \"Geoff Greer\",\n    license = \"MIT\",\n    url = \"https://github.com/ggreer/twisted_hang\",\n    download_url = \"https://github.com/ggreer/twisted_hang.git\",\n    )\n", "code_toks_joined": "from distutils . core import setup <NEWLINE> __version__ = <STRING> <NEWLINE> setup ( name = <STRING> , <NEWLINE> <INDENT> version = __version__ , <NEWLINE> description = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> license = <STRING> , <NEWLINE> url = <STRING> , <NEWLINE> download_url = <STRING> , <NEWLINE> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"0.1\"", "\"twisted_hang\"", "\"Figure out if the main thread is hanging, and if so, what's causing it to hang.\"", "\"Geoff Greer\"", "\"MIT\"", "\"https://github.com/ggreer/twisted_hang\"", "\"https://github.com/ggreer/twisted_hang.git\""]}}], ["ea22a530d1ac75bf3688c07131a0ab53", {"code_string": "\"\"\"Cisco Netflow.\"\"\"\nimport itertools, struct\nimport dpkt\n", "code_toks_joined": "<STRING> <NEWLINE> import itertools , struct <NEWLINE> import dpkt <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Cisco Netflow.\"\"\""]}}], ["94488750925875b35fcec9e3bd88cef8", {"code_string": "def parse_title(lines):\n    \"\"\"Parse optional book title.\"\"\"\n    TITLE_PREFIX = '# '\n    book_title = None\n    if lines[0].startswith(TITLE_PREFIX):\n        book_title = lines.pop(0)[len(TITLE_PREFIX): ].strip()\n    return book_title\n", "code_toks_joined": "def parse_title ( lines ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> TITLE_PREFIX = <STRING> <NEWLINE> book_title = None <NEWLINE> if lines [ 0 ] . startswith ( TITLE_PREFIX ) : <NEWLINE> <INDENT> book_title = lines . pop ( 0 ) [ len ( TITLE_PREFIX ) : ] . strip ( ) <NEWLINE> <DEDENT> return book_title <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Parse optional book title.\"\"\"", "'# '"]}}], ["2294dda711ed80539ae3ce591ba3a9d1", {"code_string": "def printer5():\n    \"\"\"Prints variable x.\"\"\"\n    print(x)\n", "code_toks_joined": "def printer5 ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> print ( x ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Prints variable x.\"\"\""]}}], ["be4b5312440eacb10ee618ef10605da0", {"code_string": "class StatusType(SurrogatePK, Model):\n    \"\"\"A type of status.\"\"\"\n    __tablename__ = 'status_types'\n    name = Column(db.String(10), nullable = False)\n    status = Column(db.String(80), nullable = False)\n    def __init__(self, ** kwargs):\n        \"\"\"Create instance.\"\"\"\n        db.Model.__init__(self, ** kwargs)\n    def __repr__(self):\n        \"\"\"Represent instance as a unique string.\"\"\"\n        return '<StatusType({name})>'.format(name = self.name)\n", "code_toks_joined": "class StatusType ( SurrogatePK , Model ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> __tablename__ = <STRING> <NEWLINE> name = Column ( db . String ( 10 ) , nullable = False ) <NEWLINE> status = Column ( db . String ( 80 ) , nullable = False ) <NEWLINE> def __init__ ( self , ** kwargs ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> db . Model . __init__ ( self , ** kwargs ) <NEWLINE> <DEDENT> def __repr__ ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return <STRING> . format ( name = self . name ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"A type of status.\"\"\"", "'status_types'", "\"\"\"Create instance.\"\"\"", "\"\"\"Represent instance as a unique string.\"\"\"", "'<StatusType({name})>'"]}}], ["f334cf64afa8e1cedbc1f64a1be5f3ac", {"code_string": "def binary(request, name):\n    binary = get_object_or_404(Binary, name = name)\n    versions = binary.generated_binaries.values_list(\n        'buildinfo__version', flat = True,\n    ).order_by('buildinfo__version').distinct()\n    return render(request, 'packages/binary.html', {\n        'binary': binary,\n        'versions': versions,\n    })\n", "code_toks_joined": "def binary ( request , name ) : <NEWLINE> <INDENT> binary = get_object_or_404 ( Binary , name = name ) <NEWLINE> versions = binary . generated_binaries . values_list ( <NEWLINE> <INDENT> <STRING> , flat = True , <NEWLINE> <DEDENT> ) . order_by ( <STRING> ) . distinct ( ) <NEWLINE> return render ( request , <STRING> , { <NEWLINE> <INDENT> <STRING> : binary , <NEWLINE> <STRING> : versions , <NEWLINE> <DEDENT> } ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'buildinfo__version'", "'buildinfo__version'", "'packages/binary.html'", "'binary'", "'versions'"]}}], ["b3d5e0b190945a6e448b5ded16116a6f", {"code_string": "def _fetch_url_data(self, url, username, password, verify):\n    ''' Hit a given http url and return the stats lines '''\n    auth = (username, password)\n    url = \"%s%s\" %(url, STATS_URL)\n    self.log.debug(\"Fetching haproxy stats from url: %s\" % url)\n    response = requests.get(url, auth = auth, headers = headers(self.agentConfig), verify = verify, timeout = self.default_integration_http_timeout)\n    response.raise_for_status()\n    return response.content.splitlines()\n", "code_toks_joined": "def _fetch_url_data ( self , url , username , password , verify ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> auth = ( username , password ) <NEWLINE> url = <STRING> % ( url , STATS_URL ) <NEWLINE> self . log . debug ( <STRING> % url ) <NEWLINE> response = requests . get ( url , auth = auth , headers = headers ( self . agentConfig ) , verify = verify , timeout = self . default_integration_http_timeout ) <NEWLINE> response . raise_for_status ( ) <NEWLINE> return response . content . splitlines ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["''' Hit a given http url and return the stats lines '''", "\"%s%s\"", "\"Fetching haproxy stats from url: %s\""]}}], ["2e9e176e097a84d7829d91e3049a36c6", {"code_string": "\"\"\"Utility functions for the potatoes projet.\"\"\"\nimport string\ntry:\n    from secrets import choice\nexcept ImportError:\n    from random import choice\n", "code_toks_joined": "<STRING> <NEWLINE> import string <NEWLINE> try : <NEWLINE> <INDENT> from secrets import choice <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> from random import choice <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Utility functions for the potatoes projet.\"\"\""]}}], ["44fc1fc3885edbc4a9c92d03156e8092", {"code_string": "import unittest\nimport os\nimport time\nimport librepo\nfrom tests.base import TestCase, TEST_DATA\nREPO_YUM_01_PATH = TEST_DATA + \"/repo_yum_01/\"\n", "code_toks_joined": "import unittest <NEWLINE> import os <NEWLINE> import time <NEWLINE> import librepo <NEWLINE> from tests . base import TestCase , TEST_DATA <NEWLINE> REPO_YUM_01_PATH = TEST_DATA + <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"/repo_yum_01/\""]}}], ["af65c126fb98fb0a9093cdfda6db1153", {"code_string": "def array2d(X, dtype = None, order = None, copy = False, force_all_finite = True):\n    \"\"\"Returns at least 2-d array with data from X\"\"\"\n    X_2d = np.asarray(np.atleast_2d(X), dtype = dtype, order = order)\n    if force_all_finite:\n        _assert_all_finite(X_2d)\n    if X is X_2d and copy:\n        X_2d = _safe_copy(X_2d)\n    return X_2d\n", "code_toks_joined": "def array2d ( X , dtype = None , order = None , copy = False , force_all_finite = True ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> X_2d = np . asarray ( np . atleast_2d ( X ) , dtype = dtype , order = order ) <NEWLINE> if force_all_finite : <NEWLINE> <INDENT> _assert_all_finite ( X_2d ) <NEWLINE> <DEDENT> if X is X_2d and copy : <NEWLINE> <INDENT> X_2d = _safe_copy ( X_2d ) <NEWLINE> <DEDENT> return X_2d <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Returns at least 2-d array with data from X\"\"\""]}}], ["d30999da62fb72229ad80999e12349aa", {"code_string": "import os\nimport unittest\nfrom byro.rms import RMS\n", "code_toks_joined": "import os <NEWLINE> import unittest <NEWLINE> from byro . rms import RMS <NEWLINE>", "anonymize_dict": {}}], ["d27d77fbd349bd214ac8feaa6753fb14", {"code_string": "def drawpaths(self, f, paths):\n    for path in paths:\n        self.drawPolyline(f, path[: - 1], strokeColor = path[- 1])\n", "code_toks_joined": "def drawpaths ( self , f , paths ) : <NEWLINE> <INDENT> for path in paths : <NEWLINE> <INDENT> self . drawPolyline ( f , path [ : - 1 ] , strokeColor = path [ - 1 ] ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["7210cf24690b4dea465503acee284b78", {"code_string": "class GenericTest(unittest.TestCase):\n    def setUp(self):\n        self.parser = argparse.ArgumentParser()\n        self.sub_parsers = self.parser.add_subparsers()\n        pass\n    def test_illegal(self):\n        with self.assertRaises(SystemExit):\n            self.parser.parse_args(['invalid'])\n            pass\n        pass\n    pass\n", "code_toks_joined": "class GenericTest ( unittest . TestCase ) : <NEWLINE> <INDENT> def setUp ( self ) : <NEWLINE> <INDENT> self . parser = argparse . ArgumentParser ( ) <NEWLINE> self . sub_parsers = self . parser . add_subparsers ( ) <NEWLINE> pass <NEWLINE> <DEDENT> def test_illegal ( self ) : <NEWLINE> <INDENT> with self . assertRaises ( SystemExit ) : <NEWLINE> <INDENT> self . parser . parse_args ( [ <STRING> ] ) <NEWLINE> pass <NEWLINE> <DEDENT> pass <NEWLINE> <DEDENT> pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'invalid'"]}}], ["d293495f3ee16523c12dc4e18b2531e7", {"code_string": "\"\"\"Abstraction point for handling of data-pointers in OpenGL\"\"\"\nimport ctypes\nimport OpenGL\nfrom OpenGL.arrays.arraydatatype import *\nfrom OpenGL.arrays import formathandler\n", "code_toks_joined": "<STRING> <NEWLINE> import ctypes <NEWLINE> import OpenGL <NEWLINE> from OpenGL . arrays . arraydatatype import * <NEWLINE> from OpenGL . arrays import formathandler <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Abstraction point for handling of data-pointers in OpenGL\"\"\""]}}], ["d8549c5ea6bd4f4ebf34083b5acc5543", {"code_string": "import pygame\nfrom guilib import get_default\nfrom Lib.Point import Point\n", "code_toks_joined": "import pygame <NEWLINE> from guilib import get_default <NEWLINE> from Lib . Point import Point <NEWLINE>", "anonymize_dict": {}}], ["5a39dedbc0dee135c5bb07a7c715ee3d", {"code_string": "import os\nfrom mako.template import Template\nfrom mako.lookup import TemplateLookup\n", "code_toks_joined": "import os <NEWLINE> from mako . template import Template <NEWLINE> from mako . lookup import TemplateLookup <NEWLINE>", "anonymize_dict": {}}], ["0117fbd1cb0aeea3c1d2514d7c16d8aa", {"code_string": "def _ResizeFile(self, file_path, file_size):\n    logging.debug('Resizing %s to %s', file_path, file_size)\n    with open(file_path, 'a') as disk_file:\n        disk_file.truncate(file_size)\n", "code_toks_joined": "def _ResizeFile ( self , file_path , file_size ) : <NEWLINE> <INDENT> logging . debug ( <STRING> , file_path , file_size ) <NEWLINE> with open ( file_path , <STRING> ) as disk_file : <NEWLINE> <INDENT> disk_file . truncate ( file_size ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Resizing %s to %s'", "'a'"]}}], ["391aebacf0cad23494a30dd220f89023", {"code_string": "def submit_history_entry(user_id, exercise_id, sets, reps, weight, exercise_date):\n    entry_to_add = RepExercisesHistory(\n        user_id = user_id,\n        exercise_id = exercise_id,\n        sets = sets,\n        reps = reps,\n        weight = weight,\n        date = exercise_date\n    )\n    RepExercisesHistoryService.add_entry_to_db(entry_to_add)\n    return entry_to_add\n", "code_toks_joined": "def submit_history_entry ( user_id , exercise_id , sets , reps , weight , exercise_date ) : <NEWLINE> <INDENT> entry_to_add = RepExercisesHistory ( <NEWLINE> <INDENT> user_id = user_id , <NEWLINE> exercise_id = exercise_id , <NEWLINE> sets = sets , <NEWLINE> reps = reps , <NEWLINE> weight = weight , <NEWLINE> date = exercise_date <NEWLINE> <DEDENT> ) <NEWLINE> RepExercisesHistoryService . add_entry_to_db ( entry_to_add ) <NEWLINE> return entry_to_add <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["faf5667b84b747085de4051976958ea3", {"code_string": "import eg\neg.RegisterPlugin(\n    name = \"Serial Port\",\n    author = \"Bitmonster\",\n    guid = \"{D565171F-1703-4212-972C-B824B55329CB}\",\n    version = \"1.1\",\n    canMultiLoad = True,\n    description = \"Arbitrary communication through a serial port.\",\n)\n", "code_toks_joined": "import eg <NEWLINE> eg . RegisterPlugin ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> guid = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> canMultiLoad = True , <NEWLINE> description = <STRING> , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"Serial Port\"", "\"Bitmonster\"", "\"{D565171F-1703-4212-972C-B824B55329CB}\"", "\"1.1\"", "\"Arbitrary communication through a serial port.\""]}}], ["8a95a7d3e82d184c47b89044ce8c85aa", {"code_string": "import sys\nreload(sys)\nsys.setdefaultencoding('utf-8')\nfrom io import open\nfrom tqdm import tqdm\nimport requests\nfrom itertools import chain\nimport json\nfrom nltk import sent_tokenize\nimport string\nimport re\nimport unicodedata\nUNK = 'unk'\nSTART = '^'\nEND = '$'\nPAD = '_'\n", "code_toks_joined": "import sys <NEWLINE> reload ( sys ) <NEWLINE> sys . setdefaultencoding ( <STRING> ) <NEWLINE> from io import open <NEWLINE> from tqdm import tqdm <NEWLINE> import requests <NEWLINE> from itertools import chain <NEWLINE> import json <NEWLINE> from nltk import sent_tokenize <NEWLINE> import string <NEWLINE> import re <NEWLINE> import unicodedata <NEWLINE> UNK = <STRING> <NEWLINE> START = <STRING> <NEWLINE> END = <STRING> <NEWLINE> PAD = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'utf-8'", "'unk'", "'^'", "'$'", "'_'"]}}], ["4558653195c6cfdd9f393271c4509e98", {"code_string": "def Args(parser):\n    parser.add_argument(\n        'names',\n        metavar = 'NAME',\n        nargs = '*',\n        default = [],\n        completion_resource = 'compute.instances',\n        help = ('If provided, show details for the specified names and/or URIs '\n            'of resources.'))\n    regexp = parser.add_argument(\n        '--regexp', '-r',\n        help = 'A regular expression to filter the names of the results on.')\n    regexp.detailed_help = \"\"\" A regular expression to filter the names of the results on. Any names\"\"\"\n", "code_toks_joined": "def Args ( parser ) : <NEWLINE> <INDENT> parser . add_argument ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> metavar = <STRING> , <NEWLINE> nargs = <STRING> , <NEWLINE> default = [ ] , <NEWLINE> completion_resource = <STRING> , <NEWLINE> help = ( <STRING> <NEWLINE> <INDENT> <STRING> ) ) <NEWLINE> <DEDENT> <DEDENT> regexp = parser . add_argument ( <NEWLINE> <INDENT> <STRING> , <STRING> , <NEWLINE> help = <STRING> ) <NEWLINE> <DEDENT> regexp . detailed_help = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'names'", "'NAME'", "'*'", "'compute.instances'", "'If provided, show details for the specified names and/or URIs '", "'of resources.'", "'--regexp'", "'-r'", "'A regular expression to filter the names of the results on.'", "\"\"\" A regular expression to filter the names of the results on. Any names\"\"\""]}}], ["f00d1bae3a1b71f5e11df57c2339da3f", {"code_string": "def testLinkedPointsPairEdgesFloatResult(self):\n    \"\"\"Test if a float is returned and not integer\"\"\"\n    self._runTest(ids = [1, 2], edges = [2, 1], weights = [[1, 1], [2, 2]],\n        starts = [1, 5], expAverage = 1.5)\n", "code_toks_joined": "def testLinkedPointsPairEdgesFloatResult ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . _runTest ( ids = [ 1 , 2 ] , edges = [ 2 , 1 ] , weights = [ [ 1 , 1 ] , [ 2 , 2 ] ] , <NEWLINE> <INDENT> starts = [ 1 , 5 ] , expAverage = 1.5 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test if a float is returned and not integer\"\"\""]}}], ["6adc13782d3c7b26d3643bb940d9f7a8", {"code_string": "import argparse, json, logging, logging.config, os\nimport telebot\nimport config\nimport version\nimport plugins\nAPI_TOKEN = 'TOKEN'\nlogger = logging.getLogger()\n", "code_toks_joined": "import argparse , json , logging , logging . config , os <NEWLINE> import telebot <NEWLINE> import config <NEWLINE> import version <NEWLINE> import plugins <NEWLINE> API_TOKEN = <STRING> <NEWLINE> logger = logging . getLogger ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'TOKEN'"]}}], ["8e9eeb4d2265a6963aa78981c1e6fb4f", {"code_string": "from __future__ import absolute_import\nfrom.dnn import DNN\nfrom.generator import SequenceGenerator\n", "code_toks_joined": "from __future__ import absolute_import <NEWLINE> from . dnn import DNN <NEWLINE> from . generator import SequenceGenerator <NEWLINE>", "anonymize_dict": {}}], ["1c3aef7879688b0c569e51eefec4f0a7", {"code_string": "import os, schedule, time, PyPDF2, re\ntmp = '/Users/workmcgerk/Desktop/repos/oir-strike-data/tmp'\npdf_folder = '/Users/workmcgerk/Desktop/repos/oir-strike-data/PDF/oir-strike-releases-pdf'\ntxt_folder = '/Users/workmcgerk/Desktop/repos/oir-strike-data/TXT/oir-strike-releases-txt'\ncount = []\n", "code_toks_joined": "import os , schedule , time , PyPDF2 , re <NEWLINE> tmp = <STRING> <NEWLINE> pdf_folder = <STRING> <NEWLINE> txt_folder = <STRING> <NEWLINE> count = [ ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'/Users/workmcgerk/Desktop/repos/oir-strike-data/tmp'", "'/Users/workmcgerk/Desktop/repos/oir-strike-data/PDF/oir-strike-releases-pdf'", "'/Users/workmcgerk/Desktop/repos/oir-strike-data/TXT/oir-strike-releases-txt'"]}}], ["ce3e0234f59d3e9bced21fa93915fca9", {"code_string": "import sys\nfrom servers.SAP import SAPserver\nserver = SAPserver()\ngenomeID = '83333.1'\nsys.stderr.write(\"Genome: \" + str(genomeID) + \"\\n\")\nprots = server.all_proteins({\"-id\": genomeID})\nprint(\"protein length \" + str(len(prots)))\n", "code_toks_joined": "import sys <NEWLINE> from servers . SAP import SAPserver <NEWLINE> server = SAPserver ( ) <NEWLINE> genomeID = <STRING> <NEWLINE> sys . stderr . write ( <STRING> + str ( genomeID ) + <STRING> ) <NEWLINE> prots = server . all_proteins ( { <STRING> : genomeID } ) <NEWLINE> print ( <STRING> + str ( len ( prots ) ) ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'83333.1'", "\"Genome: \"", "\"\\n\"", "\"-id\"", "\"protein length \""]}}], ["de4ee7a78a8d17e73dbfe27c836cd59a", {"code_string": "class User(models.Model):\n    \"\"\"Base model for all information related to single user\"\"\"\n    user_id = models.CharField(max_length = 22, primary_key = True)\n    majorcode = models.CharField(max_length = 15)\n    minorcode = models.CharField(max_length = 15)\n    def __unicode__(self):\n        return self.user_id\n", "code_toks_joined": "class User ( models . Model ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> user_id = models . CharField ( max_length = 22 , primary_key = True ) <NEWLINE> majorcode = models . CharField ( max_length = 15 ) <NEWLINE> minorcode = models . CharField ( max_length = 15 ) <NEWLINE> def __unicode__ ( self ) : <NEWLINE> <INDENT> return self . user_id <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Base model for all information related to single user\"\"\""]}}], ["410dbc10336a1e15c72efa53ba88b6a4", {"code_string": "class FakePlugin(object):\n    def loadTestsFromModule(self, event):\n        event.fake = True\n    def loadTestsFromNames(self, event):\n        event.fake = True\n", "code_toks_joined": "class FakePlugin ( object ) : <NEWLINE> <INDENT> def loadTestsFromModule ( self , event ) : <NEWLINE> <INDENT> event . fake = True <NEWLINE> <DEDENT> def loadTestsFromNames ( self , event ) : <NEWLINE> <INDENT> event . fake = True <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["00cf441ee0990c1e4aa67c74d9126a60", {"code_string": "from telemetry.web_perf.metrics import single_event\nEVENT_NAME = 'WebLocalFrameImpl::moveRangeSelectionExtent'\nMETRIC_NAME = 'text-selection'\n", "code_toks_joined": "from telemetry . web_perf . metrics import single_event <NEWLINE> EVENT_NAME = <STRING> <NEWLINE> METRIC_NAME = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'WebLocalFrameImpl::moveRangeSelectionExtent'", "'text-selection'"]}}], ["2ded1f60db1da2bab2849792add62ac0", {"code_string": "def test_find():\n    buf = CircularBuffer(32)\n    buf.write(b'asdf\\r\\njkl;\\r\\n1234\\r\\n')\n    assert buf.find(b'\\r\\n') == 4\n    assert buf.find(b'x') == - 1\n    assert buf.find(b'\\r\\n', 5) == 10\n    buf.clear()\n    buf.write(b'asdf\\r\\njkl;\\r\\n1234\\r\\na')\n    assert buf.find(b'\\r\\n') == 4\n    assert buf.find(b'x') == - 1\n    assert buf.find(b'\\r\\n', 5) == 10\n    with raises(ValueError):\n        buf.find(b'')\n", "code_toks_joined": "def test_find ( ) : <NEWLINE> <INDENT> buf = CircularBuffer ( 32 ) <NEWLINE> buf . write ( <STRING> ) <NEWLINE> assert buf . find ( <STRING> ) == 4 <NEWLINE> assert buf . find ( <STRING> ) == - 1 <NEWLINE> assert buf . find ( <STRING> , 5 ) == 10 <NEWLINE> buf . clear ( ) <NEWLINE> buf . write ( <STRING> ) <NEWLINE> assert buf . find ( <STRING> ) == 4 <NEWLINE> assert buf . find ( <STRING> ) == - 1 <NEWLINE> assert buf . find ( <STRING> , 5 ) == 10 <NEWLINE> with raises ( ValueError ) : <NEWLINE> <INDENT> buf . find ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["b'asdf\\r\\njkl;\\r\\n1234\\r\\n'", "b'\\r\\n'", "b'x'", "b'\\r\\n'", "b'asdf\\r\\njkl;\\r\\n1234\\r\\na'", "b'\\r\\n'", "b'x'", "b'\\r\\n'", "b''"]}}], ["99cb17d65405ead008510814d581d945", {"code_string": "class SecurityRoot(object):\n    __acl__ = [\n        (Allow, Authenticated, 'read'),\n        (Allow, 'user', 'edit'),\n        (Allow, 'admin', ALL_PERMISSIONS),\n        DENY_ALL\n    ]\n    def __init__(self, request):\n        self.request = request\n", "code_toks_joined": "class SecurityRoot ( object ) : <NEWLINE> <INDENT> __acl__ = [ <NEWLINE> <INDENT> ( Allow , Authenticated , <STRING> ) , <NEWLINE> ( Allow , <STRING> , <STRING> ) , <NEWLINE> ( Allow , <STRING> , ALL_PERMISSIONS ) , <NEWLINE> DENY_ALL <NEWLINE> <DEDENT> ] <NEWLINE> def __init__ ( self , request ) : <NEWLINE> <INDENT> self . request = request <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'read'", "'user'", "'edit'", "'admin'"]}}], ["03a276f80dbe6c3e6ab309197156e9ab", {"code_string": "def upgrade():\n    template_history_insert = \"\"\"INSERT INTO templates_history (id, name, template_type, created_at,\"\"\"\n    template_insert = \"\"\"INSERT INTO templates (id, name, template_type, created_at,\"\"\"\n    template_content = \"\"\"Hi ((name)),nnClick this link to confirm your new email address:\"\"\"\n    template_name = 'Confirm new email address'\n    op.execute(template_history_insert.format(template_id,\n        template_name,\n        'email',\n        datetime.utcnow(), template_content,\n        service_id,\n        template_name, user_id))\n    op.execute(template_insert.format(template_id,\n        template_name,\n        'email',\n        datetime.utcnow(),\n        template_content,\n        service_id,\n        template_name, user_id))\n", "code_toks_joined": "def upgrade ( ) : <NEWLINE> <INDENT> template_history_insert = <STRING> <NEWLINE> template_insert = <STRING> <NEWLINE> template_content = <STRING> <NEWLINE> template_name = <STRING> <NEWLINE> op . execute ( template_history_insert . format ( template_id , <NEWLINE> <INDENT> template_name , <NEWLINE> <STRING> , <NEWLINE> datetime . utcnow ( ) , template_content , <NEWLINE> service_id , <NEWLINE> template_name , user_id ) ) <NEWLINE> <DEDENT> op . execute ( template_insert . format ( template_id , <NEWLINE> <INDENT> template_name , <NEWLINE> <STRING> , <NEWLINE> datetime . utcnow ( ) , <NEWLINE> template_content , <NEWLINE> service_id , <NEWLINE> template_name , user_id ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"INSERT INTO templates_history (id, name, template_type, created_at,\"\"\"", "\"\"\"INSERT INTO templates (id, name, template_type, created_at,\"\"\"", "\"\"\"Hi ((name)),nnClick this link to confirm your new email address:\"\"\"", "'Confirm new email address'", "'email'", "'email'"]}}], ["a2f8223a1ff347d74c6926f52c3adde4", {"code_string": "class MistTest(Base):\n    \"\"\"A MIST_ typing test with a unique name.\"\"\"\n    __tablename__ = 'mist_test'\n    id = Column(Integer, primary_key = True)\n    name = Column(String, unique = True, index = True, nullable = False)\n    type = Column(MistTestType.db_type(), nullable = False)\n    def __repr__(self):\n        return '<MistTest({id}, Type={type}, Name={name})>'.format(\n            id = self.id,\n            type = self.type,\n            name = self.name)\n", "code_toks_joined": "class MistTest ( Base ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> __tablename__ = <STRING> <NEWLINE> id = Column ( Integer , primary_key = True ) <NEWLINE> name = Column ( String , unique = True , index = True , nullable = False ) <NEWLINE> type = Column ( MistTestType . db_type ( ) , nullable = False ) <NEWLINE> def __repr__ ( self ) : <NEWLINE> <INDENT> return <STRING> . format ( <NEWLINE> <INDENT> id = self . id , <NEWLINE> type = self . type , <NEWLINE> name = self . name ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"A MIST_ typing test with a unique name.\"\"\"", "'mist_test'", "'<MistTest({id}, Type={type}, Name={name})>'"]}}], ["6cac61c5e573f16e9db538f30958bcd2", {"code_string": "from distutils.core import setup\nsetup(\n    name = 'PyCharts',\n    version = '',\n    packages = ['pycharts', 'pycharts.charts',\n        'pycharts.fields', 'pycharts.fields.series', 'pycharts.fields.plot_options'],\n    url = '',\n    license = '',\n    author = 'jpedro',\n    author_email = '',\n    description = ''\n)\n", "code_toks_joined": "from distutils . core import setup <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> packages = [ <STRING> , <STRING> , <NEWLINE> <INDENT> <STRING> , <STRING> , <STRING> ] , <NEWLINE> <DEDENT> url = <STRING> , <NEWLINE> license = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> description = <STRING> <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'PyCharts'", "''", "'pycharts'", "'pycharts.charts'", "'pycharts.fields'", "'pycharts.fields.series'", "'pycharts.fields.plot_options'", "''", "''", "'jpedro'", "''", "''"]}}], ["eeccea6c4e386877c39d7168c758d2ed", {"code_string": "\"\"\" A sparse matrix in COOrdinate or 'triplet' format\"\"\"\nfrom __future__ import division, print_function, absolute_import\n__docformat__ = \"restructuredtext en\"\n__all__ = ['coo_matrix', 'isspmatrix_coo']\nfrom warnings import warn\nimport numpy as np\nfrom scipy.lib.six import xrange, zip as izip\nfrom._sparsetools import coo_tocsr, coo_todense, coo_matvec\nfrom.base import isspmatrix\nfrom.data import _data_matrix, _minmax_mixin\nfrom.sputils import(upcast, upcast_char, to_native, isshape, getdtype,\n    isintlike, get_index_dtype, downcast_intp_index, _compat_bincount)\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import division , print_function , absolute_import <NEWLINE> __docformat__ = <STRING> <NEWLINE> __all__ = [ <STRING> , <STRING> ] <NEWLINE> from warnings import warn <NEWLINE> import numpy as np <NEWLINE> from scipy . lib . six import xrange , zip as izip <NEWLINE> from . _sparsetools import coo_tocsr , coo_todense , coo_matvec <NEWLINE> from . base import isspmatrix <NEWLINE> from . data import _data_matrix , _minmax_mixin <NEWLINE> from . sputils import ( upcast , upcast_char , to_native , isshape , getdtype , <NEWLINE> <INDENT> isintlike , get_index_dtype , downcast_intp_index , _compat_bincount ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" A sparse matrix in COOrdinate or 'triplet' format\"\"\"", "\"restructuredtext en\"", "'coo_matrix'", "'isspmatrix_coo'"]}}], ["80ed73b48d9b51cf0e491db36a2a39f2", {"code_string": "import sys\nfrom argparse import ArgumentParser\nimport js2xml\n", "code_toks_joined": "import sys <NEWLINE> from argparse import ArgumentParser <NEWLINE> import js2xml <NEWLINE>", "anonymize_dict": {}}], ["7fa1dc27217d8c4399e6dab76bbbb3aa", {"code_string": "def ChangeAlias(exe, lib):\n    cmd = qtPath + lib + \".framework/Versions/4/\" + lib + \" \" + \"@executable_path/../Frameworks/\" + lib + \".framework/\" + lib + \" \" + exe\n    os.system(\"install_name_tool -change \" + cmd)\n", "code_toks_joined": "def ChangeAlias ( exe , lib ) : <NEWLINE> <INDENT> cmd = qtPath + lib + <STRING> + lib + <STRING> + <STRING> + lib + <STRING> + lib + <STRING> + exe <NEWLINE> os . system ( <STRING> + cmd ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\".framework/Versions/4/\"", "\" \"", "\"@executable_path/../Frameworks/\"", "\".framework/\"", "\" \"", "\"install_name_tool -change \""]}}], ["09b845bf7bf106b6cde030c87ac3dd30", {"code_string": "import os\nimport sys\npossible_topdir = os.path.normpath(os.path.join(os.path.abspath(__file__),\n    os.pardir,\n    os.pardir,\n    os.pardir))\nif os.path.exists(os.path.join(possible_topdir,\n    'keystone',\n    '__init__.py')):\n    sys.path.insert(0, possible_topdir)\nfrom keystone.cmd import cli\nfrom keystone.common import environment\n", "code_toks_joined": "import os <NEWLINE> import sys <NEWLINE> possible_topdir = os . path . normpath ( os . path . join ( os . path . abspath ( __file__ ) , <NEWLINE> <INDENT> os . pardir , <NEWLINE> os . pardir , <NEWLINE> os . pardir ) ) <NEWLINE> <DEDENT> if os . path . exists ( os . path . join ( possible_topdir , <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> ) ) : <NEWLINE> sys . path . insert ( 0 , possible_topdir ) <NEWLINE> <DEDENT> from keystone . cmd import cli <NEWLINE> from keystone . common import environment <NEWLINE>", "anonymize_dict": {"<STRING>": ["'keystone'", "'__init__.py'"]}}], ["f49c96cb6e765d489d7c3f3611457e99", {"code_string": "import uuid\nimport json\nimport subprocess as sp\nimport os\nimport time\ntry:\n    psi_location = os.environ[\"MONGO_PSI4\"]\nexcept:\n    raise KeyError(\"Mongo Compute: MONGO_PSI4 psi variable was not set. Failing.\")\npsi_run = \"python \" + psi_location + \" --json \"\n", "code_toks_joined": "import uuid <NEWLINE> import json <NEWLINE> import subprocess as sp <NEWLINE> import os <NEWLINE> import time <NEWLINE> try : <NEWLINE> <INDENT> psi_location = os . environ [ <STRING> ] <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> raise KeyError ( <STRING> ) <NEWLINE> <DEDENT> psi_run = <STRING> + psi_location + <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"MONGO_PSI4\"", "\"Mongo Compute: MONGO_PSI4 psi variable was not set. Failing.\"", "\"python \"", "\" --json \""]}}], ["6750dc9cf5eed187ed01de9cde75e637", {"code_string": "def deploy_app(self, app, stage, version):\n    r = self.__session.put(\n        urljoin(self.__api_uri, \"apps/{}/stages/{}/version/{}/\".format(app, stage, version)),\n        timeout = self.__timeout)\n    r.raise_for_status()\n", "code_toks_joined": "def deploy_app ( self , app , stage , version ) : <NEWLINE> <INDENT> r = self . __session . put ( <NEWLINE> <INDENT> urljoin ( self . __api_uri , <STRING> . format ( app , stage , version ) ) , <NEWLINE> timeout = self . __timeout ) <NEWLINE> <DEDENT> r . raise_for_status ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"apps/{}/stages/{}/version/{}/\""]}}], ["1a2659aba7dbde432c2c7a224e3952ef", {"code_string": "def getHtml(self):\n    \"\"\"Get the HTML associated with this object.\"\"\"\n    htmlList = [\"<sub>\"]\n    htmlList = htmlList + font.getHtml(self)\n    htmlList = htmlList +[\"</sub>\"]\n    return htmlList\n", "code_toks_joined": "def getHtml ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> htmlList = [ <STRING> ] <NEWLINE> htmlList = htmlList + font . getHtml ( self ) <NEWLINE> htmlList = htmlList + [ <STRING> ] <NEWLINE> return htmlList <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Get the HTML associated with this object.\"\"\"", "\"<sub>\"", "\"</sub>\""]}}], ["16d29ec42163421526c086f91bfcaa26", {"code_string": "def createWriterDocument(self):\n    localContext = uno.getComponentContext()\n    resolver = localContext.ServiceManager.createInstanceWithContext(\"com.sun.star.bridge.UnoUrlResolver\", localContext)\n    ctx = resolver.resolve(\"uno:socket,host=localhost,port=2002;urp;StarOffice.ComponentContext\")\n    smgr = ctx.ServiceManager\n    desktop = smgr.createInstanceWithContext(\"com.sun.star.frame.Desktop\", ctx)\n    doc = desktop.getCurrentComponent()\n    if not hasattr(doc, \"Text\"):\n        doc = desktop.loadComponentFromURL(\"private:factory/swriter\", \"_blank\", 0, ())\n    return doc\n", "code_toks_joined": "def createWriterDocument ( self ) : <NEWLINE> <INDENT> localContext = uno . getComponentContext ( ) <NEWLINE> resolver = localContext . ServiceManager . createInstanceWithContext ( <STRING> , localContext ) <NEWLINE> ctx = resolver . resolve ( <STRING> ) <NEWLINE> smgr = ctx . ServiceManager <NEWLINE> desktop = smgr . createInstanceWithContext ( <STRING> , ctx ) <NEWLINE> doc = desktop . getCurrentComponent ( ) <NEWLINE> if not hasattr ( doc , <STRING> ) : <NEWLINE> <INDENT> doc = desktop . loadComponentFromURL ( <STRING> , <STRING> , 0 , ( ) ) <NEWLINE> <DEDENT> return doc <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"com.sun.star.bridge.UnoUrlResolver\"", "\"uno:socket,host=localhost,port=2002;urp;StarOffice.ComponentContext\"", "\"com.sun.star.frame.Desktop\"", "\"Text\"", "\"private:factory/swriter\"", "\"_blank\""]}}], ["0ba15f92121cdf188f420b753afd9a89", {"code_string": "class superList(list):\n    def __sub__(self, b):\n        a = self[: ]\n        b = b[: ]\n        while len(b) > 0:\n            element_b = b.pop()\n            if element_b in a:\n                a.remove(element_b)\n        return superList(a)\n", "code_toks_joined": "class superList ( list ) : <NEWLINE> <INDENT> def __sub__ ( self , b ) : <NEWLINE> <INDENT> a = self [ : ] <NEWLINE> b = b [ : ] <NEWLINE> while len ( b ) > 0 : <NEWLINE> <INDENT> element_b = b . pop ( ) <NEWLINE> if element_b in a : <NEWLINE> <INDENT> a . remove ( element_b ) <NEWLINE> <DEDENT> <DEDENT> return superList ( a ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["d229db517d1e330ae423f0af440d21a8", {"code_string": "def __combine(self, amnt_op, this_op, other):\n    if isinstance(other, _base_multiset):\n        result = self.__class__()\n        for element in chain(self.__bag, other.__bag):\n            amount = amnt_op(self.count(element), other.count(element))\n            if amount > 0:\n                result.__bag[element] = amount\n        return result\n    if isinstance(other, Iterable):\n        return this_op(self, self.__class__(other))\n    raise NotImplementedError()\n", "code_toks_joined": "def __combine ( self , amnt_op , this_op , other ) : <NEWLINE> <INDENT> if isinstance ( other , _base_multiset ) : <NEWLINE> <INDENT> result = self . __class__ ( ) <NEWLINE> for element in chain ( self . __bag , other . __bag ) : <NEWLINE> <INDENT> amount = amnt_op ( self . count ( element ) , other . count ( element ) ) <NEWLINE> if amount > 0 : <NEWLINE> <INDENT> result . __bag [ element ] = amount <NEWLINE> <DEDENT> <DEDENT> return result <NEWLINE> <DEDENT> if isinstance ( other , Iterable ) : <NEWLINE> <INDENT> return this_op ( self , self . __class__ ( other ) ) <NEWLINE> <DEDENT> raise NotImplementedError ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["d3d6be7ace08ff1bf85a45b2dbec0f71", {"code_string": "def create_h_tunnel(x1, x2, y):\n    pts = []\n    for x in range(min(x1, x2), max(x1, x2) + 1):\n        pts.append(Point(x, y))\n    return pts\n", "code_toks_joined": "def create_h_tunnel ( x1 , x2 , y ) : <NEWLINE> <INDENT> pts = [ ] <NEWLINE> for x in range ( min ( x1 , x2 ) , max ( x1 , x2 ) + 1 ) : <NEWLINE> <INDENT> pts . append ( Point ( x , y ) ) <NEWLINE> <DEDENT> return pts <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ca090397bbb1f0d9b51a2e239bc1bf82", {"code_string": "def temp_read(pin_obj):\n    if device_type == DEVICE_TYPE_MRAA:\n        return pyupm_grove.GroveTemp(pin_obj).value()\n    elif device_type == DEVICE_TYPE_RPI:\n        raise NotImplementedError\n    elif device_type == DEVICE_TYPE_GPI:\n        return grovepi.temp(pin_obj, '1.1')\n", "code_toks_joined": "def temp_read ( pin_obj ) : <NEWLINE> <INDENT> if device_type == DEVICE_TYPE_MRAA : <NEWLINE> <INDENT> return pyupm_grove . GroveTemp ( pin_obj ) . value ( ) <NEWLINE> <DEDENT> elif device_type == DEVICE_TYPE_RPI : <NEWLINE> <INDENT> raise NotImplementedError <NEWLINE> <DEDENT> elif device_type == DEVICE_TYPE_GPI : <NEWLINE> <INDENT> return grovepi . temp ( pin_obj , <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'1.1'"]}}], ["449ad735b506bcd45a8254a678b43ef8", {"code_string": "import unittest\nfrom itertools import chain\nfrom nineml.abstraction.dynamics import(\n    Dynamics, Regime, On, OutputEvent)\nfrom nineml.abstraction.ports import AnalogSendPort, AnalogReceivePort\nfrom nineml.abstraction.expressions import reserved_identifiers\n", "code_toks_joined": "import unittest <NEWLINE> from itertools import chain <NEWLINE> from nineml . abstraction . dynamics import ( <NEWLINE> <INDENT> Dynamics , Regime , On , OutputEvent ) <NEWLINE> <DEDENT> from nineml . abstraction . ports import AnalogSendPort , AnalogReceivePort <NEWLINE> from nineml . abstraction . expressions import reserved_identifiers <NEWLINE>", "anonymize_dict": {}}], ["5f65f81df8e06934aa26e1a4c96f2ae7", {"code_string": "class Client(object):\n    def get(self, uri, ** kw):\n        return self.request('GET', uri, ** kw)\n    def post(self, uri, ** kw):\n        return self.request('POST', uri, ** kw)\n    def head(self, uri, ** kw):\n        return self.request('HEAD', uri, ** kw)\n    def put(self, uri, ** kw):\n        return self.request('PUT', uri, ** kw)\n", "code_toks_joined": "class Client ( object ) : <NEWLINE> <INDENT> def get ( self , uri , ** kw ) : <NEWLINE> <INDENT> return self . request ( <STRING> , uri , ** kw ) <NEWLINE> <DEDENT> def post ( self , uri , ** kw ) : <NEWLINE> <INDENT> return self . request ( <STRING> , uri , ** kw ) <NEWLINE> <DEDENT> def head ( self , uri , ** kw ) : <NEWLINE> <INDENT> return self . request ( <STRING> , uri , ** kw ) <NEWLINE> <DEDENT> def put ( self , uri , ** kw ) : <NEWLINE> <INDENT> return self . request ( <STRING> , uri , ** kw ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'GET'", "'POST'", "'HEAD'", "'PUT'"]}}], ["49b04f730a08917bf2d067a6caac1c9d", {"code_string": "def test_vode(self):\n    for problem_cls in PROBLEMS:\n        problem = problem_cls()\n        if problem.cmplx:\n            continue\n        if not problem.stiff:\n            self._do_problem(problem, 'vode', 'adams')\n        self._do_problem(problem, 'vode', 'bdf')\n", "code_toks_joined": "def test_vode ( self ) : <NEWLINE> <INDENT> for problem_cls in PROBLEMS : <NEWLINE> <INDENT> problem = problem_cls ( ) <NEWLINE> if problem . cmplx : <NEWLINE> <INDENT> continue <NEWLINE> <DEDENT> if not problem . stiff : <NEWLINE> <INDENT> self . _do_problem ( problem , <STRING> , <STRING> ) <NEWLINE> <DEDENT> self . _do_problem ( problem , <STRING> , <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'vode'", "'adams'", "'vode'", "'bdf'"]}}], ["0c5e1dd74620168ebd2357d1d02b4e18", {"code_string": "def test_linear_h():\n    f = np.arange(9).reshape((3, 3)) % 3 > 0\n    g = pymorph.patspec(f, 'linear-h')\n", "code_toks_joined": "def test_linear_h ( ) : <NEWLINE> <INDENT> f = np . arange ( 9 ) . reshape ( ( 3 , 3 ) ) % 3 > 0 <NEWLINE> g = pymorph . patspec ( f , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'linear-h'"]}}], ["dcd5c450fa24d38b49644a11e9e87ead", {"code_string": "def main():\n    srcPath = 'Shaders/src/'\n    binPath = 'Shaders/bin/'\n    logPath = 'Shaders/log/'\n    shaderFormats = [\n        '*.vert',\n        '*.tesc',\n        '*.tese',\n        '*.geom',\n        '*.frag',\n        '*.comp']\n    for format in shaderFormats:\n        for shaderFile in glob.glob(srcPath + format):\n            shaderName = os.path.basename(shaderFile)\n            os.system(\"glslangValidator.exe -V -H {0} -o {1} > {2}\".format(\n                srcPath + shaderName,\n                binPath + shaderName + '.spv',\n                logPath + shaderName))\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> srcPath = <STRING> <NEWLINE> binPath = <STRING> <NEWLINE> logPath = <STRING> <NEWLINE> shaderFormats = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> ] <NEWLINE> <DEDENT> for format in shaderFormats : <NEWLINE> <INDENT> for shaderFile in glob . glob ( srcPath + format ) : <NEWLINE> <INDENT> shaderName = os . path . basename ( shaderFile ) <NEWLINE> os . system ( <STRING> . format ( <NEWLINE> <INDENT> srcPath + shaderName , <NEWLINE> binPath + shaderName + <STRING> , <NEWLINE> logPath + shaderName ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Shaders/src/'", "'Shaders/bin/'", "'Shaders/log/'", "'*.vert'", "'*.tesc'", "'*.tese'", "'*.geom'", "'*.frag'", "'*.comp'", "\"glslangValidator.exe -V -H {0} -o {1} > {2}\"", "'.spv'"]}}], ["d480bc31c21a36b8d52f7c4a3b8d83c0", {"code_string": "def test_internal_link_to_home_converted_to_index(self):\n    md_link = \"\"\"[subpage/home]({{< relref \"subpage/_index.md\" >}})\"\"\"\n    doku_link = \"[[subpage/home]]\"\n    self.assertEqual(md_link, self.converter.convert(doku_link))\n", "code_toks_joined": "def test_internal_link_to_home_converted_to_index ( self ) : <NEWLINE> <INDENT> md_link = <STRING> <NEWLINE> doku_link = <STRING> <NEWLINE> self . assertEqual ( md_link , self . converter . convert ( doku_link ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"[subpage/home]({{< relref \"subpage/_index.md\" >}})\"\"\"", "\"[[subpage/home]]\""]}}], ["9c6203bd288b69411d674c65c5e74fb9", {"code_string": "class SrcClockDomain(ClockDomain):\n    type = 'SrcClockDomain'\n    cxx_header = \"sim/clock_domain.hh\"\n    clock = VectorParam.Clock(\"Clock period\")\n    voltage_domain = Param.VoltageDomain(\"Voltage domain\")\n    domain_id = Param.Int32(- 1, \"domain id\")\n    init_perf_level = Param.UInt32(0, \"Initial performance level\")\n", "code_toks_joined": "class SrcClockDomain ( ClockDomain ) : <NEWLINE> <INDENT> type = <STRING> <NEWLINE> cxx_header = <STRING> <NEWLINE> clock = VectorParam . Clock ( <STRING> ) <NEWLINE> voltage_domain = Param . VoltageDomain ( <STRING> ) <NEWLINE> domain_id = Param . Int32 ( - 1 , <STRING> ) <NEWLINE> init_perf_level = Param . UInt32 ( 0 , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'SrcClockDomain'", "\"sim/clock_domain.hh\"", "\"Clock period\"", "\"Voltage domain\"", "\"domain id\"", "\"Initial performance level\""]}}], ["0e0bed8715833a343ae72f3684141386", {"code_string": "def GetOutputs(cls):\n    \"\"\"Retrieves the available output classes.\"\"\"\n    for output_class in cls._output_classes.itervalues():\n        yield output_class.NAME, output_class.DESCRIPTION\n", "code_toks_joined": "def GetOutputs ( cls ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> for output_class in cls . _output_classes . itervalues ( ) : <NEWLINE> <INDENT> yield output_class . NAME , output_class . DESCRIPTION <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Retrieves the available output classes.\"\"\""]}}], ["09f2cdfd232a2ab33c559b6c53076159", {"code_string": "from nose import with_setup\nfrom Panini import Pack\nimport Panini\n", "code_toks_joined": "from nose import with_setup <NEWLINE> from Panini import Pack <NEWLINE> import Panini <NEWLINE>", "anonymize_dict": {}}], ["1025cbb96ef6fa8deb786248496f99c4", {"code_string": "import logging\nimport time\nfrom lib.orgproperty import OrgProperties\nfrom lib.orgformat import OrgFormat\nfrom lib.memacs import Memacs\n", "code_toks_joined": "import logging <NEWLINE> import time <NEWLINE> from lib . orgproperty import OrgProperties <NEWLINE> from lib . orgformat import OrgFormat <NEWLINE> from lib . memacs import Memacs <NEWLINE>", "anonymize_dict": {}}], ["81f25feb43856098389a76ae8616e6f8", {"code_string": "def test_event_Parse_invalid(self):\n    e = mailpile.eventlog.Event.Parse(\"all exceptions are caught\")\n    self.assertEqual(e.__class__, mailpile.eventlog.Event)\n", "code_toks_joined": "def test_event_Parse_invalid ( self ) : <NEWLINE> <INDENT> e = mailpile . eventlog . Event . Parse ( <STRING> ) <NEWLINE> self . assertEqual ( e . __class__ , mailpile . eventlog . Event ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"all exceptions are caught\""]}}], ["a7fafcf4ddacb99c3982ca02ff440610", {"code_string": "class IAsyncUtility(Interface):\n    async def initialize(self):\n        pass\n", "code_toks_joined": "class IAsyncUtility ( Interface ) : <NEWLINE> <INDENT> async def initialize ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["967d3bfe0bb736cd40d9f9d058470c4d", {"code_string": "def custom_exc(shell, etype, evalue, tb, tb_offset = None):\n    import traceback\n    from p4.interactive.excepthook import invoke_editor\n    te = traceback.extract_tb(tb)\n    shell.showtraceback((etype, evalue, tb), tb_offset = tb_offset)\n    invoke_editor(te)\n", "code_toks_joined": "def custom_exc ( shell , etype , evalue , tb , tb_offset = None ) : <NEWLINE> <INDENT> import traceback <NEWLINE> from p4 . interactive . excepthook import invoke_editor <NEWLINE> te = traceback . extract_tb ( tb ) <NEWLINE> shell . showtraceback ( ( etype , evalue , tb ) , tb_offset = tb_offset ) <NEWLINE> invoke_editor ( te ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["b3b34f4e6390641904a6dade67db86c1", {"code_string": "def save_user_profile(sender, instance, ** kwargs):\n    try:\n        instance.profile.save()\n    except:\n        Profile.objects.create(user = instance)\n", "code_toks_joined": "def save_user_profile ( sender , instance , ** kwargs ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> instance . profile . save ( ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> Profile . objects . create ( user = instance ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["4c7d4ec747934d412608488c384d7c96", {"code_string": "\"\"\"A sober python base library\"\"\"\n__version__ = \"0.6.0\"\nfrom.util import *\nfrom.obj import *\n", "code_toks_joined": "<STRING> <NEWLINE> __version__ = <STRING> <NEWLINE> from . util import * <NEWLINE> from . obj import * <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"A sober python base library\"\"\"", "\"0.6.0\""]}}], ["cf83e8e7ec749ee8581fb6c294e26da5", {"code_string": "import numpy as np\nimport pylab as pl\nimport os, sys\npl.rcParams['lines.linewidth'] = 2\npl.rcParams['legend.fontsize'] = 16\npl.rcParams['axes.labelsize'] = 16\npl.rcParams['xtick.labelsize'] = 14\npl.rcParams['ytick.labelsize'] = 14\ndataset = '/Users/double/workspace/DAE_paper/Exp/vary_datasets.txt'\nif(not os.path.isfile(dataset)):\n    print(\"the data file is not exist: \", dataset)\n    sys.exit()\n", "code_toks_joined": "import numpy as np <NEWLINE> import pylab as pl <NEWLINE> import os , sys <NEWLINE> pl . rcParams [ <STRING> ] = 2 <NEWLINE> pl . rcParams [ <STRING> ] = 16 <NEWLINE> pl . rcParams [ <STRING> ] = 16 <NEWLINE> pl . rcParams [ <STRING> ] = 14 <NEWLINE> pl . rcParams [ <STRING> ] = 14 <NEWLINE> dataset = <STRING> <NEWLINE> if ( not os . path . isfile ( dataset ) ) : <NEWLINE> <INDENT> print ( <STRING> , dataset ) <NEWLINE> sys . exit ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'lines.linewidth'", "'legend.fontsize'", "'axes.labelsize'", "'xtick.labelsize'", "'ytick.labelsize'", "'/Users/double/workspace/DAE_paper/Exp/vary_datasets.txt'", "\"the data file is not exist: \""]}}], ["57a60869f71b7168af26ec012b25fed7", {"code_string": "class Class(models.Model):\n    name = models.CharField(max_length = 4, unique = True)\n    class Meta:\n        verbose_name = 'class'\n        verbose_name_plural = 'classes'\n        app_label = 'app'\n    def __unicode__(self):\n        return self.name\n", "code_toks_joined": "class Class ( models . Model ) : <NEWLINE> <INDENT> name = models . CharField ( max_length = 4 , unique = True ) <NEWLINE> class Meta : <NEWLINE> <INDENT> verbose_name = <STRING> <NEWLINE> verbose_name_plural = <STRING> <NEWLINE> app_label = <STRING> <NEWLINE> <DEDENT> def __unicode__ ( self ) : <NEWLINE> <INDENT> return self . name <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'class'", "'classes'", "'app'"]}}], ["98024cb4808d785c4b64f28a588e8668", {"code_string": "def test_greatest_common_divisor_zero(self):\n    actual = gcd.GreatestCommonDivisor.greatest_common_divisor(12, 0)\n    self.assertEqual(0, actual)\n    actual = gcd.GreatestCommonDivisor.greatest_common_divisor(0, 13)\n    self.assertEqual(0, actual)\n    actual = gcd.GreatestCommonDivisor.greatest_common_divisor(- 5, 13)\n    self.assertEqual(0, actual)\n", "code_toks_joined": "def test_greatest_common_divisor_zero ( self ) : <NEWLINE> <INDENT> actual = gcd . GreatestCommonDivisor . greatest_common_divisor ( 12 , 0 ) <NEWLINE> self . assertEqual ( 0 , actual ) <NEWLINE> actual = gcd . GreatestCommonDivisor . greatest_common_divisor ( 0 , 13 ) <NEWLINE> self . assertEqual ( 0 , actual ) <NEWLINE> actual = gcd . GreatestCommonDivisor . greatest_common_divisor ( - 5 , 13 ) <NEWLINE> self . assertEqual ( 0 , actual ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ea7f2ba2c54dd43407dc259df596d7c9", {"code_string": "def close(self):\n    \"\"\"Close stream\"\"\"\n    if self.state == \"CLOSED\":\n        return\n    self.decryptor = None\n    self.source_fp = None\n    self.state = \"CLOSED\"\n", "code_toks_joined": "def close ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if self . state == <STRING> : <NEWLINE> <INDENT> return <NEWLINE> <DEDENT> self . decryptor = None <NEWLINE> self . source_fp = None <NEWLINE> self . state = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Close stream\"\"\"", "\"CLOSED\"", "\"CLOSED\""]}}], ["b27637b4bc20f9c8c4a1e7867926eb96", {"code_string": "def authorize_landing(self):\n    if not self.available_runways:\n        print('Request denied. No available runways')\n        return False\n    else:\n        runway = self.available_runways.pop()\n        self.engaged_runways.append(runway)\n        print('Request granted. Please land on runway {}'.format(runway))\n        self.status()\n        return True\n", "code_toks_joined": "def authorize_landing ( self ) : <NEWLINE> <INDENT> if not self . available_runways : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> return False <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> runway = self . available_runways . pop ( ) <NEWLINE> self . engaged_runways . append ( runway ) <NEWLINE> print ( <STRING> . format ( runway ) ) <NEWLINE> self . status ( ) <NEWLINE> return True <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Request denied. No available runways'", "'Request granted. Please land on runway {}'"]}}], ["6ade16fe39c7b84e20d65e767ba16064", {"code_string": "import antlr3\nfrom CalculatorLexer import CalculatorLexer\nfrom CalculatorParser import CalculatorParser\nwhile True:\n    expr = raw_input('>>> ')\n    if expr == '':\n        break\n    cStream = antlr3.StringStream(expr)\n    lexer = CalculatorLexer(cStream)\n    tStream = antlr3.CommonTokenStream(lexer)\n    parser = CalculatorParser(tStream)\n    result = parser.evaluate()\n    print(result)\n", "code_toks_joined": "import antlr3 <NEWLINE> from CalculatorLexer import CalculatorLexer <NEWLINE> from CalculatorParser import CalculatorParser <NEWLINE> while True : <NEWLINE> <INDENT> expr = raw_input ( <STRING> ) <NEWLINE> if expr == <STRING> : <NEWLINE> <INDENT> break <NEWLINE> <DEDENT> cStream = antlr3 . StringStream ( expr ) <NEWLINE> lexer = CalculatorLexer ( cStream ) <NEWLINE> tStream = antlr3 . CommonTokenStream ( lexer ) <NEWLINE> parser = CalculatorParser ( tStream ) <NEWLINE> result = parser . evaluate ( ) <NEWLINE> print ( result ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'>>> '", "''"]}}], ["70b04fc944d7a968cc38664277668ca8", {"code_string": "def __init__(self, name, email, password):\n    self.name = name\n    self.email = email\n    self.password = password\n    self.tasks = self.get_tasks()\n", "code_toks_joined": "def __init__ ( self , name , email , password ) : <NEWLINE> <INDENT> self . name = name <NEWLINE> self . email = email <NEWLINE> self . password = password <NEWLINE> self . tasks = self . get_tasks ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["51dc387cfa471af5fc258ce6b8d4a76f", {"code_string": "import sets, os\nfrom galaxy import eggs\nfrom galaxy import jobs\nfrom galaxy.tools.parameters import DataToolParameter\n", "code_toks_joined": "import sets , os <NEWLINE> from galaxy import eggs <NEWLINE> from galaxy import jobs <NEWLINE> from galaxy . tools . parameters import DataToolParameter <NEWLINE>", "anonymize_dict": {}}], ["1e48e16e5b9c53a39d990f650565a526", {"code_string": "from cx_Freeze import setup, Executable\nbuildOptions = dict(packages = ['pymodbus', 'pypeg2'], excludes = [])\nexecutables = [\n    Executable('spots_gui.py'),\n    Executable('spots_plc.py')\n]\nsetup(\n    name = 'SPotS',\n    version = '0.1',\n    author = 'Christian Wichmann',\n    author_email = 'wichmann@bbs-os-brinkstr.de',\n    packages = ['spots', 'gui'],\n    url = '',\n    license = 'LICENSE',\n    description = 'SoftPLC to control multiple I/O nodes via ModbusTCP',\n    options = dict(build_exe = buildOptions),\n    executables = executables\n)\n", "code_toks_joined": "from cx_Freeze import setup , Executable <NEWLINE> buildOptions = dict ( packages = [ <STRING> , <STRING> ] , excludes = [ ] ) <NEWLINE> executables = [ <NEWLINE> <INDENT> Executable ( <STRING> ) , <NEWLINE> Executable ( <STRING> ) <NEWLINE> <DEDENT> ] <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> packages = [ <STRING> , <STRING> ] , <NEWLINE> url = <STRING> , <NEWLINE> license = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> options = dict ( build_exe = buildOptions ) , <NEWLINE> executables = executables <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'pymodbus'", "'pypeg2'", "'spots_gui.py'", "'spots_plc.py'", "'SPotS'", "'0.1'", "'Christian Wichmann'", "'wichmann@bbs-os-brinkstr.de'", "'spots'", "'gui'", "''", "'LICENSE'", "'SoftPLC to control multiple I/O nodes via ModbusTCP'"]}}], ["2442a281e6b3f7097e8af5ac109d0258", {"code_string": "\"\"\"sentry.db.models.fields\"\"\"\nfrom __future__ import absolute_import\nfrom.bounded import *\nfrom.gzippeddict import *\nfrom.node import *\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import absolute_import <NEWLINE> from . bounded import * <NEWLINE> from . gzippeddict import * <NEWLINE> from . node import * <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"sentry.db.models.fields\"\"\""]}}], ["9088dbf07f4ebef487abdd116c17af28", {"code_string": "def read_symbol_array(path):\n    with open(path, 'r') as f:\n        return array.array('H', map(int, f.read().split()))\n", "code_toks_joined": "def read_symbol_array ( path ) : <NEWLINE> <INDENT> with open ( path , <STRING> ) as f : <NEWLINE> <INDENT> return array . array ( <STRING> , map ( int , f . read ( ) . split ( ) ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'r'", "'H'"]}}], ["b659255805f04b318fb240c4358403c9", {"code_string": "__author__ = 'Donovan Parks'\n__copyright__ = 'Copyright 2016'\n__credits__ = ['Donovan Parks']\n__license__ = 'GPL3'\n__maintainer__ = 'Donovan Parks'\n__email__ = 'donovan.parks@gmail.com'\nimport os\nimport sys\nimport logging\nimport tempfile\nfrom collections import defaultdict\nfrom comparem.aai_calculator import AAICalculator\nfrom biolib.common import concatenate_files, make_sure_path_exists\n", "code_toks_joined": "__author__ = <STRING> <NEWLINE> __copyright__ = <STRING> <NEWLINE> __credits__ = [ <STRING> ] <NEWLINE> __license__ = <STRING> <NEWLINE> __maintainer__ = <STRING> <NEWLINE> __email__ = <STRING> <NEWLINE> import os <NEWLINE> import sys <NEWLINE> import logging <NEWLINE> import tempfile <NEWLINE> from collections import defaultdict <NEWLINE> from comparem . aai_calculator import AAICalculator <NEWLINE> from biolib . common import concatenate_files , make_sure_path_exists <NEWLINE>", "anonymize_dict": {"<STRING>": ["'Donovan Parks'", "'Copyright 2016'", "'Donovan Parks'", "'GPL3'", "'Donovan Parks'", "'donovan.parks@gmail.com'"]}}], ["039ace8addcdd910c75d62fac0113a72", {"code_string": "def test_show(self):\n    instance_id = 1\n    uuid = fakes.get_fake_uuid(instance_id)\n    self.stubs.Set(compute.api.API, 'get',\n        fake_compute_get(instance_id, uuid = uuid,\n            vm_state = vm_states.ACTIVE))\n    res = self._make_request(self.base_url + '/%s' % uuid)\n    self.assertEqual(res.status_int, 200)\n    server = self._get_server(res.body)\n    addresses = self._get_addresses(server)\n    self._check_addresses(addresses, exists = True)\n", "code_toks_joined": "def test_show ( self ) : <NEWLINE> <INDENT> instance_id = 1 <NEWLINE> uuid = fakes . get_fake_uuid ( instance_id ) <NEWLINE> self . stubs . Set ( compute . api . API , <STRING> , <NEWLINE> <INDENT> fake_compute_get ( instance_id , uuid = uuid , <NEWLINE> <INDENT> vm_state = vm_states . ACTIVE ) ) <NEWLINE> <DEDENT> <DEDENT> res = self . _make_request ( self . base_url + <STRING> % uuid ) <NEWLINE> self . assertEqual ( res . status_int , 200 ) <NEWLINE> server = self . _get_server ( res . body ) <NEWLINE> addresses = self . _get_addresses ( server ) <NEWLINE> self . _check_addresses ( addresses , exists = True ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'get'", "'/%s'"]}}], ["ef56fb459b1017b43c5a1daa9caf8de9", {"code_string": "def getPartitionState(self):\n    \"\"\"Returns String\"\"\"\n    return self.partitionState\n", "code_toks_joined": "def getPartitionState ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . partitionState <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Returns String\"\"\""]}}], ["b486cc48eef95a454ebab0b8e6f7107c", {"code_string": "import csv\nfrom itertools import chain\nfrom collections import OrderedDict\nimport random\n", "code_toks_joined": "import csv <NEWLINE> from itertools import chain <NEWLINE> from collections import OrderedDict <NEWLINE> import random <NEWLINE>", "anonymize_dict": {}}], ["5796da58c9a9c0c1b7b0821abdbaefe9", {"code_string": "def update(self, screen, update_type, rects):\n    screen.blit(self.top_bar, (0, 0))\n    self.screen_objects.render(screen)\n    update_all = (update_type == BaseScreen.update_all)\n    self.list_view.render(screen, update_all, rects)\n", "code_toks_joined": "def update ( self , screen , update_type , rects ) : <NEWLINE> <INDENT> screen . blit ( self . top_bar , ( 0 , 0 ) ) <NEWLINE> self . screen_objects . render ( screen ) <NEWLINE> update_all = ( update_type == BaseScreen . update_all ) <NEWLINE> self . list_view . render ( screen , update_all , rects ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["e4b2eb32add6ac165d5c1033458b8663", {"code_string": "class Detect(object):\n    def __init__(self, kp = None, desc = None):\n        \"\"\"Keypoints and descriptors of an image\"\"\"\n        self.kp = kp\n        self.desc = desc\n", "code_toks_joined": "class Detect ( object ) : <NEWLINE> <INDENT> def __init__ ( self , kp = None , desc = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . kp = kp <NEWLINE> self . desc = desc <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Keypoints and descriptors of an image\"\"\""]}}], ["eb5479cbc92915e07da67f9fcb0d4ab9", {"code_string": "class TabletProximityRec(Structure):\n    _fields_ = (\n        ('vendorID', c_uint16),\n        ('tabletID', c_uint16),\n        ('pointerID', c_uint16),\n        ('deviceID', c_uint16),\n        ('systemTabletID', c_uint16),\n        ('vendorPointerType', c_uint16),\n        ('pointerSerialNumber', c_uint32),\n        ('uniqueID', c_uint64),\n        ('capabilityMask', c_uint32),\n        ('pointerType', c_uint8),\n        ('enterProximity', c_uint8),\n    )\n", "code_toks_joined": "class TabletProximityRec ( Structure ) : <NEWLINE> <INDENT> _fields_ = ( <NEWLINE> <INDENT> ( <STRING> , c_uint16 ) , <NEWLINE> ( <STRING> , c_uint16 ) , <NEWLINE> ( <STRING> , c_uint16 ) , <NEWLINE> ( <STRING> , c_uint16 ) , <NEWLINE> ( <STRING> , c_uint16 ) , <NEWLINE> ( <STRING> , c_uint16 ) , <NEWLINE> ( <STRING> , c_uint32 ) , <NEWLINE> ( <STRING> , c_uint64 ) , <NEWLINE> ( <STRING> , c_uint32 ) , <NEWLINE> ( <STRING> , c_uint8 ) , <NEWLINE> ( <STRING> , c_uint8 ) , <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'vendorID'", "'tabletID'", "'pointerID'", "'deviceID'", "'systemTabletID'", "'vendorPointerType'", "'pointerSerialNumber'", "'uniqueID'", "'capabilityMask'", "'pointerType'", "'enterProximity'"]}}], ["05e3adc14ec61c49db1e096ae6fd9225", {"code_string": "import mnist\nimport numpy as np\ndata = mnist.read(\"training\")\n(img, lab) = next(data)\n(img, lab) = next(data)\n(img, lab) = next(data)\nmnist.show(img)\n", "code_toks_joined": "import mnist <NEWLINE> import numpy as np <NEWLINE> data = mnist . read ( <STRING> ) <NEWLINE> ( img , lab ) = next ( data ) <NEWLINE> ( img , lab ) = next ( data ) <NEWLINE> ( img , lab ) = next ( data ) <NEWLINE> mnist . show ( img ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"training\""]}}], ["c8a5bb3d9d1bd253cae606fae38ddb66", {"code_string": "from __future__ import unicode_literals\nfrom django.apps import apps\nfrom django.conf import settings\nfrom django.utils._os import safe_join\nfrom.globals import HACS_APP_NAME\n__author__ = \"Md Nazrul Islam<connect2nazrul@gmail.com>\"\nHACS_CACHE_SETTING_NAME = 'default'\nHACS_FALLBACK_URLCONF = settings.ROOT_URLCONF\nHACS_GENERATED_URLCONF_DIR = safe_join(apps.get_app_config(HACS_APP_NAME).path, 'generated')\nHACS_SERIALIZED_ROUTING_DIR = None\nHACS_USER_OBJECT_QUERY_CALLABLE = \"hacs.utils.get_user_object\"\nHACS_DEVELOPMENT_MODE = False\nHACS_AUTO_DISCOVER_URL_MODULE = [\"admin.site.urls\", ]\nHACS_AC_BYPASS = 0\nHACS_ANONYMOUS_ROLE_NAME = \"Guest\"\nHACS_DEFAULT_STATE = \"draft\"\nHACS_DEFAULT_STATES = (\n    \"published\", \"internally_published\", \"draft\", \"private\"\n)\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> from django . apps import apps <NEWLINE> from django . conf import settings <NEWLINE> from django . utils . _os import safe_join <NEWLINE> from . globals import HACS_APP_NAME <NEWLINE> __author__ = <STRING> <NEWLINE> HACS_CACHE_SETTING_NAME = <STRING> <NEWLINE> HACS_FALLBACK_URLCONF = settings . ROOT_URLCONF <NEWLINE> HACS_GENERATED_URLCONF_DIR = safe_join ( apps . get_app_config ( HACS_APP_NAME ) . path , <STRING> ) <NEWLINE> HACS_SERIALIZED_ROUTING_DIR = None <NEWLINE> HACS_USER_OBJECT_QUERY_CALLABLE = <STRING> <NEWLINE> HACS_DEVELOPMENT_MODE = False <NEWLINE> HACS_AUTO_DISCOVER_URL_MODULE = [ <STRING> , ] <NEWLINE> HACS_AC_BYPASS = 0 <NEWLINE> HACS_ANONYMOUS_ROLE_NAME = <STRING> <NEWLINE> HACS_DEFAULT_STATE = <STRING> <NEWLINE> HACS_DEFAULT_STATES = ( <NEWLINE> <INDENT> <STRING> , <STRING> , <STRING> , <STRING> <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"Md Nazrul Islam<connect2nazrul@gmail.com>\"", "'default'", "'generated'", "\"hacs.utils.get_user_object\"", "\"admin.site.urls\"", "\"Guest\"", "\"draft\"", "\"published\"", "\"internally_published\"", "\"draft\"", "\"private\""]}}], ["b62c4e363b9286ed878cf43cd2336efc", {"code_string": "def _complete_python_while_typing(self, document):\n    char_before_cursor = document.char_before_cursor\n    return document.text and(\n        char_before_cursor.isalnum() or char_before_cursor in '_.')\n", "code_toks_joined": "def _complete_python_while_typing ( self , document ) : <NEWLINE> <INDENT> char_before_cursor = document . char_before_cursor <NEWLINE> return document . text and ( <NEWLINE> <INDENT> char_before_cursor . isalnum ( ) or char_before_cursor in <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'_.'"]}}], ["aded9fd059ad174f343245d28c87bdc7", {"code_string": "def constant(val = 0.1):\n    p = Param(val = val)\n    def _init(shape, dtype):\n        out = val * tf.ones(shape, dtype = dtype)\n        out.for_print = 'constant(%s)' % p\n        return out\n    return _init\n", "code_toks_joined": "def constant ( val = 0.1 ) : <NEWLINE> <INDENT> p = Param ( val = val ) <NEWLINE> def _init ( shape , dtype ) : <NEWLINE> <INDENT> out = val * tf . ones ( shape , dtype = dtype ) <NEWLINE> out . for_print = <STRING> % p <NEWLINE> return out <NEWLINE> <DEDENT> return _init <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'constant(%s)'"]}}], ["3f8c69b55a0b0dacd449a6e9af147e4e", {"code_string": "def get_wiki_syntax(self):\n    def revlink(f, match, fullmatch):\n        rev = match.split(' ', 1)[1]\n        return self._format_revision_link(f, 'revision', rev, rev,\n            fullmatch)\n    yield(r\"!?(?:%s)\\s+%s\" %(\"|\".join(self.KEYWORDS),\n        ChangesetModule.CHANGESET_ID),\n        revlink)\n", "code_toks_joined": "def get_wiki_syntax ( self ) : <NEWLINE> <INDENT> def revlink ( f , match , fullmatch ) : <NEWLINE> <INDENT> rev = match . split ( <STRING> , 1 ) [ 1 ] <NEWLINE> return self . _format_revision_link ( f , <STRING> , rev , rev , <NEWLINE> <INDENT> fullmatch ) <NEWLINE> <DEDENT> <DEDENT> yield ( <STRING> % ( <STRING> . join ( self . KEYWORDS ) , <NEWLINE> <INDENT> ChangesetModule . CHANGESET_ID ) , <NEWLINE> revlink ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["' '", "'revision'", "r\"!?(?:%s)\\s+%s\"", "\"|\""]}}], ["f53c82ca0f6924c5f3f9bac2e8e6d4c9", {"code_string": "def setUp(self):\n    \"\"\"Create the UI\"\"\"\n    Registry.create()\n    self.setup_application()\n    self.main_window = QtGui.QMainWindow()\n    Registry().register('main_window', self.main_window)\n    self.form = ShortcutListForm()\n", "code_toks_joined": "def setUp ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> Registry . create ( ) <NEWLINE> self . setup_application ( ) <NEWLINE> self . main_window = QtGui . QMainWindow ( ) <NEWLINE> Registry ( ) . register ( <STRING> , self . main_window ) <NEWLINE> self . form = ShortcutListForm ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Create the UI\"\"\"", "'main_window'"]}}], ["80ebeb3ac1204763b33e1f1fa1e53adb", {"code_string": "def onPathmappingRemove(self, button = None):\n    builder = self._builder\n    treeviewPathmapping = builder.get_object(\"treeviewPathmapping\")\n    liststorePathmapping = builder.get_object(\"liststorePathmapping\")\n    selection = treeviewPathmapping.get_selection()\n    store, selected_rows = selection.get_selected_rows()\n    for path in selected_rows:\n        treeIter = liststorePathmapping.get_iter(path)\n        localPath = liststorePathmapping.get_value(treeIter, 0)\n        remotePath = liststorePathmapping.get_value(treeIter, 1)\n        self._path_mapping_manager.remove_path_mapping(localPath, remotePath)\n", "code_toks_joined": "def onPathmappingRemove ( self , button = None ) : <NEWLINE> <INDENT> builder = self . _builder <NEWLINE> treeviewPathmapping = builder . get_object ( <STRING> ) <NEWLINE> liststorePathmapping = builder . get_object ( <STRING> ) <NEWLINE> selection = treeviewPathmapping . get_selection ( ) <NEWLINE> store , selected_rows = selection . get_selected_rows ( ) <NEWLINE> for path in selected_rows : <NEWLINE> <INDENT> treeIter = liststorePathmapping . get_iter ( path ) <NEWLINE> localPath = liststorePathmapping . get_value ( treeIter , 0 ) <NEWLINE> remotePath = liststorePathmapping . get_value ( treeIter , 1 ) <NEWLINE> self . _path_mapping_manager . remove_path_mapping ( localPath , remotePath ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"treeviewPathmapping\"", "\"liststorePathmapping\""]}}], ["8cf4f02635359b4bf3c3b6b78aa1de42", {"code_string": "class DNSForwardPolicy(enum.Enum):\n    ONLY = 'only'\n    FIRST = 'first'\n", "code_toks_joined": "class DNSForwardPolicy ( enum . Enum ) : <NEWLINE> <INDENT> ONLY = <STRING> <NEWLINE> FIRST = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'only'", "'first'"]}}], ["3a89271d338f15ce19a92c0d189b3066", {"code_string": "def does_user_exist(self, user_path, user_name, ** kwargs):\n    node_path = '{0}/{1}'.format(user_path.rstrip('/'), user_name.lstrip('/'))\n    return self._does_node_exist(node_path, 'User', ** kwargs)\n", "code_toks_joined": "def does_user_exist ( self , user_path , user_name , ** kwargs ) : <NEWLINE> <INDENT> node_path = <STRING> . format ( user_path . rstrip ( <STRING> ) , user_name . lstrip ( <STRING> ) ) <NEWLINE> return self . _does_node_exist ( node_path , <STRING> , ** kwargs ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'{0}/{1}'", "'/'", "'/'", "'User'"]}}], ["13e5f58bcfed8dd5a1ae48ad22ba3f4d", {"code_string": "from.import test_create_mgmtsystem\n", "code_toks_joined": "from . import test_create_mgmtsystem <NEWLINE>", "anonymize_dict": {}}], ["02d03ba8c386116ae541013162b14a7f", {"code_string": "def environments_by_org(self, orgId):\n    path = \"/api/organizations/%s/environments\" % orgId\n    envs = self.server.GET(path)[1]\n    return envs\n", "code_toks_joined": "def environments_by_org ( self , orgId ) : <NEWLINE> <INDENT> path = <STRING> % orgId <NEWLINE> envs = self . server . GET ( path ) [ 1 ] <NEWLINE> return envs <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"/api/organizations/%s/environments\""]}}], ["ca66f3deec9ae0280f41c9adb9fea4d7", {"code_string": "from django.conf.urls import patterns, include, url\nfrom django.contrib import admin\nurlpatterns = patterns('',\n    url(r'^admin/', include(admin.site.urls)),\n    url(r'^app/', include('app.urls', namespace = 'app'))\n)\n", "code_toks_joined": "from django . conf . urls import patterns , include , url <NEWLINE> from django . contrib import admin <NEWLINE> urlpatterns = patterns ( <STRING> , <NEWLINE> <INDENT> url ( <STRING> , include ( admin . site . urls ) ) , <NEWLINE> url ( <STRING> , include ( <STRING> , namespace = <STRING> ) ) <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["''", "r'^admin/'", "r'^app/'", "'app.urls'", "'app'"]}}], ["d7723320b4791d9010c503c490d662d1", {"code_string": "def cmd_quickbuffer(data, buffer, command):\n    \"\"\"Any command being run will be checked to see if it matches /<number>, and intercepted if it does\"\"\"\n    match = QUICKBUFFER_REGEXP.match(command)\n    if match:\n        w.command(buffer, \"/buffer {}\".format(match.group(1)))\n        return w.WEECHAT_RC_OK_EAT\n    return w.WEECHAT_RC_OK\n", "code_toks_joined": "def cmd_quickbuffer ( data , buffer , command ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> match = QUICKBUFFER_REGEXP . match ( command ) <NEWLINE> if match : <NEWLINE> <INDENT> w . command ( buffer , <STRING> . format ( match . group ( 1 ) ) ) <NEWLINE> return w . WEECHAT_RC_OK_EAT <NEWLINE> <DEDENT> return w . WEECHAT_RC_OK <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Any command being run will be checked to see if it matches /<number>, and intercepted if it does\"\"\"", "\"/buffer {}\""]}}], ["7cde211ac25facabad7ec843964bd1f4", {"code_string": "\"\"\"Tests of code for cluster quality\"\"\"\n__author__ = \"Justin Kuczynski\"\n__copyright__ = \"Copyright 2011, The QIIME project\"\n__credits__ = [\"Justin Kuczynski\"]\n__license__ = \"GPL\"\n__version__ = \"1.9.1-dev\"\n__maintainer__ = \"Justin Kuczynski\"\n__email__ = \"justinak@gmail.com\"\nimport numpy\nfrom os import remove\nfrom skbio.util import create_dir\nfrom unittest import TestCase, main\nfrom numpy.testing import assert_almost_equal\nfrom qiime.cluster_quality import clust_qual_ratio\n", "code_toks_joined": "<STRING> <NEWLINE> __author__ = <STRING> <NEWLINE> __copyright__ = <STRING> <NEWLINE> __credits__ = [ <STRING> ] <NEWLINE> __license__ = <STRING> <NEWLINE> __version__ = <STRING> <NEWLINE> __maintainer__ = <STRING> <NEWLINE> __email__ = <STRING> <NEWLINE> import numpy <NEWLINE> from os import remove <NEWLINE> from skbio . util import create_dir <NEWLINE> from unittest import TestCase , main <NEWLINE> from numpy . testing import assert_almost_equal <NEWLINE> from qiime . cluster_quality import clust_qual_ratio <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Tests of code for cluster quality\"\"\"", "\"Justin Kuczynski\"", "\"Copyright 2011, The QIIME project\"", "\"Justin Kuczynski\"", "\"GPL\"", "\"1.9.1-dev\"", "\"Justin Kuczynski\"", "\"justinak@gmail.com\""]}}], ["d90f7c7524906b00518b0aa41f6683ac", {"code_string": "def get_focusable_widget(self):\n    ''':returns: tuple (bool, widget)'''\n    return(True, self._scale)\n", "code_toks_joined": "def get_focusable_widget ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return ( True , self . _scale ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["''':returns: tuple (bool, widget)'''"]}}], ["25ad493d470c4b98d14158f0cd0b858d", {"code_string": "def get_filtered(cls, service, filter_):\n    \"\"\" Use this API to fetch filtered set of systemglobal_auditnslogpolicy_binding resources.\"\"\"\n    try:\n        obj = systemglobal_auditnslogpolicy_binding()\n        option_ = options()\n        option_.filter = filter_\n        response = obj.getfiltered(service, option_)\n        return response\n    except Exception as e:\n        raise e\n", "code_toks_joined": "def get_filtered ( cls , service , filter_ ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> try : <NEWLINE> <INDENT> obj = systemglobal_auditnslogpolicy_binding ( ) <NEWLINE> option_ = options ( ) <NEWLINE> option_ . filter = filter_ <NEWLINE> response = obj . getfiltered ( service , option_ ) <NEWLINE> return response <NEWLINE> <DEDENT> except Exception as e : <NEWLINE> <INDENT> raise e <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Use this API to fetch filtered set of systemglobal_auditnslogpolicy_binding resources.\"\"\""]}}], ["9505794f8aaef2c69e7707773c324900", {"code_string": "def tearDown(self):\n    \"\"\"Tears down the test class.\"\"\"\n    self.symbolhandler.dump()\n", "code_toks_joined": "def tearDown ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . symbolhandler . dump ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Tears down the test class.\"\"\""]}}], ["7e09e08848cb37c1a8cce21569ca4238", {"code_string": "def test_bad_images_identified_in_sub_dirs(self, imgdir):\n    base = os.path.dirname(str(imgdir))\n    data = [d for d in ImageVerifier.verify_gen(base, ['.TXT'])\n        if d[0].endswith('/images')]\n    assert len(data[0][1]) == 5\n", "code_toks_joined": "def test_bad_images_identified_in_sub_dirs ( self , imgdir ) : <NEWLINE> <INDENT> base = os . path . dirname ( str ( imgdir ) ) <NEWLINE> data = [ d for d in ImageVerifier . verify_gen ( base , [ <STRING> ] ) <NEWLINE> <INDENT> if d [ 0 ] . endswith ( <STRING> ) ] <NEWLINE> <DEDENT> assert len ( data [ 0 ] [ 1 ] ) == 5 <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'.TXT'", "'/images'"]}}], ["34dc97952767290b1073e2a97f98ccb4", {"code_string": "def suite():\n    suite = unittest.TestSuite()\n    suite.addTests(TestDiGraph.suite())\n    suite.addTests(TestHyGraph.suite())\n    suite.addTests(TestParVec.suite())\n    suite.addTests(TestSpParVec.suite())\n    return suite\n", "code_toks_joined": "def suite ( ) : <NEWLINE> <INDENT> suite = unittest . TestSuite ( ) <NEWLINE> suite . addTests ( TestDiGraph . suite ( ) ) <NEWLINE> suite . addTests ( TestHyGraph . suite ( ) ) <NEWLINE> suite . addTests ( TestParVec . suite ( ) ) <NEWLINE> suite . addTests ( TestSpParVec . suite ( ) ) <NEWLINE> return suite <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["9ad5fd79d7220c96652a1066b72054dc", {"code_string": "def test_descr():\n    wtc = get_wtc()\n    eq_(wtc.get('/description.xml').status_code, 200)\n", "code_toks_joined": "def test_descr ( ) : <NEWLINE> <INDENT> wtc = get_wtc ( ) <NEWLINE> eq_ ( wtc . get ( <STRING> ) . status_code , 200 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/description.xml'"]}}], ["90d0f20ccad82edfd5896ba70056f6a5", {"code_string": "class Tracklist(BaseModel):\n    mix = models.ForeignKey(Mix, related_name = 'tracklist')\n    index = models.SmallIntegerField()\n    timeindex = models.TimeField(null = True)\n    description = models.CharField(max_length = 255)\n    artist = models.CharField(max_length = 255)\n    title = models.CharField(max_length = 255)\n    remixer = models.CharField(max_length = 255)\n    label = models.CharField(max_length = 255)\n", "code_toks_joined": "class Tracklist ( BaseModel ) : <NEWLINE> <INDENT> mix = models . ForeignKey ( Mix , related_name = <STRING> ) <NEWLINE> index = models . SmallIntegerField ( ) <NEWLINE> timeindex = models . TimeField ( null = True ) <NEWLINE> description = models . CharField ( max_length = 255 ) <NEWLINE> artist = models . CharField ( max_length = 255 ) <NEWLINE> title = models . CharField ( max_length = 255 ) <NEWLINE> remixer = models . CharField ( max_length = 255 ) <NEWLINE> label = models . CharField ( max_length = 255 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'tracklist'"]}}], ["95e2d53064aa064fd4c9708cfe3b74c2", {"code_string": "def send_log(cls, type, in_data):\n    data = json.dumps(in_data, default = json_default, ensure_ascii = False)\n    message = '{0} {1}'.format(type, data)\n    with cls.socketLock:\n        cls.socket.send(message)\n", "code_toks_joined": "def send_log ( cls , type , in_data ) : <NEWLINE> <INDENT> data = json . dumps ( in_data , default = json_default , ensure_ascii = False ) <NEWLINE> message = <STRING> . format ( type , data ) <NEWLINE> with cls . socketLock : <NEWLINE> <INDENT> cls . socket . send ( message ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'{0} {1}'"]}}], ["6c9c6d719112a7b000c20c229b47f869", {"code_string": "def delete_pool_port(context, backend_port):\n    session = context.session\n    with session.begin(subtransactions = True):\n        port = (session.query(nmodel.Port).filter_by(\n            id = backend_port['port_id'])).first()\n        if port:\n            session.delete(backend_port)\n            session.delete(port)\n", "code_toks_joined": "def delete_pool_port ( context , backend_port ) : <NEWLINE> <INDENT> session = context . session <NEWLINE> with session . begin ( subtransactions = True ) : <NEWLINE> <INDENT> port = ( session . query ( nmodel . Port ) . filter_by ( <NEWLINE> <INDENT> id = backend_port [ <STRING> ] ) ) . first ( ) <NEWLINE> <DEDENT> if port : <NEWLINE> <INDENT> session . delete ( backend_port ) <NEWLINE> session . delete ( port ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'port_id'"]}}], ["2f8aad45d0476f666fa1c7502dda9b85", {"code_string": "def example(request):\n    context = {}\n    if request.method == \"POST\":\n        form = SimpleForm(request.POST, request.FILES)\n        if form.is_valid():\n            context['message'] = \"Source: %r; Destination: %r\" %(\n                form.cleaned_data['source'],\n                form.cleaned_data['destination'])\n    else:\n        form = SimpleForm()\n    context['form'] = form\n    return render_to_response(\n        'example.html', context, context_instance = RequestContext(request))\n", "code_toks_joined": "def example ( request ) : <NEWLINE> <INDENT> context = { } <NEWLINE> if request . method == <STRING> : <NEWLINE> <INDENT> form = SimpleForm ( request . POST , request . FILES ) <NEWLINE> if form . is_valid ( ) : <NEWLINE> <INDENT> context [ <STRING> ] = <STRING> % ( <NEWLINE> <INDENT> form . cleaned_data [ <STRING> ] , <NEWLINE> form . cleaned_data [ <STRING> ] ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> form = SimpleForm ( ) <NEWLINE> <DEDENT> context [ <STRING> ] = form <NEWLINE> return render_to_response ( <NEWLINE> <INDENT> <STRING> , context , context_instance = RequestContext ( request ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"POST\"", "'message'", "\"Source: %r; Destination: %r\"", "'source'", "'destination'", "'form'", "'example.html'"]}}], ["e3e98190fbc5de771d57720d815f7c25", {"code_string": "import pygeoip\nimport json\nimport mixcoatl.utils\nimport mixcoatl.resource\nimport dcm_console_api\nfrom urlparse import urlparse\nconfig = dcm_console_api.APP_CONFIG\nuncamel = mixcoatl.utils.uncamel\nuncamel_keys = mixcoatl.utils.uncamel\ncamelize = mixcoatl.utils.camelize\ncamel_keys = mixcoatl.utils.camel_keys\n", "code_toks_joined": "import pygeoip <NEWLINE> import json <NEWLINE> import mixcoatl . utils <NEWLINE> import mixcoatl . resource <NEWLINE> import dcm_console_api <NEWLINE> from urlparse import urlparse <NEWLINE> config = dcm_console_api . APP_CONFIG <NEWLINE> uncamel = mixcoatl . utils . uncamel <NEWLINE> uncamel_keys = mixcoatl . utils . uncamel <NEWLINE> camelize = mixcoatl . utils . camelize <NEWLINE> camel_keys = mixcoatl . utils . camel_keys <NEWLINE>", "anonymize_dict": {}}], ["93d0752d72594675a106f7e7a4fac62e", {"code_string": "def test_roster_item_with_roles():\n    item = salt.roster_item(cluster.head, roles = ['cdh5', 'conda2'], mine = False)\n    assert item =={\n        'host': '0.0.0.0',\n        'port': 22,\n        'sudo': True,\n        'user': 'me',\n        'priv': '/home/ubuntu/.ssh/id_rsa',\n        'grains': {'roles': ['cdh5', 'conda2']}\n    }\n", "code_toks_joined": "def test_roster_item_with_roles ( ) : <NEWLINE> <INDENT> item = salt . roster_item ( cluster . head , roles = [ <STRING> , <STRING> ] , mine = False ) <NEWLINE> assert item == { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : 22 , <NEWLINE> <STRING> : True , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : { <STRING> : [ <STRING> , <STRING> ] } <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'cdh5'", "'conda2'", "'host'", "'0.0.0.0'", "'port'", "'sudo'", "'user'", "'me'", "'priv'", "'/home/ubuntu/.ssh/id_rsa'", "'grains'", "'roles'", "'cdh5'", "'conda2'"]}}], ["8f6318198e53412797a40f1c7169c960", {"code_string": "import sys\nfrom com.l2scoria.gameserver.model.quest import State\nfrom com.l2scoria.gameserver.model.quest import QuestState\nfrom com.l2scoria.gameserver.model.quest.jython import QuestJython as JQuest\nqn = \"48_ToTheImmortalPlateau\"\nTRADER_GALLADUCCI_ID = 30097\nGALLADUCCIS_ORDER_DOCUMENT_ID_1 = 7563\nGALLADUCCIS_ORDER_DOCUMENT_ID_2 = 7564\nGALLADUCCIS_ORDER_DOCUMENT_ID_3 = 7565\nMAGIC_TRADER_GENTLER_ID = 30094\nMAGIC_SWORD_HILT_ID = 7568\nJEWELER_SANDRA_ID = 30090\nGEMSTONE_POWDER_ID = 7567\nPRIEST_DUSTIN_ID = 30116\nPURIFIED_MAGIC_NECKLACE_ID = 7566\nMARK_OF_TRAVELER_ID = 7570\nSCROLL_OF_ESCAPE_SPECIAL = 7557\nADENA_ID = 57\nRACE = 3\n", "code_toks_joined": "import sys <NEWLINE> from com . l2scoria . gameserver . model . quest import State <NEWLINE> from com . l2scoria . gameserver . model . quest import QuestState <NEWLINE> from com . l2scoria . gameserver . model . quest . jython import QuestJython as JQuest <NEWLINE> qn = <STRING> <NEWLINE> TRADER_GALLADUCCI_ID = 30097 <NEWLINE> GALLADUCCIS_ORDER_DOCUMENT_ID_1 = 7563 <NEWLINE> GALLADUCCIS_ORDER_DOCUMENT_ID_2 = 7564 <NEWLINE> GALLADUCCIS_ORDER_DOCUMENT_ID_3 = 7565 <NEWLINE> MAGIC_TRADER_GENTLER_ID = 30094 <NEWLINE> MAGIC_SWORD_HILT_ID = 7568 <NEWLINE> JEWELER_SANDRA_ID = 30090 <NEWLINE> GEMSTONE_POWDER_ID = 7567 <NEWLINE> PRIEST_DUSTIN_ID = 30116 <NEWLINE> PURIFIED_MAGIC_NECKLACE_ID = 7566 <NEWLINE> MARK_OF_TRAVELER_ID = 7570 <NEWLINE> SCROLL_OF_ESCAPE_SPECIAL = 7557 <NEWLINE> ADENA_ID = 57 <NEWLINE> RACE = 3 <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"48_ToTheImmortalPlateau\""]}}], ["311b7be83fc727bd24dc8e78b95cc752", {"code_string": "class URLTest(TestCase):\n    def test_u_bind(self):\n        response = self.client.get('/u/bind')\n        self.assertContains(response, '\u7ed1\u5b9a\u5b66\u53f7')\n", "code_toks_joined": "class URLTest ( TestCase ) : <NEWLINE> <INDENT> def test_u_bind ( self ) : <NEWLINE> <INDENT> response = self . client . get ( <STRING> ) <NEWLINE> self . assertContains ( response , <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/u/bind'", "'\u7ed1\u5b9a\u5b66\u53f7'"]}}], ["592c4bcf56c710c4bef5ca809133ea3f", {"code_string": "__author__ = \"Jean-Christophe Malapert\"\n__date__ = \"$9 juin 2013 12:17:18$\"\nimport unittest\nfrom sitools2.clients.gaia_client_medoc import *\nfrom datetime import datetime, timedelta\n", "code_toks_joined": "__author__ = <STRING> <NEWLINE> __date__ = <STRING> <NEWLINE> import unittest <NEWLINE> from sitools2 . clients . gaia_client_medoc import * <NEWLINE> from datetime import datetime , timedelta <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"Jean-Christophe Malapert\"", "\"$9 juin 2013 12:17:18$\""]}}], ["665163356d06066654418f2103f87df8", {"code_string": "class Is666(object):\n    def validate(self, password, * args, ** kwargs):\n        if password == '666':\n            raise ValidationError(\"Password 666 is not allowed.\")\n", "code_toks_joined": "class Is666 ( object ) : <NEWLINE> <INDENT> def validate ( self , password , * args , ** kwargs ) : <NEWLINE> <INDENT> if password == <STRING> : <NEWLINE> <INDENT> raise ValidationError ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'666'", "\"Password 666 is not allowed.\""]}}], ["334b7bf59c8aaee655c95139a2908693", {"code_string": "import optparse\nimport os\nimport re\nfrom docs_server_utils import SanitizeAPIName\n", "code_toks_joined": "import optparse <NEWLINE> import os <NEWLINE> import re <NEWLINE> from docs_server_utils import SanitizeAPIName <NEWLINE>", "anonymize_dict": {}}], ["c9d36fffa5c93e52aefd2004cd605d2a", {"code_string": "\"\"\"This script functions as a git filter for versioning MediaWiki XML exports.\"\"\"\nimport sys\nimport lxml.etree as le\n", "code_toks_joined": "<STRING> <NEWLINE> import sys <NEWLINE> import lxml . etree as le <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"This script functions as a git filter for versioning MediaWiki XML exports.\"\"\""]}}], ["93713169e7bf488be5eee603dbe5868f", {"code_string": "class TestPortenseBienScript(p3bot_testcase.P3BotTestCase):\n    def setUp(self):\n        p3bot_testcase.P3BotTestCase.setUp(self)\n        self._script = scripts.portensebien.init(self.bot)\n    def test_basic(self):\n        self.assertEqual('chicos, portense bien', self._script.execute('person', 'bot, deciles que se porten bien'))\n        self.assertEqual('chicos, portense bien', self._script.execute('person', 'bot,deciles que se porten bien'))\n        self.assertEqual('chicos, portense bien', self._script.execute('person', 'bot deciles que se porten bien'))\n", "code_toks_joined": "class TestPortenseBienScript ( p3bot_testcase . P3BotTestCase ) : <NEWLINE> <INDENT> def setUp ( self ) : <NEWLINE> <INDENT> p3bot_testcase . P3BotTestCase . setUp ( self ) <NEWLINE> self . _script = scripts . portensebien . init ( self . bot ) <NEWLINE> <DEDENT> def test_basic ( self ) : <NEWLINE> <INDENT> self . assertEqual ( <STRING> , self . _script . execute ( <STRING> , <STRING> ) ) <NEWLINE> self . assertEqual ( <STRING> , self . _script . execute ( <STRING> , <STRING> ) ) <NEWLINE> self . assertEqual ( <STRING> , self . _script . execute ( <STRING> , <STRING> ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'chicos, portense bien'", "'person'", "'bot, deciles que se porten bien'", "'chicos, portense bien'", "'person'", "'bot,deciles que se porten bien'", "'chicos, portense bien'", "'person'", "'bot deciles que se porten bien'"]}}], ["20882eb7839b00d2fe40aaac32ff279f", {"code_string": "\"\"\"The second thing.\"\"\"\nfrom.all_the_things import THING1\n__revision__ = None\nTHING2 = \"I am thing2\"\nTHING1_PLUS_THING2 = \"%s, plus %s\" %(THING1, THING2)\n", "code_toks_joined": "<STRING> <NEWLINE> from . all_the_things import THING1 <NEWLINE> __revision__ = None <NEWLINE> THING2 = <STRING> <NEWLINE> THING1_PLUS_THING2 = <STRING> % ( THING1 , THING2 ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"The second thing.\"\"\"", "\"I am thing2\"", "\"%s, plus %s\""]}}], ["45aaa3b69592bf09960a8916634f907c", {"code_string": "\"\"\"flask-rst.modules.archive\"\"\"\nfrom flask import Blueprint, render_template, abort\nfrom flaskrst.modules.blog import get_posts\n", "code_toks_joined": "<STRING> <NEWLINE> from flask import Blueprint , render_template , abort <NEWLINE> from flaskrst . modules . blog import get_posts <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"flask-rst.modules.archive\"\"\""]}}], ["aba2f672fd635b2b50b37e90c4dc5271", {"code_string": "import wx\nimport os\nfrom printrun.utils import imagefile\nfrom.utils import make_autosize_button\n", "code_toks_joined": "import wx <NEWLINE> import os <NEWLINE> from printrun . utils import imagefile <NEWLINE> from . utils import make_autosize_button <NEWLINE>", "anonymize_dict": {}}], ["bb455d6f6480fe91df309266edeb2a71", {"code_string": "\"\"\"Tests for simulation of time series\"\"\"\nfrom __future__ import division, absolute_import, print_function\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport os\nfrom scipy.signal import lfilter\nfrom statsmodels.tsa.statespace import(sarimax, structural, varmax,\n    dynamic_factor)\nfrom statsmodels.tsa.statespace.tools import compatibility_mode\nfrom numpy.testing import(assert_allclose, assert_almost_equal, assert_equal,\n    assert_raises)\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import division , absolute_import , print_function <NEWLINE> import warnings <NEWLINE> import numpy as np <NEWLINE> import pandas as pd <NEWLINE> import os <NEWLINE> from scipy . signal import lfilter <NEWLINE> from statsmodels . tsa . statespace import ( sarimax , structural , varmax , <NEWLINE> <INDENT> dynamic_factor ) <NEWLINE> <DEDENT> from statsmodels . tsa . statespace . tools import compatibility_mode <NEWLINE> from numpy . testing import ( assert_allclose , assert_almost_equal , assert_equal , <NEWLINE> <INDENT> assert_raises ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Tests for simulation of time series\"\"\""]}}], ["95581c81aeb1215756a2bb06d61f7e7c", {"code_string": "def _get_name_and_abbr_set(self, name):\n    result_set = {name}\n    result_set.update(self._name_abbr_dict.get(name, {}))\n    return result_set\n", "code_toks_joined": "def _get_name_and_abbr_set ( self , name ) : <NEWLINE> <INDENT> result_set = { name } <NEWLINE> result_set . update ( self . _name_abbr_dict . get ( name , { } ) ) <NEWLINE> return result_set <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["b879062645233846dfafe34de3bcf10c", {"code_string": "def compare_poll(request, diff):\n    msgs = []\n    for f in(diff.left, diff.right):\n        m = Message('file-viewer:%s' % f).get(delete = True)\n        if m:\n            msgs.append(m)\n    return{'status': diff.is_extracted(), 'msg': msgs}\n", "code_toks_joined": "def compare_poll ( request , diff ) : <NEWLINE> <INDENT> msgs = [ ] <NEWLINE> for f in ( diff . left , diff . right ) : <NEWLINE> <INDENT> m = Message ( <STRING> % f ) . get ( delete = True ) <NEWLINE> if m : <NEWLINE> <INDENT> msgs . append ( m ) <NEWLINE> <DEDENT> <DEDENT> return { <STRING> : diff . is_extracted ( ) , <STRING> : msgs } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'file-viewer:%s'", "'status'", "'msg'"]}}], ["6045adb12dda07fa5edbd86b9cc9a0b1", {"code_string": "def makeNewSquare(edge_size, offset_left, offset_top, color):\n    new_square_string = \"\\t\\t\\t\\t<i style=\\\"position:absolute;display:inline-block;width: %sem;height: %sem;border:none;left: %sem;top: %sem;background-color: %s \\\"></i>\\n\" %(edge_size, edge_size, offset_left, offset_top, color)\n    output_file.write(new_square_string)\n", "code_toks_joined": "def makeNewSquare ( edge_size , offset_left , offset_top , color ) : <NEWLINE> <INDENT> new_square_string = <STRING> % ( edge_size , edge_size , offset_left , offset_top , color ) <NEWLINE> output_file . write ( new_square_string ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\\t\\t\\t\\t<i style=\\\"position:absolute;display:inline-block;width: %sem;height: %sem;border:none;left: %sem;top: %sem;background-color: %s \\\"></i>\\n\""]}}], ["ec14eb7d1f390d50861f69e0fd332b74", {"code_string": "import binascii\nimport base64\nstr = input(\"Enter your hex: \")\nprint(\"\\nconvering to raw bytes...\")\nbin = binascii.unhexlify(str);\nprint(\"Raw data- \", bin.decode(\"utf-8\"))\nprint()\nprint(\"\\nencoding in base64...\")\nb64 = base64.b64encode(bin)\nprint(\"Base64 encoded - \", b64.decode(\"utf-8\"))\n", "code_toks_joined": "import binascii <NEWLINE> import base64 <NEWLINE> str = input ( <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> bin = binascii . unhexlify ( str ) ; <NEWLINE> print ( <STRING> , bin . decode ( <STRING> ) ) <NEWLINE> print ( ) <NEWLINE> print ( <STRING> ) <NEWLINE> b64 = base64 . b64encode ( bin ) <NEWLINE> print ( <STRING> , b64 . decode ( <STRING> ) ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"Enter your hex: \"", "\"\\nconvering to raw bytes...\"", "\"Raw data- \"", "\"utf-8\"", "\"\\nencoding in base64...\"", "\"Base64 encoded - \"", "\"utf-8\""]}}], ["b9b187cc104e4418b63252a60de049af", {"code_string": "class SQSBackend(BrokerBackend):\n    def __init__(self, aws_access_key_id, aws_secret_access_key):\n        super(SQSBackend, self).__init__()\n        self.connection = SQSConnection(aws_access_key_id, aws_secret_access_key)\n    def _get_queues(self, prefix = None):\n        return self.connection.get_all_queues(prefix)\n", "code_toks_joined": "class SQSBackend ( BrokerBackend ) : <NEWLINE> <INDENT> def __init__ ( self , aws_access_key_id , aws_secret_access_key ) : <NEWLINE> <INDENT> super ( SQSBackend , self ) . __init__ ( ) <NEWLINE> self . connection = SQSConnection ( aws_access_key_id , aws_secret_access_key ) <NEWLINE> <DEDENT> def _get_queues ( self , prefix = None ) : <NEWLINE> <INDENT> return self . connection . get_all_queues ( prefix ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["3e5a77c490626aca9b2a19288d446c6a", {"code_string": "def table(self, G):\n    \"\"\"Make an appropriate DPTable object\"\"\"\n    if self.use_color_dp:\n        self.tableobj = BVColorDPTable(G, self.p, self.colors,\n            reuse = self.table_hints['reuse'])\n        return self.tableobj\n    else:\n        return self.uncolored_table(G)\n", "code_toks_joined": "def table ( self , G ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if self . use_color_dp : <NEWLINE> <INDENT> self . tableobj = BVColorDPTable ( G , self . p , self . colors , <NEWLINE> <INDENT> reuse = self . table_hints [ <STRING> ] ) <NEWLINE> <DEDENT> return self . tableobj <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return self . uncolored_table ( G ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Make an appropriate DPTable object\"\"\"", "'reuse'"]}}], ["9b6a8e2a63566b3eac20bf5ddffd50f1", {"code_string": "def clear(self):\n    \"\"\"Reset the semaphore, which also wipes out any waiting callbacks.\"\"\"\n    self._waiting.clear()\n    self.value = self.initial_value\n", "code_toks_joined": "def clear ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . _waiting . clear ( ) <NEWLINE> self . value = self . initial_value <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Reset the semaphore, which also wipes out any waiting callbacks.\"\"\""]}}], ["610efeab840ff2dcac3ff78ce26ad28e", {"code_string": "class res_partner(osv.osv):\n    _inherit = 'res.partner'\n    _columns = {\n        'to_date': fields.date('To Date'),\n        'lock_unlock': fields.selection([('unlock', 'Unlock'), ('lock', 'Lock')], 'Lock/Unlock'),\n        'lock_registry': fields.one2many('res.partner.lock_registry', 'partner_id', 'Lock Registry'),\n    }\n    _defaults = {\n        'lock_unlock': 'unlock',\n    }\n", "code_toks_joined": "class res_partner ( osv . osv ) : <NEWLINE> <INDENT> _inherit = <STRING> <NEWLINE> _columns = { <NEWLINE> <INDENT> <STRING> : fields . date ( <STRING> ) , <NEWLINE> <STRING> : fields . selection ( [ ( <STRING> , <STRING> ) , ( <STRING> , <STRING> ) ] , <STRING> ) , <NEWLINE> <STRING> : fields . one2many ( <STRING> , <STRING> , <STRING> ) , <NEWLINE> <DEDENT> } <NEWLINE> _defaults = { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'res.partner'", "'to_date'", "'To Date'", "'lock_unlock'", "'unlock'", "'Unlock'", "'lock'", "'Lock'", "'Lock/Unlock'", "'lock_registry'", "'res.partner.lock_registry'", "'partner_id'", "'Lock Registry'", "'lock_unlock'", "'unlock'"]}}], ["4aaa2ec5d3e4d40746e712636cdeede4", {"code_string": "def handle_compare_intent(self, center_node, target_node):\n    self.crawler.update_connector(self.connector)\n    flag = is_this_that(center_node, target_node, self.crawler)\n    self.speak(\"answer to is \" + center_node + \" a \" + target_node + \" is \" + str(flag))\n    return True\n", "code_toks_joined": "def handle_compare_intent ( self , center_node , target_node ) : <NEWLINE> <INDENT> self . crawler . update_connector ( self . connector ) <NEWLINE> flag = is_this_that ( center_node , target_node , self . crawler ) <NEWLINE> self . speak ( <STRING> + center_node + <STRING> + target_node + <STRING> + str ( flag ) ) <NEWLINE> return True <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"answer to is \"", "\" a \"", "\" is \""]}}], ["43e8f9b4339b078bc5dfb8967d1c1f6c", {"code_string": "def __init__(self):\n    super(InstaSession, self).__init__()\n    self.csrftoken = ''\n    self.login_status = False\n    self.user_id = None\n    self.user_login = None\n    self.user_password = None\n    self.last_response = None\n", "code_toks_joined": "def __init__ ( self ) : <NEWLINE> <INDENT> super ( InstaSession , self ) . __init__ ( ) <NEWLINE> self . csrftoken = <STRING> <NEWLINE> self . login_status = False <NEWLINE> self . user_id = None <NEWLINE> self . user_login = None <NEWLINE> self . user_password = None <NEWLINE> self . last_response = None <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["''"]}}], ["b70f92511430fcbd341997f5ceddbbec", {"code_string": "def test_idadb_ida_query_first_row_only(self, idadb, idadf, df):\n    query = \"SELECT * FROM %s FETCH FIRST 5 ROWS ONLY\" % idadf.name\n    downloaded_df = idadb.ida_query(query, first_row_only = True)\n    assert(isinstance(downloaded_df, tuple))\n    assert(len(downloaded_df) == len(df.loc[0]))\n", "code_toks_joined": "def test_idadb_ida_query_first_row_only ( self , idadb , idadf , df ) : <NEWLINE> <INDENT> query = <STRING> % idadf . name <NEWLINE> downloaded_df = idadb . ida_query ( query , first_row_only = True ) <NEWLINE> assert ( isinstance ( downloaded_df , tuple ) ) <NEWLINE> assert ( len ( downloaded_df ) == len ( df . loc [ 0 ] ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"SELECT * FROM %s FETCH FIRST 5 ROWS ONLY\""]}}], ["a5a23c04fc6e9506340b51ffb25fbe30", {"code_string": "from kivy.uix.behaviors import ButtonBehavior\nfrom inspect import getmembers, ismethod\nfrom copy import copy\nimport operator\n", "code_toks_joined": "from kivy . uix . behaviors import ButtonBehavior <NEWLINE> from inspect import getmembers , ismethod <NEWLINE> from copy import copy <NEWLINE> import operator <NEWLINE>", "anonymize_dict": {}}], ["2d64cbb65fb3043cdf54c1026dcf61ef", {"code_string": "\"\"\"Created on Thu Aug 27 14:41:06 2015\"\"\"\nimport os\nimport sys\nimport logging\nimport re\nfrom opendxmc.materials.materials import Material\nfrom opendxmc.utils import find_all_files\nlogger = logging.getLogger('OpenDXMC')\nMATERIAL_DATA_PATH = os.path.join(os.path.dirname(sys.argv[0]), 'opendxmc',\n    'data', 'materials')\nBASE_PATH = os.path.dirname(os.path.dirname(__file__))\nMATERIAL_DATA_PATH = os.path.join(BASE_PATH,\n    'data', 'materials')\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> import sys <NEWLINE> import logging <NEWLINE> import re <NEWLINE> from opendxmc . materials . materials import Material <NEWLINE> from opendxmc . utils import find_all_files <NEWLINE> logger = logging . getLogger ( <STRING> ) <NEWLINE> MATERIAL_DATA_PATH = os . path . join ( os . path . dirname ( sys . argv [ 0 ] ) , <STRING> , <NEWLINE> <INDENT> <STRING> , <STRING> ) <NEWLINE> <DEDENT> BASE_PATH = os . path . dirname ( os . path . dirname ( __file__ ) ) <NEWLINE> MATERIAL_DATA_PATH = os . path . join ( BASE_PATH , <NEWLINE> <INDENT> <STRING> , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Created on Thu Aug 27 14:41:06 2015\"\"\"", "'OpenDXMC'", "'opendxmc'", "'data'", "'materials'", "'data'", "'materials'"]}}], ["8df1fd37d8fe71da1a481c3a34cf6ddf", {"code_string": "class EB_pbdSLAP(RPackage):\n    \"\"\"Support for building/installing pbdSLAP.\"\"\"\n    def __init__(self, * args, ** kwargs):\n        \"\"\"Initialisation of custom class variables for pbdSLAP.\"\"\"\n        super(EB_pbdSLAP, self).__init__(* args, ** kwargs)\n        self.configurevars.append(\"EXT_LDFLAGS='$LIBSCALAPACK'\")\n", "code_toks_joined": "class EB_pbdSLAP ( RPackage ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , * args , ** kwargs ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> super ( EB_pbdSLAP , self ) . __init__ ( * args , ** kwargs ) <NEWLINE> self . configurevars . append ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Support for building/installing pbdSLAP.\"\"\"", "\"\"\"Initialisation of custom class variables for pbdSLAP.\"\"\"", "\"EXT_LDFLAGS='$LIBSCALAPACK'\""]}}], ["aa08861a4f46f644531d37fe58b5e8ae", {"code_string": "class LoginResetForm_Locators_Base(object):\n    \"\"\"locators for LoginResetForm object\"\"\"\n    locators = {\n        'base': \"css=#hubForm\",\n        'username': \"css=#username\",\n        'submit': \"css=#hubForm .validate\",\n    }\n", "code_toks_joined": "class LoginResetForm_Locators_Base ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> locators = { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"locators for LoginResetForm object\"\"\"", "'base'", "\"css=#hubForm\"", "'username'", "\"css=#username\"", "'submit'", "\"css=#hubForm .validate\""]}}], ["930c59cd1453fccc9e2407d03b15ef7e", {"code_string": "\"\"\"Tests for the Software Update plist plugin.\"\"\"\nimport unittest\nfrom plaso.formatters import plist as plist_formatter\nfrom plaso.lib import event\nfrom plaso.parsers import plist\nfrom plaso.parsers.plist_plugins import softwareupdate\nfrom plaso.parsers.plist_plugins import test_lib\n", "code_toks_joined": "<STRING> <NEWLINE> import unittest <NEWLINE> from plaso . formatters import plist as plist_formatter <NEWLINE> from plaso . lib import event <NEWLINE> from plaso . parsers import plist <NEWLINE> from plaso . parsers . plist_plugins import softwareupdate <NEWLINE> from plaso . parsers . plist_plugins import test_lib <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Tests for the Software Update plist plugin.\"\"\""]}}], ["931c5e9ac6a62b0b1b63d84f32405973", {"code_string": "def get_full_path_to_file(path_on_host, schedule_name):\n    \"\"\" Returns full path to db backup file on host\"\"\"\n    if not path_on_host.endswith('/'):\n        path_on_host += '/'\n    full_path = path_on_host + \"db_backup/region_*/{}\".format(schedule_name)\n    return full_path\n", "code_toks_joined": "def get_full_path_to_file ( path_on_host , schedule_name ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if not path_on_host . endswith ( <STRING> ) : <NEWLINE> <INDENT> path_on_host += <STRING> <NEWLINE> <DEDENT> full_path = path_on_host + <STRING> . format ( schedule_name ) <NEWLINE> return full_path <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Returns full path to db backup file on host\"\"\"", "'/'", "'/'", "\"db_backup/region_*/{}\""]}}], ["0b9d4e50f49bd6383c1bf064e1bbcd5d", {"code_string": "def main(_):\n    mnist = input_data.read_data_sets(FLAGS.datadir, one_hot = True)\n    prepare_samples(mnist)\n", "code_toks_joined": "def main ( _ ) : <NEWLINE> <INDENT> mnist = input_data . read_data_sets ( FLAGS . datadir , one_hot = True ) <NEWLINE> prepare_samples ( mnist ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["9a48d46b36c805bf6db9649b6850f2b9", {"code_string": "import six\nfrom collections import defaultdict\nfrom django.db import models\nfrom south.db import db\nfrom south.utils import datetime_utils as datetime\nfrom south.v2 import DataMigration\n", "code_toks_joined": "import six <NEWLINE> from collections import defaultdict <NEWLINE> from django . db import models <NEWLINE> from south . db import db <NEWLINE> from south . utils import datetime_utils as datetime <NEWLINE> from south . v2 import DataMigration <NEWLINE>", "anonymize_dict": {}}], ["1def50b43a0519e5d5884dbaac3f331e", {"code_string": "import unittest\nimport numpy as np\nfrom AlphaLineupPuzzle import lineup_puzzle\nfrom AlphaLineupPuzzle.preprocessing import preprocessing\n", "code_toks_joined": "import unittest <NEWLINE> import numpy as np <NEWLINE> from AlphaLineupPuzzle import lineup_puzzle <NEWLINE> from AlphaLineupPuzzle . preprocessing import preprocessing <NEWLINE>", "anonymize_dict": {}}], ["f4ccfd1ca13615e929ab9e9b61df415d", {"code_string": "def draw(self, surface):\n    for button in self.buttons:\n        button.draw(surface)\n    label = utils.TextWrapping().render_textrect(self.credits_plain_text, self.credits_font, pygame.Rect((0, 0), (constants.SCREEN_WIDTH, constants.SCREEN_HEIGHT - 150)), (255, 255, 255))\n    x = 100\n    y = 40\n    surface.blit(label, (x, y))\n", "code_toks_joined": "def draw ( self , surface ) : <NEWLINE> <INDENT> for button in self . buttons : <NEWLINE> <INDENT> button . draw ( surface ) <NEWLINE> <DEDENT> label = utils . TextWrapping ( ) . render_textrect ( self . credits_plain_text , self . credits_font , pygame . Rect ( ( 0 , 0 ) , ( constants . SCREEN_WIDTH , constants . SCREEN_HEIGHT - 150 ) ) , ( 255 , 255 , 255 ) ) <NEWLINE> x = 100 <NEWLINE> y = 40 <NEWLINE> surface . blit ( label , ( x , y ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["37ea85d5c6b4373a17cfcc9b31ce7bda", {"code_string": "def __init__(self):\n    super(Observer, self).__init__()\n    self.last_update = - 101\n", "code_toks_joined": "def __init__ ( self ) : <NEWLINE> <INDENT> super ( Observer , self ) . __init__ ( ) <NEWLINE> self . last_update = - 101 <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["9b9ed15e29ba15fd1e674f64b37a8189", {"code_string": "def _pre_processing_x(self, X):\n    X = self.standardize(X)\n    return X\n", "code_toks_joined": "def _pre_processing_x ( self , X ) : <NEWLINE> <INDENT> X = self . standardize ( X ) <NEWLINE> return X <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["8a9dc37a7118a5ce8f37bb0504bb89d8", {"code_string": "from setuptools import setup, find_packages\nsetup(\n    name = 'bioshadock_biotools',\n    version = '1.0.1',\n    packages = find_packages(),\n    author = \"Francois Moreews\",\n    description = \"Import tool for biotools from Dockerfile\",\n    include_package_data = True,\n    classifiers = [\n        \"Programming Language :: Python\",\n        \"Development Status :: 5 - Production/Stable\",\n        \"License :: Apache 2.0\",\n        \"Natural Language :: English\",\n        \"Operating System :: OS Independent\",\n        \"Programming Language :: Python :: 2.7\",\n        \"Topic :: Communications\",\n    ],\n    scripts = [\n        'parseDockerFile.py',\n        'registryClient.py'\n    ],\n    install_requires = [\n        'lxml',\n        'requests>=2.7.0'\n    ],\n    license = \"Apache 2.0\",\n)\n", "code_toks_joined": "from setuptools import setup , find_packages <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> packages = find_packages ( ) , <NEWLINE> author = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> include_package_data = True , <NEWLINE> classifiers = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <DEDENT> ] , <NEWLINE> scripts = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> <NEWLINE> <DEDENT> ] , <NEWLINE> install_requires = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> <NEWLINE> <DEDENT> ] , <NEWLINE> license = <STRING> , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'bioshadock_biotools'", "'1.0.1'", "\"Francois Moreews\"", "\"Import tool for biotools from Dockerfile\"", "\"Programming Language :: Python\"", "\"Development Status :: 5 - Production/Stable\"", "\"License :: Apache 2.0\"", "\"Natural Language :: English\"", "\"Operating System :: OS Independent\"", "\"Programming Language :: Python :: 2.7\"", "\"Topic :: Communications\"", "'parseDockerFile.py'", "'registryClient.py'", "'lxml'", "'requests>=2.7.0'", "\"Apache 2.0\""]}}], ["59c624d6d5b12166b245d79887cbd309", {"code_string": "import sys\nsys.path.append(\".\")\nfrom recon.wall import WallReader\nfor file in sys.argv[1: ]:\n    with open(file, \"rb\") as fp:\n        wall = WallReader(fp, verbose = False)\n        wall.asJSON(sys.stdout)\n", "code_toks_joined": "import sys <NEWLINE> sys . path . append ( <STRING> ) <NEWLINE> from recon . wall import WallReader <NEWLINE> for file in sys . argv [ 1 : ] : <NEWLINE> <INDENT> with open ( file , <STRING> ) as fp : <NEWLINE> <INDENT> wall = WallReader ( fp , verbose = False ) <NEWLINE> wall . asJSON ( sys . stdout ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\".\"", "\"rb\""]}}], ["e63441fa887f35e3a63f1d80a3ca3cb6", {"code_string": "def getArchive():\n    \"\"\"Download the TPC-H data generation tools archive from the TPC website.\"\"\"\n    try:\n        subprocess.check_call(['wget', tpchArchiveWeb], cwd = dataDir)\n    except:\n        print(\"Error: Failed to download TPC-H generation tools archive.\")\n        sys.exit(2)\n    return\n", "code_toks_joined": "def getArchive ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> try : <NEWLINE> <INDENT> subprocess . check_call ( [ <STRING> , tpchArchiveWeb ] , cwd = dataDir ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> sys . exit ( 2 ) <NEWLINE> <DEDENT> return <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Download the TPC-H data generation tools archive from the TPC website.\"\"\"", "'wget'", "\"Error: Failed to download TPC-H generation tools archive.\""]}}], ["1d9fd3a28d62d1a79a4ee904073632ca", {"code_string": "def get_keys(client):\n    keys = []\n    headers = ['ID', 'NAME']\n    for key in client.get('/cloud/project/{}/sshkey'.format(client._project)):\n        keys.append(\n            (\n                key['id'],\n                key['name']\n            )\n        )\n    return columns(headers, keys)\n", "code_toks_joined": "def get_keys ( client ) : <NEWLINE> <INDENT> keys = [ ] <NEWLINE> headers = [ <STRING> , <STRING> ] <NEWLINE> for key in client . get ( <STRING> . format ( client . _project ) ) : <NEWLINE> <INDENT> keys . append ( <NEWLINE> <INDENT> ( <NEWLINE> <INDENT> key [ <STRING> ] , <NEWLINE> key [ <STRING> ] <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> return columns ( headers , keys ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'ID'", "'NAME'", "'/cloud/project/{}/sshkey'", "'id'", "'name'"]}}], ["2fb32269c2f276b7df3c02d9c4a9eff4", {"code_string": "def digitalRead(self, pin):\n    GPIO.setmode(GPIO.BCM)\n    GPIO.setup(pin, GPIO.IN)\n    return GPIO.input(pin)\n", "code_toks_joined": "def digitalRead ( self , pin ) : <NEWLINE> <INDENT> GPIO . setmode ( GPIO . BCM ) <NEWLINE> GPIO . setup ( pin , GPIO . IN ) <NEWLINE> return GPIO . input ( pin ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["dfd4e7a6cadd115c3400fa55083200f9", {"code_string": "def __init__(self, server, path):\n    self._path = path\n    super(JsonScript, self).__init__(server)\n", "code_toks_joined": "def __init__ ( self , server , path ) : <NEWLINE> <INDENT> self . _path = path <NEWLINE> super ( JsonScript , self ) . __init__ ( server ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["db1e02060780a63e349c6303b82334f0", {"code_string": "import numpy as np\nfrom random import shuffle\nfrom IPython.core.debugger import Tracer\n", "code_toks_joined": "import numpy as np <NEWLINE> from random import shuffle <NEWLINE> from IPython . core . debugger import Tracer <NEWLINE>", "anonymize_dict": {}}], ["4398ad477f6c738dbf3c27a2c9047ae5", {"code_string": "def show_image(self, pil_image):\n    \"\"\"Show the image on canvas.\"\"\"\n    show_image = pil_image.resize((self.width, self.height),\n        resample = Image.ANTIALIAS)\n    self.tk_image = ImageTk.PhotoImage(show_image)\n    self.cv.create_image(0, 0, anchor = \"nw\", image = self.tk_image)\n    self.cv.pack(fill = BOTH, expand = YES)\n", "code_toks_joined": "def show_image ( self , pil_image ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> show_image = pil_image . resize ( ( self . width , self . height ) , <NEWLINE> <INDENT> resample = Image . ANTIALIAS ) <NEWLINE> <DEDENT> self . tk_image = ImageTk . PhotoImage ( show_image ) <NEWLINE> self . cv . create_image ( 0 , 0 , anchor = <STRING> , image = self . tk_image ) <NEWLINE> self . cv . pack ( fill = BOTH , expand = YES ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Show the image on canvas.\"\"\"", "\"nw\""]}}], ["c74791f5701071133d487f9f74488368", {"code_string": "def diagnose_data(cls):\n    \"\"\"This method is just an example of how to call diagnostic module\"\"\"\n    configuration_file = os.path.join(os.path.dirname(__file__), '../../../cerebralcortex.yml')\n    CC = CerebralCortex(configuration_file, master = \"local[*]\", name = \"Data Diagnostic App\", time_zone = \"US/Central\")\n    configuration = Configuration(filepath = \"data_diagnostic_config.yml\").config\n    stream_name = configuration[\"sensor_types\"][\"autosense_rip\"]\n    cls.diagnose(\"de5b4a7d-ba1b-44c4-b55e-cd0ca7487734\", CC, configuration, stream_name)\n", "code_toks_joined": "def diagnose_data ( cls ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> configuration_file = os . path . join ( os . path . dirname ( __file__ ) , <STRING> ) <NEWLINE> CC = CerebralCortex ( configuration_file , master = <STRING> , name = <STRING> , time_zone = <STRING> ) <NEWLINE> configuration = Configuration ( filepath = <STRING> ) . config <NEWLINE> stream_name = configuration [ <STRING> ] [ <STRING> ] <NEWLINE> cls . diagnose ( <STRING> , CC , configuration , stream_name ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"This method is just an example of how to call diagnostic module\"\"\"", "'../../../cerebralcortex.yml'", "\"local[*]\"", "\"Data Diagnostic App\"", "\"US/Central\"", "\"data_diagnostic_config.yml\"", "\"sensor_types\"", "\"autosense_rip\"", "\"de5b4a7d-ba1b-44c4-b55e-cd0ca7487734\""]}}], ["c8cf4db60d54c9b63f5575a85a48a2e9", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('calendars', '0020_auto_20151104_1112'),\n    ]\n    operations = [\n        migrations.RemoveField(\n            model_name = 'event',\n            name = 'category',\n        ),\n        migrations.AddField(\n            model_name = 'event',\n            name = 'category',\n            field = models.ManyToManyField(null = True, to = 'calendars.Category', blank = True, verbose_name = 'Kategoria'),\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . RemoveField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> <DEDENT> ) , <NEWLINE> migrations . AddField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . ManyToManyField ( null = True , to = <STRING> , blank = True , verbose_name = <STRING> ) , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'calendars'", "'0020_auto_20151104_1112'", "'event'", "'category'", "'event'", "'category'", "'calendars.Category'", "'Kategoria'"]}}], ["73601dca921944b5609086fd01a2ec9c", {"code_string": "class TimeTicks(univ.Integer):\n    tagSet = univ.Integer.tagSet.tagImplicitly(\n        tag.Tag(tag.tagClassApplication, tag.tagFormatSimple, 0x03)\n    )\n    subtypeSpec = univ.Integer.subtypeSpec + constraint.ValueRangeConstraint(\n        0, 4294967295\n    )\n", "code_toks_joined": "class TimeTicks ( univ . Integer ) : <NEWLINE> <INDENT> tagSet = univ . Integer . tagSet . tagImplicitly ( <NEWLINE> <INDENT> tag . Tag ( tag . tagClassApplication , tag . tagFormatSimple , 0x03 ) <NEWLINE> <DEDENT> ) <NEWLINE> subtypeSpec = univ . Integer . subtypeSpec + constraint . ValueRangeConstraint ( <NEWLINE> <INDENT> 0 , 4294967295 <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["890d922d06ad2a9d3cdd865706010a41", {"code_string": "__module_name__ = \"ChanMsg\"\n__module_version__ = \"1.0\"\n__module_description__ = \"Messages an array of channels\"\n__author__ = \"ApolloJustice\"\nimport hexchat\n", "code_toks_joined": "__module_name__ = <STRING> <NEWLINE> __module_version__ = <STRING> <NEWLINE> __module_description__ = <STRING> <NEWLINE> __author__ = <STRING> <NEWLINE> import hexchat <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"ChanMsg\"", "\"1.0\"", "\"Messages an array of channels\"", "\"ApolloJustice\""]}}], ["e523c7be76c0ce384ecce116ce34e66f", {"code_string": "def test_fit(self):\n    expected_avgs = [1, 1, 3, 5]\n    transformed_avgs = self.scaler.fit(self.X, self.y)._avgs\n    self.assertListEqual(expected_avgs, transformed_avgs)\n", "code_toks_joined": "def test_fit ( self ) : <NEWLINE> <INDENT> expected_avgs = [ 1 , 1 , 3 , 5 ] <NEWLINE> transformed_avgs = self . scaler . fit ( self . X , self . y ) . _avgs <NEWLINE> self . assertListEqual ( expected_avgs , transformed_avgs ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ff4f9dec76175de261d52e4a630c105d", {"code_string": "def __ToggleImage(self, image):\n    imagePath = image['img_path'] + image['img_name']\n    image[\"checked\"] = not image[\"checked\"]\n    wxImage = self.__CheckOrUncheckImage(imagePath, image[\"checked\"])\n    image['img_ctrl'].SetBitmap(wx.BitmapFromImage(wxImage))\n", "code_toks_joined": "def __ToggleImage ( self , image ) : <NEWLINE> <INDENT> imagePath = image [ <STRING> ] + image [ <STRING> ] <NEWLINE> image [ <STRING> ] = not image [ <STRING> ] <NEWLINE> wxImage = self . __CheckOrUncheckImage ( imagePath , image [ <STRING> ] ) <NEWLINE> image [ <STRING> ] . SetBitmap ( wx . BitmapFromImage ( wxImage ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'img_path'", "'img_name'", "\"checked\"", "\"checked\"", "\"checked\"", "'img_ctrl'"]}}], ["4b94a639296ffc168ec6287cb7ae3409", {"code_string": "def main():\n    success, msg = alarm_performance_test()\n    if not success:\n        print(\"-----Test failed to complete-----\")\n        print(msg)\n        return 1\n    return 0\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> success , msg = alarm_performance_test ( ) <NEWLINE> if not success : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> print ( msg ) <NEWLINE> return 1 <NEWLINE> <DEDENT> return 0 <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"-----Test failed to complete-----\""]}}], ["06bde67090f3e91d83a411f0850abb41", {"code_string": "from dal import autocomplete\nfrom django.conf.urls import url\nfrom.models import TModel\nurlpatterns = [\n    url(\n        'test-autocomplete/$',\n        autocomplete.Select2QuerySetView.as_view(model = TModel),\n        name = 'select2_fk',\n    ),\n]\n", "code_toks_joined": "from dal import autocomplete <NEWLINE> from django . conf . urls import url <NEWLINE> from . models import TModel <NEWLINE> urlpatterns = [ <NEWLINE> <INDENT> url ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> autocomplete . Select2QuerySetView . as_view ( model = TModel ) , <NEWLINE> name = <STRING> , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'test-autocomplete/$'", "'select2_fk'"]}}], ["bf658fca33dbdca47b86ab4d54b19d0f", {"code_string": "def login(db, login, password):\n    res_users = odoo.registry(db)['res.users']\n    return res_users._login(db, login, password)\n", "code_toks_joined": "def login ( db , login , password ) : <NEWLINE> <INDENT> res_users = odoo . registry ( db ) [ <STRING> ] <NEWLINE> return res_users . _login ( db , login , password ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'res.users'"]}}], ["84893c80b40502e4c2465ec09f7b4012", {"code_string": "def finvec(word, xwords, xweights):\n    for i in range(len(xwords)):\n        if xwords[i] == word:\n            return xweights[i]\n    return None\n", "code_toks_joined": "def finvec ( word , xwords , xweights ) : <NEWLINE> <INDENT> for i in range ( len ( xwords ) ) : <NEWLINE> <INDENT> if xwords [ i ] == word : <NEWLINE> <INDENT> return xweights [ i ] <NEWLINE> <DEDENT> <DEDENT> return None <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["cd483781efeb5668518adb1b99df15bf", {"code_string": "def talker():\n    pub = rospy.Publisher('chatter', Float64MultiArray, queue_size = 10)\n    rospy.init_node('talker', anonymous = True)\n    rate = rospy.Rate(10)\n    f = Float64MultiArray()\n    f.data = [0.1, 0, 2]\n    while not rospy.is_shutdown():\n        hello_str = \"hello world %f, %f\" %(f.data[0], f.data[1])\n        rospy.loginfo(hello_str)\n        pub.publish(f)\n        rate.sleep()\n", "code_toks_joined": "def talker ( ) : <NEWLINE> <INDENT> pub = rospy . Publisher ( <STRING> , Float64MultiArray , queue_size = 10 ) <NEWLINE> rospy . init_node ( <STRING> , anonymous = True ) <NEWLINE> rate = rospy . Rate ( 10 ) <NEWLINE> f = Float64MultiArray ( ) <NEWLINE> f . data = [ 0.1 , 0 , 2 ] <NEWLINE> while not rospy . is_shutdown ( ) : <NEWLINE> <INDENT> hello_str = <STRING> % ( f . data [ 0 ] , f . data [ 1 ] ) <NEWLINE> rospy . loginfo ( hello_str ) <NEWLINE> pub . publish ( f ) <NEWLINE> rate . sleep ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'chatter'", "'talker'", "\"hello world %f, %f\""]}}], ["e753bb198e57e7a1441e521f2e7a9754", {"code_string": "time = input(\"How long are you willing to spend setting up your Linux system? This time should be in hours, if you want help type 'help' \")\nif time == 'help':\n    print(\"Your Linux system will not be able to do everything you want it to immediately, you will need to configure it according to your own preferences. So this question is essentially how much time you, personally, are willing to spend configuring your system and making it suit your needs. If you want a system that should require minimal configuration then give an answer that is less than 1. If you want a system you have to build from the ground-up (potentially taking > 5 hours), you should choose a larger number.\")\n    time = input(\"How long are you willing to spend setting up your Linux system? This time should be in hours, if you want help type 'help' \")\npatience = input(\"How patient are you, from one to ten? With ten being you are a saint, with respect to this particular virtue, and one being you have little patience. \")\nfoss = input(\"Where do you land on the FOSS spectrum, from 1 to 5? 1 being FOSS is not important, proprietary software is fine! 5 being it is either FOSS or nothing! Enter 'help' for further info. \")\nif foss == 'help':\n    print(\"FOSS or free and open-source software is software that is licensed such that its source code and pre-built forms can be freely and openly shared, modified, redistributed, etc. without legal restriction.\")\n", "code_toks_joined": "time = input ( <STRING> ) <NEWLINE> if time == <STRING> : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> time = input ( <STRING> ) <NEWLINE> <DEDENT> patience = input ( <STRING> ) <NEWLINE> foss = input ( <STRING> ) <NEWLINE> if foss == <STRING> : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"How long are you willing to spend setting up your Linux system? This time should be in hours, if you want help type 'help' \"", "'help'", "\"Your Linux system will not be able to do everything you want it to immediately, you will need to configure it according to your own preferences. So this question is essentially how much time you, personally, are willing to spend configuring your system and making it suit your needs. If you want a system that should require minimal configuration then give an answer that is less than 1. If you want a system you have to build from the ground-up (potentially taking > 5 hours), you should choose a larger number.\"", "\"How long are you willing to spend setting up your Linux system? This time should be in hours, if you want help type 'help' \"", "\"How patient are you, from one to ten? With ten being you are a saint, with respect to this particular virtue, and one being you have little patience. \"", "\"Where do you land on the FOSS spectrum, from 1 to 5? 1 being FOSS is not important, proprietary software is fine! 5 being it is either FOSS or nothing! Enter 'help' for further info. \"", "'help'", "\"FOSS or free and open-source software is software that is licensed such that its source code and pre-built forms can be freely and openly shared, modified, redistributed, etc. without legal restriction.\""]}}], ["a1649c9fd33594b337eb85d31315653b", {"code_string": "def UserActTodo(opts):\n    \"\"\"List CLs needing your review\"\"\"\n    emails, reviewers, owners = _MyUserInfo()\n    cls = FilteredQuery(opts, '( %s ) status:open NOT ( %s )' %\n        (' OR '.join(reviewers), ' OR '.join(owners)))\n    cls = [x for x in cls if not IsApprover(x, emails)]\n    lims = limits(cls)\n    for cl in cls:\n        PrintCl(opts, cl, lims)\n", "code_toks_joined": "def UserActTodo ( opts ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> emails , reviewers , owners = _MyUserInfo ( ) <NEWLINE> cls = FilteredQuery ( opts , <STRING> % <NEWLINE> <INDENT> ( <STRING> . join ( reviewers ) , <STRING> . join ( owners ) ) ) <NEWLINE> <DEDENT> cls = [ x for x in cls if not IsApprover ( x , emails ) ] <NEWLINE> lims = limits ( cls ) <NEWLINE> for cl in cls : <NEWLINE> <INDENT> PrintCl ( opts , cl , lims ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"List CLs needing your review\"\"\"", "'( %s ) status:open NOT ( %s )'", "' OR '", "' OR '"]}}], ["ee5481ad4bf40bd0b7a252189f0c27e4", {"code_string": "def on_accelerator_focus_out(self, entry, event):\n    if self.current_node is not None:\n        self.update_accelerator_label()\n        self.tool_changed(self.current_node)\n", "code_toks_joined": "def on_accelerator_focus_out ( self , entry , event ) : <NEWLINE> <INDENT> if self . current_node is not None : <NEWLINE> <INDENT> self . update_accelerator_label ( ) <NEWLINE> self . tool_changed ( self . current_node ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["a354e35cdc05787f16dfe5637d827b5f", {"code_string": "class ContactForm(ModelForm):\n    class Meta:\n        model = ContactMessage\n        fields = ['name', 'email', 'message']\n", "code_toks_joined": "class ContactForm ( ModelForm ) : <NEWLINE> <INDENT> class Meta : <NEWLINE> <INDENT> model = ContactMessage <NEWLINE> fields = [ <STRING> , <STRING> , <STRING> ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'name'", "'email'", "'message'"]}}], ["6c62afe1c94b2b269269438fa883fcb0", {"code_string": "def build_report(template_dict):\n    report_dir = os.path.abspath('reports')\n    jinja_env = jinja2.Environment(loader = jinja2.FileSystemLoader(report_dir))\n    template = jinja_env.get_template('report_template.html')\n    report = template.render(template_dict)\n    with open(os.path.join(report_dir, 'report.html'), 'w') as f:\n        f.write(report)\n", "code_toks_joined": "def build_report ( template_dict ) : <NEWLINE> <INDENT> report_dir = os . path . abspath ( <STRING> ) <NEWLINE> jinja_env = jinja2 . Environment ( loader = jinja2 . FileSystemLoader ( report_dir ) ) <NEWLINE> template = jinja_env . get_template ( <STRING> ) <NEWLINE> report = template . render ( template_dict ) <NEWLINE> with open ( os . path . join ( report_dir , <STRING> ) , <STRING> ) as f : <NEWLINE> <INDENT> f . write ( report ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'reports'", "'report_template.html'", "'report.html'", "'w'"]}}], ["6590fb4fa04545544eb9c5abd9fdd3e6", {"code_string": "from __future__ import print_function, division\nfrom time_base import comparison_timer\nisreal_re = ''' import re'''\nisreal_try = ''' def isreal_try(x):'''\ncomparison_timer(['isreal_re', isreal_re],\n    ['isreal_try', isreal_try],\n    ['isreal', 'from fastnumbers import isreal'])\n", "code_toks_joined": "from __future__ import print_function , division <NEWLINE> from time_base import comparison_timer <NEWLINE> isreal_re = <STRING> <NEWLINE> isreal_try = <STRING> <NEWLINE> comparison_timer ( [ <STRING> , isreal_re ] , <NEWLINE> <INDENT> [ <STRING> , isreal_try ] , <NEWLINE> [ <STRING> , <STRING> ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["''' import re'''", "''' def isreal_try(x):'''", "'isreal_re'", "'isreal_try'", "'isreal'", "'from fastnumbers import isreal'"]}}], ["1bb561f82d0658daaf7d54c680146d4b", {"code_string": "def MergeFrom(self, other):\n    \"\"\"Merges the messages from MessageSet 'other' into this set.\"\"\"\n    assert other is not self\n    for(type_id, item) in other.items.items():\n        if type_id in self.items:\n            self.items[type_id].MergeFrom(item)\n        else:\n            self.items[type_id] = item.Copy()\n", "code_toks_joined": "def MergeFrom ( self , other ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> assert other is not self <NEWLINE> for ( type_id , item ) in other . items . items ( ) : <NEWLINE> <INDENT> if type_id in self . items : <NEWLINE> <INDENT> self . items [ type_id ] . MergeFrom ( item ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . items [ type_id ] = item . Copy ( ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Merges the messages from MessageSet 'other' into this set.\"\"\""]}}], ["bc65018569350b9226d2bb4b7393dc07", {"code_string": "from dbindexer.api import register_index\nfrom pirate_forum.models import View\nregister_index(View, {'modified_dt': 'month', 'modified_dt': 'day',\n    'modified_dt': 'year', 'created_dt': 'month', 'created_dt': 'day', 'created_dt': 'year'})\n", "code_toks_joined": "from dbindexer . api import register_index <NEWLINE> from pirate_forum . models import View <NEWLINE> register_index ( View , { <STRING> : <STRING> , <STRING> : <STRING> , <NEWLINE> <INDENT> <STRING> : <STRING> , <STRING> : <STRING> , <STRING> : <STRING> , <STRING> : <STRING> } ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'modified_dt'", "'month'", "'modified_dt'", "'day'", "'modified_dt'", "'year'", "'created_dt'", "'month'", "'created_dt'", "'day'", "'created_dt'", "'year'"]}}], ["7f75688945bf68c2c1b8d7dd51b752b1", {"code_string": "def handle_int(self):\n    \"SIGINT handling\"\n    self.stop(False)\n    raise StopIteration\n", "code_toks_joined": "def handle_int ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . stop ( False ) <NEWLINE> raise StopIteration <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"SIGINT handling\""]}}], ["1ef5471d95660a174011e58a4f4618eb", {"code_string": "def read_packet(self):\n    \"\"\"Synchronously read a message. This message could be from the Pebble(in which case it will be a\"\"\"\n    pass\n", "code_toks_joined": "def read_packet ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Synchronously read a message. This message could be from the Pebble(in which case it will be a\"\"\""]}}], ["8a606f641fa403b2dacd3a72aa524ec6", {"code_string": "def getCpuStat(self):\n    with open('/proc/stat') as fd:\n        cpustats = []\n        while True:\n            line = fd.readline()\n            if len(line) == 0:\n                break;\n            if line[0: 3] == 'cpu':\n                cpustats.append(line.replace('\\n', ''))\n        return cpustats\n", "code_toks_joined": "def getCpuStat ( self ) : <NEWLINE> <INDENT> with open ( <STRING> ) as fd : <NEWLINE> <INDENT> cpustats = [ ] <NEWLINE> while True : <NEWLINE> <INDENT> line = fd . readline ( ) <NEWLINE> if len ( line ) == 0 : <NEWLINE> <INDENT> break ; <NEWLINE> <DEDENT> if line [ 0 : 3 ] == <STRING> : <NEWLINE> <INDENT> cpustats . append ( line . replace ( <STRING> , <STRING> ) ) <NEWLINE> <DEDENT> <DEDENT> return cpustats <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/proc/stat'", "'cpu'", "'\\n'", "''"]}}], ["2408e2c53acbe4c814e7c5ffee4bc4d3", {"code_string": "def close(self):\n    '''Close the device serial port.'''\n    self._serial_device.close()\n", "code_toks_joined": "def close ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . _serial_device . close ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Close the device serial port.'''"]}}], ["a8f5758ded3c59d1c35f8a4ebec7893f", {"code_string": "import os\nimport re\nimport sys\nimport subprocess\npath = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'swedish_chef.l')\nCOMPILE_CMD = \"lex -o /tmp/swedish_chef.c {0} && cc /tmp/swedish_chef.c -o /tmp/swedish_chef -ll\".format(path)\nsubprocess.Popen(COMPILE_CMD, stdout = subprocess.PIPE, shell = True).wait()\nRUN_CMD = \"/tmp/swedish_chef\"\n", "code_toks_joined": "import os <NEWLINE> import re <NEWLINE> import sys <NEWLINE> import subprocess <NEWLINE> path = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ ) ) , <STRING> ) <NEWLINE> COMPILE_CMD = <STRING> . format ( path ) <NEWLINE> subprocess . Popen ( COMPILE_CMD , stdout = subprocess . PIPE , shell = True ) . wait ( ) <NEWLINE> RUN_CMD = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'swedish_chef.l'", "\"lex -o /tmp/swedish_chef.c {0} && cc /tmp/swedish_chef.c -o /tmp/swedish_chef -ll\"", "\"/tmp/swedish_chef\""]}}], ["85ca7096a3ca8b24e8524119d1294a4e", {"code_string": "def create_app():\n    sentry.init_app(app)\n    bootstrap = Bootstrap(app)\n    moment = Moment(app)\n    from app.views.login import auth as auth_blueprint\n    app.register_blueprint(auth_blueprint, url_prefix = '/auth')\n    from app.views.wx import wx as wx_blueprint\n    app.register_blueprint(wx_blueprint, url_prefix = '/wx')\n    from app.views.home import home as home_blueprint\n    app.register_blueprint(home_blueprint)\n    from app.views.errors import error as error_blueprint\n    app.register_blueprint(error_blueprint)\n    return app\n", "code_toks_joined": "def create_app ( ) : <NEWLINE> <INDENT> sentry . init_app ( app ) <NEWLINE> bootstrap = Bootstrap ( app ) <NEWLINE> moment = Moment ( app ) <NEWLINE> from app . views . login import auth as auth_blueprint <NEWLINE> app . register_blueprint ( auth_blueprint , url_prefix = <STRING> ) <NEWLINE> from app . views . wx import wx as wx_blueprint <NEWLINE> app . register_blueprint ( wx_blueprint , url_prefix = <STRING> ) <NEWLINE> from app . views . home import home as home_blueprint <NEWLINE> app . register_blueprint ( home_blueprint ) <NEWLINE> from app . views . errors import error as error_blueprint <NEWLINE> app . register_blueprint ( error_blueprint ) <NEWLINE> return app <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/auth'", "'/wx'"]}}], ["0c2cac108f6fb84d12428ac46ea05c4f", {"code_string": "class StreamItem(models.Model):\n    stream = models.ForeignKey(Stream, related_name = 'items')\n    pub_date = models.DateTimeField()\n    objects = InheritanceManager()\n", "code_toks_joined": "class StreamItem ( models . Model ) : <NEWLINE> <INDENT> stream = models . ForeignKey ( Stream , related_name = <STRING> ) <NEWLINE> pub_date = models . DateTimeField ( ) <NEWLINE> objects = InheritanceManager ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'items'"]}}], ["2ba25e39aebe7dac8bb7f040c1a74648", {"code_string": "def page_no(self):\n    if self.placement:\n        placement = json.loads(self.placement)\n        if 'page-no' in placement:\n            return placement['page-no']\n    return None\n", "code_toks_joined": "def page_no ( self ) : <NEWLINE> <INDENT> if self . placement : <NEWLINE> <INDENT> placement = json . loads ( self . placement ) <NEWLINE> if <STRING> in placement : <NEWLINE> <INDENT> return placement [ <STRING> ] <NEWLINE> <DEDENT> <DEDENT> return None <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'page-no'", "'page-no'"]}}], ["dd1990025664363c4b4dc12bb990fd3d", {"code_string": "def df(x):\n    wing_param.set_thetaY(x)\n    DLLM.set_direct_computed()\n    DLLM.run_post()\n    func_grad = DLLM.get_dpF_list_dpthetaY()\n    return func_grad\n", "code_toks_joined": "def df ( x ) : <NEWLINE> <INDENT> wing_param . set_thetaY ( x ) <NEWLINE> DLLM . set_direct_computed ( ) <NEWLINE> DLLM . run_post ( ) <NEWLINE> func_grad = DLLM . get_dpF_list_dpthetaY ( ) <NEWLINE> return func_grad <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["85b94d51dc3fc07f8561c4804f2e600e", {"code_string": "def convert_np_audio_to_sample_blocks(song_np, block_size):\n    block_lists = []\n    total_samples = song_np.shape[0]\n    print('total_samples = ', total_samples)\n    num_samples_so_far = 0\n    while(num_samples_so_far < total_samples):\n        block = song_np[num_samples_so_far: num_samples_so_far + block_size]\n        '''print(\"block.shape[0]=\", block.shape[0])'''\n        if(block.shape[0] < block_size):\n            padding = np.zeros((block_size - block.shape[0], ))\n            block = np.concatenate((block, padding))\n        block_lists.append(block)\n        num_samples_so_far += block_size\n    return block_lists\n", "code_toks_joined": "def convert_np_audio_to_sample_blocks ( song_np , block_size ) : <NEWLINE> <INDENT> block_lists = [ ] <NEWLINE> total_samples = song_np . shape [ 0 ] <NEWLINE> print ( <STRING> , total_samples ) <NEWLINE> num_samples_so_far = 0 <NEWLINE> while ( num_samples_so_far < total_samples ) : <NEWLINE> <INDENT> block = song_np [ num_samples_so_far : num_samples_so_far + block_size ] <NEWLINE> <STRING> <NEWLINE> if ( block . shape [ 0 ] < block_size ) : <NEWLINE> <INDENT> padding = np . zeros ( ( block_size - block . shape [ 0 ] , ) ) <NEWLINE> block = np . concatenate ( ( block , padding ) ) <NEWLINE> <DEDENT> block_lists . append ( block ) <NEWLINE> num_samples_so_far += block_size <NEWLINE> <DEDENT> return block_lists <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'total_samples = '", "'''print(\"block.shape[0]=\", block.shape[0])'''"]}}], ["1fc8174365f3918d982342e5bbccd769", {"code_string": "def __validate_fields(self, validation_function, validations):\n    for v in validations:\n        validation_function(v, validations[v])\n", "code_toks_joined": "def __validate_fields ( self , validation_function , validations ) : <NEWLINE> <INDENT> for v in validations : <NEWLINE> <INDENT> validation_function ( v , validations [ v ] ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["680e03801310ff1bc2d809a74a0d88b8", {"code_string": "def rank_maximin(self):\n    \"\"\"Return a sparse matrix encoding ordering obtained by maximin\"\"\"\n    rank = dok_matrix((self.nbDecision, self.nbDecision))\n    for i in range(self.nbDecision):\n        for j in range(self.nbDecision):\n            if self.scores[j, 0] < self.scores[i, 0]:\n                rank[i, j] = 1\n            elif self.scores[i, 0] < self.scores[j, 0]:\n                rank[j, i] = 1\n    return rank\n", "code_toks_joined": "def rank_maximin ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> rank = dok_matrix ( ( self . nbDecision , self . nbDecision ) ) <NEWLINE> for i in range ( self . nbDecision ) : <NEWLINE> <INDENT> for j in range ( self . nbDecision ) : <NEWLINE> <INDENT> if self . scores [ j , 0 ] < self . scores [ i , 0 ] : <NEWLINE> <INDENT> rank [ i , j ] = 1 <NEWLINE> <DEDENT> elif self . scores [ i , 0 ] < self . scores [ j , 0 ] : <NEWLINE> <INDENT> rank [ j , i ] = 1 <NEWLINE> <DEDENT> <DEDENT> <DEDENT> return rank <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Return a sparse matrix encoding ordering obtained by maximin\"\"\""]}}], ["6b95f987eeeb3d49e2d2270b56e27663", {"code_string": "import datetime\nimport trainer.corpora as crp\nimport trainer.features as ftr\nimport trainer.classifier_test as cls\nNLTK = True\nSKLEARN = False\n", "code_toks_joined": "import datetime <NEWLINE> import trainer . corpora as crp <NEWLINE> import trainer . features as ftr <NEWLINE> import trainer . classifier_test as cls <NEWLINE> NLTK = True <NEWLINE> SKLEARN = False <NEWLINE>", "anonymize_dict": {}}], ["dc772fbea4a746ff7fe67a1634619d7f", {"code_string": "from app import app\napp.secret_key = 'abcd_key'\napp.config['SQLALCHEMY_ECHO'] = True\nif __name__ == '__main__':\n    app.run(host = '0.0.0.0', port = 5000, debug = True)\n", "code_toks_joined": "from app import app <NEWLINE> app . secret_key = <STRING> <NEWLINE> app . config [ <STRING> ] = True <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> app . run ( host = <STRING> , port = 5000 , debug = True ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'abcd_key'", "'SQLALCHEMY_ECHO'", "'__main__'", "'0.0.0.0'"]}}], ["04e18ff531bb5b1b41b17c887c7dc1b6", {"code_string": "class Test_236_Intermediate(unittest.TestCase):\n    def test_lowest_fibonacci_sequence(self):\n        self.assertEqual(lowest_fibonacci_sequence(21)[1], 1)\n        self.assertEqual(lowest_fibonacci_sequence(84)[1], 4)\n        self.assertEqual(lowest_fibonacci_sequence(0)[1], 0)\n        self.assertEqual(lowest_fibonacci_sequence(578)[1], 17)\n        self.assertEqual(lowest_fibonacci_sequence(123456789)[1], 41152263)\n        self.assertEqual(lowest_fibonacci_sequence(38695577906193299)[1], 7)\n", "code_toks_joined": "class Test_236_Intermediate ( unittest . TestCase ) : <NEWLINE> <INDENT> def test_lowest_fibonacci_sequence ( self ) : <NEWLINE> <INDENT> self . assertEqual ( lowest_fibonacci_sequence ( 21 ) [ 1 ] , 1 ) <NEWLINE> self . assertEqual ( lowest_fibonacci_sequence ( 84 ) [ 1 ] , 4 ) <NEWLINE> self . assertEqual ( lowest_fibonacci_sequence ( 0 ) [ 1 ] , 0 ) <NEWLINE> self . assertEqual ( lowest_fibonacci_sequence ( 578 ) [ 1 ] , 17 ) <NEWLINE> self . assertEqual ( lowest_fibonacci_sequence ( 123456789 ) [ 1 ] , 41152263 ) <NEWLINE> self . assertEqual ( lowest_fibonacci_sequence ( 38695577906193299 ) [ 1 ] , 7 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["fcb568e03768bd5cf2710be50d363b3f", {"code_string": "def user_create(request, user_id, email, password, tenant_id, enabled):\n    return User(keystoneclient(request).users.create(\n        user_id, password, email, tenant_id, enabled))\n", "code_toks_joined": "def user_create ( request , user_id , email , password , tenant_id , enabled ) : <NEWLINE> <INDENT> return User ( keystoneclient ( request ) . users . create ( <NEWLINE> <INDENT> user_id , password , email , tenant_id , enabled ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["429c05abccc26e977d60a095a54eb4bb", {"code_string": "def detail_view(request, voter_id = None, ** kw):\n    context = kw\n    site = request.session['site']\n    context['site'] = site\n    detail = site.active_section.active_subsection.detail\n    detail.render_pagination()\n    if detail.obj:\n        context['page_title'] = detail.obj.first_name + ' ' + detail.obj.last_name\n    else:\n        context['page_title'] = 'Voter Not Found'\n    return render_to_response(\n        'voters/detail.html',\n        context,\n    )\n", "code_toks_joined": "def detail_view ( request , voter_id = None , ** kw ) : <NEWLINE> <INDENT> context = kw <NEWLINE> site = request . session [ <STRING> ] <NEWLINE> context [ <STRING> ] = site <NEWLINE> detail = site . active_section . active_subsection . detail <NEWLINE> detail . render_pagination ( ) <NEWLINE> if detail . obj : <NEWLINE> <INDENT> context [ <STRING> ] = detail . obj . first_name + <STRING> + detail . obj . last_name <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> context [ <STRING> ] = <STRING> <NEWLINE> <DEDENT> return render_to_response ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> context , <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'site'", "'site'", "'page_title'", "' '", "'page_title'", "'Voter Not Found'", "'voters/detail.html'"]}}], ["3111e4f559ac7de4028e2d5532c396df", {"code_string": "class SchedulerContext(base.BaseContext):\n    def __init__(self, adminContext, config):\n        base.BaseContext.__init__(self, adminContext)\n        self.config = config\n    def getAdminContext(self):\n        return self.parent\n", "code_toks_joined": "class SchedulerContext ( base . BaseContext ) : <NEWLINE> <INDENT> def __init__ ( self , adminContext , config ) : <NEWLINE> <INDENT> base . BaseContext . __init__ ( self , adminContext ) <NEWLINE> self . config = config <NEWLINE> <DEDENT> def getAdminContext ( self ) : <NEWLINE> <INDENT> return self . parent <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["77b9497dce75fe0a5f2288004bad9d2c", {"code_string": "def setUp(self):\n    s = LazySettings(settings_module = 'kay.tests.rest_settings')\n    app = get_application(settings = s)\n    self.client = Client(app, BaseResponse)\n    self.client.test_logout()\n", "code_toks_joined": "def setUp ( self ) : <NEWLINE> <INDENT> s = LazySettings ( settings_module = <STRING> ) <NEWLINE> app = get_application ( settings = s ) <NEWLINE> self . client = Client ( app , BaseResponse ) <NEWLINE> self . client . test_logout ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'kay.tests.rest_settings'"]}}], ["f429b7ecdf117af49e247e2d4069c72a", {"code_string": "\"\"\"jss_helper_lib\"\"\"\nfrom.import actions\nfrom.jss_connection import JSSConnection\nfrom.import tools\n__version__ = \"2.0.1\"\n", "code_toks_joined": "<STRING> <NEWLINE> from . import actions <NEWLINE> from . jss_connection import JSSConnection <NEWLINE> from . import tools <NEWLINE> __version__ = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"jss_helper_lib\"\"\"", "\"2.0.1\""]}}], ["0e89003e8a2277b2502151725f281c76", {"code_string": "class BooktypeGroupExist(Exception):\n    def __init__(self, group_name):\n        self.group_name = group_name\n    def __str__(self):\n        return 'Booktype group already exists'\n", "code_toks_joined": "class BooktypeGroupExist ( Exception ) : <NEWLINE> <INDENT> def __init__ ( self , group_name ) : <NEWLINE> <INDENT> self . group_name = group_name <NEWLINE> <DEDENT> def __str__ ( self ) : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Booktype group already exists'"]}}], ["04b9a16a3c48a17402e8f5b683a39d3e", {"code_string": "class Result(Receivable):\n    def to_array(self):\n        return{}\n    pass\n", "code_toks_joined": "class Result ( Receivable ) : <NEWLINE> <INDENT> def to_array ( self ) : <NEWLINE> <INDENT> return { } <NEWLINE> <DEDENT> pass <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["df24df9159fb983748a0398b90a5735a", {"code_string": "class ValidationView(APIView):\n    permission_classes = (IsAuthenticated, )\n    def post(self, request, * args, ** kwargs):\n        data = request.data\n        request = ValidationRequest(data)\n        return Response(request.validateAndGetResponseData(), 200)\n", "code_toks_joined": "class ValidationView ( APIView ) : <NEWLINE> <INDENT> permission_classes = ( IsAuthenticated , ) <NEWLINE> def post ( self , request , * args , ** kwargs ) : <NEWLINE> <INDENT> data = request . data <NEWLINE> request = ValidationRequest ( data ) <NEWLINE> return Response ( request . validateAndGetResponseData ( ) , 200 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["69dd191553bc67e133748cc706099fb6", {"code_string": "def check_forward_ones(self, x_data, use_cudnn = True):\n    x = chainer.Variable(x_data)\n    y = functions.spatial_pyramid_pooling_2d(\n        x, self.pyramid_height, self.pooling_class, use_cudnn = use_cudnn)\n    y_data = cuda.to_cpu(y.data)\n    self.assertEqual((self.n, self.output_dim, 1, 1), y_data.shape)\n    gradient_check.assert_allclose(y_data, numpy.ones_like(y_data))\n", "code_toks_joined": "def check_forward_ones ( self , x_data , use_cudnn = True ) : <NEWLINE> <INDENT> x = chainer . Variable ( x_data ) <NEWLINE> y = functions . spatial_pyramid_pooling_2d ( <NEWLINE> <INDENT> x , self . pyramid_height , self . pooling_class , use_cudnn = use_cudnn ) <NEWLINE> <DEDENT> y_data = cuda . to_cpu ( y . data ) <NEWLINE> self . assertEqual ( ( self . n , self . output_dim , 1 , 1 ) , y_data . shape ) <NEWLINE> gradient_check . assert_allclose ( y_data , numpy . ones_like ( y_data ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["e15e9249d1bc358303ddd8609814e57f", {"code_string": "def approx_gradients(function, argument_array, epsilon = 1e-6):\n    g = zeros(argument_array.shape)\n    for i in range(argument_array.size):\n        a_plus = argument_array.copy()\n        a_plus.flat[i] += epsilon\n        a_minus = argument_array.copy()\n        a_minus.flat[i] -= epsilon\n        g.flat[i] = (function(a_plus) - function(a_minus)) /(2 * epsilon)\n    return g\n", "code_toks_joined": "def approx_gradients ( function , argument_array , epsilon = 1e-6 ) : <NEWLINE> <INDENT> g = zeros ( argument_array . shape ) <NEWLINE> for i in range ( argument_array . size ) : <NEWLINE> <INDENT> a_plus = argument_array . copy ( ) <NEWLINE> a_plus . flat [ i ] += epsilon <NEWLINE> a_minus = argument_array . copy ( ) <NEWLINE> a_minus . flat [ i ] -= epsilon <NEWLINE> g . flat [ i ] = ( function ( a_plus ) - function ( a_minus ) ) / ( 2 * epsilon ) <NEWLINE> <DEDENT> return g <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["8a048f10c2b1e91dc8152c289ebba8be", {"code_string": "class IPsecPolicy(object):\n    '''Security IPsec policy.'''\n    def __init__(self, name):\n        self.name = name\n        self.proposals = []\n", "code_toks_joined": "class IPsecPolicy ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , name ) : <NEWLINE> <INDENT> self . name = name <NEWLINE> self . proposals = [ ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Security IPsec policy.'''"]}}], ["2cccaf1e653f135c7eec6c6dcfbc42d6", {"code_string": "def _trace_cons(self, x):\n    ax = pycppad.independent(x)\n    ay = self.cons(ax)\n    if not isinstance(ay, np.ndarray):\n        ay = np.array([ay])\n    self._cppad_adfun_cons = pycppad.adfun(ax, ay)\n", "code_toks_joined": "def _trace_cons ( self , x ) : <NEWLINE> <INDENT> ax = pycppad . independent ( x ) <NEWLINE> ay = self . cons ( ax ) <NEWLINE> if not isinstance ( ay , np . ndarray ) : <NEWLINE> <INDENT> ay = np . array ( [ ay ] ) <NEWLINE> <DEDENT> self . _cppad_adfun_cons = pycppad . adfun ( ax , ay ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["9dc72c0261b8955be6571353e2f40903", {"code_string": "from __future__ import absolute_import\nimport logging\nfrom geocoder.base import OneResult\nfrom geocoder.arcgis import ArcgisQuery\nfrom geocoder.location import Location\n", "code_toks_joined": "from __future__ import absolute_import <NEWLINE> import logging <NEWLINE> from geocoder . base import OneResult <NEWLINE> from geocoder . arcgis import ArcgisQuery <NEWLINE> from geocoder . location import Location <NEWLINE>", "anonymize_dict": {}}], ["102b0c8aa3a47043dcba64d5332bce7b", {"code_string": "def test_set_availability_zone_compute_service(self):\n    \"\"\"Test for compute service get right availability zone.\"\"\"\n    service = self._create_service_with_topic('compute', self.host)\n    services = db.service_get_all(self.context)\n    new_service = az.set_availability_zones(self.context, services)[0]\n    self.assertEqual(new_service['availability_zone'],\n        self.default_az)\n    self._add_to_aggregate(service, self.agg)\n    new_service = az.set_availability_zones(self.context, services)[0]\n    self.assertEqual(new_service['availability_zone'],\n        self.availability_zone)\n    self._destroy_service(service)\n", "code_toks_joined": "def test_set_availability_zone_compute_service ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> service = self . _create_service_with_topic ( <STRING> , self . host ) <NEWLINE> services = db . service_get_all ( self . context ) <NEWLINE> new_service = az . set_availability_zones ( self . context , services ) [ 0 ] <NEWLINE> self . assertEqual ( new_service [ <STRING> ] , <NEWLINE> <INDENT> self . default_az ) <NEWLINE> <DEDENT> self . _add_to_aggregate ( service , self . agg ) <NEWLINE> new_service = az . set_availability_zones ( self . context , services ) [ 0 ] <NEWLINE> self . assertEqual ( new_service [ <STRING> ] , <NEWLINE> <INDENT> self . availability_zone ) <NEWLINE> <DEDENT> self . _destroy_service ( service ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test for compute service get right availability zone.\"\"\"", "'compute'", "'availability_zone'", "'availability_zone'"]}}], ["55c0d104eb96a6e5b5f4fa3d1313351c", {"code_string": "def remove_conference(cls, key):\n    if key in cls.observers:\n        cls.observers[key].stop()\n        del cls.observers[key]\n        return True\n    else:\n        return False\n", "code_toks_joined": "def remove_conference ( cls , key ) : <NEWLINE> <INDENT> if key in cls . observers : <NEWLINE> <INDENT> cls . observers [ key ] . stop ( ) <NEWLINE> del cls . observers [ key ] <NEWLINE> return True <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["af6c2ce8799e6bfbc1fc7b3ec5bc8eb5", {"code_string": "def get_coords(self):\n    \"\"\"Returns the x,y coordinates of that have been selected\"\"\"\n    if self.circ is not None:\n        return self.circ.center, self.circ.radius\n", "code_toks_joined": "def get_coords ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if self . circ is not None : <NEWLINE> <INDENT> return self . circ . center , self . circ . radius <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Returns the x,y coordinates of that have been selected\"\"\""]}}], ["4455cf7b5e38ce07aa87a43c5017a133", {"code_string": "def is_registered(chromosome):\n    resultCursor = postgresConnHandle.cursor()\n    resultCursor.execute(\"select * from public_1.reg_chrom where chrom = '{0}'\".format(chromosome))\n    if resultCursor.rowcount > 0:\n        return True\n    return False\n", "code_toks_joined": "def is_registered ( chromosome ) : <NEWLINE> <INDENT> resultCursor = postgresConnHandle . cursor ( ) <NEWLINE> resultCursor . execute ( <STRING> . format ( chromosome ) ) <NEWLINE> if resultCursor . rowcount > 0 : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> return False <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"select * from public_1.reg_chrom where chrom = '{0}'\""]}}], ["bc633243bd1ecd2425423bd6513db94a", {"code_string": "def test_to_python(self):\n    \"\"\" Tests that to_python of value column is called \"\"\"\n    column = columns.Map(JsonTestColumn, JsonTestColumn)\n    val = {1: 2, 3: 4, 5: 6}\n    db_val = column.to_database(val)\n    assert db_val.value =={json.dumps(k): json.dumps(v) for k, v in val.items()}\n    py_val = column.to_python(db_val.value)\n    assert py_val == val\n", "code_toks_joined": "def test_to_python ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> column = columns . Map ( JsonTestColumn , JsonTestColumn ) <NEWLINE> val = { 1 : 2 , 3 : 4 , 5 : 6 } <NEWLINE> db_val = column . to_database ( val ) <NEWLINE> assert db_val . value == { json . dumps ( k ) : json . dumps ( v ) for k , v in val . items ( ) } <NEWLINE> py_val = column . to_python ( db_val . value ) <NEWLINE> assert py_val == val <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Tests that to_python of value column is called \"\"\""]}}], ["6156386d209c404d462b356fd2300204", {"code_string": "def main():\n    fa('1')\n    fl('0')\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> fa ( <STRING> ) <NEWLINE> fl ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'1'", "'0'"]}}], ["e887232febbb81971d2e73b651688d31", {"code_string": "def __str__(self):\n    s = (\"parted.FileSystem instance --\\n\"\n        \"  type: %(type)s  geometry: %(geometry)r  checked: %(checked)s\\n\"\n        \"  PedFileSystem: %(ped)r\" %\n        {\"type\": self.type, \"geometry\": self.geometry,\n            \"checked\": self.checked, \"ped\": self.__fileSystem})\n    return s\n", "code_toks_joined": "def __str__ ( self ) : <NEWLINE> <INDENT> s = ( <STRING> <NEWLINE> <INDENT> <STRING> <NEWLINE> <STRING> % <NEWLINE> { <STRING> : self . type , <STRING> : self . geometry , <NEWLINE> <INDENT> <STRING> : self . checked , <STRING> : self . __fileSystem } ) <NEWLINE> <DEDENT> <DEDENT> return s <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"parted.FileSystem instance --\\n\"", "\"  type: %(type)s  geometry: %(geometry)r  checked: %(checked)s\\n\"", "\"  PedFileSystem: %(ped)r\"", "\"type\"", "\"geometry\"", "\"checked\"", "\"ped\""]}}], ["3937960fd5eca7577d3dd91a1d58d301", {"code_string": "def test_raises_original_error_when_no_label_available(self, session):\n    with pytest.raises(ElementNotFound) as excinfo:\n        session.check(\"form_cars_ariel\")\n    assert \"Unable to find checkbox 'form_cars_ariel'\" in str(excinfo.value)\n", "code_toks_joined": "def test_raises_original_error_when_no_label_available ( self , session ) : <NEWLINE> <INDENT> with pytest . raises ( ElementNotFound ) as excinfo : <NEWLINE> <INDENT> session . check ( <STRING> ) <NEWLINE> <DEDENT> assert <STRING> in str ( excinfo . value ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"form_cars_ariel\"", "\"Unable to find checkbox 'form_cars_ariel'\""]}}], ["7314bf5d6488a0fd281f1e732cbf9de7", {"code_string": "class ExampleModel(models.Model):\n    name = models.CharField(max_length = 50)\n    @ staticmethod\n    def get_translated_string():\n        return _(u\"Translatable string\")\n    def __unicode__(self):\n        return u\"ExampleModel %s\" % self.name\n", "code_toks_joined": "class ExampleModel ( models . Model ) : <NEWLINE> <INDENT> name = models . CharField ( max_length = 50 ) <NEWLINE> @ staticmethod <NEWLINE> def get_translated_string ( ) : <NEWLINE> <INDENT> return _ ( <STRING> ) <NEWLINE> <DEDENT> def __unicode__ ( self ) : <NEWLINE> <INDENT> return <STRING> % self . name <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["u\"Translatable string\"", "u\"ExampleModel %s\""]}}], ["4b010a502ba19152fdadf7fa665700ac", {"code_string": "from storage import *\nfrom storageitu import *\nset_logger(get_logfile_logger())\nenvironment = Environment(False)\nstorage = Storage(environment)\nstorage.probe()\nstaging = storage.get_staging()\nprint(staging)\npartitionable = Partitionable.find_by_name(staging, \"/dev/dasdb\")\npartitionable.remove_descendants()\npartitionable.create_partition_table(PtType_IMPLICIT)\nprint(staging)\ncommit(storage)\n", "code_toks_joined": "from storage import * <NEWLINE> from storageitu import * <NEWLINE> set_logger ( get_logfile_logger ( ) ) <NEWLINE> environment = Environment ( False ) <NEWLINE> storage = Storage ( environment ) <NEWLINE> storage . probe ( ) <NEWLINE> staging = storage . get_staging ( ) <NEWLINE> print ( staging ) <NEWLINE> partitionable = Partitionable . find_by_name ( staging , <STRING> ) <NEWLINE> partitionable . remove_descendants ( ) <NEWLINE> partitionable . create_partition_table ( PtType_IMPLICIT ) <NEWLINE> print ( staging ) <NEWLINE> commit ( storage ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"/dev/dasdb\""]}}], ["1776a96897a9d1fb7774c7cc262417fb", {"code_string": "\"\"\"InformationMachineAPILib.Controllers.UserStoresController\"\"\"\nimport unirest\nfrom InformationMachineAPILib.APIHelper import APIHelper\nfrom InformationMachineAPILib.Configuration import Configuration\nfrom InformationMachineAPILib.APIException import APIException\nfrom InformationMachineAPILib.Models.GetAllStoresWrapper import GetAllStoresWrapper\nfrom InformationMachineAPILib.Models.ConnectStoreWrapper import ConnectStoreWrapper\nfrom InformationMachineAPILib.Models.ConnectStoreWrapper import ConnectStoreWrapper\nfrom InformationMachineAPILib.Models.GetSingleStoresWrapper import GetSingleStoresWrapper\nfrom InformationMachineAPILib.Models.UpdateStoreConnectionWrapper import UpdateStoreConnectionWrapper\nfrom InformationMachineAPILib.Models.DeleteSingleStoreWrapper import DeleteSingleStoreWrapper\n", "code_toks_joined": "<STRING> <NEWLINE> import unirest <NEWLINE> from InformationMachineAPILib . APIHelper import APIHelper <NEWLINE> from InformationMachineAPILib . Configuration import Configuration <NEWLINE> from InformationMachineAPILib . APIException import APIException <NEWLINE> from InformationMachineAPILib . Models . GetAllStoresWrapper import GetAllStoresWrapper <NEWLINE> from InformationMachineAPILib . Models . ConnectStoreWrapper import ConnectStoreWrapper <NEWLINE> from InformationMachineAPILib . Models . ConnectStoreWrapper import ConnectStoreWrapper <NEWLINE> from InformationMachineAPILib . Models . GetSingleStoresWrapper import GetSingleStoresWrapper <NEWLINE> from InformationMachineAPILib . Models . UpdateStoreConnectionWrapper import UpdateStoreConnectionWrapper <NEWLINE> from InformationMachineAPILib . Models . DeleteSingleStoreWrapper import DeleteSingleStoreWrapper <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"InformationMachineAPILib.Controllers.UserStoresController\"\"\""]}}], ["b62b3f40780c33eee0c9fb1e188a0538", {"code_string": "class AclAdmin(admin.ModelAdmin):\n    search_fields = ('topic__name', )\n    list_filter = ('acc', 'allow', )\n    ordering = ('topic', )\n    list_display = ('topic', 'allow', 'acc', 'password')\n", "code_toks_joined": "class AclAdmin ( admin . ModelAdmin ) : <NEWLINE> <INDENT> search_fields = ( <STRING> , ) <NEWLINE> list_filter = ( <STRING> , <STRING> , ) <NEWLINE> ordering = ( <STRING> , ) <NEWLINE> list_display = ( <STRING> , <STRING> , <STRING> , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'topic__name'", "'acc'", "'allow'", "'topic'", "'topic'", "'allow'", "'acc'", "'password'"]}}], ["75572d6540b2cac51d90ea5a3c5972ff", {"code_string": "import logging\nfrom app import get_app\nlogger = logging.getLogger(__name__)\ncelery = get_app().celery\n", "code_toks_joined": "import logging <NEWLINE> from app import get_app <NEWLINE> logger = logging . getLogger ( __name__ ) <NEWLINE> celery = get_app ( ) . celery <NEWLINE>", "anonymize_dict": {}}], ["ccf6c732581da799af0f7640c3fc209f", {"code_string": "def test_authorfactory(session):\n    author = AuthorFactory()\n    author.save()\n    assert isinstance(author, Author)\n    assert author.id is not None\n    assert author.name is not None\n    assert author.givenname is not None\n    assert author.familyname is not None\n    assert author.url is not None\n    assert author.email is not None\n    author2 = AuthorFactory()\n    author2.save()\n    assert author.id != author2.id\n", "code_toks_joined": "def test_authorfactory ( session ) : <NEWLINE> <INDENT> author = AuthorFactory ( ) <NEWLINE> author . save ( ) <NEWLINE> assert isinstance ( author , Author ) <NEWLINE> assert author . id is not None <NEWLINE> assert author . name is not None <NEWLINE> assert author . givenname is not None <NEWLINE> assert author . familyname is not None <NEWLINE> assert author . url is not None <NEWLINE> assert author . email is not None <NEWLINE> author2 = AuthorFactory ( ) <NEWLINE> author2 . save ( ) <NEWLINE> assert author . id != author2 . id <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["e493734f1242df32355f489399890af6", {"code_string": "from threeML.classicMLE.joint_likelihood import JointLikelihood\nfrom threeML.bayesian.bayesian_analysis import BayesianAnalysis\n__all__ = []\ntry:\n    import copyreg\nexcept ImportError:\n    import copy_reg as copyreg\n", "code_toks_joined": "from threeML . classicMLE . joint_likelihood import JointLikelihood <NEWLINE> from threeML . bayesian . bayesian_analysis import BayesianAnalysis <NEWLINE> __all__ = [ ] <NEWLINE> try : <NEWLINE> <INDENT> import copyreg <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> import copy_reg as copyreg <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["dcb144ad36ff24fb1058bc5b74696ba0", {"code_string": "def _extract_brightcove_urls(cls, webpage):\n    \"\"\"Return a list of all Brightcove URLs from the webpage \"\"\"\n    url_m = re.search(\n        r'<meta\\s+property=[\\'\"]og:video[\\'\"]\\s+content=[\\'\"](https?://(?:secure|c)\\.brightcove.com/[^\\'\"]+)[\\'\"]',\n        webpage)\n    if url_m:\n        url = unescapeHTML(url_m.group(1))\n        if 'playerKey' in url or 'videoId' in url:\n            return[url]\n    matches = re.findall(\n        r'''(?sx)<object''',\n        webpage)\n    return list(filter(None, [cls._build_brighcove_url(m) for m in matches]))\n", "code_toks_joined": "def _extract_brightcove_urls ( cls , webpage ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> url_m = re . search ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> webpage ) <NEWLINE> <DEDENT> if url_m : <NEWLINE> <INDENT> url = unescapeHTML ( url_m . group ( 1 ) ) <NEWLINE> if <STRING> in url or <STRING> in url : <NEWLINE> <INDENT> return [ url ] <NEWLINE> <DEDENT> <DEDENT> matches = re . findall ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> webpage ) <NEWLINE> <DEDENT> return list ( filter ( None , [ cls . _build_brighcove_url ( m ) for m in matches ] ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Return a list of all Brightcove URLs from the webpage \"\"\"", "r'<meta\\s+property=[\\'\"]og:video[\\'\"]\\s+content=[\\'\"](https?://(?:secure|c)\\.brightcove.com/[^\\'\"]+)[\\'\"]'", "'playerKey'", "'videoId'", "r'''(?sx)<object'''"]}}], ["9391ba389ed5342d34790ffb16016db2", {"code_string": "import wx\ncolor_codes = ['black', 'red', 'green', 'yellow', 'blue', 'magenta', 'cyan', 'white']\nsolarized = {\n    'black': '#073642',\n    'red': '#dc322f',\n    'green': '#859900',\n    'yellow': '#b58900',\n    'blue': '#268bd2',\n    'magenta': '#d33682',\n    'cyan': '#2aa198',\n    'white': '#eee8d5',\n}\n", "code_toks_joined": "import wx <NEWLINE> color_codes = [ <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE> solarized = { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <DEDENT> } <NEWLINE>", "anonymize_dict": {"<STRING>": ["'black'", "'red'", "'green'", "'yellow'", "'blue'", "'magenta'", "'cyan'", "'white'", "'black'", "'#073642'", "'red'", "'#dc322f'", "'green'", "'#859900'", "'yellow'", "'#b58900'", "'blue'", "'#268bd2'", "'magenta'", "'#d33682'", "'cyan'", "'#2aa198'", "'white'", "'#eee8d5'"]}}], ["326fc9da8d4db6859eb14ed682427c83", {"code_string": "class report_lunchorder(models.AbstractModel):\n    _name = 'report.hotel.report_hotel_folio'\n    _inherit = 'report.abstract_report'\n    _template = 'hotel.report_hotel_folio'\n    _wrapped_report_class = folio_report\n", "code_toks_joined": "class report_lunchorder ( models . AbstractModel ) : <NEWLINE> <INDENT> _name = <STRING> <NEWLINE> _inherit = <STRING> <NEWLINE> _template = <STRING> <NEWLINE> _wrapped_report_class = folio_report <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'report.hotel.report_hotel_folio'", "'report.abstract_report'", "'hotel.report_hotel_folio'"]}}], ["87265775be8cbd9d400bc3b5716ef1ab", {"code_string": "from setuptools import setup\nsetup(\n    name = 'mdx_ditaa',\n    version = '0.3',\n    py_modules = ['mdx_ditaa'],\n    install_requires = ['markdown>=2.5'],\n)\n", "code_toks_joined": "from setuptools import setup <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> py_modules = [ <STRING> ] , <NEWLINE> install_requires = [ <STRING> ] , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'mdx_ditaa'", "'0.3'", "'mdx_ditaa'", "'markdown>=2.5'"]}}], ["f3170c11713ba58a0c15557d5c1d0e4b", {"code_string": "def create_client(reactor, host, port):\n    \"\"\"Start a Nats Protocol and connect it to a NATS endpoint over TCP4\"\"\"\n    log.info(\"Start client.\")\n    point = TCP4ClientEndpoint(reactor, host, port)\n    nats_protocol = txnats.io.NatsProtocol(\n        verbose = False,\n        on_connect = lambda np: np.sub(\"happy\", \"6\", on_msg = on_happy_msg))\n    connecting = connectProtocol(point, nats_protocol)\n    connecting.addErrback(lambda np: log.info(\"{p}\", p = np))\n    connecting.addCallback(lambda np: log.info(\"{p}\", p = np))\n    return connecting\n", "code_toks_joined": "def create_client ( reactor , host , port ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> log . info ( <STRING> ) <NEWLINE> point = TCP4ClientEndpoint ( reactor , host , port ) <NEWLINE> nats_protocol = txnats . io . NatsProtocol ( <NEWLINE> <INDENT> verbose = False , <NEWLINE> on_connect = lambda np : np . sub ( <STRING> , <STRING> , on_msg = on_happy_msg ) ) <NEWLINE> <DEDENT> connecting = connectProtocol ( point , nats_protocol ) <NEWLINE> connecting . addErrback ( lambda np : log . info ( <STRING> , p = np ) ) <NEWLINE> connecting . addCallback ( lambda np : log . info ( <STRING> , p = np ) ) <NEWLINE> return connecting <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Start a Nats Protocol and connect it to a NATS endpoint over TCP4\"\"\"", "\"Start client.\"", "\"happy\"", "\"6\"", "\"{p}\"", "\"{p}\""]}}], ["3390b1bf38380fe07933a433a96d955d", {"code_string": "def _get_providers(self):\n    providers = super(ProviderDumy, self)._get_providers()\n    providers.append(['dumy', 'Dumy'])\n    return providers\n", "code_toks_joined": "def _get_providers ( self ) : <NEWLINE> <INDENT> providers = super ( ProviderDumy , self ) . _get_providers ( ) <NEWLINE> providers . append ( [ <STRING> , <STRING> ] ) <NEWLINE> return providers <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'dumy'", "'Dumy'"]}}], ["ff1e37da7b49780dc52e7fbf3f629274", {"code_string": "def osbsapi(func):\n    @ wraps(func)\n    def catch_exceptions(* args, ** kwargs):\n        try:\n            return func(* args, ** kwargs)\n        except OsbsException:\n            raise\n        except Exception as ex:\n            raise OsbsException(cause = ex, traceback = sys.exc_info()[2])\n    return catch_exceptions\n", "code_toks_joined": "def osbsapi ( func ) : <NEWLINE> <INDENT> @ wraps ( func ) <NEWLINE> def catch_exceptions ( * args , ** kwargs ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> return func ( * args , ** kwargs ) <NEWLINE> <DEDENT> except OsbsException : <NEWLINE> <INDENT> raise <NEWLINE> <DEDENT> except Exception as ex : <NEWLINE> <INDENT> raise OsbsException ( cause = ex , traceback = sys . exc_info ( ) [ 2 ] ) <NEWLINE> <DEDENT> <DEDENT> return catch_exceptions <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["eebe3895b13eb22a678bf7032faa49af", {"code_string": "def upgrade(migrate_engine):\n    meta.bind = migrate_engine\n    for table in(instance_type_extra_specs_table, ):\n        try:\n            table.create()\n        except Exception:\n            LOG.info(repr(table))\n            LOG.exception('Exception while creating table')\n            raise\n", "code_toks_joined": "def upgrade ( migrate_engine ) : <NEWLINE> <INDENT> meta . bind = migrate_engine <NEWLINE> for table in ( instance_type_extra_specs_table , ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> table . create ( ) <NEWLINE> <DEDENT> except Exception : <NEWLINE> <INDENT> LOG . info ( repr ( table ) ) <NEWLINE> LOG . exception ( <STRING> ) <NEWLINE> raise <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Exception while creating table'"]}}], ["be9e381202041fd33161ae9d571acc11", {"code_string": "def default_callback(id):\n    print(\"P: {0}() (callback {1})\".format(notifString[id], id))\n    raw_input(\"press Enter for next\")\n", "code_toks_joined": "def default_callback ( id ) : <NEWLINE> <INDENT> print ( <STRING> . format ( notifString [ id ] , id ) ) <NEWLINE> raw_input ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"P: {0}() (callback {1})\"", "\"press Enter for next\""]}}], ["6bc6d665ee1621df287726dc2115c28f", {"code_string": "\"\"\"Test LpPenalty cost\"\"\"\nimport numpy\nimport theano\nfrom pylearn2.models.mlp import Linear\nfrom pylearn2.models.mlp import Softmax\nfrom pylearn2.models.mlp import MLP\nfrom pylearn2.costs.cost import LpPenalty\n", "code_toks_joined": "<STRING> <NEWLINE> import numpy <NEWLINE> import theano <NEWLINE> from pylearn2 . models . mlp import Linear <NEWLINE> from pylearn2 . models . mlp import Softmax <NEWLINE> from pylearn2 . models . mlp import MLP <NEWLINE> from pylearn2 . costs . cost import LpPenalty <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Test LpPenalty cost\"\"\""]}}], ["f40695a1f45b014aa9dabc46b98f8eef", {"code_string": "def read_graph_from_file(in_file):\n    \"\"\"Reads in a graph and returns it\"\"\"\n    in_file = generate_file_path(in_file)\n    with open(in_file) as in_file:\n        graph = json.load(in_file, encoding = 'utf8')\n    return graph\n", "code_toks_joined": "def read_graph_from_file ( in_file ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> in_file = generate_file_path ( in_file ) <NEWLINE> with open ( in_file ) as in_file : <NEWLINE> <INDENT> graph = json . load ( in_file , encoding = <STRING> ) <NEWLINE> <DEDENT> return graph <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Reads in a graph and returns it\"\"\"", "'utf8'"]}}], ["2320c36db9ac208068c22e000faca124", {"code_string": "import numpy as np\nimport pandas as pd\nimport re\nfrom sklearn.cluster import MiniBatchKMeans\n", "code_toks_joined": "import numpy as np <NEWLINE> import pandas as pd <NEWLINE> import re <NEWLINE> from sklearn . cluster import MiniBatchKMeans <NEWLINE>", "anonymize_dict": {}}], ["5b488c078df06451350bcccd2bd33845", {"code_string": "def _seek(self, seek_to_func, args):\n    if args is None:\n        return False\n    pos, duration = seek_to_func(* args)\n    if duration <= 0:\n        logging.warning('_seek: duration = %s', duration)\n        return None\n    self.seek_to(pos / duration)\n    return True\n", "code_toks_joined": "def _seek ( self , seek_to_func , args ) : <NEWLINE> <INDENT> if args is None : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> pos , duration = seek_to_func ( * args ) <NEWLINE> if duration <= 0 : <NEWLINE> <INDENT> logging . warning ( <STRING> , duration ) <NEWLINE> return None <NEWLINE> <DEDENT> self . seek_to ( pos / duration ) <NEWLINE> return True <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'_seek: duration = %s'"]}}], ["f2b6c5e28d69165f82e942ec55d69189", {"code_string": "from sync import barrier\nfrom threading import Thread\nimport time\nb = barrier(2)\n", "code_toks_joined": "from sync import barrier <NEWLINE> from threading import Thread <NEWLINE> import time <NEWLINE> b = barrier ( 2 ) <NEWLINE>", "anonymize_dict": {}}], ["28f2cc86bf49fc55ac57dbda9e58a0ff", {"code_string": "class response(BaseHTTPServer.BaseHTTPRequestHandler):\n    def do_GET(self):\n        self.send_response(200)\n        self.send_header(\"Content-type\", \"text/html\")\n        now = datetime.datetime.now()\n        headers = self.headers.headers\n        html = \"\"\"<html><head><title></title></head><body><h1>%s</h1>\"\"\" %(now, headers)\n        self.wfile.write(html)\n", "code_toks_joined": "class response ( BaseHTTPServer . BaseHTTPRequestHandler ) : <NEWLINE> <INDENT> def do_GET ( self ) : <NEWLINE> <INDENT> self . send_response ( 200 ) <NEWLINE> self . send_header ( <STRING> , <STRING> ) <NEWLINE> now = datetime . datetime . now ( ) <NEWLINE> headers = self . headers . headers <NEWLINE> html = <STRING> % ( now , headers ) <NEWLINE> self . wfile . write ( html ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Content-type\"", "\"text/html\"", "\"\"\"<html><head><title></title></head><body><h1>%s</h1>\"\"\""]}}], ["27dbd2b75e6d42f52a33e4d7f46c26f5", {"code_string": "raise DeprecationWarning(\"manage.py will be removed when porting to Django 1.7 will be terminated\")\nfrom django.core.management import execute_manager\ntry:\n    import settings\nexcept ImportError:\n    import sys\n    sys.stderr.write(\"Error: Can't find the file 'settings.py' in the directory containing %r. It appears you've customized things.\\nYou'll have to run django-admin.py, passing it your settings module.\\n(If the file settings.py does indeed exist, it's causing an ImportError somehow.)\\n\" % __file__)\n    sys.exit(1)\nif __name__ == \"__main__\":\n    execute_manager(settings)\n", "code_toks_joined": "raise DeprecationWarning ( <STRING> ) <NEWLINE> from django . core . management import execute_manager <NEWLINE> try : <NEWLINE> <INDENT> import settings <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> import sys <NEWLINE> sys . stderr . write ( <STRING> % __file__ ) <NEWLINE> sys . exit ( 1 ) <NEWLINE> <DEDENT> if __name__ == <STRING> : <NEWLINE> <INDENT> execute_manager ( settings ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"manage.py will be removed when porting to Django 1.7 will be terminated\"", "\"Error: Can't find the file 'settings.py' in the directory containing %r. It appears you've customized things.\\nYou'll have to run django-admin.py, passing it your settings module.\\n(If the file settings.py does indeed exist, it's causing an ImportError somehow.)\\n\"", "\"__main__\""]}}], ["05d0e905fcbbb3bf68136466c3038549", {"code_string": "def __init__(self, address, port, timeout = 0):\n    self.address = address\n    self.port = port\n    self.timeout = timeout\n", "code_toks_joined": "def __init__ ( self , address , port , timeout = 0 ) : <NEWLINE> <INDENT> self . address = address <NEWLINE> self . port = port <NEWLINE> self . timeout = timeout <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["20f6abec3c95517e59bc0565e5246409", {"code_string": "class Dog(object):\n    def __init__(self):\n        self.name = \"Dog\"\n    def bark(self):\n        return \"woof!\"\n", "code_toks_joined": "class Dog ( object ) : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> self . name = <STRING> <NEWLINE> <DEDENT> def bark ( self ) : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Dog\"", "\"woof!\""]}}], ["3ac014bb58e2a36abe4ce1a4568a2adc", {"code_string": "def validate_form():\n    username = request.form['username']\n    password = request.form['password']\n    error = None\n    if not username:\n        error = json.dumps({'error': 'Username absent'})\n    if not password:\n        error = json.dumps({'error': 'Password absent'})\n    return username, password, error\n", "code_toks_joined": "def validate_form ( ) : <NEWLINE> <INDENT> username = request . form [ <STRING> ] <NEWLINE> password = request . form [ <STRING> ] <NEWLINE> error = None <NEWLINE> if not username : <NEWLINE> <INDENT> error = json . dumps ( { <STRING> : <STRING> } ) <NEWLINE> <DEDENT> if not password : <NEWLINE> <INDENT> error = json . dumps ( { <STRING> : <STRING> } ) <NEWLINE> <DEDENT> return username , password , error <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'username'", "'password'", "'error'", "'Username absent'", "'error'", "'Password absent'"]}}], ["a7a6e98cfb259fe1b8c2651161b7619f", {"code_string": "class Perc98ServerTimeMetric(BaseMetric):\n    def __init__(self):\n        BaseMetric.__init__(self, 'perc_98_server_time')\n    def get_continious_query_body(self):\n        return 'SELECT percentile(\"resp-time\", 98) INTO \"{}\" FROM {}'.format(self.name, HTTP_SERVER_REQ_RESP_MEASUREMENT_NAME)\n    def data_key(self):\n        return 'percentile'\n    def chart_type(self):\n        return 'linear'\n    def unit_name(self):\n        return 'ms'\n    def metric_title(self):\n        return '98th percentile server response time'\n    def get_data_points_query(self, app = None):\n        return self.get_basic_data_points_query(app = app)\n", "code_toks_joined": "class Perc98ServerTimeMetric ( BaseMetric ) : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> BaseMetric . __init__ ( self , <STRING> ) <NEWLINE> <DEDENT> def get_continious_query_body ( self ) : <NEWLINE> <INDENT> return <STRING> . format ( self . name , HTTP_SERVER_REQ_RESP_MEASUREMENT_NAME ) <NEWLINE> <DEDENT> def data_key ( self ) : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> def chart_type ( self ) : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> def unit_name ( self ) : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> def metric_title ( self ) : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> def get_data_points_query ( self , app = None ) : <NEWLINE> <INDENT> return self . get_basic_data_points_query ( app = app ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'perc_98_server_time'", "'SELECT percentile(\"resp-time\", 98) INTO \"{}\" FROM {}'", "'percentile'", "'linear'", "'ms'", "'98th percentile server response time'"]}}], ["3073d7ecc8f5f862b56beec3a19e21af", {"code_string": "from __future__ import print_function, division\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom stats2 import get_column\n", "code_toks_joined": "from __future__ import print_function , division <NEWLINE> import matplotlib . pyplot as plt <NEWLINE> import numpy as np <NEWLINE> from stats2 import get_column <NEWLINE>", "anonymize_dict": {}}], ["73c56401fe42764df8603fbb1f3f5005", {"code_string": "def read_sas(sas_file_path, clean = False):\n    from sas7bdat import SAS7BDAT\n    data_frame = SAS7BDAT(sas_file_path).to_data_frame()\n    return data_frame\n", "code_toks_joined": "def read_sas ( sas_file_path , clean = False ) : <NEWLINE> <INDENT> from sas7bdat import SAS7BDAT <NEWLINE> data_frame = SAS7BDAT ( sas_file_path ) . to_data_frame ( ) <NEWLINE> return data_frame <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["5d43907c0d7784e204f80241ee8a8de9", {"code_string": "def init_commands():\n    \"\"\"Init and cache commands in PATH.\"\"\"\n    for path in os.environ[\"PATH\"].split(\":\"):\n        binaries = os.listdir(path)\n        kCommandList.append((path, set(binaries)))\n", "code_toks_joined": "def init_commands ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> for path in os . environ [ <STRING> ] . split ( <STRING> ) : <NEWLINE> <INDENT> binaries = os . listdir ( path ) <NEWLINE> kCommandList . append ( ( path , set ( binaries ) ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Init and cache commands in PATH.\"\"\"", "\"PATH\"", "\":\""]}}], ["18161fd68aba00c40a405a121945a6f7", {"code_string": "def find_modtime(the_file):\n    \"\"\"remove the .py or .ipynb extenstion from the file name\"\"\"\n    head, ext = os.path.splitext(the_file)\n    print('finding modtime for {}'.format(head))\n    the_date = datetime.datetime.fromtimestamp(os.stat(the_file)[stat.ST_MTIME])\n    local_tz = tzlocal.get_localzone()\n    the_date = local_tz.localize(the_date)\n    the_date = the_date.astimezone(pytz.utc)\n    head = head.split('/')[- 1]\n    return head, the_date\n", "code_toks_joined": "def find_modtime ( the_file ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> head , ext = os . path . splitext ( the_file ) <NEWLINE> print ( <STRING> . format ( head ) ) <NEWLINE> the_date = datetime . datetime . fromtimestamp ( os . stat ( the_file ) [ stat . ST_MTIME ] ) <NEWLINE> local_tz = tzlocal . get_localzone ( ) <NEWLINE> the_date = local_tz . localize ( the_date ) <NEWLINE> the_date = the_date . astimezone ( pytz . utc ) <NEWLINE> head = head . split ( <STRING> ) [ - 1 ] <NEWLINE> return head , the_date <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"remove the .py or .ipynb extenstion from the file name\"\"\"", "'finding modtime for {}'", "'/'"]}}], ["c888ebec3925a2bc09cece29be1291af", {"code_string": "import websocket\nwebsocket.enableTrace(True)\nws = websocket.create_connection(\"ws://node-0:8080/ws/wsexample\")\nmsg = \"Hello Server\"\nprint(\"SENT: %s\" % msg)\nws.send(msg)\nresult = ws.recv()\nprint(\"RESPONSE: %s\" % result)\n", "code_toks_joined": "import websocket <NEWLINE> websocket . enableTrace ( True ) <NEWLINE> ws = websocket . create_connection ( <STRING> ) <NEWLINE> msg = <STRING> <NEWLINE> print ( <STRING> % msg ) <NEWLINE> ws . send ( msg ) <NEWLINE> result = ws . recv ( ) <NEWLINE> print ( <STRING> % result ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"ws://node-0:8080/ws/wsexample\"", "\"Hello Server\"", "\"SENT: %s\"", "\"RESPONSE: %s\""]}}], ["a6f1f8a8de57ba7c5e84bc2572982e3d", {"code_string": "from django.contrib import admin\nfrom trivia.models import *\nadmin.site.register(Question)\n", "code_toks_joined": "from django . contrib import admin <NEWLINE> from trivia . models import * <NEWLINE> admin . site . register ( Question ) <NEWLINE>", "anonymize_dict": {}}], ["d83a0afcf6ed1bea209ec7d54f93e187", {"code_string": "def __init__(self, input_file, halt_on_error = False):\n    self.input_file = input_file\n    self.lines = 0\n    self.halt_on_error = halt_on_error\n", "code_toks_joined": "def __init__ ( self , input_file , halt_on_error = False ) : <NEWLINE> <INDENT> self . input_file = input_file <NEWLINE> self . lines = 0 <NEWLINE> self . halt_on_error = halt_on_error <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["4e18fd109db93ef1cfdc5fced48dae02", {"code_string": "class TaskCancelled(TaskMessage):\n    \"\"\"Indicate that a task has been cancelled.\"\"\"\n    def __unicode__(self):\n        return \"Task {0.task.id} cancelled by PID {0.sender.pid} on host: {0.sender.host}\".format(self)\n    if py2:\n        __unicode__ = __str__\n", "code_toks_joined": "class TaskCancelled ( TaskMessage ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __unicode__ ( self ) : <NEWLINE> <INDENT> return <STRING> . format ( self ) <NEWLINE> <DEDENT> if py2 : <NEWLINE> <INDENT> __unicode__ = __str__ <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Indicate that a task has been cancelled.\"\"\"", "\"Task {0.task.id} cancelled by PID {0.sender.pid} on host: {0.sender.host}\""]}}], ["2beb8956cce857d4c2ddb887ebe6994e", {"code_string": "def test_dbxref(self):\n    ref = Dbxref('/db_xref=\"GDB:39999\"')\n    assert ref.database == 'GDB'\n    assert ref.identifier == '39999'\n    ref = Dbxref(\"GDB:39999\")\n    assert ref.database == 'GDB'\n    assert ref.identifier == '39999'\n    ref = Dbxref('GDB', '39999')\n    assert ref.database == 'GDB'\n    assert ref.identifier == '39999'\n    s = repr(ref)\n    s2 = str(ref)\n", "code_toks_joined": "def test_dbxref ( self ) : <NEWLINE> <INDENT> ref = Dbxref ( <STRING> ) <NEWLINE> assert ref . database == <STRING> <NEWLINE> assert ref . identifier == <STRING> <NEWLINE> ref = Dbxref ( <STRING> ) <NEWLINE> assert ref . database == <STRING> <NEWLINE> assert ref . identifier == <STRING> <NEWLINE> ref = Dbxref ( <STRING> , <STRING> ) <NEWLINE> assert ref . database == <STRING> <NEWLINE> assert ref . identifier == <STRING> <NEWLINE> s = repr ( ref ) <NEWLINE> s2 = str ( ref ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/db_xref=\"GDB:39999\"'", "'GDB'", "'39999'", "\"GDB:39999\"", "'GDB'", "'39999'", "'GDB'", "'39999'", "'GDB'", "'39999'"]}}], ["a52cef6a34dc24e5a102e486718db21e", {"code_string": "import logging\nimport netaddr\nfrom django.core.urlresolvers import reverse\nfrom django.utils.translation import ugettext_lazy as _\nfrom horizon import exceptions\nfrom horizon import forms\nfrom horizon import messages\nfrom horizon import workflows\nfrom horizon.utils import fields\nfrom openstack_dashboard import api\nfrom openstack_dashboard.api import raksha\nfrom openstack_dashboard.api import nova\nfrom openstack_dashboard.usage import quotas\nLOG = logging.getLogger(__name__)\n", "code_toks_joined": "import logging <NEWLINE> import netaddr <NEWLINE> from django . core . urlresolvers import reverse <NEWLINE> from django . utils . translation import ugettext_lazy as _ <NEWLINE> from horizon import exceptions <NEWLINE> from horizon import forms <NEWLINE> from horizon import messages <NEWLINE> from horizon import workflows <NEWLINE> from horizon . utils import fields <NEWLINE> from openstack_dashboard import api <NEWLINE> from openstack_dashboard . api import raksha <NEWLINE> from openstack_dashboard . api import nova <NEWLINE> from openstack_dashboard . usage import quotas <NEWLINE> LOG = logging . getLogger ( __name__ ) <NEWLINE>", "anonymize_dict": {}}], ["cba2c1abacd2a07025f4ac8974a71bec", {"code_string": "from gbpservice.contrib.nfp.config_orchestrator.common import(\n    topics as a_topics)\nfrom gbpservice.contrib.nfp.config_orchestrator.handlers.config import(\n    firewall as fw)\nfrom gbpservice.contrib.nfp.config_orchestrator.handlers.config import(\n    loadbalancerv2 as lbv2)\nfrom gbpservice.contrib.nfp.config_orchestrator.handlers.config import vpn\nfrom gbpservice.contrib.nfp.config_orchestrator.handlers.notification import(\n    handler as notif_handler)\nfrom gbpservice.nfp.core.rpc import RpcAgent\nfrom oslo_config import cfg\n", "code_toks_joined": "from gbpservice . contrib . nfp . config_orchestrator . common import ( <NEWLINE> <INDENT> topics as a_topics ) <NEWLINE> <DEDENT> from gbpservice . contrib . nfp . config_orchestrator . handlers . config import ( <NEWLINE> <INDENT> firewall as fw ) <NEWLINE> <DEDENT> from gbpservice . contrib . nfp . config_orchestrator . handlers . config import ( <NEWLINE> <INDENT> loadbalancerv2 as lbv2 ) <NEWLINE> <DEDENT> from gbpservice . contrib . nfp . config_orchestrator . handlers . config import vpn <NEWLINE> from gbpservice . contrib . nfp . config_orchestrator . handlers . notification import ( <NEWLINE> <INDENT> handler as notif_handler ) <NEWLINE> <DEDENT> from gbpservice . nfp . core . rpc import RpcAgent <NEWLINE> from oslo_config import cfg <NEWLINE>", "anonymize_dict": {}}], ["afb10ecb8d3d09f1c1164687c77c33c6", {"code_string": "def test_in_filter(self):\n    pks = []\n    for i in xrange(10):\n        pks.append(RelatedModelA.objects.create(\n            data = random_string()\n        ).pk)\n    qs = RelatedModelA.objects.filter(pk__in = pks)\n    self.assertEqual(len(pks), len(qs))\n", "code_toks_joined": "def test_in_filter ( self ) : <NEWLINE> <INDENT> pks = [ ] <NEWLINE> for i in xrange ( 10 ) : <NEWLINE> <INDENT> pks . append ( RelatedModelA . objects . create ( <NEWLINE> <INDENT> data = random_string ( ) <NEWLINE> <DEDENT> ) . pk ) <NEWLINE> <DEDENT> qs = RelatedModelA . objects . filter ( pk__in = pks ) <NEWLINE> self . assertEqual ( len ( pks ) , len ( qs ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["69c267de4f58c1f10f76be05c89f02d5", {"code_string": "from __future__ import print_function\nfrom Hattrick.Web import HattrickWeb\nfrom Hattrick.Parsers import CHPPHolderParser\nimport os\nimport getpass\nimport json\ntry:\n    input = raw_input\nexcept NameError:\n    pass\n", "code_toks_joined": "from __future__ import print_function <NEWLINE> from Hattrick . Web import HattrickWeb <NEWLINE> from Hattrick . Parsers import CHPPHolderParser <NEWLINE> import os <NEWLINE> import getpass <NEWLINE> import json <NEWLINE> try : <NEWLINE> <INDENT> input = raw_input <NEWLINE> <DEDENT> except NameError : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["1824530afed93eb8f4f3fd420bc769cb", {"code_string": "def update(self):\n    '''Updates the quadtree and begins recursive process of subdividing or collision testing'''\n    if len(self.particles) > self.maxparticles and self.level <= self.maxlevel:\n        self.subdivide()\n        self.subdivide_particles()\n        for branch in self.branches:\n            branch.update()\n    else:\n        pass\n", "code_toks_joined": "def update ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if len ( self . particles ) > self . maxparticles and self . level <= self . maxlevel : <NEWLINE> <INDENT> self . subdivide ( ) <NEWLINE> self . subdivide_particles ( ) <NEWLINE> for branch in self . branches : <NEWLINE> <INDENT> branch . update ( ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Updates the quadtree and begins recursive process of subdividing or collision testing'''"]}}], ["7f4cf9691fcc6292284df7b03f1a8194", {"code_string": "def check_segment(self, segment, agent = None):\n    \"\"\"Check if segment can be bound.\"\"\"\n    network_type = segment[api.NETWORK_TYPE]\n    if network_type in self.supported_network_types:\n        if agent:\n            mappings = agent['configurations'].get('device_mappings', {})\n            LOG.debug(\"Checking segment: %(segment)s \"\n                \"for mappings: %(mappings)s \",\n                {'segment': segment, 'mappings': mappings})\n            return segment[api.PHYSICAL_NETWORK] in mappings\n        return True\n    return False\n", "code_toks_joined": "def check_segment ( self , segment , agent = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> network_type = segment [ api . NETWORK_TYPE ] <NEWLINE> if network_type in self . supported_network_types : <NEWLINE> <INDENT> if agent : <NEWLINE> <INDENT> mappings = agent [ <STRING> ] . get ( <STRING> , { } ) <NEWLINE> LOG . debug ( <STRING> <NEWLINE> <INDENT> <STRING> , <NEWLINE> { <STRING> : segment , <STRING> : mappings } ) <NEWLINE> <DEDENT> return segment [ api . PHYSICAL_NETWORK ] in mappings <NEWLINE> <DEDENT> return True <NEWLINE> <DEDENT> return False <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Check if segment can be bound.\"\"\"", "'configurations'", "'device_mappings'", "\"Checking segment: %(segment)s \"", "\"for mappings: %(mappings)s \"", "'segment'", "'mappings'"]}}], ["76b94f7afa230792db6929eac0d09920", {"code_string": "def gxx_modifier_aix(conf):\n    v = conf.env\n    v['program_LINKFLAGS'] = ['-Wl,-brtl']\n    v['shlib_LINKFLAGS'] = ['-shared', '-Wl,-brtl,-bexpfull']\n    v['SHLIB_MARKER'] = ''\n", "code_toks_joined": "def gxx_modifier_aix ( conf ) : <NEWLINE> <INDENT> v = conf . env <NEWLINE> v [ <STRING> ] = [ <STRING> ] <NEWLINE> v [ <STRING> ] = [ <STRING> , <STRING> ] <NEWLINE> v [ <STRING> ] = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'program_LINKFLAGS'", "'-Wl,-brtl'", "'shlib_LINKFLAGS'", "'-shared'", "'-Wl,-brtl,-bexpfull'", "'SHLIB_MARKER'", "''"]}}], ["b3c0b4509f75eb671d10ce58bf2cd276", {"code_string": "import errno\nimport os\nimport sys\nimport tempfile\n", "code_toks_joined": "import errno <NEWLINE> import os <NEWLINE> import sys <NEWLINE> import tempfile <NEWLINE>", "anonymize_dict": {}}], ["0b290719e9dc4fa0dec8738d059027e7", {"code_string": "def _setup_parser_for_module(subparsers, module, name):\n    doc = module.__doc__\n    doc_subject = doc.splitlines()[0]\n    doc_epilog = '\\n'.join(doc.splitlines()[1: ])\n    parser = subparsers.add_parser(\n        name,\n        formatter_class = argparse.RawDescriptionHelpFormatter,\n        help = doc_subject,\n        description = doc_subject,\n        epilog = doc_epilog)\n    module.setup_parser(parser)\n    parser.set_defaults(func = module.process_args)\n", "code_toks_joined": "def _setup_parser_for_module ( subparsers , module , name ) : <NEWLINE> <INDENT> doc = module . __doc__ <NEWLINE> doc_subject = doc . splitlines ( ) [ 0 ] <NEWLINE> doc_epilog = <STRING> . join ( doc . splitlines ( ) [ 1 : ] ) <NEWLINE> parser = subparsers . add_parser ( <NEWLINE> <INDENT> name , <NEWLINE> formatter_class = argparse . RawDescriptionHelpFormatter , <NEWLINE> help = doc_subject , <NEWLINE> description = doc_subject , <NEWLINE> epilog = doc_epilog ) <NEWLINE> <DEDENT> module . setup_parser ( parser ) <NEWLINE> parser . set_defaults ( func = module . process_args ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'\\n'"]}}], ["928e08a8a7fde00c8aaf0b3ec6b64c00", {"code_string": "def _reason_data(alarm_ids):\n    \"\"\"Create a reason data dictionary for this evaluator type.\"\"\"\n    return{'type': 'combination', 'alarm_ids': alarm_ids}\n", "code_toks_joined": "def _reason_data ( alarm_ids ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return { <STRING> : <STRING> , <STRING> : alarm_ids } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Create a reason data dictionary for this evaluator type.\"\"\"", "'type'", "'combination'", "'alarm_ids'"]}}], ["b92d01782346580c95d282edffc61aed", {"code_string": "\"\"\"The :mod:`imblearn.over_sampling` provides a set of method to\"\"\"\nfrom.random_over_sampler import RandomOverSampler\nfrom.smote import SMOTE\nfrom.adasyn import ADASYN\n__all__ = ['RandomOverSampler',\n    'SMOTE',\n    'ADASYN']\n", "code_toks_joined": "<STRING> <NEWLINE> from . random_over_sampler import RandomOverSampler <NEWLINE> from . smote import SMOTE <NEWLINE> from . adasyn import ADASYN <NEWLINE> __all__ = [ <STRING> , <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"The :mod:`imblearn.over_sampling` provides a set of method to\"\"\"", "'RandomOverSampler'", "'SMOTE'", "'ADASYN'"]}}], ["3dcbd62ece2f0c258a34fb3e508083bb", {"code_string": "def get_following_word(sent, word):\n    words = sent.split(' ')\n    for idx, w in enumerate(words):\n        if w == word:\n            return words[idx + 1]\n", "code_toks_joined": "def get_following_word ( sent , word ) : <NEWLINE> <INDENT> words = sent . split ( <STRING> ) <NEWLINE> for idx , w in enumerate ( words ) : <NEWLINE> <INDENT> if w == word : <NEWLINE> <INDENT> return words [ idx + 1 ] <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["' '"]}}], ["7bfd0c65595c03b478fc70af3efcd842", {"code_string": "class OpenIDForm(Form):\n    openid = StringField('Your OpenID', [DataRequired()])\n    submit = SubmitField('Log in with OpenID')\n", "code_toks_joined": "class OpenIDForm ( Form ) : <NEWLINE> <INDENT> openid = StringField ( <STRING> , [ DataRequired ( ) ] ) <NEWLINE> submit = SubmitField ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Your OpenID'", "'Log in with OpenID'"]}}], ["439277100ee76343eac7d21b6f84f9ff", {"code_string": "def cwtmorlet(points, width):\n    \"\"\"complex morlet wavelet function compatible with scipy.signal.cwt\"\"\"\n    omega = 5.0\n    s = points /(2.0 * omega * width)\n    return wavelets.morlet(points, omega, s, complete = True)\n", "code_toks_joined": "def cwtmorlet ( points , width ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> omega = 5.0 <NEWLINE> s = points / ( 2.0 * omega * width ) <NEWLINE> return wavelets . morlet ( points , omega , s , complete = True ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"complex morlet wavelet function compatible with scipy.signal.cwt\"\"\""]}}], ["525bbad4bce871a2424c478338f1e9e5", {"code_string": "def negbinomPdf(k, r, p):\n    return exp(gammaln(r + k) - gammaln(k + 1) - gammaln(r) +\n        r * log(p) + k * log(1 - p))\n", "code_toks_joined": "def negbinomPdf ( k , r , p ) : <NEWLINE> <INDENT> return exp ( gammaln ( r + k ) - gammaln ( k + 1 ) - gammaln ( r ) + <NEWLINE> <INDENT> r * log ( p ) + k * log ( 1 - p ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["7cbd3a635093a0da59f79d1c56f00c7f", {"code_string": "class ManualUpload(webapp2.RequestHandler):\n    def get(self):\n        self.response.headers['Content-Type'] = 'text/html'\n        self.response.headers['Cache-Control'] = 'max-age=259200'\n        def response():\n            template = templater.get_template('templates/manual_upload.html')\n            return template.render({})\n        self.response.write(\n            memcache.get('manual_upload', response))\n", "code_toks_joined": "class ManualUpload ( webapp2 . RequestHandler ) : <NEWLINE> <INDENT> def get ( self ) : <NEWLINE> <INDENT> self . response . headers [ <STRING> ] = <STRING> <NEWLINE> self . response . headers [ <STRING> ] = <STRING> <NEWLINE> def response ( ) : <NEWLINE> <INDENT> template = templater . get_template ( <STRING> ) <NEWLINE> return template . render ( { } ) <NEWLINE> <DEDENT> self . response . write ( <NEWLINE> <INDENT> memcache . get ( <STRING> , response ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Content-Type'", "'text/html'", "'Cache-Control'", "'max-age=259200'", "'templates/manual_upload.html'", "'manual_upload'"]}}], ["e3472db8b2c802e1e34ee647028e0184", {"code_string": "from django.conf import settings\nfrom django.core.mail import EmailMultiAlternatives\nfrom django.core.urlresolvers import reverse_lazy, reverse\nfrom django.contrib.messages.views import SuccessMessageMixin\nfrom django.views.generic import FormView, TemplateView\nfrom contact_us.forms import ContactForm\n", "code_toks_joined": "from django . conf import settings <NEWLINE> from django . core . mail import EmailMultiAlternatives <NEWLINE> from django . core . urlresolvers import reverse_lazy , reverse <NEWLINE> from django . contrib . messages . views import SuccessMessageMixin <NEWLINE> from django . views . generic import FormView , TemplateView <NEWLINE> from contact_us . forms import ContactForm <NEWLINE>", "anonymize_dict": {}}], ["6012efafd3a930724f598d3d05525384", {"code_string": "def getParameterList(self):\n    \"\"\"Get a 'pretty' listing of the input parameters and corresponding models.\"\"\"\n    inputList = []\n    for name, n in zip(self._names, self._inputs):\n        inputList +=['%s.x%d' %(name, i) for i in range(n)]\n    return inputList\n", "code_toks_joined": "def getParameterList ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> inputList = [ ] <NEWLINE> for name , n in zip ( self . _names , self . _inputs ) : <NEWLINE> <INDENT> inputList += [ <STRING> % ( name , i ) for i in range ( n ) ] <NEWLINE> <DEDENT> return inputList <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Get a 'pretty' listing of the input parameters and corresponding models.\"\"\"", "'%s.x%d'"]}}], ["6e561ec4e857ec293507cc6cc68efd4f", {"code_string": "def _vision_api(self):\n    \"\"\"Proxy method that handles which transport call Vision Annotate.\"\"\"\n    if self._vision_api_internal is None:\n        if self._use_gax:\n            self._vision_api_internal = _GAPICVisionAPI(self)\n        else:\n            self._vision_api_internal = _HTTPVisionAPI(self)\n    return self._vision_api_internal\n", "code_toks_joined": "def _vision_api ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if self . _vision_api_internal is None : <NEWLINE> <INDENT> if self . _use_gax : <NEWLINE> <INDENT> self . _vision_api_internal = _GAPICVisionAPI ( self ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . _vision_api_internal = _HTTPVisionAPI ( self ) <NEWLINE> <DEDENT> <DEDENT> return self . _vision_api_internal <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Proxy method that handles which transport call Vision Annotate.\"\"\""]}}], ["764b54e5965b7079ea41b360ea671082", {"code_string": "class CLI(harambe.cli.CLI):\n    def __init__(self, command, click):\n        \"\"\"Initiate the command line\"\"\"\n        @ command()\n        def setup():\n            \"\"\" The setup \"\"\"\n            click.echo(\"This is a setup!\")\n", "code_toks_joined": "class CLI ( harambe . cli . CLI ) : <NEWLINE> <INDENT> def __init__ ( self , command , click ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> @ command ( ) <NEWLINE> def setup ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> click . echo ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Initiate the command line\"\"\"", "\"\"\" The setup \"\"\"", "\"This is a setup!\""]}}], ["130e1980afc7225d67979ce33cd05016", {"code_string": "\"\"\"cis_dev_portal URL Configuration\"\"\"\nfrom django.conf.urls import url, include\nfrom django.contrib import admin\nfrom django.contrib.staticfiles.urls import staticfiles_urlpatterns\nurlpatterns = [\n    url(r'^admin/', admin.site.urls),\n    url(r'^shib/', include('shibboleth.urls', namespace = 'shibboleth')),\n    url(r'^dashboard/', include('dashboard.urls', namespace = \"dashboard\")),\n    url('', include('dashboard.urls')),\n]\nurlpatterns += staticfiles_urlpatterns()\n", "code_toks_joined": "<STRING> <NEWLINE> from django . conf . urls import url , include <NEWLINE> from django . contrib import admin <NEWLINE> from django . contrib . staticfiles . urls import staticfiles_urlpatterns <NEWLINE> urlpatterns = [ <NEWLINE> <INDENT> url ( <STRING> , admin . site . urls ) , <NEWLINE> url ( <STRING> , include ( <STRING> , namespace = <STRING> ) ) , <NEWLINE> url ( <STRING> , include ( <STRING> , namespace = <STRING> ) ) , <NEWLINE> url ( <STRING> , include ( <STRING> ) ) , <NEWLINE> <DEDENT> ] <NEWLINE> urlpatterns += staticfiles_urlpatterns ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"cis_dev_portal URL Configuration\"\"\"", "r'^admin/'", "r'^shib/'", "'shibboleth.urls'", "'shibboleth'", "r'^dashboard/'", "'dashboard.urls'", "\"dashboard\"", "''", "'dashboard.urls'"]}}], ["a091c0afd0e7d750e3a6115aa62493e7", {"code_string": "def upgrade():\n    op.add_column('bay', sa.Column('bay_create_timeout',\n        sa.Integer(), nullable = True))\n", "code_toks_joined": "def upgrade ( ) : <NEWLINE> <INDENT> op . add_column ( <STRING> , sa . Column ( <STRING> , <NEWLINE> <INDENT> sa . Integer ( ) , nullable = True ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'bay'", "'bay_create_timeout'"]}}], ["ad62190b4169684051d09b06f0bfdb19", {"code_string": "def update(self, current_position = - 1, delta_position = - 1):\n    self.time_last = self.time_current\n    self.time_current = datetime.datetime.now()\n    if current_position > - 1:\n        self.current_position = current_position\n    elif delta_position > - 1:\n        self.current_position += delta_position\n    self.display()\n", "code_toks_joined": "def update ( self , current_position = - 1 , delta_position = - 1 ) : <NEWLINE> <INDENT> self . time_last = self . time_current <NEWLINE> self . time_current = datetime . datetime . now ( ) <NEWLINE> if current_position > - 1 : <NEWLINE> <INDENT> self . current_position = current_position <NEWLINE> <DEDENT> elif delta_position > - 1 : <NEWLINE> <INDENT> self . current_position += delta_position <NEWLINE> <DEDENT> self . display ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["b33b10061eae10ff393be32b70f55ebf", {"code_string": "from __future__ import absolute_import\nimport numpy as np\nfrom..polyaffine import PolyAffine\nfrom..affine import Affine\n", "code_toks_joined": "from __future__ import absolute_import <NEWLINE> import numpy as np <NEWLINE> from . . polyaffine import PolyAffine <NEWLINE> from . . affine import Affine <NEWLINE>", "anonymize_dict": {}}], ["115e709cd9daba68864b5e969970a9d5", {"code_string": "def FibonacciGenerator(N):\n    if N == 0:\n        return 0\n    if N == 1:\n        return 1\n    if N not in fib_memo:\n        fib_memo[N] = FibonacciGenerator(N - 1) + FibonacciGenerator(N - 2)\n    return fib_memo[N]\n", "code_toks_joined": "def FibonacciGenerator ( N ) : <NEWLINE> <INDENT> if N == 0 : <NEWLINE> <INDENT> return 0 <NEWLINE> <DEDENT> if N == 1 : <NEWLINE> <INDENT> return 1 <NEWLINE> <DEDENT> if N not in fib_memo : <NEWLINE> <INDENT> fib_memo [ N ] = FibonacciGenerator ( N - 1 ) + FibonacciGenerator ( N - 2 ) <NEWLINE> <DEDENT> return fib_memo [ N ] <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["5b5c9f917915826c520aee9989d976cd", {"code_string": "from setuptools import setup\nrequires = [\n    'numpy',\n    ]\nsetup(name = 'qubit_dst',\n    version = '0.0',\n    py_modules = ['dst_povm_sampling'],\n    install_requires = requires,\n    setup_requires = ['numpy'],\n    packages = ['qubit_dst'],\n    package_dir = {'qubit_dst': 'src/qubit_dst'},\n    )\n", "code_toks_joined": "from setuptools import setup <NEWLINE> requires = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> ] <NEWLINE> <DEDENT> setup ( name = <STRING> , <NEWLINE> <INDENT> version = <STRING> , <NEWLINE> py_modules = [ <STRING> ] , <NEWLINE> install_requires = requires , <NEWLINE> setup_requires = [ <STRING> ] , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> package_dir = { <STRING> : <STRING> } , <NEWLINE> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'numpy'", "'qubit_dst'", "'0.0'", "'dst_povm_sampling'", "'numpy'", "'qubit_dst'", "'qubit_dst'", "'src/qubit_dst'"]}}], ["476d72cd5eff42170eebac92c289f571", {"code_string": "def _main(argv = []):\n    local_port = 0xDCAC\n    if len(argv) >= 2:\n        local_port = int(argv[1])\n    sock = socket(AF_INET, SOCK_DGRAM)\n    sock.bind((\"localhost\", local_port))\n    while True:\n        data = sock.recv(4096)\n        print(\"Received:\")\n        print(data)\n", "code_toks_joined": "def _main ( argv = [ ] ) : <NEWLINE> <INDENT> local_port = 0xDCAC <NEWLINE> if len ( argv ) >= 2 : <NEWLINE> <INDENT> local_port = int ( argv [ 1 ] ) <NEWLINE> <DEDENT> sock = socket ( AF_INET , SOCK_DGRAM ) <NEWLINE> sock . bind ( ( <STRING> , local_port ) ) <NEWLINE> while True : <NEWLINE> <INDENT> data = sock . recv ( 4096 ) <NEWLINE> print ( <STRING> ) <NEWLINE> print ( data ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"localhost\"", "\"Received:\""]}}], ["489c4438f7ea9f366805f8342cf4aadf", {"code_string": "from zato.server.service import Service\nimport os, urllib2\nfrom time import sleep\nimport socket\nos.environ[\"PYOKO_SETTINGS\"] = 'ulakbus.settings'\nfrom ulakbus.models.hitap import AskerlikKayitlari\nH_USER = os.environ[\"HITAP_USER\"]\nH_PASS = os.environ[\"HITAP_PASS\"]\n", "code_toks_joined": "from zato . server . service import Service <NEWLINE> import os , urllib2 <NEWLINE> from time import sleep <NEWLINE> import socket <NEWLINE> os . environ [ <STRING> ] = <STRING> <NEWLINE> from ulakbus . models . hitap import AskerlikKayitlari <NEWLINE> H_USER = os . environ [ <STRING> ] <NEWLINE> H_PASS = os . environ [ <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"PYOKO_SETTINGS\"", "'ulakbus.settings'", "\"HITAP_USER\"", "\"HITAP_PASS\""]}}], ["73fb3e21a2ef92b710abcc89d2626492", {"code_string": "\"\"\"zchat URL Configuration\"\"\"\nfrom django.conf.urls import url, include\nfrom django.contrib import admin\nfrom rest_framework_jwt.views import verify_jwt_token, refresh_jwt_token, obtain_jwt_token\nfrom zmessages import urls as zm_urls\nurlpatterns = [\n    url(r'^api/', include(zm_urls)),\n    url(r'^admin/', admin.site.urls),\n    url(r'^api-token-auth/', obtain_jwt_token),\n    url(r'^api-token-refresh/', refresh_jwt_token),\n    url(r'^api-token-verify/', verify_jwt_token),\n    url(r'^api-auth/', include('rest_framework.urls', namespace = 'rest_framework'))\n]\n", "code_toks_joined": "<STRING> <NEWLINE> from django . conf . urls import url , include <NEWLINE> from django . contrib import admin <NEWLINE> from rest_framework_jwt . views import verify_jwt_token , refresh_jwt_token , obtain_jwt_token <NEWLINE> from zmessages import urls as zm_urls <NEWLINE> urlpatterns = [ <NEWLINE> <INDENT> url ( <STRING> , include ( zm_urls ) ) , <NEWLINE> url ( <STRING> , admin . site . urls ) , <NEWLINE> url ( <STRING> , obtain_jwt_token ) , <NEWLINE> url ( <STRING> , refresh_jwt_token ) , <NEWLINE> url ( <STRING> , verify_jwt_token ) , <NEWLINE> url ( <STRING> , include ( <STRING> , namespace = <STRING> ) ) <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"zchat URL Configuration\"\"\"", "r'^api/'", "r'^admin/'", "r'^api-token-auth/'", "r'^api-token-refresh/'", "r'^api-token-verify/'", "r'^api-auth/'", "'rest_framework.urls'", "'rest_framework'"]}}], ["12485918b2d45fe78d18b35036dddcb0", {"code_string": "def langinfo_from_doctype(self, public_id = None, system_id = None):\n    \"\"\"Return a LangInfo instance matching any of the specified\"\"\"\n    if self._li_from_doctype_public_id is None:\n        self._build_tables()\n    if public_id is not None and public_id in self._li_from_doctype_public_id:\n        return self._li_from_doctype_public_id[public_id]\n    if system_id is not None and system_id in self._li_from_doctype_system_id:\n        return self._li_from_doctype_system_id[system_id]\n", "code_toks_joined": "def langinfo_from_doctype ( self , public_id = None , system_id = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if self . _li_from_doctype_public_id is None : <NEWLINE> <INDENT> self . _build_tables ( ) <NEWLINE> <DEDENT> if public_id is not None and public_id in self . _li_from_doctype_public_id : <NEWLINE> <INDENT> return self . _li_from_doctype_public_id [ public_id ] <NEWLINE> <DEDENT> if system_id is not None and system_id in self . _li_from_doctype_system_id : <NEWLINE> <INDENT> return self . _li_from_doctype_system_id [ system_id ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Return a LangInfo instance matching any of the specified\"\"\""]}}], ["3f26ce43e60c59cb2e9b8cfb549cbf79", {"code_string": "from __future__ import unicode_literals\nfrom netmiko.avaya.avaya_vsp_ssh import AvayaVspSSH\nfrom netmiko.avaya.avaya_ers_ssh import AvayaErsSSH\n__all__ = ['AvayaVspSSH', 'AvayaErsSSH']\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> from netmiko . avaya . avaya_vsp_ssh import AvayaVspSSH <NEWLINE> from netmiko . avaya . avaya_ers_ssh import AvayaErsSSH <NEWLINE> __all__ = [ <STRING> , <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'AvayaVspSSH'", "'AvayaErsSSH'"]}}], ["854d6df8566acde15d51e0e1ee4189f3", {"code_string": "import os\nfrom tempfile import mkstemp\nfrom circuits.web import Controller\nfrom.helpers import urlopen\n", "code_toks_joined": "import os <NEWLINE> from tempfile import mkstemp <NEWLINE> from circuits . web import Controller <NEWLINE> from . helpers import urlopen <NEWLINE>", "anonymize_dict": {}}], ["d73a1847976e490f34e61d04d6d18bb2", {"code_string": "def flatten_list(x):\n    \"\"\"Flatten nested lists\"\"\"\n    if type(x) is not list:\n        return x\n    x_len = len(x)\n    i = 0\n    while i < x_len:\n        if type(x[i]) is list:\n            x_len += len(x[i]) - 1\n            x[i: i + 1] = x[i]\n        else:\n            i += 1\n    return x\n", "code_toks_joined": "def flatten_list ( x ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if type ( x ) is not list : <NEWLINE> <INDENT> return x <NEWLINE> <DEDENT> x_len = len ( x ) <NEWLINE> i = 0 <NEWLINE> while i < x_len : <NEWLINE> <INDENT> if type ( x [ i ] ) is list : <NEWLINE> <INDENT> x_len += len ( x [ i ] ) - 1 <NEWLINE> x [ i : i + 1 ] = x [ i ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> i += 1 <NEWLINE> <DEDENT> <DEDENT> return x <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Flatten nested lists\"\"\""]}}], ["1a9565b5aeab06ca1309c7e8b81a7678", {"code_string": "class Router_5_3_10(HarnessCase):\n    role = HarnessCase.ROLE_ROUTER\n    case = '5 3 10'\n    golden_devices_required = 4\n    def on_dialog(self, dialog, title):\n        pass\n", "code_toks_joined": "class Router_5_3_10 ( HarnessCase ) : <NEWLINE> <INDENT> role = HarnessCase . ROLE_ROUTER <NEWLINE> case = <STRING> <NEWLINE> golden_devices_required = 4 <NEWLINE> def on_dialog ( self , dialog , title ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'5 3 10'"]}}], ["82fe76250d798b80007a8010b52c5d7f", {"code_string": "from distutils.core import setup\nimport dicts\nsetup(name = 'dicts',\n    version = dicts.__version__,\n    description = 'Easy use dictionaries with specific features',\n    long_description = open('README.rst').read(),\n    author = dicts.__author__,\n    author_email = dicts.__email__,\n    url = 'https://github.com/moliware/dicts',\n    packages = ['dicts'],\n    license = 'LGPL',\n    classifiers = ('Development Status :: 5 - Production/Stable',\n        'License :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)',\n        'Natural Language :: English',\n        'Programming Language :: Python :: 2.5',\n        'Programming Language :: Python :: 2.6',\n        'Programming Language :: Python :: 2.7',\n    ),\n)\n", "code_toks_joined": "from distutils . core import setup <NEWLINE> import dicts <NEWLINE> setup ( name = <STRING> , <NEWLINE> <INDENT> version = dicts . __version__ , <NEWLINE> description = <STRING> , <NEWLINE> long_description = open ( <STRING> ) . read ( ) , <NEWLINE> author = dicts . __author__ , <NEWLINE> author_email = dicts . __email__ , <NEWLINE> url = <STRING> , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> license = <STRING> , <NEWLINE> classifiers = ( <STRING> , <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'dicts'", "'Easy use dictionaries with specific features'", "'README.rst'", "'https://github.com/moliware/dicts'", "'dicts'", "'LGPL'", "'Development Status :: 5 - Production/Stable'", "'License :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)'", "'Natural Language :: English'", "'Programming Language :: Python :: 2.5'", "'Programming Language :: Python :: 2.6'", "'Programming Language :: Python :: 2.7'"]}}], ["0164449f1f935ee5c890c8a710cae4fe", {"code_string": "def __init__(self):\n    target = messaging.Target(topic = 'central', version = '2.0', server = 'server1')\n    self.central_dbapi = dbapi.DBAPI()\n    super(CentralRPCAPI, self).__init__('central', target)\n", "code_toks_joined": "def __init__ ( self ) : <NEWLINE> <INDENT> target = messaging . Target ( topic = <STRING> , version = <STRING> , server = <STRING> ) <NEWLINE> self . central_dbapi = dbapi . DBAPI ( ) <NEWLINE> super ( CentralRPCAPI , self ) . __init__ ( <STRING> , target ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'central'", "'2.0'", "'server1'", "'central'"]}}], ["71b90c37de8f2cce127a15d8d6159d1e", {"code_string": "from mock import patch\nfrom pyramid import testing\nfrom parks.models import User\nfrom parks.tests.test_base import IntegrationTestBase\nfrom parks.views.profile import profile_user\n", "code_toks_joined": "from mock import patch <NEWLINE> from pyramid import testing <NEWLINE> from parks . models import User <NEWLINE> from parks . tests . test_base import IntegrationTestBase <NEWLINE> from parks . views . profile import profile_user <NEWLINE>", "anonymize_dict": {}}], ["dac01a0261edac1bc953433e4c3e9f0b", {"code_string": "from setuptools import setup\ndescription = 'Collection of fun git commands'\nlong_desc = open('README.rst').read()\nsetup(\n    name = 'gitutils',\n    version = '0.1.2',\n    install_requires = [],\n    description = description,\n    long_description = long_desc,\n    author = 'Honza Pokorny',\n    maintainer = 'Honza Pokorny',\n    maintainer_email = 'me@honza.ca',\n    packages = ['gitutils'],\n    include_package_data = True,\n    scripts = ['bin/blamer', 'bin/chart'],\n)\n", "code_toks_joined": "from setuptools import setup <NEWLINE> description = <STRING> <NEWLINE> long_desc = open ( <STRING> ) . read ( ) <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> install_requires = [ ] , <NEWLINE> description = description , <NEWLINE> long_description = long_desc , <NEWLINE> author = <STRING> , <NEWLINE> maintainer = <STRING> , <NEWLINE> maintainer_email = <STRING> , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> include_package_data = True , <NEWLINE> scripts = [ <STRING> , <STRING> ] , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'Collection of fun git commands'", "'README.rst'", "'gitutils'", "'0.1.2'", "'Honza Pokorny'", "'Honza Pokorny'", "'me@honza.ca'", "'gitutils'", "'bin/blamer'", "'bin/chart'"]}}], ["be84defe58d984a1bdfb6e773920345f", {"code_string": "class CmdCamera:\n    def __init__(self, connection):\n        self.conn = connection\n    def setNormal(self, * args):\n        \"\"\"Set camera mode to normal Minecraft view ([entityId])\"\"\"\n        self.conn.send(\"camera.mode.setNormal\", args)\n    def setFixed(self):\n        \"\"\"Set camera mode to fixed view\"\"\"\n        self.conn.send(\"camera.mode.setFixed\")\n    def setFollow(self, * args):\n        \"\"\"Set camera mode to follow an entity ([entityId])\"\"\"\n        self.conn.send(\"camera.mode.setFollow\", args)\n    def setPos(self, * args):\n        \"\"\"Set camera entity position (x,y,z)\"\"\"\n        self.conn.send(\"camera.setPos\", args)\n", "code_toks_joined": "class CmdCamera : <NEWLINE> <INDENT> def __init__ ( self , connection ) : <NEWLINE> <INDENT> self . conn = connection <NEWLINE> <DEDENT> def setNormal ( self , * args ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . conn . send ( <STRING> , args ) <NEWLINE> <DEDENT> def setFixed ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . conn . send ( <STRING> ) <NEWLINE> <DEDENT> def setFollow ( self , * args ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . conn . send ( <STRING> , args ) <NEWLINE> <DEDENT> def setPos ( self , * args ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . conn . send ( <STRING> , args ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Set camera mode to normal Minecraft view ([entityId])\"\"\"", "\"camera.mode.setNormal\"", "\"\"\"Set camera mode to fixed view\"\"\"", "\"camera.mode.setFixed\"", "\"\"\"Set camera mode to follow an entity ([entityId])\"\"\"", "\"camera.mode.setFollow\"", "\"\"\"Set camera entity position (x,y,z)\"\"\"", "\"camera.setPos\""]}}], ["b7b8a1bbf31936583942bce6d8e903e7", {"code_string": "def test_get_link_provider_not_found(self):\n    link = get_link('barbaz', 'Baz', PROVIDERS)\n    self.assertTrue(link is None)\n", "code_toks_joined": "def test_get_link_provider_not_found ( self ) : <NEWLINE> <INDENT> link = get_link ( <STRING> , <STRING> , PROVIDERS ) <NEWLINE> self . assertTrue ( link is None ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'barbaz'", "'Baz'"]}}], ["8ed6399fac9bd4948cbb572c7a5c321f", {"code_string": "def folderitems(self):\n    items = BikaListingView.folderitems(self)\n    for x in range(len(items)):\n        if not items[x].has_key('obj'): continue\n        obj = items[x]['obj']\n        items[x]['replace']['Title'] = \"<a href='%s'>%s</a>\" %(items[x]['url'], items[x]['Title'])\n    return items\n", "code_toks_joined": "def folderitems ( self ) : <NEWLINE> <INDENT> items = BikaListingView . folderitems ( self ) <NEWLINE> for x in range ( len ( items ) ) : <NEWLINE> <INDENT> if not items [ x ] . has_key ( <STRING> ) : continue <NEWLINE> obj = items [ x ] [ <STRING> ] <NEWLINE> items [ x ] [ <STRING> ] [ <STRING> ] = <STRING> % ( items [ x ] [ <STRING> ] , items [ x ] [ <STRING> ] ) <NEWLINE> <DEDENT> return items <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'obj'", "'obj'", "'replace'", "'Title'", "\"<a href='%s'>%s</a>\"", "'url'", "'Title'"]}}], ["04b41cd7b1b8d1859bc84c4e27da045e", {"code_string": "def test_with_ndarray():\n    \"\"\"Test with 1d numpy arrays as args.\"\"\"\n    rmg = RasterModelGrid(4, 5)\n    coords = (np.array([0.1, .2]), np.array([3.4, 2.6]))\n    id = rfuncs.find_nearest_node(rmg, coords)\n    assert_array_equal(id, np.array([15, 15], dtype = int))\n    assert_is_instance(id, np.ndarray)\n", "code_toks_joined": "def test_with_ndarray ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> rmg = RasterModelGrid ( 4 , 5 ) <NEWLINE> coords = ( np . array ( [ 0.1 , .2 ] ) , np . array ( [ 3.4 , 2.6 ] ) ) <NEWLINE> id = rfuncs . find_nearest_node ( rmg , coords ) <NEWLINE> assert_array_equal ( id , np . array ( [ 15 , 15 ] , dtype = int ) ) <NEWLINE> assert_is_instance ( id , np . ndarray ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test with 1d numpy arrays as args.\"\"\""]}}], ["d2a47ff3ebf1cecd6b739ab4e3ed4670", {"code_string": "import config\nAPPNAME = 'pyipmsg'\nVERSION = '0.0.1.0'\nAPPDESC = 'ipmsg alternative for gnome'\nAUTHOR = 'Shaung'\nEMAIL = 'shaun.geng@gmail.com'\nURL = 'http://github.com/shaung/pyipmsg'\nLICENSE = 'GPLv3'\nLICENSE_DESC = \"\"\"This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License version 3, as published by the Free Software Foundation.\"\"\"\nimport os.path\nINSTALL_ROOT_DIR = '/usr/share/pyipmsg/'\nCONF_PATH = os.path.expanduser('~/.pyipmsg/ipmsg.conf')\nWEB_SHARE_DIR = '/tmp/pyipmsg/webshare/'\nDEBUG_LOG = os.path.expanduser('~/.pyipmsg/debug.log')\n", "code_toks_joined": "import config <NEWLINE> APPNAME = <STRING> <NEWLINE> VERSION = <STRING> <NEWLINE> APPDESC = <STRING> <NEWLINE> AUTHOR = <STRING> <NEWLINE> EMAIL = <STRING> <NEWLINE> URL = <STRING> <NEWLINE> LICENSE = <STRING> <NEWLINE> LICENSE_DESC = <STRING> <NEWLINE> import os . path <NEWLINE> INSTALL_ROOT_DIR = <STRING> <NEWLINE> CONF_PATH = os . path . expanduser ( <STRING> ) <NEWLINE> WEB_SHARE_DIR = <STRING> <NEWLINE> DEBUG_LOG = os . path . expanduser ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'pyipmsg'", "'0.0.1.0'", "'ipmsg alternative for gnome'", "'Shaung'", "'shaun.geng@gmail.com'", "'http://github.com/shaung/pyipmsg'", "'GPLv3'", "\"\"\"This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License version 3, as published by the Free Software Foundation.\"\"\"", "'/usr/share/pyipmsg/'", "'~/.pyipmsg/ipmsg.conf'", "'/tmp/pyipmsg/webshare/'", "'~/.pyipmsg/debug.log'"]}}], ["687c42c35e7b0b96440f5dc97398ca5d", {"code_string": "class ProductCategory(osv.osv):\n    _inherit = 'product.category'\n    _columns = {\n        'attribute_ids': fields.many2many('product.attribute',\n            id1 = 'category_att_id', id2 = 'attr_id',\n            string = 'Attributes'),\n    }\n", "code_toks_joined": "class ProductCategory ( osv . osv ) : <NEWLINE> <INDENT> _inherit = <STRING> <NEWLINE> _columns = { <NEWLINE> <INDENT> <STRING> : fields . many2many ( <STRING> , <NEWLINE> <INDENT> id1 = <STRING> , id2 = <STRING> , <NEWLINE> string = <STRING> ) , <NEWLINE> <DEDENT> <DEDENT> } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'product.category'", "'attribute_ids'", "'product.attribute'", "'category_att_id'", "'attr_id'", "'Attributes'"]}}], ["ffbf08f6bb3c256ee8394342148f143e", {"code_string": "def shortest_vector(self, delta):\n    \"\"\"Compute the relative vector under periodic boundary conditions.\"\"\"\n    fractional = self.to_fractional(delta)\n    fractional = np.floor(fractional + 0.5)\n    return delta - self.to_cartesian(fractional)\n", "code_toks_joined": "def shortest_vector ( self , delta ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> fractional = self . to_fractional ( delta ) <NEWLINE> fractional = np . floor ( fractional + 0.5 ) <NEWLINE> return delta - self . to_cartesian ( fractional ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Compute the relative vector under periodic boundary conditions.\"\"\""]}}], ["f5013bd586a4192f892db0d286b04783", {"code_string": "def __init__(self):\n    self.commentid = None\n    self.parentid = None\n    self.posted = None\n    self.replies = None\n    self.hidden = None\n    self.body = None\n    self.user = None\n", "code_toks_joined": "def __init__ ( self ) : <NEWLINE> <INDENT> self . commentid = None <NEWLINE> self . parentid = None <NEWLINE> self . posted = None <NEWLINE> self . replies = None <NEWLINE> self . hidden = None <NEWLINE> self . body = None <NEWLINE> self . user = None <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["73f3bad00c498f20af77f11807536125", {"code_string": "def test_parenthesis():\n    s = \"(a + \\n     b)\"\n    tokens = pythonlex(s)\n    assert[t.name for t in tokens] ==[\"Operator\", \"Name\", \"Operator\", \"Name\",\n        \"Operator\"]\n", "code_toks_joined": "def test_parenthesis ( ) : <NEWLINE> <INDENT> s = <STRING> <NEWLINE> tokens = pythonlex ( s ) <NEWLINE> assert [ t . name for t in tokens ] == [ <STRING> , <STRING> , <STRING> , <STRING> , <NEWLINE> <INDENT> <STRING> ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"(a + \\n     b)\"", "\"Operator\"", "\"Name\"", "\"Operator\"", "\"Name\"", "\"Operator\""]}}], ["71047d77496295b02ebad0dd6bee6ec7", {"code_string": "def build_settings(self, settings):\n    settings.add_json_panel('MetaMan', self.config, data = metaman_settings_base_json)\n    settings.add_json_panel('Audio', self.config, data = metaman_settings_audio_json)\n    settings.add_json_panel('Video', self.config, data = metaman_settings_video_json)\n    settings.add_json_panel('Library', self.config, data = metaman_settings_library_json)\n    settings.add_json_panel('Playback', self.config, data = metaman_settings_playback_json)\n", "code_toks_joined": "def build_settings ( self , settings ) : <NEWLINE> <INDENT> settings . add_json_panel ( <STRING> , self . config , data = metaman_settings_base_json ) <NEWLINE> settings . add_json_panel ( <STRING> , self . config , data = metaman_settings_audio_json ) <NEWLINE> settings . add_json_panel ( <STRING> , self . config , data = metaman_settings_video_json ) <NEWLINE> settings . add_json_panel ( <STRING> , self . config , data = metaman_settings_library_json ) <NEWLINE> settings . add_json_panel ( <STRING> , self . config , data = metaman_settings_playback_json ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'MetaMan'", "'Audio'", "'Video'", "'Library'", "'Playback'"]}}], ["a20bddc3a5cec4907a2733981082e911", {"code_string": "def manage(self):\n    \"\"\"Handle the current hook by doing The Right Thing with the registered services.\"\"\"\n    hookenv._run_atstart()\n    try:\n        hook_name = hookenv.hook_name()\n        if hook_name == 'stop':\n            self.stop_services()\n        else:\n            self.reconfigure_services()\n            self.provide_data()\n    except SystemExit as x:\n        if x.code is None or x.code == 0:\n            hookenv._run_atexit()\n    hookenv._run_atexit()\n", "code_toks_joined": "def manage ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> hookenv . _run_atstart ( ) <NEWLINE> try : <NEWLINE> <INDENT> hook_name = hookenv . hook_name ( ) <NEWLINE> if hook_name == <STRING> : <NEWLINE> <INDENT> self . stop_services ( ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . reconfigure_services ( ) <NEWLINE> self . provide_data ( ) <NEWLINE> <DEDENT> <DEDENT> except SystemExit as x : <NEWLINE> <INDENT> if x . code is None or x . code == 0 : <NEWLINE> <INDENT> hookenv . _run_atexit ( ) <NEWLINE> <DEDENT> <DEDENT> hookenv . _run_atexit ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Handle the current hook by doing The Right Thing with the registered services.\"\"\"", "'stop'"]}}], ["593a04fca21bcf4eeb0a675411d2e354", {"code_string": "def main():\n    setup(console = [{'script': 'client.py', 'icon_resources': [(1, 'yellowsub.ico')]}],\n        data_files = [('', ['projects/__init__.py', 'projects/p80search.py', 'projects/sp1deep.py'])],\n        options = {'py2exe': {'bundle_files': 1, 'includes': ['poster'], 'dll_excludes': ['w9xpopen.exe'], }},\n        zipfile = None,\n        optimize = 2,\n        icon_resources = [(1, 'yellowsub.ico')],\n        )\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> setup ( console = [ { <STRING> : <STRING> , <STRING> : [ ( 1 , <STRING> ) ] } ] , <NEWLINE> <INDENT> data_files = [ ( <STRING> , [ <STRING> , <STRING> , <STRING> ] ) ] , <NEWLINE> options = { <STRING> : { <STRING> : 1 , <STRING> : [ <STRING> ] , <STRING> : [ <STRING> ] , } } , <NEWLINE> zipfile = None , <NEWLINE> optimize = 2 , <NEWLINE> icon_resources = [ ( 1 , <STRING> ) ] , <NEWLINE> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'script'", "'client.py'", "'icon_resources'", "'yellowsub.ico'", "''", "'projects/__init__.py'", "'projects/p80search.py'", "'projects/sp1deep.py'", "'py2exe'", "'bundle_files'", "'includes'", "'poster'", "'dll_excludes'", "'w9xpopen.exe'", "'yellowsub.ico'"]}}], ["500c757fbfb3820b5e4bfa92fd2ebe58", {"code_string": "from xml.etree import ElementTree as ET\nimport os\nMETADATA_ROOT_DIRECTORY = \"md\"\nMODSXMLNS = \"{http://www.loc.gov/mods/v3}\"\n", "code_toks_joined": "from xml . etree import ElementTree as ET <NEWLINE> import os <NEWLINE> METADATA_ROOT_DIRECTORY = <STRING> <NEWLINE> MODSXMLNS = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"md\"", "\"{http://www.loc.gov/mods/v3}\""]}}], ["ba888e52c18fa18269c8e340724465a1", {"code_string": "class Exit(Exception):\n    \"\"\"Simple stand-in for SystemExit that lets us gracefully exit.\"\"\"\n    def __init__(self, code = 0):\n        self.code = code\n", "code_toks_joined": "class Exit ( Exception ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , code = 0 ) : <NEWLINE> <INDENT> self . code = code <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Simple stand-in for SystemExit that lets us gracefully exit.\"\"\""]}}], ["4c7c5b9351aa41bc357f5b28b7f284c0", {"code_string": "def addNewAsciiKey(self, userId, asciiData):\n    keyData = openpgpfile.parseAsciiArmorKey(asciiData)\n    if not keyData:\n        raise openpgpfile.IncompatibleKey('Unable to parse ASCII armored key')\n    self.addNewKey(userId, keyData)\n", "code_toks_joined": "def addNewAsciiKey ( self , userId , asciiData ) : <NEWLINE> <INDENT> keyData = openpgpfile . parseAsciiArmorKey ( asciiData ) <NEWLINE> if not keyData : <NEWLINE> <INDENT> raise openpgpfile . IncompatibleKey ( <STRING> ) <NEWLINE> <DEDENT> self . addNewKey ( userId , keyData ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Unable to parse ASCII armored key'"]}}], ["b2f0121ab1cb0fb551173f0ca2564cc6", {"code_string": "class GoogleMap(Widget):\n    templates = Dependency('jinja')\n    def __init__(self, size):\n        self.size = size\n    def __call__(self, context, center = (0, 0), markers = None):\n        template = self.templates.get('recollectives.widgets.google_map:widget.html')\n        return template.render({\n            'id': 'dx-widget-gmap',\n            'markers': markers or[],\n            'center': center\n        })\n", "code_toks_joined": "class GoogleMap ( Widget ) : <NEWLINE> <INDENT> templates = Dependency ( <STRING> ) <NEWLINE> def __init__ ( self , size ) : <NEWLINE> <INDENT> self . size = size <NEWLINE> <DEDENT> def __call__ ( self , context , center = ( 0 , 0 ) , markers = None ) : <NEWLINE> <INDENT> template = self . templates . get ( <STRING> ) <NEWLINE> return template . render ( { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : markers or [ ] , <NEWLINE> <STRING> : center <NEWLINE> <DEDENT> } ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'jinja'", "'recollectives.widgets.google_map:widget.html'", "'id'", "'dx-widget-gmap'", "'markers'", "'center'"]}}], ["8add4ccc1412d9b79447e31ef6a1f10a", {"code_string": "import shutil\nfrom django.contrib.admin.models import User\nfrom projects.models import Project\nfrom rtd_tests.utils import make_test_git\nfrom rtd_tests.base import RTDTestCase\n", "code_toks_joined": "import shutil <NEWLINE> from django . contrib . admin . models import User <NEWLINE> from projects . models import Project <NEWLINE> from rtd_tests . utils import make_test_git <NEWLINE> from rtd_tests . base import RTDTestCase <NEWLINE>", "anonymize_dict": {}}], ["b21060880479ab2ef9d3ee2fbaa5ce29", {"code_string": "def downgrade(migrate_engine):\n    meta = MetaData()\n    meta.bind = migrate_engine\n    nodes = Table('node', meta, autoload = True)\n    weight = Column('weight', Integer, nullable = False, default = 100,\n        server_default = '100')\n    nodes.drop_column(weight)\n", "code_toks_joined": "def downgrade ( migrate_engine ) : <NEWLINE> <INDENT> meta = MetaData ( ) <NEWLINE> meta . bind = migrate_engine <NEWLINE> nodes = Table ( <STRING> , meta , autoload = True ) <NEWLINE> weight = Column ( <STRING> , Integer , nullable = False , default = 100 , <NEWLINE> <INDENT> server_default = <STRING> ) <NEWLINE> <DEDENT> nodes . drop_column ( weight ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'node'", "'weight'", "'100'"]}}], ["8eb285e07fddf33e32e02f9b64960d32", {"code_string": "import numpy\nfrom numpy.testing import assert_allclose\nfrom keras.layers import Dense, Embedding, Input\nfrom keras.models import Model, load_model\nfrom deep_qa.layers.attention import MatrixAttention\nfrom deep_qa.layers.wrappers import OutputMask\nfrom deep_qa.testing.test_case import DeepQaTestCase\n", "code_toks_joined": "import numpy <NEWLINE> from numpy . testing import assert_allclose <NEWLINE> from keras . layers import Dense , Embedding , Input <NEWLINE> from keras . models import Model , load_model <NEWLINE> from deep_qa . layers . attention import MatrixAttention <NEWLINE> from deep_qa . layers . wrappers import OutputMask <NEWLINE> from deep_qa . testing . test_case import DeepQaTestCase <NEWLINE>", "anonymize_dict": {}}], ["676261d2f088e07321ca66e88d41f40e", {"code_string": "def __init__(self):\n    self.CHUNK = 2048\n    self.FORMAT = pyaudio.paInt16\n    self.CHANNELS = 1\n    self.RATE = 44100\n    self.THRESHOLD = 2100\n    self.SILENCE_LIMIT = 0.2\n    self.PREV_AUDIO = 0.5\n    self.GENERATED_FILE_NAME, self.NOTE_NAME = file_name_generator()\n    self.PATH = os.getcwd()\n", "code_toks_joined": "def __init__ ( self ) : <NEWLINE> <INDENT> self . CHUNK = 2048 <NEWLINE> self . FORMAT = pyaudio . paInt16 <NEWLINE> self . CHANNELS = 1 <NEWLINE> self . RATE = 44100 <NEWLINE> self . THRESHOLD = 2100 <NEWLINE> self . SILENCE_LIMIT = 0.2 <NEWLINE> self . PREV_AUDIO = 0.5 <NEWLINE> self . GENERATED_FILE_NAME , self . NOTE_NAME = file_name_generator ( ) <NEWLINE> self . PATH = os . getcwd ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["be0d8a821287541843e1fe2814cbe360", {"code_string": "\"\"\"This example deletes an ad group criterion using the 'REMOVE' operator.\"\"\"\n__author__ = 'api.kwinter@gmail.com (Kevin Winter)'\nfrom googleads import adwords\nAD_GROUP_ID = 'INSERT_AD_GROUP_ID_HERE'\nCRITERION_ID = 'INSERT_CRITERION_ID_HERE'\n", "code_toks_joined": "<STRING> <NEWLINE> __author__ = <STRING> <NEWLINE> from googleads import adwords <NEWLINE> AD_GROUP_ID = <STRING> <NEWLINE> CRITERION_ID = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"This example deletes an ad group criterion using the 'REMOVE' operator.\"\"\"", "'api.kwinter@gmail.com (Kevin Winter)'", "'INSERT_AD_GROUP_ID_HERE'", "'INSERT_CRITERION_ID_HERE'"]}}], ["bb3715501cc29df091e116737ae4f53c", {"code_string": "def dateToTimestamp(datestring):\n    \"\"\"convert iso date to timestring\"\"\"\n    t = time.strptime(datestring + \" UTC\", \"%Y-%m-%d %Z\")\n    return int(calendar.timegm(t))\n", "code_toks_joined": "def dateToTimestamp ( datestring ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> t = time . strptime ( datestring + <STRING> , <STRING> ) <NEWLINE> return int ( calendar . timegm ( t ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"convert iso date to timestring\"\"\"", "\" UTC\"", "\"%Y-%m-%d %Z\""]}}], ["f181990d53b606aeb2a51df711b7f50e", {"code_string": "def infer_net_from_xcorr(S, dtmax, smooth = None):\n    if smooth is not None:\n        S = _moving_average(S, window = smooth, axis = 0)\n    H = xcorr(S, dtmax)\n    H_sum = np.sum(np.abs(H), axis = 2)\n    return H_sum\n", "code_toks_joined": "def infer_net_from_xcorr ( S , dtmax , smooth = None ) : <NEWLINE> <INDENT> if smooth is not None : <NEWLINE> <INDENT> S = _moving_average ( S , window = smooth , axis = 0 ) <NEWLINE> <DEDENT> H = xcorr ( S , dtmax ) <NEWLINE> H_sum = np . sum ( np . abs ( H ) , axis = 2 ) <NEWLINE> return H_sum <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["6e08b3ac0b28d768fcf1774434d46373", {"code_string": "def __init__(self, point):\n    self._x = point[0]\n    self._y = point[1]\n", "code_toks_joined": "def __init__ ( self , point ) : <NEWLINE> <INDENT> self . _x = point [ 0 ] <NEWLINE> self . _y = point [ 1 ] <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["6f63278aeb34cd7bb2c735fd6a60cc28", {"code_string": "\"\"\"Python Interchangeable Virtual Instrument Library\"\"\"\nfrom..import ivi\nMode = set(['312.5ps', '625ps'])\n", "code_toks_joined": "<STRING> <NEWLINE> from . . import ivi <NEWLINE> Mode = set ( [ <STRING> , <STRING> ] ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Python Interchangeable Virtual Instrument Library\"\"\"", "'312.5ps'", "'625ps'"]}}], ["e9bc93fa856a9e031f6cf3e90939d69c", {"code_string": "def pattern_matching(pattern, genome, d):\n    pattern_length = len(pattern)\n    pos = []\n    for i in range(0, len(genome) - pattern_length + 1):\n        _pattern = genome[i: i + pattern_length]\n        if(hamming_distance(pattern, _pattern) <= d):\n            pos.append(i)\n    return pos\n", "code_toks_joined": "def pattern_matching ( pattern , genome , d ) : <NEWLINE> <INDENT> pattern_length = len ( pattern ) <NEWLINE> pos = [ ] <NEWLINE> for i in range ( 0 , len ( genome ) - pattern_length + 1 ) : <NEWLINE> <INDENT> _pattern = genome [ i : i + pattern_length ] <NEWLINE> if ( hamming_distance ( pattern , _pattern ) <= d ) : <NEWLINE> <INDENT> pos . append ( i ) <NEWLINE> <DEDENT> <DEDENT> return pos <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["3a8ba9ecc1e375f5e742541140b59808", {"code_string": "def timeonline(self, unused, player):\n    playerid = player.GameID\n    timeplayed = DataStore.Get(\"LastConnected\", playerid)\n    totaltime = DataStore.Get(\"TotalTimePlayed\", playerid)\n    timeplayed = datetime.datetime.fromtimestamp(timeplayed).strftime('%Y-%m-%d %H:%M:%S')\n    if timeplayed and totaltime is not None:\n        player.Message(\"Last Played:\" + str(timeplayed))\n        player.Message(\"Total Time Played:\" + str(totaltime))\n    else:\n        player.Message(\"Your time hasn't been recorded yet.\")\n", "code_toks_joined": "def timeonline ( self , unused , player ) : <NEWLINE> <INDENT> playerid = player . GameID <NEWLINE> timeplayed = DataStore . Get ( <STRING> , playerid ) <NEWLINE> totaltime = DataStore . Get ( <STRING> , playerid ) <NEWLINE> timeplayed = datetime . datetime . fromtimestamp ( timeplayed ) . strftime ( <STRING> ) <NEWLINE> if timeplayed and totaltime is not None : <NEWLINE> <INDENT> player . Message ( <STRING> + str ( timeplayed ) ) <NEWLINE> player . Message ( <STRING> + str ( totaltime ) ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> player . Message ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"LastConnected\"", "\"TotalTimePlayed\"", "'%Y-%m-%d %H:%M:%S'", "\"Last Played:\"", "\"Total Time Played:\"", "\"Your time hasn't been recorded yet.\""]}}], ["d75d314f3512d6b5fe48015425c0585c", {"code_string": "__all__ = [\"EmbedWdg\"]\nfrom pyasm.common import Environment\nfrom pyasm.biz import File\nfrom pyasm.web import DivWdg, HtmlElement, SpanWdg\nfrom tactic.ui.common import BaseRefreshWdg\nimport os\n", "code_toks_joined": "__all__ = [ <STRING> ] <NEWLINE> from pyasm . common import Environment <NEWLINE> from pyasm . biz import File <NEWLINE> from pyasm . web import DivWdg , HtmlElement , SpanWdg <NEWLINE> from tactic . ui . common import BaseRefreshWdg <NEWLINE> import os <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"EmbedWdg\""]}}], ["4bfee610c80a4fdd11bfd503ec5718d0", {"code_string": "from dolfin import *\nfrom dolfin_adjoint import *\nif not hasattr(dolfin, \"FunctionAssigner\"):\n    info_red(\"Need dolfin.FunctionAssigner for this test.\")\n    import sys\n    sys.exit(0)\nmesh = UnitIntervalMesh(2)\nV = VectorFunctionSpace(mesh, \"CG\", 2)\nP = FunctionSpace(mesh, \"CG\", 1)\nZ = MixedFunctionSpace([V, P])\n", "code_toks_joined": "from dolfin import * <NEWLINE> from dolfin_adjoint import * <NEWLINE> if not hasattr ( dolfin , <STRING> ) : <NEWLINE> <INDENT> info_red ( <STRING> ) <NEWLINE> import sys <NEWLINE> sys . exit ( 0 ) <NEWLINE> <DEDENT> mesh = UnitIntervalMesh ( 2 ) <NEWLINE> V = VectorFunctionSpace ( mesh , <STRING> , 2 ) <NEWLINE> P = FunctionSpace ( mesh , <STRING> , 1 ) <NEWLINE> Z = MixedFunctionSpace ( [ V , P ] ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"FunctionAssigner\"", "\"Need dolfin.FunctionAssigner for this test.\"", "\"CG\"", "\"CG\""]}}], ["2093b4e1410ee673fbc29e4121933d6e", {"code_string": "\"\"\"Tests for ShapeUtil.\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib.distributions.python.ops.shape import _ShapeUtil\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import absolute_import <NEWLINE> from __future__ import division <NEWLINE> from __future__ import print_function <NEWLINE> import numpy as np <NEWLINE> import tensorflow as tf <NEWLINE> from tensorflow . contrib . distributions . python . ops . shape import _ShapeUtil <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Tests for ShapeUtil.\"\"\""]}}], ["b5a0cd7c5e41440db4c4dcd95e618598", {"code_string": "def fromDB(rank_method_code):\n    \"\"\"Get the data for a rank method\"\"\"\n    id = run_sql(\"SELECT id from rnkMETHOD where name=%s\", (rank_method_code, ))\n    res = run_sql(\"SELECT relevance_data FROM rnkMETHODDATA WHERE id_rnkMETHOD=%s\", (id[0][0], ))\n    if res:\n        return deserialize_via_marshal(res[0][0])\n    else:\n        return{}\n", "code_toks_joined": "def fromDB ( rank_method_code ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> id = run_sql ( <STRING> , ( rank_method_code , ) ) <NEWLINE> res = run_sql ( <STRING> , ( id [ 0 ] [ 0 ] , ) ) <NEWLINE> if res : <NEWLINE> <INDENT> return deserialize_via_marshal ( res [ 0 ] [ 0 ] ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return { } <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Get the data for a rank method\"\"\"", "\"SELECT id from rnkMETHOD where name=%s\"", "\"SELECT relevance_data FROM rnkMETHODDATA WHERE id_rnkMETHOD=%s\""]}}], ["05a6a4f1b8ae1063f28c3b7d96681ee3", {"code_string": "def forward_content_url_scheme(apps, schema_editor):\n    \"\"\"Removes the img_src content of each element.\"\"\"\n    Post = apps.get_model('blog', 'Post')\n    files = [\n        '2015-12-22',\n        '2015-12-28',\n        '2015-12-30',\n        '2016-05-01',\n    ]\n    for i in range(len(files)):\n        post = Post.objects.get(pk = i + 1)\n        post.content_url = files[i]\n        post.save()\n", "code_toks_joined": "def forward_content_url_scheme ( apps , schema_editor ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> Post = apps . get_model ( <STRING> , <STRING> ) <NEWLINE> files = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <DEDENT> ] <NEWLINE> for i in range ( len ( files ) ) : <NEWLINE> <INDENT> post = Post . objects . get ( pk = i + 1 ) <NEWLINE> post . content_url = files [ i ] <NEWLINE> post . save ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Removes the img_src content of each element.\"\"\"", "'blog'", "'Post'", "'2015-12-22'", "'2015-12-28'", "'2015-12-30'", "'2016-05-01'"]}}], ["75b5fbd64c76940983ae6c69b95b0b96", {"code_string": "def handle_tree_change(symbol):\n    if symbol == key.BACKSPACE:\n        global root\n        print(\"Generating a new tree\", end = \"... \")\n        root = generate_tree()\n        print(\"Done!\")\n        print(\"   \", Branch.branch_count, \" branches created.\")\n", "code_toks_joined": "def handle_tree_change ( symbol ) : <NEWLINE> <INDENT> if symbol == key . BACKSPACE : <NEWLINE> <INDENT> global root <NEWLINE> print ( <STRING> , end = <STRING> ) <NEWLINE> root = generate_tree ( ) <NEWLINE> print ( <STRING> ) <NEWLINE> print ( <STRING> , Branch . branch_count , <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Generating a new tree\"", "\"... \"", "\"Done!\"", "\"   \"", "\" branches created.\""]}}], ["c476f57b57a83f2c1304bac98249e2c6", {"code_string": "def test_redirect_keeps_language(self):\n    Redirect.objects.create(\n        project = self.pip, redirect_type = 'page',\n        from_url = '/how_to_install.html', to_url = '/install.html')\n    with patch('readthedocs.core.views._serve_docs') as _serve_docs:\n        _serve_docs.side_effect = Http404()\n        r = self.client.get('/de/0.8.1/how_to_install.html',\n            HTTP_HOST = 'pip.readthedocs.org')\n        self.assertEqual(r.status_code, 302)\n        self.assertEqual(\n            r['Location'],\n            'http://pip.readthedocs.org/de/0.8.1/install.html')\n", "code_toks_joined": "def test_redirect_keeps_language ( self ) : <NEWLINE> <INDENT> Redirect . objects . create ( <NEWLINE> <INDENT> project = self . pip , redirect_type = <STRING> , <NEWLINE> from_url = <STRING> , to_url = <STRING> ) <NEWLINE> <DEDENT> with patch ( <STRING> ) as _serve_docs : <NEWLINE> <INDENT> _serve_docs . side_effect = Http404 ( ) <NEWLINE> r = self . client . get ( <STRING> , <NEWLINE> <INDENT> HTTP_HOST = <STRING> ) <NEWLINE> <DEDENT> self . assertEqual ( r . status_code , 302 ) <NEWLINE> self . assertEqual ( <NEWLINE> <INDENT> r [ <STRING> ] , <NEWLINE> <STRING> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'page'", "'/how_to_install.html'", "'/install.html'", "'readthedocs.core.views._serve_docs'", "'/de/0.8.1/how_to_install.html'", "'pip.readthedocs.org'", "'Location'", "'http://pip.readthedocs.org/de/0.8.1/install.html'"]}}], ["6015343e064687688b9dc3ef2cd4a895", {"code_string": "def quality_checks(str_, economy):\n    \"\"\"This functions performs all the quality checks on the economy.\"\"\"\n    if str_ == 'populate':\n        assert(economy.get_status() is False)\n        assert(economy.attr['is_populated'] is False)\n    elif str_ == 'simulate':\n        assert(economy.get_status() is True)\n        assert(economy.attr['is_populated'] is True)\n        assert(economy.attr['is_simulated'] is False)\n    else:\n        raise OSError\n    return True\n", "code_toks_joined": "def quality_checks ( str_ , economy ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if str_ == <STRING> : <NEWLINE> <INDENT> assert ( economy . get_status ( ) is False ) <NEWLINE> assert ( economy . attr [ <STRING> ] is False ) <NEWLINE> <DEDENT> elif str_ == <STRING> : <NEWLINE> <INDENT> assert ( economy . get_status ( ) is True ) <NEWLINE> assert ( economy . attr [ <STRING> ] is True ) <NEWLINE> assert ( economy . attr [ <STRING> ] is False ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> raise OSError <NEWLINE> <DEDENT> return True <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"This functions performs all the quality checks on the economy.\"\"\"", "'populate'", "'is_populated'", "'simulate'", "'is_populated'", "'is_simulated'"]}}], ["a058b12a0981fcf0bc7a5114deea09eb", {"code_string": "class Command(BaseCommand):\n    help = 'Load all tweet counts'\n    def handle(self, * args, ** options):\n        start = datetime.datetime(2016, 1, 1)\n        end = datetime.datetime(2017, 1, 1)\n        n = 0\n        d = start\n        while d < end:\n            tc = TweetCountCache.get_or_create(day = d)\n            n += tc.count\n            d += datetime.timedelta(days = 1)\n        self.stdout.write(self.style.SUCCESS('Successfully imported clusters, created %d entries' % n))\n", "code_toks_joined": "class Command ( BaseCommand ) : <NEWLINE> <INDENT> help = <STRING> <NEWLINE> def handle ( self , * args , ** options ) : <NEWLINE> <INDENT> start = datetime . datetime ( 2016 , 1 , 1 ) <NEWLINE> end = datetime . datetime ( 2017 , 1 , 1 ) <NEWLINE> n = 0 <NEWLINE> d = start <NEWLINE> while d < end : <NEWLINE> <INDENT> tc = TweetCountCache . get_or_create ( day = d ) <NEWLINE> n += tc . count <NEWLINE> d += datetime . timedelta ( days = 1 ) <NEWLINE> <DEDENT> self . stdout . write ( self . style . SUCCESS ( <STRING> % n ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Load all tweet counts'", "'Successfully imported clusters, created %d entries'"]}}], ["4519638c45867e01f019bea45888ff3f", {"code_string": "class CollectionGetterFromObjectGetter(object):\n    \"\"\"Convert an object getter to a collection getter.  The resulting\"\"\"\n    def __init__(self, object_getter):\n        \"\"\":param object_getter: a function that returns the object to\"\"\"\n        self._object_getter = object_getter\n        self._collection = None\n    def __call__(self):\n        if not self._collection:\n            self._collection = [self._object_getter()]\n        return self._collection\n", "code_toks_joined": "class CollectionGetterFromObjectGetter ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , object_getter ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . _object_getter = object_getter <NEWLINE> self . _collection = None <NEWLINE> <DEDENT> def __call__ ( self ) : <NEWLINE> <INDENT> if not self . _collection : <NEWLINE> <INDENT> self . _collection = [ self . _object_getter ( ) ] <NEWLINE> <DEDENT> return self . _collection <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Convert an object getter to a collection getter.  The resulting\"\"\"", "\"\"\":param object_getter: a function that returns the object to\"\"\""]}}], ["c18de5bd1ca6d40b9dc4f543178aa819", {"code_string": "def create_cuboid_xml(height, width, depth):\n    \"\"\"Create the XML string to describe a cuboid of the given dimensions\"\"\"\n    half_height, half_width, half_thick = 0.5 * height, 0.5 * width, 0.5 * depth\n    xml_str = \" <cuboid id=\\\"sample-shape\\\"> \" + \"<left-front-bottom-point \" + \"x=\\\"%f\\\" y=\\\"%f\\\" z=\\\"%f\\\" /> \" %(half_width, - half_height, half_thick) + \"<left-front-top-point \" + \"x=\\\"%f\\\" y=\\\"%f\\\" z=\\\"%f\\\" /> \" %(half_width, half_height, half_thick) + \"<left-back-bottom-point \" + \"x=\\\"%f\\\" y=\\\"%f\\\" z=\\\"%f\\\" /> \" %(half_width, - half_height, - half_thick) + \"<right-front-bottom-point \" + \"x=\\\"%f\\\" y=\\\"%f\\\" z=\\\"%f\\\" /> \" %(- half_width, - half_height, half_thick) + \"</cuboid>\"\n    return xml_str\n", "code_toks_joined": "def create_cuboid_xml ( height , width , depth ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> half_height , half_width , half_thick = 0.5 * height , 0.5 * width , 0.5 * depth <NEWLINE> xml_str = <STRING> + <STRING> + <STRING> % ( half_width , - half_height , half_thick ) + <STRING> + <STRING> % ( half_width , half_height , half_thick ) + <STRING> + <STRING> % ( half_width , - half_height , - half_thick ) + <STRING> + <STRING> % ( - half_width , - half_height , half_thick ) + <STRING> <NEWLINE> return xml_str <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Create the XML string to describe a cuboid of the given dimensions\"\"\"", "\" <cuboid id=\\\"sample-shape\\\"> \"", "\"<left-front-bottom-point \"", "\"x=\\\"%f\\\" y=\\\"%f\\\" z=\\\"%f\\\" /> \"", "\"<left-front-top-point \"", "\"x=\\\"%f\\\" y=\\\"%f\\\" z=\\\"%f\\\" /> \"", "\"<left-back-bottom-point \"", "\"x=\\\"%f\\\" y=\\\"%f\\\" z=\\\"%f\\\" /> \"", "\"<right-front-bottom-point \"", "\"x=\\\"%f\\\" y=\\\"%f\\\" z=\\\"%f\\\" /> \"", "\"</cuboid>\""]}}], ["85d72498916e33e827d33766b362f1ec", {"code_string": "class ComparisonOperator(tuple):\n    def __new__(cls,\n        name: str,\n        operator_fun: types.FunctionType):\n        return tuple.__new__(cls, (name, operator_fun))\n    @ property\n    def name(self) -> str:\n        return self[0]\n    @ property\n    def operator_fun(self) -> types.FunctionType:\n        \"\"\"A function that takes two arguments and returns an integer \u00e0 la cmp\u00a7\"\"\"\n        return self[1]\n", "code_toks_joined": "class ComparisonOperator ( tuple ) : <NEWLINE> <INDENT> def __new__ ( cls , <NEWLINE> <INDENT> name : str , <NEWLINE> operator_fun : types . FunctionType ) : <NEWLINE> return tuple . __new__ ( cls , ( name , operator_fun ) ) <NEWLINE> <DEDENT> @ property <NEWLINE> def name ( self ) -> str : <NEWLINE> <INDENT> return self [ 0 ] <NEWLINE> <DEDENT> @ property <NEWLINE> def operator_fun ( self ) -> types . FunctionType : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self [ 1 ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"A function that takes two arguments and returns an integer \u00e0 la cmp\u00a7\"\"\""]}}], ["ffddc18eeef76e97cdd3ed83c35fd929", {"code_string": "class TestInsertController(APIController):\n    def process(self):\n        param = self.get_parameters(['name', 'sur'])\n        self.db.test_db.insert(param)\n", "code_toks_joined": "class TestInsertController ( APIController ) : <NEWLINE> <INDENT> def process ( self ) : <NEWLINE> <INDENT> param = self . get_parameters ( [ <STRING> , <STRING> ] ) <NEWLINE> self . db . test_db . insert ( param ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'name'", "'sur'"]}}], ["edcc85b2ed98fb6d199e6f11fe4ce1bf", {"code_string": "from decimal import Decimal\nfrom weboob.browser.pages import HTMLPage, JsonPage\nfrom weboob.browser.elements import ItemElement, ListElement, method\nfrom weboob.browser.filters.json import Dict\nfrom weboob.browser.filters.standard import Format, CleanText, Regexp, CleanDecimal, Date, Env, BrowserURL\nfrom weboob.browser.filters.html import XPath\nfrom weboob.capabilities.housing import Housing, HousingPhoto, City\nfrom weboob.capabilities.base import NotAvailable\n", "code_toks_joined": "from decimal import Decimal <NEWLINE> from weboob . browser . pages import HTMLPage , JsonPage <NEWLINE> from weboob . browser . elements import ItemElement , ListElement , method <NEWLINE> from weboob . browser . filters . json import Dict <NEWLINE> from weboob . browser . filters . standard import Format , CleanText , Regexp , CleanDecimal , Date , Env , BrowserURL <NEWLINE> from weboob . browser . filters . html import XPath <NEWLINE> from weboob . capabilities . housing import Housing , HousingPhoto , City <NEWLINE> from weboob . capabilities . base import NotAvailable <NEWLINE>", "anonymize_dict": {}}], ["b3760bbb8848c84b5b26841a5d37b8fd", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('entries', '0005_auto_20161101_1257'),\n    ]\n    operations = [\n        migrations.AlterField(\n            model_name = 'entry',\n            name = 'category',\n            field = models.CharField(choices = [('fc', 'FOOD_CONSUMPTION'), ('rc', 'FOOD_CONSUMPTION'), ('a', 'ACTIVITY')], max_length = 1),\n        ),\n        migrations.AlterField(\n            model_name = 'recipeingredient',\n            name = 'what',\n            field = models.CharField(max_length = 255),\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . AlterField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . CharField ( choices = [ ( <STRING> , <STRING> ) , ( <STRING> , <STRING> ) , ( <STRING> , <STRING> ) ] , max_length = 1 ) , <NEWLINE> <DEDENT> ) , <NEWLINE> migrations . AlterField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . CharField ( max_length = 255 ) , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'entries'", "'0005_auto_20161101_1257'", "'entry'", "'category'", "'fc'", "'FOOD_CONSUMPTION'", "'rc'", "'FOOD_CONSUMPTION'", "'a'", "'ACTIVITY'", "'recipeingredient'", "'what'"]}}], ["c64058b4071519fa1c56f6e4ddd0c4fd", {"code_string": "from collections import Counter\nfrom itertools import product\nimport numpy as np\nDEF_BASES_DNA = [\"A\", \"C\", \"G\", \"T\"]\n", "code_toks_joined": "from collections import Counter <NEWLINE> from itertools import product <NEWLINE> import numpy as np <NEWLINE> DEF_BASES_DNA = [ <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"A\"", "\"C\"", "\"G\"", "\"T\""]}}], ["6936751b590d694dcf9c05e725dcbe61", {"code_string": "def _prepare_invoice_line_details(self, line, desc_rule):\n    details = []\n    if desc_rule[0] == '1':\n        details.append(line.date)\n    if desc_rule[1] == '1':\n        details.append(\n            \"%s %s\" %(line.unit_amount, line.product_uom_id.name))\n    if desc_rule[2] == '1':\n        details.append(line.name)\n    return details\n", "code_toks_joined": "def _prepare_invoice_line_details ( self , line , desc_rule ) : <NEWLINE> <INDENT> details = [ ] <NEWLINE> if desc_rule [ 0 ] == <STRING> : <NEWLINE> <INDENT> details . append ( line . date ) <NEWLINE> <DEDENT> if desc_rule [ 1 ] == <STRING> : <NEWLINE> <INDENT> details . append ( <NEWLINE> <INDENT> <STRING> % ( line . unit_amount , line . product_uom_id . name ) ) <NEWLINE> <DEDENT> <DEDENT> if desc_rule [ 2 ] == <STRING> : <NEWLINE> <INDENT> details . append ( line . name ) <NEWLINE> <DEDENT> return details <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'1'", "'1'", "\"%s %s\"", "'1'"]}}], ["3e534243f018c20427f075a6f5c10082", {"code_string": "def set_model(self, likelihood_model_instance):\n    \"\"\"Set the model to be used in the joint minimization. Must be a LikelihoodModel instance.\"\"\"\n    if likelihood_model_instance is None:\n        return\n    if self._source_name is not None:\n        assert self._source_name in likelihood_model_instance.sources, \"This XYLike plugin refers to the source %s, \" \"but that source is not in the likelihood model\" %(self._source_name)\n    self._likelihood_model = likelihood_model_instance\n", "code_toks_joined": "def set_model ( self , likelihood_model_instance ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if likelihood_model_instance is None : <NEWLINE> <INDENT> return <NEWLINE> <DEDENT> if self . _source_name is not None : <NEWLINE> <INDENT> assert self . _source_name in likelihood_model_instance . sources , <STRING> <STRING> % ( self . _source_name ) <NEWLINE> <DEDENT> self . _likelihood_model = likelihood_model_instance <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Set the model to be used in the joint minimization. Must be a LikelihoodModel instance.\"\"\"", "\"This XYLike plugin refers to the source %s, \"", "\"but that source is not in the likelihood model\""]}}], ["d0330d1bebc69195d55ef391ed85eb33", {"code_string": "from distutils.core import setup\nimport os\nimport codecs\ntry:\n    codecs.lookup('mbcs')\nexcept LookupError:\n    ascii = codecs.lookup('ascii')\n    func = lambda name, enc = ascii: {True: enc}.get(name == 'mbcs')\n    codecs.register(func)\n", "code_toks_joined": "from distutils . core import setup <NEWLINE> import os <NEWLINE> import codecs <NEWLINE> try : <NEWLINE> <INDENT> codecs . lookup ( <STRING> ) <NEWLINE> <DEDENT> except LookupError : <NEWLINE> <INDENT> ascii = codecs . lookup ( <STRING> ) <NEWLINE> func = lambda name , enc = ascii : { True : enc } . get ( name == <STRING> ) <NEWLINE> codecs . register ( func ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'mbcs'", "'ascii'", "'mbcs'"]}}], ["27ec404ad3ec699aafe3897626594c58", {"code_string": "def update_sub_domain(self, domain, tld, domain_id, ip):\n    if self.delete_sub_domain(domain_id):\n        self.create_sub_domain(domain, tld, ip)\n    return True\n", "code_toks_joined": "def update_sub_domain ( self , domain , tld , domain_id , ip ) : <NEWLINE> <INDENT> if self . delete_sub_domain ( domain_id ) : <NEWLINE> <INDENT> self . create_sub_domain ( domain , tld , ip ) <NEWLINE> <DEDENT> return True <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ec0909c305347cd3b2b10fdb87756554", {"code_string": "def _load(self, name, k, P):\n    \"\"\"Load data into a given power attribute, as specified by power_term\"\"\"\n    if name not in self._loadable_power_terms:\n        raise ValueError(\"`%s` not a valid term to be loaded;\"\n            \" must be one of %s\" %(name, self._loadable_power_terms))\n    self._loaded_data[name] = spline(k, P)\n    setattr(self, name + '_loaded', True)\n", "code_toks_joined": "def _load ( self , name , k , P ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if name not in self . _loadable_power_terms : <NEWLINE> <INDENT> raise ValueError ( <STRING> <NEWLINE> <INDENT> <STRING> % ( name , self . _loadable_power_terms ) ) <NEWLINE> <DEDENT> <DEDENT> self . _loaded_data [ name ] = spline ( k , P ) <NEWLINE> setattr ( self , name + <STRING> , True ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Load data into a given power attribute, as specified by power_term\"\"\"", "\"`%s` not a valid term to be loaded;\"", "\" must be one of %s\"", "'_loaded'"]}}], ["e38c2a601e52704ec89b29ccdeb44144", {"code_string": "s = input()\nn = \"\"\nif len(s) > 1:\n    for i in s:\n        if(i == \"a\" or i == \"e\" or i == \"i\" or i == \"o\" or i == \"u\"):\n            n += i\n    n2 = n[: : - 1]\n    if(n2 == n):\n        print(\"S\")\n    else:\n        print(\"N\")\nelse:\n    print(\"S\")\n", "code_toks_joined": "s = input ( ) <NEWLINE> n = <STRING> <NEWLINE> if len ( s ) > 1 : <NEWLINE> <INDENT> for i in s : <NEWLINE> <INDENT> if ( i == <STRING> or i == <STRING> or i == <STRING> or i == <STRING> or i == <STRING> ) : <NEWLINE> <INDENT> n += i <NEWLINE> <DEDENT> <DEDENT> n2 = n [ : : - 1 ] <NEWLINE> if ( n2 == n ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"", "\"a\"", "\"e\"", "\"i\"", "\"o\"", "\"u\"", "\"S\"", "\"N\"", "\"S\""]}}], ["6560e211b0733c8220513a9e9c26f53b", {"code_string": "def test_invalid_form_data(self):\n    self.register('David', 'david@meltwater.org', 'python', 'python')\n    response = self.login('alert(\"alert box!\");', 'foo')\n    self.assertIn(b'Invalid username or password.', response.data)\n", "code_toks_joined": "def test_invalid_form_data ( self ) : <NEWLINE> <INDENT> self . register ( <STRING> , <STRING> , <STRING> , <STRING> ) <NEWLINE> response = self . login ( <STRING> , <STRING> ) <NEWLINE> self . assertIn ( <STRING> , response . data ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'David'", "'david@meltwater.org'", "'python'", "'python'", "'alert(\"alert box!\");'", "'foo'", "b'Invalid username or password.'"]}}], ["db37242e4b54bd9bfc590060e5a8f7fc", {"code_string": "def do_upgrade(env, ver, cursor):\n    cursor.execute(sql)\n    env.config.set('attachment', 'max_size', '262144')\n    env.config.save()\n", "code_toks_joined": "def do_upgrade ( env , ver , cursor ) : <NEWLINE> <INDENT> cursor . execute ( sql ) <NEWLINE> env . config . set ( <STRING> , <STRING> , <STRING> ) <NEWLINE> env . config . save ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'attachment'", "'max_size'", "'262144'"]}}], ["85fee4af7bab99466d898399c2712f23", {"code_string": "def test_key_is_created_for_project(self):\n    user = self.create_user('admin@example.com')\n    team = self.create_team(name = 'Test')\n    project = self.create_project(name = 'Test', team = team)\n    assert project.key_set.exists() is True\n", "code_toks_joined": "def test_key_is_created_for_project ( self ) : <NEWLINE> <INDENT> user = self . create_user ( <STRING> ) <NEWLINE> team = self . create_team ( name = <STRING> ) <NEWLINE> project = self . create_project ( name = <STRING> , team = team ) <NEWLINE> assert project . key_set . exists ( ) is True <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'admin@example.com'", "'Test'", "'Test'"]}}], ["ffc1819b57482b7e328f254148986e5b", {"code_string": "def register():\n    logging.debug(\"%s\\tRegistered node install trigger\\n\", time.strftime('%X %x %Z'))\n    return \"/var/lib/cobbler/triggers/install/post/*\"\n", "code_toks_joined": "def register ( ) : <NEWLINE> <INDENT> logging . debug ( <STRING> , time . strftime ( <STRING> ) ) <NEWLINE> return <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"%s\\tRegistered node install trigger\\n\"", "'%X %x %Z'", "\"/var/lib/cobbler/triggers/install/post/*\""]}}], ["d6ab523e22dffb8be7683f3b2f89c6a9", {"code_string": "def cron_remove_empty_session(self):\n    hours = 1\n    self.env.cr.execute(\"\"\"SELECT id as id\"\"\", (\"%s hours\" % hours, ))\n    empty_channel_ids = [item['id'] for item in self.env.cr.dictfetchall()]\n    self.browse(empty_channel_ids).unlink()\n", "code_toks_joined": "def cron_remove_empty_session ( self ) : <NEWLINE> <INDENT> hours = 1 <NEWLINE> self . env . cr . execute ( <STRING> , ( <STRING> % hours , ) ) <NEWLINE> empty_channel_ids = [ item [ <STRING> ] for item in self . env . cr . dictfetchall ( ) ] <NEWLINE> self . browse ( empty_channel_ids ) . unlink ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"SELECT id as id\"\"\"", "\"%s hours\"", "'id'"]}}], ["6003c61372ba1f098586e73d3316e0c2", {"code_string": "import sys\nimport os\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))\ntestinfo = \"s, t 1, s, t 1.9, s, t 2.1, s, q\"\ntags = \"Scene, Rotate\"\nimport cocos\nfrom cocos.director import director\nfrom cocos.actions import RotateBy\nfrom cocos.sprite import Sprite\nfrom cocos.layer import *\nimport pyglet\n", "code_toks_joined": "import sys <NEWLINE> import os <NEWLINE> sys . path . insert ( 0 , os . path . join ( os . path . dirname ( __file__ ) , <STRING> ) ) <NEWLINE> testinfo = <STRING> <NEWLINE> tags = <STRING> <NEWLINE> import cocos <NEWLINE> from cocos . director import director <NEWLINE> from cocos . actions import RotateBy <NEWLINE> from cocos . sprite import Sprite <NEWLINE> from cocos . layer import * <NEWLINE> import pyglet <NEWLINE>", "anonymize_dict": {"<STRING>": ["'..'", "\"s, t 1, s, t 1.9, s, t 2.1, s, q\"", "\"Scene, Rotate\""]}}], ["6352751d6c7657334a01934f571e647e", {"code_string": "def next_layer(self):\n    if self.__current_frame == self.__top_frame:\n        self.__ended = True\n    frame = self.layers[self.__current_frame]\n    if self.__current_frame < self.__top_frame:\n        self.__current_frame += 1\n    return frame\n", "code_toks_joined": "def next_layer ( self ) : <NEWLINE> <INDENT> if self . __current_frame == self . __top_frame : <NEWLINE> <INDENT> self . __ended = True <NEWLINE> <DEDENT> frame = self . layers [ self . __current_frame ] <NEWLINE> if self . __current_frame < self . __top_frame : <NEWLINE> <INDENT> self . __current_frame += 1 <NEWLINE> <DEDENT> return frame <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["68ab31d593b599d3a0cfdab6b3a48ab1", {"code_string": "\"\"\"*   This module is part of the sql_data_plot.py application\"\"\"\nfrom PyQt4 import QtCore\nfrom PyQt4 import QtGui\nfrom authenticate_ui import Ui_Dialog\nimport csv\nimport numpy as np\n", "code_toks_joined": "<STRING> <NEWLINE> from PyQt4 import QtCore <NEWLINE> from PyQt4 import QtGui <NEWLINE> from authenticate_ui import Ui_Dialog <NEWLINE> import csv <NEWLINE> import numpy as np <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"*   This module is part of the sql_data_plot.py application\"\"\""]}}], ["e4e06177fabb1be4471d90cca0114ac6", {"code_string": "import paramiko\nimport MySQLdb\nimport os\nimport sys\nimport time\nfrom optparse import OptionParser\nuser_value = \"autopilot\"; pass_value = \"YTkzNDJjZDRhNWMyNzJkOTZiMTllMTI4\"; port_value = 3306;\n", "code_toks_joined": "import paramiko <NEWLINE> import MySQLdb <NEWLINE> import os <NEWLINE> import sys <NEWLINE> import time <NEWLINE> from optparse import OptionParser <NEWLINE> user_value = <STRING> ; pass_value = <STRING> ; port_value = 3306 ; <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"autopilot\"", "\"YTkzNDJjZDRhNWMyNzJkOTZiMTllMTI4\""]}}], ["bf0dce2eb1884e4fb2a064d0c2049b1d", {"code_string": "def __init__(self, consumer_key, consumer_secret, request_token_url = REQUEST_TOKEN_URL, access_token_url = ACCESS_TOKEN_URL, authorization_url = AUTHORIZATION_URL):\n    self.consumer_secret = consumer_secret\n    self.consumer_key = consumer_key\n    self.consumer = oauth.OAuthConsumer(consumer_key, consumer_secret)\n    self.signature_method = oauth.OAuthSignatureMethod_HMAC_SHA1()\n    self.request_token_url = request_token_url\n    self.access_token_url = access_token_url\n    self.authorization_url = authorization_url\n", "code_toks_joined": "def __init__ ( self , consumer_key , consumer_secret , request_token_url = REQUEST_TOKEN_URL , access_token_url = ACCESS_TOKEN_URL , authorization_url = AUTHORIZATION_URL ) : <NEWLINE> <INDENT> self . consumer_secret = consumer_secret <NEWLINE> self . consumer_key = consumer_key <NEWLINE> self . consumer = oauth . OAuthConsumer ( consumer_key , consumer_secret ) <NEWLINE> self . signature_method = oauth . OAuthSignatureMethod_HMAC_SHA1 ( ) <NEWLINE> self . request_token_url = request_token_url <NEWLINE> self . access_token_url = access_token_url <NEWLINE> self . authorization_url = authorization_url <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["4a8c7089020bc3b52fc5d7eef989ff4c", {"code_string": "\"\"\"Implements vlans, bridges, and iptables rules using linux utilities.\"\"\"\nimport os\nfrom oslo_log import log as logging\nfrom oslo_utils import excutils\nfrom vif_plug_midonet.i18n import _LE\nfrom vif_plug_midonet import processutils\nLOG = logging.getLogger(__name__)\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> from oslo_log import log as logging <NEWLINE> from oslo_utils import excutils <NEWLINE> from vif_plug_midonet . i18n import _LE <NEWLINE> from vif_plug_midonet import processutils <NEWLINE> LOG = logging . getLogger ( __name__ ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Implements vlans, bridges, and iptables rules using linux utilities.\"\"\""]}}], ["94dd8151b1f87aaee4b6e88587237259", {"code_string": "def test_parse_volumes_invalid_params(self):\n    self.assertEquals(\n        ({}, []), utils.parse_volumes(None))\n    self.assertEquals(\n        ({}, []), utils.parse_volumes(\"\"))\n", "code_toks_joined": "def test_parse_volumes_invalid_params ( self ) : <NEWLINE> <INDENT> self . assertEquals ( <NEWLINE> <INDENT> ( { } , [ ] ) , utils . parse_volumes ( None ) ) <NEWLINE> <DEDENT> self . assertEquals ( <NEWLINE> <INDENT> ( { } , [ ] ) , utils . parse_volumes ( <STRING> ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\""]}}], ["7f8e4d0fe70887fe4850c5818d8ad6b6", {"code_string": "def __set__(self, instance, value):\n    if value in self.choices:\n        return super(ChoiceProperty, self).__set__(instance, value)\n    possible_choices = \", \".join(self.choices.keys())\n    raise ValueError(\n        \"Wrong value `{0}` for property `{1}`. Available values: \"\n        \"{2}\".format(value, self.name, possible_choices)\n    )\n", "code_toks_joined": "def __set__ ( self , instance , value ) : <NEWLINE> <INDENT> if value in self . choices : <NEWLINE> <INDENT> return super ( ChoiceProperty , self ) . __set__ ( instance , value ) <NEWLINE> <DEDENT> possible_choices = <STRING> . join ( self . choices . keys ( ) ) <NEWLINE> raise ValueError ( <NEWLINE> <INDENT> <STRING> <NEWLINE> <STRING> . format ( value , self . name , possible_choices ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\", \"", "\"Wrong value `{0}` for property `{1}`. Available values: \"", "\"{2}\""]}}], ["92342df08db55499db22ae31f5859900", {"code_string": "class Client(object):\n    def __init__(self, api_key):\n        self.api_key = api_key\n    def get_historical_rates(self, date):\n        response = requests.get(HISTORICAL_ENDPOINT % date, params = {'app_id': self.api_key})\n        return response.json()['rates']\n", "code_toks_joined": "class Client ( object ) : <NEWLINE> <INDENT> def __init__ ( self , api_key ) : <NEWLINE> <INDENT> self . api_key = api_key <NEWLINE> <DEDENT> def get_historical_rates ( self , date ) : <NEWLINE> <INDENT> response = requests . get ( HISTORICAL_ENDPOINT % date , params = { <STRING> : self . api_key } ) <NEWLINE> return response . json ( ) [ <STRING> ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'app_id'", "'rates'"]}}], ["83c1c80ec0e16a92900e33c147799eb8", {"code_string": "def datespan(self):\n    datespan = DateSpan.since(self.default_days, timezone = self.timezone, inclusive = self.inclusive)\n    if self.request.datespan.is_valid() and self.slug == 'datespan':\n        datespan.startdate = self.request.datespan.startdate\n        datespan.enddate = self.request.datespan.enddate\n    return datespan\n", "code_toks_joined": "def datespan ( self ) : <NEWLINE> <INDENT> datespan = DateSpan . since ( self . default_days , timezone = self . timezone , inclusive = self . inclusive ) <NEWLINE> if self . request . datespan . is_valid ( ) and self . slug == <STRING> : <NEWLINE> <INDENT> datespan . startdate = self . request . datespan . startdate <NEWLINE> datespan . enddate = self . request . datespan . enddate <NEWLINE> <DEDENT> return datespan <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'datespan'"]}}], ["868ba2d579d687801a82618129feb967", {"code_string": "class Transform(RegisterLookupMixin, Func):\n    \"\"\"RegisterLookupMixin() is first so that get_lookup() and get_transform()\"\"\"\n    bilateral = False\n    arity = 1\n    @ property\n    def lhs(self):\n        return self.get_source_expressions()[0]\n    def get_bilateral_transforms(self):\n        if hasattr(self.lhs, 'get_bilateral_transforms'):\n            bilateral_transforms = self.lhs.get_bilateral_transforms()\n        else:\n            bilateral_transforms = []\n        if self.bilateral:\n            bilateral_transforms.append(self.__class__)\n        return bilateral_transforms\n", "code_toks_joined": "class Transform ( RegisterLookupMixin , Func ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> bilateral = False <NEWLINE> arity = 1 <NEWLINE> @ property <NEWLINE> def lhs ( self ) : <NEWLINE> <INDENT> return self . get_source_expressions ( ) [ 0 ] <NEWLINE> <DEDENT> def get_bilateral_transforms ( self ) : <NEWLINE> <INDENT> if hasattr ( self . lhs , <STRING> ) : <NEWLINE> <INDENT> bilateral_transforms = self . lhs . get_bilateral_transforms ( ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> bilateral_transforms = [ ] <NEWLINE> <DEDENT> if self . bilateral : <NEWLINE> <INDENT> bilateral_transforms . append ( self . __class__ ) <NEWLINE> <DEDENT> return bilateral_transforms <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"RegisterLookupMixin() is first so that get_lookup() and get_transform()\"\"\"", "'get_bilateral_transforms'"]}}], ["a89c27e492da5b9ad40a3c3577065ee2", {"code_string": "def __sub__(self, other):\n    return RationalFunction(self.numerator * other.denominator -\n        self.denominator * other.numerator,\n        self.denominator * other.denominator)\n", "code_toks_joined": "def __sub__ ( self , other ) : <NEWLINE> <INDENT> return RationalFunction ( self . numerator * other . denominator - <NEWLINE> <INDENT> self . denominator * other . numerator , <NEWLINE> self . denominator * other . denominator ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["9223d6a56cab291340a6fc052791f721", {"code_string": "def testCreateEdfContainer(self, fname):\n    print(\"createEdfContainer(): {}\".format(fname))\n    edf_container = self.createEdfContainer(fname)\n    print(\"\\topen existing file [ OK ]\")\n    try:\n        not_edf_c = self.createEdfContainer('not_existing_filename')\n        print(\"\\tnot existing file was opened... [ FAIL ]\")\n    except FileNotFoundError:\n        print(\"\\ttry non-existing file [ OK ]\")\n    return edf_container\n", "code_toks_joined": "def testCreateEdfContainer ( self , fname ) : <NEWLINE> <INDENT> print ( <STRING> . format ( fname ) ) <NEWLINE> edf_container = self . createEdfContainer ( fname ) <NEWLINE> print ( <STRING> ) <NEWLINE> try : <NEWLINE> <INDENT> not_edf_c = self . createEdfContainer ( <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> <DEDENT> except FileNotFoundError : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> return edf_container <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"createEdfContainer(): {}\"", "\"\\topen existing file [ OK ]\"", "'not_existing_filename'", "\"\\tnot existing file was opened... [ FAIL ]\"", "\"\\ttry non-existing file [ OK ]\""]}}], ["f93e3f3758b780b133624506e1ea960e", {"code_string": "import os\nimport os.path\nimport logging\nfrom lascaux import config\nif not os.path.isdir(\"tmp\"):\n    os.mkdir(\"tmp\")\nlogging.basicConfig(filename = \"tmp/log.txt\", level = logging.DEBUG)\nformatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\nstream_handler = logging.StreamHandler()\nstream_handler.setFormatter(formatter)\n", "code_toks_joined": "import os <NEWLINE> import os . path <NEWLINE> import logging <NEWLINE> from lascaux import config <NEWLINE> if not os . path . isdir ( <STRING> ) : <NEWLINE> <INDENT> os . mkdir ( <STRING> ) <NEWLINE> <DEDENT> logging . basicConfig ( filename = <STRING> , level = logging . DEBUG ) <NEWLINE> formatter = logging . Formatter ( <STRING> ) <NEWLINE> stream_handler = logging . StreamHandler ( ) <NEWLINE> stream_handler . setFormatter ( formatter ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"tmp\"", "\"tmp\"", "\"tmp/log.txt\"", "\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\""]}}], ["de67a85a0505db483a7157727333c59f", {"code_string": "\"\"\"Store status messages in the database.\"\"\"\nfrom config_models.admin import ConfigurationModelAdmin\nfrom config_models.models import ConfigurationModel\nfrom django.contrib import admin\nfrom django.core.cache import cache\nfrom django.db import models\nfrom openedx.core.djangoapps.xmodule_django.models import CourseKeyField\n", "code_toks_joined": "<STRING> <NEWLINE> from config_models . admin import ConfigurationModelAdmin <NEWLINE> from config_models . models import ConfigurationModel <NEWLINE> from django . contrib import admin <NEWLINE> from django . core . cache import cache <NEWLINE> from django . db import models <NEWLINE> from openedx . core . djangoapps . xmodule_django . models import CourseKeyField <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Store status messages in the database.\"\"\""]}}], ["a7aac97e108ff02ae209f47f3ad3527d", {"code_string": "def get_newslink_create_url(self):\n    return reverse('organizer_newslink_create', kwargs = {\n        'startup_slug': self.slug})\n", "code_toks_joined": "def get_newslink_create_url ( self ) : <NEWLINE> <INDENT> return reverse ( <STRING> , kwargs = { <NEWLINE> <INDENT> <STRING> : self . slug } ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'organizer_newslink_create'", "'startup_slug'"]}}], ["4ca07cebfdcdb643528444ada8637ea2", {"code_string": "import pprint\nimport click\nimport os\nimport subprocess\nimport glob\nimport time\nimport sys\nimport datetime\nimport re\nimport csv\n", "code_toks_joined": "import pprint <NEWLINE> import click <NEWLINE> import os <NEWLINE> import subprocess <NEWLINE> import glob <NEWLINE> import time <NEWLINE> import sys <NEWLINE> import datetime <NEWLINE> import re <NEWLINE> import csv <NEWLINE>", "anonymize_dict": {}}], ["9177dc8e166a5242f1a50ebd08dce72d", {"code_string": "class RandomSequenceInside(Block):\n    def apply(self, x):\n        out = T.scan(self.rec, sequences = x, outputs_info = [None])\n        return out\n    def rec(self, x_t):\n        return RVal().normal(x_t.shape)\n", "code_toks_joined": "class RandomSequenceInside ( Block ) : <NEWLINE> <INDENT> def apply ( self , x ) : <NEWLINE> <INDENT> out = T . scan ( self . rec , sequences = x , outputs_info = [ None ] ) <NEWLINE> return out <NEWLINE> <DEDENT> def rec ( self , x_t ) : <NEWLINE> <INDENT> return RVal ( ) . normal ( x_t . shape ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["4cba044ee6f1715669880c76800745b5", {"code_string": "from django.conf import settings\nfrom django.http import Http404\nfrom amanda.redirects.views import DynamicRedirectView\n", "code_toks_joined": "from django . conf import settings <NEWLINE> from django . http import Http404 <NEWLINE> from amanda . redirects . views import DynamicRedirectView <NEWLINE>", "anonymize_dict": {}}], ["1a18b526a2d0ac154f3ffed9ee82949d", {"code_string": "def on_completed(self):\n    \"\"\"Notifies all subscribed observers of the end of the sequence.\"\"\"\n    os = None\n    with self.lock:\n        self.check_disposed()\n        if not self.is_stopped:\n            os = self.observers[: ]\n            self.observers = []\n            self.is_stopped = True\n    if os:\n        for observer in os:\n            observer.on_completed()\n", "code_toks_joined": "def on_completed ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> os = None <NEWLINE> with self . lock : <NEWLINE> <INDENT> self . check_disposed ( ) <NEWLINE> if not self . is_stopped : <NEWLINE> <INDENT> os = self . observers [ : ] <NEWLINE> self . observers = [ ] <NEWLINE> self . is_stopped = True <NEWLINE> <DEDENT> <DEDENT> if os : <NEWLINE> <INDENT> for observer in os : <NEWLINE> <INDENT> observer . on_completed ( ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Notifies all subscribed observers of the end of the sequence.\"\"\""]}}], ["6c584c735ac80e1b0770d241c92879e6", {"code_string": "class PostgreSQLDatabases(object):\n    \"\"\"Settings for local PostgreSQL databases.\"\"\"\n    DATABASES = values.DictValue({\n        'default': {\n            'ENGINE': 'django.db.backends.postgresql_psycopg2',\n            'NAME': 'hopper',\n            'USER': 'hopper',\n            'PASSWORD': 'hopper',\n            'HOST': 'localhost',\n            'CONN_MAX_AGE': None,\n        },\n    })\n", "code_toks_joined": "class PostgreSQLDatabases ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> DATABASES = values . DictValue ( { <NEWLINE> <INDENT> <STRING> : { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : None , <NEWLINE> <DEDENT> } , <NEWLINE> <DEDENT> } ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Settings for local PostgreSQL databases.\"\"\"", "'default'", "'ENGINE'", "'django.db.backends.postgresql_psycopg2'", "'NAME'", "'hopper'", "'USER'", "'hopper'", "'PASSWORD'", "'hopper'", "'HOST'", "'localhost'", "'CONN_MAX_AGE'"]}}], ["842a77570a13487e47c1b997c772f01d", {"code_string": "from fabric.api import abort, run, settings, sudo, local\nfrom fabric.colors import blue, red, green, magenta, cyan\nfrom fabric.context_managers import hide\nfrom fabric.contrib import console\nimport fnmatch\nimport os\nimport os.path\nfrom bismarck_cli.utils import term\nfrom bismarck_cli.utils.misc import is_sequence\nOK = 0\nINFO = 10\nWARN = 50\nERROR = 100\n", "code_toks_joined": "from fabric . api import abort , run , settings , sudo , local <NEWLINE> from fabric . colors import blue , red , green , magenta , cyan <NEWLINE> from fabric . context_managers import hide <NEWLINE> from fabric . contrib import console <NEWLINE> import fnmatch <NEWLINE> import os <NEWLINE> import os . path <NEWLINE> from bismarck_cli . utils import term <NEWLINE> from bismarck_cli . utils . misc import is_sequence <NEWLINE> OK = 0 <NEWLINE> INFO = 10 <NEWLINE> WARN = 50 <NEWLINE> ERROR = 100 <NEWLINE>", "anonymize_dict": {}}], ["6c14799a59ecc9c56e1f544f64b940e5", {"code_string": "def get_nodes(self, flag):\n    \"\"\" A method returning a list of all nodes having the flag 'flag'\"\"\"\n    match = []\n    for n in self._nodes:\n        if n.has_flag(flag):\n            match.append(n)\n    return match\n", "code_toks_joined": "def get_nodes ( self , flag ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> match = [ ] <NEWLINE> for n in self . _nodes : <NEWLINE> <INDENT> if n . has_flag ( flag ) : <NEWLINE> <INDENT> match . append ( n ) <NEWLINE> <DEDENT> <DEDENT> return match <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" A method returning a list of all nodes having the flag 'flag'\"\"\""]}}], ["38ae57ad233082272c89d792051a4d50", {"code_string": "def delete_room(self, room_token):\n    resp = self.session.delete(\n        self.base_url + '/rooms/%s' % room_token,\n        headers = {'Content-Type': 'application/json'},\n        auth = self.hawk_room_owner\n    )\n    self.assertEquals(204, resp.status_code,\n        \"Room deletion failed with code %s: %s\" %(\n            resp.status_code, resp.content))\n    self.incr_counter(\"delete-room\")\n", "code_toks_joined": "def delete_room ( self , room_token ) : <NEWLINE> <INDENT> resp = self . session . delete ( <NEWLINE> <INDENT> self . base_url + <STRING> % room_token , <NEWLINE> headers = { <STRING> : <STRING> } , <NEWLINE> auth = self . hawk_room_owner <NEWLINE> <DEDENT> ) <NEWLINE> self . assertEquals ( 204 , resp . status_code , <NEWLINE> <INDENT> <STRING> % ( <NEWLINE> <INDENT> resp . status_code , resp . content ) ) <NEWLINE> <DEDENT> <DEDENT> self . incr_counter ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/rooms/%s'", "'Content-Type'", "'application/json'", "\"Room deletion failed with code %s: %s\"", "\"delete-room\""]}}], ["9db5bcbbcbc18e45a11bbd563592ddcb", {"code_string": "\"\"\"Library for pretty-printing tables.\"\"\"\nimport util\nfrom util import out, nl\n", "code_toks_joined": "<STRING> <NEWLINE> import util <NEWLINE> from util import out , nl <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Library for pretty-printing tables.\"\"\""]}}], ["d03b76010adbc9b9644988e5834f8f50", {"code_string": "import numpy as np\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom random import sample, seed\nfrom collections import OrderedDict\n", "code_toks_joined": "import numpy as np <NEWLINE> from sklearn . ensemble import GradientBoostingClassifier <NEWLINE> from random import sample , seed <NEWLINE> from collections import OrderedDict <NEWLINE>", "anonymize_dict": {}}], ["838a6c0448959e1103206d98c2e8078e", {"code_string": "from matplotlib.contour import ContourSet\nfrom matplotlib.tri.triangulation import Triangulation\nimport matplotlib._tri as _tri\nimport numpy as np\n", "code_toks_joined": "from matplotlib . contour import ContourSet <NEWLINE> from matplotlib . tri . triangulation import Triangulation <NEWLINE> import matplotlib . _tri as _tri <NEWLINE> import numpy as np <NEWLINE>", "anonymize_dict": {}}], ["83654ebf042d19ace721d0e3cd0ef530", {"code_string": "version_info = (0, 3, 2)\n__version__ = '.'.join(str(s) for s in version_info)\n__author__ = 'James Brown <jbrown@easypost.com>'\n", "code_toks_joined": "version_info = ( 0 , 3 , 2 ) <NEWLINE> __version__ = <STRING> . join ( str ( s ) for s in version_info ) <NEWLINE> __author__ = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'.'", "'James Brown <jbrown@easypost.com>'"]}}], ["0f60b13ce1fb503d13599bfc9194c263", {"code_string": "def score(self, p, x, y, sample_weight = None):\n    \"\"\"Overloading default regression score method\"\"\"\n    return r2_score(y_pred = self.predict(p, x),\n        y_true = y,\n        sample_weight = sample_weight)\n", "code_toks_joined": "def score ( self , p , x , y , sample_weight = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return r2_score ( y_pred = self . predict ( p , x ) , <NEWLINE> <INDENT> y_true = y , <NEWLINE> sample_weight = sample_weight ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Overloading default regression score method\"\"\""]}}], ["f7d9313e34148faf627406e640914517", {"code_string": "def add_mdf(* args, ** argv):\n    ro = mkRO(astrotype = \"GEMINI\", copy_input = True,\n        args = args, argv = argv)\n    ro.runstep(\"addMDF\", ro.context)\n    outputs = ro.context.get_outputs(style = \"AD\")\n    if len(outputs) == 0:\n        return None\n    elif len(outputs) == 1:\n        return outputs[0]\n    else:\n        return outputs\n", "code_toks_joined": "def add_mdf ( * args , ** argv ) : <NEWLINE> <INDENT> ro = mkRO ( astrotype = <STRING> , copy_input = True , <NEWLINE> <INDENT> args = args , argv = argv ) <NEWLINE> <DEDENT> ro . runstep ( <STRING> , ro . context ) <NEWLINE> outputs = ro . context . get_outputs ( style = <STRING> ) <NEWLINE> if len ( outputs ) == 0 : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> elif len ( outputs ) == 1 : <NEWLINE> <INDENT> return outputs [ 0 ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return outputs <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"GEMINI\"", "\"addMDF\"", "\"AD\""]}}], ["a2741fbb45aca1226ef9b579a7d3397f", {"code_string": "def test_wrong_schema(self):\n    httpretty.HTTPretty.register_uri(httpretty.HTTPretty.GET, 'https://ci.mailroute.net/api/v1/',\n        status = 200, body = json.dumps({}),\n        content_type = 'application/json')\n    mailroute.configure(* self.ACCESS_USER, server = 'https://ci.mailroute.net')\n    for QClass in self.entity_classes:\n        QClass.Entity.schema.when.called_with().should.throw(mailroute.CanNotInitSchema)\n", "code_toks_joined": "def test_wrong_schema ( self ) : <NEWLINE> <INDENT> httpretty . HTTPretty . register_uri ( httpretty . HTTPretty . GET , <STRING> , <NEWLINE> <INDENT> status = 200 , body = json . dumps ( { } ) , <NEWLINE> content_type = <STRING> ) <NEWLINE> <DEDENT> mailroute . configure ( * self . ACCESS_USER , server = <STRING> ) <NEWLINE> for QClass in self . entity_classes : <NEWLINE> <INDENT> QClass . Entity . schema . when . called_with ( ) . should . throw ( mailroute . CanNotInitSchema ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'https://ci.mailroute.net/api/v1/'", "'application/json'", "'https://ci.mailroute.net'"]}}], ["455c5b400e40ace17c9e384efebf1647", {"code_string": "from __future__ import(division, print_function)\nimport random\nimport numpy\nimport dendropy\nimport re\nfrom Bio import Phylo\nfrom cStringIO import StringIO\n", "code_toks_joined": "from __future__ import ( division , print_function ) <NEWLINE> import random <NEWLINE> import numpy <NEWLINE> import dendropy <NEWLINE> import re <NEWLINE> from Bio import Phylo <NEWLINE> from cStringIO import StringIO <NEWLINE>", "anonymize_dict": {}}], ["258f6557cbe3796437ee57fd40548833", {"code_string": "def factor_result(base_result: dict, result_type: ResultType) -> dict:\n    if result_type == ResultType.Field:\n        base_result[\"result_type\"] = result_type\n    elif result_type == ResultType.ListField:\n        base_result[\"result_type\"] = result_type\n    elif result_type == ResultType.ListFieldItem:\n        base_result[\"result_type\"] = result_type\n    return base_result\n", "code_toks_joined": "def factor_result ( base_result : dict , result_type : ResultType ) -> dict : <NEWLINE> <INDENT> if result_type == ResultType . Field : <NEWLINE> <INDENT> base_result [ <STRING> ] = result_type <NEWLINE> <DEDENT> elif result_type == ResultType . ListField : <NEWLINE> <INDENT> base_result [ <STRING> ] = result_type <NEWLINE> <DEDENT> elif result_type == ResultType . ListFieldItem : <NEWLINE> <INDENT> base_result [ <STRING> ] = result_type <NEWLINE> <DEDENT> return base_result <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"result_type\"", "\"result_type\"", "\"result_type\""]}}], ["c61dd224cec23c6102926411fd56190a", {"code_string": "class LoginForm(FlaskForm):\n    username = StringField('username', validators = [DataRequired()])\n    password = StringField('password', validators = [DataRequired()])\n    redirectonlogin = StringField('redirectonlogin', default = 'true', validators = [])\n", "code_toks_joined": "class LoginForm ( FlaskForm ) : <NEWLINE> <INDENT> username = StringField ( <STRING> , validators = [ DataRequired ( ) ] ) <NEWLINE> password = StringField ( <STRING> , validators = [ DataRequired ( ) ] ) <NEWLINE> redirectonlogin = StringField ( <STRING> , default = <STRING> , validators = [ ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'username'", "'password'", "'redirectonlogin'", "'true'"]}}], ["085b10f1091bd8664a7befada475a8f5", {"code_string": "def get_back_file_rarity(back_file_name):\n    for r in BACK_FILE_DICT.keys():\n        if(is_a_back_file_with_rarity(r, back_file_name)):\n            return r\n", "code_toks_joined": "def get_back_file_rarity ( back_file_name ) : <NEWLINE> <INDENT> for r in BACK_FILE_DICT . keys ( ) : <NEWLINE> <INDENT> if ( is_a_back_file_with_rarity ( r , back_file_name ) ) : <NEWLINE> <INDENT> return r <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["1acb7d777a1bcfa92be5a78140a46d67", {"code_string": "def task6(a, b):\n    if isinstance(a, str) or isinstance(b, str):\n        return \"\u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0430 \u0441\u0442\u0440\u043e\u043a\u0430\"\n    else:\n        if a > b:\n            return \"\u0431\u043e\u043b\u044c\u0448\u0435\"\n        elif a == b:\n            return \"\u0440\u0430\u0432\u043d\u044b\"\n        elif a < b:\n            return \"\u043c\u0435\u043d\u044c\u0448\u0435\"\n", "code_toks_joined": "def task6 ( a , b ) : <NEWLINE> <INDENT> if isinstance ( a , str ) or isinstance ( b , str ) : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> if a > b : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> elif a == b : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> elif a < b : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0430 \u0441\u0442\u0440\u043e\u043a\u0430\"", "\"\u0431\u043e\u043b\u044c\u0448\u0435\"", "\"\u0440\u0430\u0432\u043d\u044b\"", "\"\u043c\u0435\u043d\u044c\u0448\u0435\""]}}], ["4faa119f43bfab566b9a4a623d595ad5", {"code_string": "from.demo import *\nSITE = Site(\n    globals(),\n    use_java = True,\n    ignore_model_errors = True,\n    remote_user_header = 'REMOTE_USER')\nDEBUG = True\nSITE.webdav_url = '/'\n", "code_toks_joined": "from . demo import * <NEWLINE> SITE = Site ( <NEWLINE> <INDENT> globals ( ) , <NEWLINE> use_java = True , <NEWLINE> ignore_model_errors = True , <NEWLINE> remote_user_header = <STRING> ) <NEWLINE> <DEDENT> DEBUG = True <NEWLINE> SITE . webdav_url = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'REMOTE_USER'", "'/'"]}}], ["b03fe2e44deb25bcb1e104690b5b2414", {"code_string": "def detail(self, req, resp_obj):\n    context = req.environ['nova.context']\n    if instance_authorize(context):\n        resp_obj.attach(xml = PciServersTemplate())\n        servers = list(resp_obj.obj['servers'])\n        for server in servers:\n            instance = req.get_db_instance(server['id'])\n            self._extend_server(server, instance)\n", "code_toks_joined": "def detail ( self , req , resp_obj ) : <NEWLINE> <INDENT> context = req . environ [ <STRING> ] <NEWLINE> if instance_authorize ( context ) : <NEWLINE> <INDENT> resp_obj . attach ( xml = PciServersTemplate ( ) ) <NEWLINE> servers = list ( resp_obj . obj [ <STRING> ] ) <NEWLINE> for server in servers : <NEWLINE> <INDENT> instance = req . get_db_instance ( server [ <STRING> ] ) <NEWLINE> self . _extend_server ( server , instance ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'nova.context'", "'servers'", "'id'"]}}], ["c9cbdfce18c5adbc505a90a4452017bb", {"code_string": "import pyblish.main\npyblish.main.publish()\n", "code_toks_joined": "import pyblish . main <NEWLINE> pyblish . main . publish ( ) <NEWLINE>", "anonymize_dict": {}}], ["6d3555fe6712a01a866ef3fe12f02cad", {"code_string": "\"\"\"This module extends the Destination class to work with the HDF5 file format.\"\"\"\nimport os\nimport json\nimport h5py\nimport numpy as np\nfrom origin.server import Destination\nfrom origin import data_types, TIMESTAMP\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> import json <NEWLINE> import h5py <NEWLINE> import numpy as np <NEWLINE> from origin . server import Destination <NEWLINE> from origin import data_types , TIMESTAMP <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"This module extends the Destination class to work with the HDF5 file format.\"\"\""]}}], ["9b0306e7ef9b7fa075ff387e7157a90d", {"code_string": "def test_logger_connection_id(self):\n    log = logging.getLogger(__name__)\n    log.connection_id = 'test'\n    self.assertEqual(log.connection_id, 'test')\n    del log.connection_id\n    self.assertEqual(log.connection_id, '')\n", "code_toks_joined": "def test_logger_connection_id ( self ) : <NEWLINE> <INDENT> log = logging . getLogger ( __name__ ) <NEWLINE> log . connection_id = <STRING> <NEWLINE> self . assertEqual ( log . connection_id , <STRING> ) <NEWLINE> del log . connection_id <NEWLINE> self . assertEqual ( log . connection_id , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'test'", "'test'", "''"]}}], ["d15946213ca4d2b2365330a67755a9cd", {"code_string": "def edge_splits(t, taxa):\n    splits = t.splits()\n    splits = filter(lambda x: len(x[0]) != 1 and len(x[1]) != 1, splits)\n    ret = []\n    for split in splits:\n        s = \"\"\n        for i in range(len(taxa)):\n            if taxa[i] in split[0]:\n                s += \"1\"\n            else:\n                s += \"0\"\n        ret.append(s)\n    return ret\n", "code_toks_joined": "def edge_splits ( t , taxa ) : <NEWLINE> <INDENT> splits = t . splits ( ) <NEWLINE> splits = filter ( lambda x : len ( x [ 0 ] ) != 1 and len ( x [ 1 ] ) != 1 , splits ) <NEWLINE> ret = [ ] <NEWLINE> for split in splits : <NEWLINE> <INDENT> s = <STRING> <NEWLINE> for i in range ( len ( taxa ) ) : <NEWLINE> <INDENT> if taxa [ i ] in split [ 0 ] : <NEWLINE> <INDENT> s += <STRING> <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> s += <STRING> <NEWLINE> <DEDENT> <DEDENT> ret . append ( s ) <NEWLINE> <DEDENT> return ret <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"", "\"1\"", "\"0\""]}}], ["4914dd666368b67b9029677ef79ba0ab", {"code_string": "def __init__(self, ** kwargs):\n    self.availableOptions.update({\n        'always': True,\n        'class': 'Q15618652',\n        'min_labels': 1,\n    })\n    super(DuosManagingBot, self).__init__(** kwargs)\n    self.store = QueryStore()\n", "code_toks_joined": "def __init__ ( self , ** kwargs ) : <NEWLINE> <INDENT> self . availableOptions . update ( { <NEWLINE> <INDENT> <STRING> : True , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : 1 , <NEWLINE> <DEDENT> } ) <NEWLINE> super ( DuosManagingBot , self ) . __init__ ( ** kwargs ) <NEWLINE> self . store = QueryStore ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'always'", "'class'", "'Q15618652'", "'min_labels'"]}}], ["ebe366360370633b561f193880438b61", {"code_string": "def false_value(self, value):\n    if not value:\n        value = None\n    else:\n        value = str(value)\n    original_value = self._name\n    if value != original_value:\n        self._false_value = value\n        self._false_value_changed(self, original_value, value)\n", "code_toks_joined": "def false_value ( self , value ) : <NEWLINE> <INDENT> if not value : <NEWLINE> <INDENT> value = None <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> value = str ( value ) <NEWLINE> <DEDENT> original_value = self . _name <NEWLINE> if value != original_value : <NEWLINE> <INDENT> self . _false_value = value <NEWLINE> self . _false_value_changed ( self , original_value , value ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["a1dc3017c9cbe85b68de0bbeac9bdf9e", {"code_string": "\"\"\"testing chef api\"\"\"\nimport os\nimport ruamel.yaml as yaml\nfrom ddf_utils.chef.api import Chef\nfrom ddf_utils.chef.ingredient import Ingredient\nfrom ddf_utils.chef.exceptions import IngredientError\nwd = os.path.dirname(__file__)\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> import ruamel . yaml as yaml <NEWLINE> from ddf_utils . chef . api import Chef <NEWLINE> from ddf_utils . chef . ingredient import Ingredient <NEWLINE> from ddf_utils . chef . exceptions import IngredientError <NEWLINE> wd = os . path . dirname ( __file__ ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"testing chef api\"\"\""]}}], ["8900e74782d4e4cfcbe95f10cbe214f5", {"code_string": "def get_latest_plans(self, date):\n    iso_dt = parse_date(date)\n    dt = iso_dt.strftime(\"%Y-%m-%d\")\n    tm = iso_dt.strftime(\"%H:%M:%S\")\n    response = self._get_resource_item(\n        '{}?offset={}T{}&opt_fields=plan_id&mode=test'.format(\n            self.prefix_path,\n            dt,\n            tm\n        )\n    )\n    if response.status_int == 200:\n        plan_list = munchify(loads(response.body_string()))\n        self._update_params(plan_list.next_page)\n        return plan_list.data\n    raise InvalidResponse\n", "code_toks_joined": "def get_latest_plans ( self , date ) : <NEWLINE> <INDENT> iso_dt = parse_date ( date ) <NEWLINE> dt = iso_dt . strftime ( <STRING> ) <NEWLINE> tm = iso_dt . strftime ( <STRING> ) <NEWLINE> response = self . _get_resource_item ( <NEWLINE> <INDENT> <STRING> . format ( <NEWLINE> <INDENT> self . prefix_path , <NEWLINE> dt , <NEWLINE> tm <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> ) <NEWLINE> if response . status_int == 200 : <NEWLINE> <INDENT> plan_list = munchify ( loads ( response . body_string ( ) ) ) <NEWLINE> self . _update_params ( plan_list . next_page ) <NEWLINE> return plan_list . data <NEWLINE> <DEDENT> raise InvalidResponse <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"%Y-%m-%d\"", "\"%H:%M:%S\"", "'{}?offset={}T{}&opt_fields=plan_id&mode=test'"]}}], ["3e9f7275fc2da77f803b00ba6d824e66", {"code_string": "def removeQuotes(line):\n    for i in range(len(line)):\n        if line[i][0] == '\"': line[i] = line[i][1: ]\n        if line[i][- 1] == '\"': line[i] = line[i][: - 1]\n", "code_toks_joined": "def removeQuotes ( line ) : <NEWLINE> <INDENT> for i in range ( len ( line ) ) : <NEWLINE> <INDENT> if line [ i ] [ 0 ] == <STRING> : line [ i ] = line [ i ] [ 1 : ] <NEWLINE> if line [ i ] [ - 1 ] == <STRING> : line [ i ] = line [ i ] [ : - 1 ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'\"'", "'\"'"]}}], ["672d5fea4d33a6e6d110157f9005a219", {"code_string": "def init(self, ** parameters):\n    self.instance.run_commands(\n        'cd ' + self.dir,\n        'composer install --no-scripts',\n        'cp app/config/parameters.yml.dist app/config/parameters.yml'\n    )\n    if parameters:\n        self.set_parameters(** parameters)\n", "code_toks_joined": "def init ( self , ** parameters ) : <NEWLINE> <INDENT> self . instance . run_commands ( <NEWLINE> <INDENT> <STRING> + self . dir , <NEWLINE> <STRING> , <NEWLINE> <STRING> <NEWLINE> <DEDENT> ) <NEWLINE> if parameters : <NEWLINE> <INDENT> self . set_parameters ( ** parameters ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'cd '", "'composer install --no-scripts'", "'cp app/config/parameters.yml.dist app/config/parameters.yml'"]}}], ["52ccf787d9d36c350ac8bc859a4b29e4", {"code_string": "def __init__(self, sender = None, * a, ** k):\n    super(ModInputSignal, self).__init__(sender = sender, * a, ** k)\n    self._input_control = sender\n", "code_toks_joined": "def __init__ ( self , sender = None , * a , ** k ) : <NEWLINE> <INDENT> super ( ModInputSignal , self ) . __init__ ( sender = sender , * a , ** k ) <NEWLINE> self . _input_control = sender <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["9bea25583494204a11bd45aa3f52dbf6", {"code_string": "def get_max_product(n, k, num):\n    str_n = list(str(num))\n    result = - 1;\n    for i in xrange(n - k):\n        temp = 1\n        for j in map(int, str_n[i: i + k]):\n            temp = temp * j\n        if result < temp:\n            result = temp\n    return result\n", "code_toks_joined": "def get_max_product ( n , k , num ) : <NEWLINE> <INDENT> str_n = list ( str ( num ) ) <NEWLINE> result = - 1 ; <NEWLINE> for i in xrange ( n - k ) : <NEWLINE> <INDENT> temp = 1 <NEWLINE> for j in map ( int , str_n [ i : i + k ] ) : <NEWLINE> <INDENT> temp = temp * j <NEWLINE> <DEDENT> if result < temp : <NEWLINE> <INDENT> result = temp <NEWLINE> <DEDENT> <DEDENT> return result <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["585873b5046582f20c929e6a2d420706", {"code_string": "def splitPathFN(PathFN):\n    Dir, FN = os.path.split(PathFN)\n    BN = os.path.splitext(FN)[0]\n    DIRBN = Dir + \"/\" + BN\n    return(FN, BN, Dir, DIRBN, PathFN)\n", "code_toks_joined": "def splitPathFN ( PathFN ) : <NEWLINE> <INDENT> Dir , FN = os . path . split ( PathFN ) <NEWLINE> BN = os . path . splitext ( FN ) [ 0 ] <NEWLINE> DIRBN = Dir + <STRING> + BN <NEWLINE> return ( FN , BN , Dir , DIRBN , PathFN ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"/\""]}}], ["8362079f4887254254d6d49e0c3aae1f", {"code_string": "def compute_bins(interval):\n    \"\"\" Make even intervals centered around zero\"\"\"\n    halfsz = interval / 2.\n    multi = int(80. / interval)\n    v = halfsz + interval * multi\n    return np.arange(0 - v, v + 0.1, interval)\n", "code_toks_joined": "def compute_bins ( interval ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> halfsz = interval / 2. <NEWLINE> multi = int ( 80. / interval ) <NEWLINE> v = halfsz + interval * multi <NEWLINE> return np . arange ( 0 - v , v + 0.1 , interval ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Make even intervals centered around zero\"\"\""]}}], ["6c338ed0fb9a50dccabeaa2c029e8288", {"code_string": "def test_get_header(self):\n    robj = wsgi.ResponseObject({})\n    robj['Header'] = 'foo'\n    self.assertEqual(robj['hEADER'], 'foo')\n", "code_toks_joined": "def test_get_header ( self ) : <NEWLINE> <INDENT> robj = wsgi . ResponseObject ( { } ) <NEWLINE> robj [ <STRING> ] = <STRING> <NEWLINE> self . assertEqual ( robj [ <STRING> ] , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Header'", "'foo'", "'hEADER'", "'foo'"]}}], ["083604774a9ddef75d7025e71d973bcc", {"code_string": "def get_uid(oauth_token):\n    r = requests.get(\"%s/users/me/?token=%s\" %(eb_api_endpoint, oauth_token))\n    return r.json()['id']\n", "code_toks_joined": "def get_uid ( oauth_token ) : <NEWLINE> <INDENT> r = requests . get ( <STRING> % ( eb_api_endpoint , oauth_token ) ) <NEWLINE> return r . json ( ) [ <STRING> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"%s/users/me/?token=%s\"", "'id'"]}}], ["f0600013c172d746002fafdc484d8aed", {"code_string": "def get_value(self):\n    has_ace = False\n    result = 0\n    for card in self.__cards:\n        value = VALUES[card.get_rank()]\n        result += value\n        if value == 1:\n            has_ace = True\n    if has_ace and result + 10 <= 21:\n        result += 10\n    return result\n", "code_toks_joined": "def get_value ( self ) : <NEWLINE> <INDENT> has_ace = False <NEWLINE> result = 0 <NEWLINE> for card in self . __cards : <NEWLINE> <INDENT> value = VALUES [ card . get_rank ( ) ] <NEWLINE> result += value <NEWLINE> if value == 1 : <NEWLINE> <INDENT> has_ace = True <NEWLINE> <DEDENT> <DEDENT> if has_ace and result + 10 <= 21 : <NEWLINE> <INDENT> result += 10 <NEWLINE> <DEDENT> return result <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["3e6be6e2e5db0f29d61463397fa1487f", {"code_string": "def pdfparser(file_name):\n    fp = file(file_name, 'rb')\n    rsrcmgr = PDFResourceManager()\n    retstr = StringIO()\n    codec = 'utf-8'\n    laparams = LAParams()\n    device = TextConverter(rsrcmgr, retstr, codec = codec, laparams = laparams)\n    interpreter = PDFPageInterpreter(rsrcmgr, device)\n    for page in PDFPage.get_pages(fp):\n        interpreter.process_page(page)\n        data = retstr.getvalue()\n    return data\n", "code_toks_joined": "def pdfparser ( file_name ) : <NEWLINE> <INDENT> fp = file ( file_name , <STRING> ) <NEWLINE> rsrcmgr = PDFResourceManager ( ) <NEWLINE> retstr = StringIO ( ) <NEWLINE> codec = <STRING> <NEWLINE> laparams = LAParams ( ) <NEWLINE> device = TextConverter ( rsrcmgr , retstr , codec = codec , laparams = laparams ) <NEWLINE> interpreter = PDFPageInterpreter ( rsrcmgr , device ) <NEWLINE> for page in PDFPage . get_pages ( fp ) : <NEWLINE> <INDENT> interpreter . process_page ( page ) <NEWLINE> data = retstr . getvalue ( ) <NEWLINE> <DEDENT> return data <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'rb'", "'utf-8'"]}}], ["8534d443620ac069841d56869a43a363", {"code_string": "from ypip.sources.requirements_txt import RequirementsTxt\nfrom ypip.sources.git_github import GitOnGitHub\nfrom ypip.sources.pip_fallback import PipFallback\n", "code_toks_joined": "from ypip . sources . requirements_txt import RequirementsTxt <NEWLINE> from ypip . sources . git_github import GitOnGitHub <NEWLINE> from ypip . sources . pip_fallback import PipFallback <NEWLINE>", "anonymize_dict": {}}], ["5f828fb9f3232c0df6a01546d13d48f2", {"code_string": "import eventlet\nimport falcon\nfrom eventlet import wsgi\nfrom include.common.db.db_connection_handler import DbConnectionHandler\nfrom include.web_server.css_manager import CssManager\nfrom include.web_server.endpoints.generic_endpoint import GenericEndpoint\nfrom include.web_server.endpoints.home_endpoint import HomeEndpoint\nfrom include.web_server.endpoints.logout_endpoint import LogoutEndpoint\nfrom include.web_server.endpoints.user_details_endpoint import UserDetailsEndpoint\nfrom include.web_server.endpoints.users_list_endpoint import UsersListEndpoint\nfrom include.web_server.web_links_factory import WebLinksFactory\nDbConnectionHandler.initialize_db_connection_handler()\n", "code_toks_joined": "import eventlet <NEWLINE> import falcon <NEWLINE> from eventlet import wsgi <NEWLINE> from include . common . db . db_connection_handler import DbConnectionHandler <NEWLINE> from include . web_server . css_manager import CssManager <NEWLINE> from include . web_server . endpoints . generic_endpoint import GenericEndpoint <NEWLINE> from include . web_server . endpoints . home_endpoint import HomeEndpoint <NEWLINE> from include . web_server . endpoints . logout_endpoint import LogoutEndpoint <NEWLINE> from include . web_server . endpoints . user_details_endpoint import UserDetailsEndpoint <NEWLINE> from include . web_server . endpoints . users_list_endpoint import UsersListEndpoint <NEWLINE> from include . web_server . web_links_factory import WebLinksFactory <NEWLINE> DbConnectionHandler . initialize_db_connection_handler ( ) <NEWLINE>", "anonymize_dict": {}}], ["e65e6215675ef5d56ded374a4e36e403", {"code_string": "import unittest\nimport tempfile\nfrom mathics.core.parser.feed import SingleLineFeeder, MultiLineFeeder, FileLineFeeder\n", "code_toks_joined": "import unittest <NEWLINE> import tempfile <NEWLINE> from mathics . core . parser . feed import SingleLineFeeder , MultiLineFeeder , FileLineFeeder <NEWLINE>", "anonymize_dict": {}}], ["6fe21bf77707215d236691f883754905", {"code_string": "class OperationDisplay(Model):\n    \"\"\"The object that represents the operation.\"\"\"\n    _validation = {\n        'provider': {'readonly': True},\n        'resource': {'readonly': True},\n        'operation': {'readonly': True},\n    }\n    _attribute_map = {\n        'provider': {'key': 'provider', 'type': 'str'},\n        'resource': {'key': 'resource', 'type': 'str'},\n        'operation': {'key': 'operation', 'type': 'str'},\n    }\n    def __init__(self):\n        self.provider = None\n        self.resource = None\n        self.operation = None\n", "code_toks_joined": "class OperationDisplay ( Model ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> _validation = { <NEWLINE> <INDENT> <STRING> : { <STRING> : True } , <NEWLINE> <STRING> : { <STRING> : True } , <NEWLINE> <STRING> : { <STRING> : True } , <NEWLINE> <DEDENT> } <NEWLINE> _attribute_map = { <NEWLINE> <INDENT> <STRING> : { <STRING> : <STRING> , <STRING> : <STRING> } , <NEWLINE> <STRING> : { <STRING> : <STRING> , <STRING> : <STRING> } , <NEWLINE> <STRING> : { <STRING> : <STRING> , <STRING> : <STRING> } , <NEWLINE> <DEDENT> } <NEWLINE> def __init__ ( self ) : <NEWLINE> <INDENT> self . provider = None <NEWLINE> self . resource = None <NEWLINE> self . operation = None <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"The object that represents the operation.\"\"\"", "'provider'", "'readonly'", "'resource'", "'readonly'", "'operation'", "'readonly'", "'provider'", "'key'", "'provider'", "'type'", "'str'", "'resource'", "'key'", "'resource'", "'type'", "'str'", "'operation'", "'key'", "'operation'", "'type'", "'str'"]}}], ["7463c93349d21e0a7f2245d7fa2bea86", {"code_string": "class RelationInline(admin.StackedInline):\n    extra = 1\n    fk_name = 'child'\n    model = models.Relation\n", "code_toks_joined": "class RelationInline ( admin . StackedInline ) : <NEWLINE> <INDENT> extra = 1 <NEWLINE> fk_name = <STRING> <NEWLINE> model = models . Relation <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'child'"]}}], ["34b4d090d8b2f91b698be725e9642e24", {"code_string": "def addRef(self, blockName):\n    assert not blockName in self._refTo\n    self._refTo.add(blockName)\n", "code_toks_joined": "def addRef ( self , blockName ) : <NEWLINE> <INDENT> assert not blockName in self . _refTo <NEWLINE> self . _refTo . add ( blockName ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["d6737fed84144091fcb241eb2331cfce", {"code_string": "def testNewStyleIndividualAudioRoute(self):\n    \"\"\"Tests fetching an individual audio clip from an old-style summary.\"\"\"\n    response = self.server.get(\n        \"/data/plugin/audio/individualAudio\"\n        \"?run=bar&tag=quux/audio_summary&sample=0&index=0\")\n    self.assertEqual(200, response.status_code)\n    self.assertEqual(\"audio/wav\", response.headers.get(\"content-type\"))\n", "code_toks_joined": "def testNewStyleIndividualAudioRoute ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> response = self . server . get ( <NEWLINE> <INDENT> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <DEDENT> self . assertEqual ( 200 , response . status_code ) <NEWLINE> self . assertEqual ( <STRING> , response . headers . get ( <STRING> ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Tests fetching an individual audio clip from an old-style summary.\"\"\"", "\"/data/plugin/audio/individualAudio\"", "\"?run=bar&tag=quux/audio_summary&sample=0&index=0\"", "\"audio/wav\"", "\"content-type\""]}}], ["e4711b9f7fbd518bba50af0dca594388", {"code_string": "def enclose_in_double_quotes(query_txt):\n    \"\"\"Encloses each word in query_txt in double quotes.\"\"\"\n    query_words = query_txt.split(' ')\n    return '\"' + '\" \"'.join([word for word in query_words if word]) + '\"'\n", "code_toks_joined": "def enclose_in_double_quotes ( query_txt ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> query_words = query_txt . split ( <STRING> ) <NEWLINE> return <STRING> + <STRING> . join ( [ word for word in query_words if word ] ) + <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Encloses each word in query_txt in double quotes.\"\"\"", "' '", "'\"'", "'\" \"'", "'\"'"]}}], ["db94e49bde8bb42e25bb7da590aa8697", {"code_string": "class WagtailRoutablePageTestsAppConfig(AppConfig):\n    name = 'wagtail.tests.routablepage'\n    label = 'routablepagetests'\n    verbose_name = \"Wagtail routable page tests\"\n", "code_toks_joined": "class WagtailRoutablePageTestsAppConfig ( AppConfig ) : <NEWLINE> <INDENT> name = <STRING> <NEWLINE> label = <STRING> <NEWLINE> verbose_name = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'wagtail.tests.routablepage'", "'routablepagetests'", "\"Wagtail routable page tests\""]}}], ["3965de0ab72d06b457747d53cb1748c1", {"code_string": "from cStringIO import StringIO\nimport mock\nfrom nose.tools import eq_, ok_\nfrom funfactory.urlresolvers import reverse\nfrom airmozilla.main.models import Event\nfrom.base import ManageTestCase\nfrom airmozilla.manage.tests.test_vidly import SAMPLE_MEDIALIST_XML\n", "code_toks_joined": "from cStringIO import StringIO <NEWLINE> import mock <NEWLINE> from nose . tools import eq_ , ok_ <NEWLINE> from funfactory . urlresolvers import reverse <NEWLINE> from airmozilla . main . models import Event <NEWLINE> from . base import ManageTestCase <NEWLINE> from airmozilla . manage . tests . test_vidly import SAMPLE_MEDIALIST_XML <NEWLINE>", "anonymize_dict": {}}], ["4915d5035eeaadc1a8420307fcca0d6b", {"code_string": "\"\"\"(c) All rights reserved. ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE, Switzerland, VPSI, 2017\"\"\"\nfrom django.test import TestCase\nfrom api.apikey import APIKey\nfrom api.redis import save_key, exists, get_apikeys, flush_all\nfrom config.settings.base import get_config\nfrom api.apikeyhandler import ApiKeyHandler\n", "code_toks_joined": "<STRING> <NEWLINE> from django . test import TestCase <NEWLINE> from api . apikey import APIKey <NEWLINE> from api . redis import save_key , exists , get_apikeys , flush_all <NEWLINE> from config . settings . base import get_config <NEWLINE> from api . apikeyhandler import ApiKeyHandler <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"(c) All rights reserved. ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE, Switzerland, VPSI, 2017\"\"\""]}}], ["ad2ecace03c8e91f003bef046e576750", {"code_string": "def handle_process(conn, data):\n    command = struct.unpack(b\"!I\", data[: 4])[0]\n    data = data[4: ]\n    content = public.pack_dict.loads_json_unicode(data)\n    print(__name__, \"handle_process\", command, content)\n    process = HANDLE_PROCESS.get(command)\n    if not process:\n        print(__name__, \"handle_process no math\", command, content)\n        return\n    process(conn, content)\n", "code_toks_joined": "def handle_process ( conn , data ) : <NEWLINE> <INDENT> command = struct . unpack ( <STRING> , data [ : 4 ] ) [ 0 ] <NEWLINE> data = data [ 4 : ] <NEWLINE> content = public . pack_dict . loads_json_unicode ( data ) <NEWLINE> print ( __name__ , <STRING> , command , content ) <NEWLINE> process = HANDLE_PROCESS . get ( command ) <NEWLINE> if not process : <NEWLINE> <INDENT> print ( __name__ , <STRING> , command , content ) <NEWLINE> return <NEWLINE> <DEDENT> process ( conn , content ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["b\"!I\"", "\"handle_process\"", "\"handle_process no math\""]}}], ["0bbd9fdb4f9e946b158df18164352413", {"code_string": "def css_files(self):\n    result = []\n    for f in self._get_resources(\"css_files\"):\n        if isinstance(f, (unicode_type, bytes_type)):\n            result.append(f)\n        else:\n            result.extend(f)\n    return result\n", "code_toks_joined": "def css_files ( self ) : <NEWLINE> <INDENT> result = [ ] <NEWLINE> for f in self . _get_resources ( <STRING> ) : <NEWLINE> <INDENT> if isinstance ( f , ( unicode_type , bytes_type ) ) : <NEWLINE> <INDENT> result . append ( f ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> result . extend ( f ) <NEWLINE> <DEDENT> <DEDENT> return result <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"css_files\""]}}], ["6a718954ee32401f67c0bb5d1c7221ac", {"code_string": "def do_ngram(ori, mode, num):\n    if mode == \"word\":\n        str = []\n        str = ori.split()\n    elif mode == \"char\":\n        str = \"\"\n        str = ori.replace(\" \", \"\")\n    i = 0\n    n = num\n    ngram = []\n    while i < len(str) - 1:\n        ngram.append(str[i: n])\n        i += 1\n        n += 1\n    return ngram\n", "code_toks_joined": "def do_ngram ( ori , mode , num ) : <NEWLINE> <INDENT> if mode == <STRING> : <NEWLINE> <INDENT> str = [ ] <NEWLINE> str = ori . split ( ) <NEWLINE> <DEDENT> elif mode == <STRING> : <NEWLINE> <INDENT> str = <STRING> <NEWLINE> str = ori . replace ( <STRING> , <STRING> ) <NEWLINE> <DEDENT> i = 0 <NEWLINE> n = num <NEWLINE> ngram = [ ] <NEWLINE> while i < len ( str ) - 1 : <NEWLINE> <INDENT> ngram . append ( str [ i : n ] ) <NEWLINE> i += 1 <NEWLINE> n += 1 <NEWLINE> <DEDENT> return ngram <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"word\"", "\"char\"", "\"\"", "\" \"", "\"\""]}}], ["efeb98a406afa8d2534ebdb490a595d7", {"code_string": "def handleClientRequest(request, successorSocket):\n    clientId = request['id']\n    clientAddress = request['answer_to']\n    sc = context.socket(zmq.PUSH)\n    sc.connect(clientAddress)\n    clients[clientId] = sc\n    key = request['key']\n    if in_range(key):\n        print(\"Key {} is mine!\".format(key))\n        localOP(request)\n    else:\n        print(\"Key {} is not mine, delegating...\".format(key))\n        successorSocket.send_json(request)\n", "code_toks_joined": "def handleClientRequest ( request , successorSocket ) : <NEWLINE> <INDENT> clientId = request [ <STRING> ] <NEWLINE> clientAddress = request [ <STRING> ] <NEWLINE> sc = context . socket ( zmq . PUSH ) <NEWLINE> sc . connect ( clientAddress ) <NEWLINE> clients [ clientId ] = sc <NEWLINE> key = request [ <STRING> ] <NEWLINE> if in_range ( key ) : <NEWLINE> <INDENT> print ( <STRING> . format ( key ) ) <NEWLINE> localOP ( request ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> print ( <STRING> . format ( key ) ) <NEWLINE> successorSocket . send_json ( request ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'id'", "'answer_to'", "'key'", "\"Key {} is mine!\"", "\"Key {} is not mine, delegating...\""]}}], ["73c7526afb09d5b6aa24ee5ebda7055e", {"code_string": "def sum_values_generator(kvi):\n    for k, vs in kvi:\n        try:\n            yield k, sum(vs)\n        except TypeError:\n            yield k, vs\n", "code_toks_joined": "def sum_values_generator ( kvi ) : <NEWLINE> <INDENT> for k , vs in kvi : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> yield k , sum ( vs ) <NEWLINE> <DEDENT> except TypeError : <NEWLINE> <INDENT> yield k , vs <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["6f6f140f2018e2a4ce7f7f49f36f5af7", {"code_string": "def standard_cl_params(items):\n    \"\"\"Shared command line parameters for GATK programs.\"\"\"\n    out = []\n    def _skip_duplicates(data):\n        return(dd.get_coverage_interval(data) == \"amplicon\" or\n            (dd.get_aligner(data) and not dd.get_mark_duplicates(data)))\n    if any(_skip_duplicates(d) for d in items):\n        broad_runner = broad.runner_from_config(items[0][\"config\"])\n        if LooseVersion(broad_runner.gatk_major_version()) >= LooseVersion(\"3.5\"):\n            out +=[\"-drf\", \"DuplicateRead\"]\n    return out\n", "code_toks_joined": "def standard_cl_params ( items ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> out = [ ] <NEWLINE> def _skip_duplicates ( data ) : <NEWLINE> <INDENT> return ( dd . get_coverage_interval ( data ) == <STRING> or <NEWLINE> <INDENT> ( dd . get_aligner ( data ) and not dd . get_mark_duplicates ( data ) ) ) <NEWLINE> <DEDENT> <DEDENT> if any ( _skip_duplicates ( d ) for d in items ) : <NEWLINE> <INDENT> broad_runner = broad . runner_from_config ( items [ 0 ] [ <STRING> ] ) <NEWLINE> if LooseVersion ( broad_runner . gatk_major_version ( ) ) >= LooseVersion ( <STRING> ) : <NEWLINE> <INDENT> out += [ <STRING> , <STRING> ] <NEWLINE> <DEDENT> <DEDENT> return out <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Shared command line parameters for GATK programs.\"\"\"", "\"amplicon\"", "\"config\"", "\"3.5\"", "\"-drf\"", "\"DuplicateRead\""]}}], ["fad013266ddedef5e0c2d2c75f88e6a3", {"code_string": "import json\nfrom crypt import encrypt, decrypt\nfrom google.appengine.ext import ndb\n", "code_toks_joined": "import json <NEWLINE> from crypt import encrypt , decrypt <NEWLINE> from google . appengine . ext import ndb <NEWLINE>", "anonymize_dict": {}}], ["27c399842ec5a67109fbda3bb82210a8", {"code_string": "class CommandEchoer():\n    def __init__(self):\n        pass\n    def solr_query_raw(self, query_string):\n        return query_string\n    def solr_query(self, applied_facets = None, filter_queries = None):\n        return applied_facets, filter_queries\n    def get_science_object_through_cache(self, pid):\n        return pid\n    def get_system_metadata_through_cache(self, pid):\n        return pid\n", "code_toks_joined": "class CommandEchoer ( ) : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def solr_query_raw ( self , query_string ) : <NEWLINE> <INDENT> return query_string <NEWLINE> <DEDENT> def solr_query ( self , applied_facets = None , filter_queries = None ) : <NEWLINE> <INDENT> return applied_facets , filter_queries <NEWLINE> <DEDENT> def get_science_object_through_cache ( self , pid ) : <NEWLINE> <INDENT> return pid <NEWLINE> <DEDENT> def get_system_metadata_through_cache ( self , pid ) : <NEWLINE> <INDENT> return pid <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["c49fd51821b93ef3691ad2a78486c750", {"code_string": "def create_omf_iface(ec, ip, node):\n    iface = ec.register_resource(\"omf::WifiInterface\")\n    ec.set(iface, 'name', 'wlan0')\n    ec.set(iface, 'mode', \"adhoc\")\n    ec.set(iface, 'hw_mode', \"g\")\n    ec.set(iface, 'essid', \"vlc\")\n    ec.set(iface, 'ip', ip)\n    ec.register_connection(iface, node)\n    return iface\n", "code_toks_joined": "def create_omf_iface ( ec , ip , node ) : <NEWLINE> <INDENT> iface = ec . register_resource ( <STRING> ) <NEWLINE> ec . set ( iface , <STRING> , <STRING> ) <NEWLINE> ec . set ( iface , <STRING> , <STRING> ) <NEWLINE> ec . set ( iface , <STRING> , <STRING> ) <NEWLINE> ec . set ( iface , <STRING> , <STRING> ) <NEWLINE> ec . set ( iface , <STRING> , ip ) <NEWLINE> ec . register_connection ( iface , node ) <NEWLINE> return iface <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"omf::WifiInterface\"", "'name'", "'wlan0'", "'mode'", "\"adhoc\"", "'hw_mode'", "\"g\"", "'essid'", "\"vlc\"", "'ip'"]}}], ["5c10aa478caeb8238ce61ba16e8dddba", {"code_string": "def conv_to_double_link(self, head):\n    pre = None\n    root = head\n    while root:\n        if not root.left:\n            root.left = pre\n            pre = root\n            root = root.right\n        else:\n            p = root.left\n            while p.right:\n                p = p.right\n            p.right = root.right\n            root.right = root.left\n            root.left = None\n    return head\n", "code_toks_joined": "def conv_to_double_link ( self , head ) : <NEWLINE> <INDENT> pre = None <NEWLINE> root = head <NEWLINE> while root : <NEWLINE> <INDENT> if not root . left : <NEWLINE> <INDENT> root . left = pre <NEWLINE> pre = root <NEWLINE> root = root . right <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> p = root . left <NEWLINE> while p . right : <NEWLINE> <INDENT> p = p . right <NEWLINE> <DEDENT> p . right = root . right <NEWLINE> root . right = root . left <NEWLINE> root . left = None <NEWLINE> <DEDENT> <DEDENT> return head <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["8ba95f068cab1d47f5e891f6296a7539", {"code_string": "def test_lp_all(dummy_site):\n    '''Test the List Projects command'''\n    s = dummy_site(lambda x: [x], '2.7.0')\n    cmd = ProjectList('--all').execute_on(s)\n    assert len(cmd) == 1\n    assert cmd[0] == 'ls-projects --all'\n    cmd = ProjectList().execute_on(s)\n    assert len(cmd) == 1\n    assert cmd[0] == 'ls-projects'\n", "code_toks_joined": "def test_lp_all ( dummy_site ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> s = dummy_site ( lambda x : [ x ] , <STRING> ) <NEWLINE> cmd = ProjectList ( <STRING> ) . execute_on ( s ) <NEWLINE> assert len ( cmd ) == 1 <NEWLINE> assert cmd [ 0 ] == <STRING> <NEWLINE> cmd = ProjectList ( ) . execute_on ( s ) <NEWLINE> assert len ( cmd ) == 1 <NEWLINE> assert cmd [ 0 ] == <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Test the List Projects command'''", "'2.7.0'", "'--all'", "'ls-projects --all'", "'ls-projects'"]}}], ["95eea742d153fcfcedba9dfc36d2f406", {"code_string": "from.physical import PhysicalGraph\nfrom.shader import HasUniforms\nfrom.utils import mixins\n", "code_toks_joined": "from . physical import PhysicalGraph <NEWLINE> from . shader import HasUniforms <NEWLINE> from . utils import mixins <NEWLINE>", "anonymize_dict": {}}], ["a88f2721b4a598cf423bb79dd70bd976", {"code_string": "from wetteronline.api import get\nfrom wetteronline.api import manual\nfrom wetteronline.api import request_url\n", "code_toks_joined": "from wetteronline . api import get <NEWLINE> from wetteronline . api import manual <NEWLINE> from wetteronline . api import request_url <NEWLINE>", "anonymize_dict": {}}], ["98ad2f2ffb9802a985dc8c82fa875d5b", {"code_string": "def __init__(self, name = '', ** config):\n    super(Signal, self).__init__(** config)\n    self.name = name\n    latency = 0\n    self.connections_ = set()\n    self.new_samples = 0\n    self.timestamp = 0\n    self._buffer_size_changed()\n", "code_toks_joined": "def __init__ ( self , name = <STRING> , ** config ) : <NEWLINE> <INDENT> super ( Signal , self ) . __init__ ( ** config ) <NEWLINE> self . name = name <NEWLINE> latency = 0 <NEWLINE> self . connections_ = set ( ) <NEWLINE> self . new_samples = 0 <NEWLINE> self . timestamp = 0 <NEWLINE> self . _buffer_size_changed ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["''"]}}], ["19b8363f09d4386243dd2019f2c6d05c", {"code_string": "from oslo.config import cfg\nLOG_DIR = '/var/log/ool-ofp-ofc'\nLOG_FILE_NAME = 'ofc.log'\nCONF_DIR = 'conf'\nCONF_FILE = CONF_DIR + '/' + 'ofp-ofc.conf'\nSERVICE_URL = '/ofc/ryu/ctrl'\nofp_ofc_config = None\n", "code_toks_joined": "from oslo . config import cfg <NEWLINE> LOG_DIR = <STRING> <NEWLINE> LOG_FILE_NAME = <STRING> <NEWLINE> CONF_DIR = <STRING> <NEWLINE> CONF_FILE = CONF_DIR + <STRING> + <STRING> <NEWLINE> SERVICE_URL = <STRING> <NEWLINE> ofp_ofc_config = None <NEWLINE>", "anonymize_dict": {"<STRING>": ["'/var/log/ool-ofp-ofc'", "'ofc.log'", "'conf'", "'/'", "'ofp-ofc.conf'", "'/ofc/ryu/ctrl'"]}}], ["83f26e27ff0d79059ce6166b44823c6e", {"code_string": "def setUp(self):\n    sample_doc_path = [\"data\", \"doc\", \"sample.doc\"]\n    blair_doc_path = [\"data\", \"doc\", \"blair.doc\"]\n    sample_doc_stream = RawIStream(join(* sample_doc_path))\n    blair_doc_stream = RawIStream(join(* blair_doc_path))\n    self.sample_doc_stream = sample_doc_stream\n    self.blair_doc_stream = blair_doc_stream\n    self.sample_doc = CompoundFile(sample_doc_stream)\n    self.blair_doc = CompoundFile(blair_doc_stream)\n", "code_toks_joined": "def setUp ( self ) : <NEWLINE> <INDENT> sample_doc_path = [ <STRING> , <STRING> , <STRING> ] <NEWLINE> blair_doc_path = [ <STRING> , <STRING> , <STRING> ] <NEWLINE> sample_doc_stream = RawIStream ( join ( * sample_doc_path ) ) <NEWLINE> blair_doc_stream = RawIStream ( join ( * blair_doc_path ) ) <NEWLINE> self . sample_doc_stream = sample_doc_stream <NEWLINE> self . blair_doc_stream = blair_doc_stream <NEWLINE> self . sample_doc = CompoundFile ( sample_doc_stream ) <NEWLINE> self . blair_doc = CompoundFile ( blair_doc_stream ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"data\"", "\"doc\"", "\"sample.doc\"", "\"data\"", "\"doc\"", "\"blair.doc\""]}}], ["4a41eaf5b202cad40fe0b43f22712356", {"code_string": "def check_config(config):\n    \"\"\"Check and validate configuration attributes, to help administrators\"\"\"\n    cfg = vodka.config.Config(read = config)\n    vodka.log.set_loggers(cfg.get(\"logging\"))\n    vodka.app.load_all(cfg)\n    click.echo(\"Checking config at %s for errors ...\" % config)\n    num_crit, num_warn = vodka.config.InstanceHandler.validate(cfg)\n    click.echo(\"%d config ERRORS, %d config WARNINGS\" %(num_crit, num_warn))\n", "code_toks_joined": "def check_config ( config ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> cfg = vodka . config . Config ( read = config ) <NEWLINE> vodka . log . set_loggers ( cfg . get ( <STRING> ) ) <NEWLINE> vodka . app . load_all ( cfg ) <NEWLINE> click . echo ( <STRING> % config ) <NEWLINE> num_crit , num_warn = vodka . config . InstanceHandler . validate ( cfg ) <NEWLINE> click . echo ( <STRING> % ( num_crit , num_warn ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Check and validate configuration attributes, to help administrators\"\"\"", "\"logging\"", "\"Checking config at %s for errors ...\"", "\"%d config ERRORS, %d config WARNINGS\""]}}], ["eaaa1ea6c233e9888b80a2c20c9191b1", {"code_string": "class RQDashboard(object):\n    def __init__(self, app = None, url_prefix = '/rq', auth_handler = None):\n        self.url_prefix = url_prefix\n        if app is not None:\n            self.app = app\n            self.init_app(app)\n        else:\n            self.app = None\n        self.auth_handler = auth_handler\n        self.redis_conn = None\n    def init_app(self, app):\n        \"\"\"Initializes the RQ-Dashboard for the specified application.\"\"\"\n        app.register_blueprint(dashboard, url_prefix = self.url_prefix)\n        app.extensions['rq-dashboard'] = self\n", "code_toks_joined": "class RQDashboard ( object ) : <NEWLINE> <INDENT> def __init__ ( self , app = None , url_prefix = <STRING> , auth_handler = None ) : <NEWLINE> <INDENT> self . url_prefix = url_prefix <NEWLINE> if app is not None : <NEWLINE> <INDENT> self . app = app <NEWLINE> self . init_app ( app ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . app = None <NEWLINE> <DEDENT> self . auth_handler = auth_handler <NEWLINE> self . redis_conn = None <NEWLINE> <DEDENT> def init_app ( self , app ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> app . register_blueprint ( dashboard , url_prefix = self . url_prefix ) <NEWLINE> app . extensions [ <STRING> ] = self <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/rq'", "\"\"\"Initializes the RQ-Dashboard for the specified application.\"\"\"", "'rq-dashboard'"]}}], ["e025a47ae4b58747daefab21ce6501c9", {"code_string": "import sqlite3\nimport yaml\nwith open('config.yaml', 'r') as config_file:\n    config = yaml.load(config_file)\nprint('db file at %s' % config['db_file'])\nconn = sqlite3.connect(config['db_file'])\ncursor = conn.cursor()\nfrom collections import OrderedDict\ndb_model = OrderedDict()\n", "code_toks_joined": "import sqlite3 <NEWLINE> import yaml <NEWLINE> with open ( <STRING> , <STRING> ) as config_file : <NEWLINE> <INDENT> config = yaml . load ( config_file ) <NEWLINE> <DEDENT> print ( <STRING> % config [ <STRING> ] ) <NEWLINE> conn = sqlite3 . connect ( config [ <STRING> ] ) <NEWLINE> cursor = conn . cursor ( ) <NEWLINE> from collections import OrderedDict <NEWLINE> db_model = OrderedDict ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'config.yaml'", "'r'", "'db file at %s'", "'db_file'", "'db_file'"]}}], ["07e5e9f055f9b5d318bf125aeac2de5e", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('app', '0016_auto_20160322_2237'),\n    ]\n    operations = [\n        migrations.AlterField(\n            model_name = 'roominstance',\n            name = 'expirydate',\n            field = models.DateTimeField(blank = True, default = datetime.datetime(2016, 3, 23, 23, 4, 21, 358722)),\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . AlterField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . DateTimeField ( blank = True , default = datetime . datetime ( 2016 , 3 , 23 , 23 , 4 , 21 , 358722 ) ) , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'app'", "'0016_auto_20160322_2237'", "'roominstance'", "'expirydate'"]}}], ["e7b1f4a0212a2d714edf10a016b4c269", {"code_string": "def setUp(self):\n    self.dist_version = DIST_VERSION\n    self.log_file = LOG_FILE\n    self.log_level = LOG_LEVEL\n    self.celery_pid_path = CELERY_PID_PATH\n    if self.dist_version == '14.04':\n        self.run = subprocess.check_call\n        subprocess.check_call = MagicMock()\n    elif self.dist_version == '16.04':\n        self.run = subprocess.run\n        subprocess.run = MagicMock()\n    if os.path.isfile(self.log_file):\n        os.remove(self.log_file)\n    remove_test_dir()\n", "code_toks_joined": "def setUp ( self ) : <NEWLINE> <INDENT> self . dist_version = DIST_VERSION <NEWLINE> self . log_file = LOG_FILE <NEWLINE> self . log_level = LOG_LEVEL <NEWLINE> self . celery_pid_path = CELERY_PID_PATH <NEWLINE> if self . dist_version == <STRING> : <NEWLINE> <INDENT> self . run = subprocess . check_call <NEWLINE> subprocess . check_call = MagicMock ( ) <NEWLINE> <DEDENT> elif self . dist_version == <STRING> : <NEWLINE> <INDENT> self . run = subprocess . run <NEWLINE> subprocess . run = MagicMock ( ) <NEWLINE> <DEDENT> if os . path . isfile ( self . log_file ) : <NEWLINE> <INDENT> os . remove ( self . log_file ) <NEWLINE> <DEDENT> remove_test_dir ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'14.04'", "'16.04'"]}}], ["3ffd3d50a6137534c89d60c63a8854f9", {"code_string": "import curses\nimport json\nimport locale\nimport urllib.request, urllib.parse, urllib.error\nimport argparse\nimport os\nimport livestreamer\nfrom.featured import FeaturedScreen\nfrom.games import GamesScreen\nfrom.streams import StreamsScreen\nfrom.search import SearchScreen\nfrom.util import SCREEN_CODE, QUALITY, DESCRIPTION, EPILOG\n", "code_toks_joined": "import curses <NEWLINE> import json <NEWLINE> import locale <NEWLINE> import urllib . request , urllib . parse , urllib . error <NEWLINE> import argparse <NEWLINE> import os <NEWLINE> import livestreamer <NEWLINE> from . featured import FeaturedScreen <NEWLINE> from . games import GamesScreen <NEWLINE> from . streams import StreamsScreen <NEWLINE> from . search import SearchScreen <NEWLINE> from . util import SCREEN_CODE , QUALITY , DESCRIPTION , EPILOG <NEWLINE>", "anonymize_dict": {}}], ["8ac64fc359999a53ad03f6d405415c7a", {"code_string": "class NotImplementedYet(NotImplementedError, VEOIBDSynapseError):\n    \"\"\"Raise when a section of code that has been left for another time is asked to execute.\"\"\"\n    def __init__(self, msg = None):\n        \"\"\"Set up the Exception.\"\"\"\n        if msg is None:\n            msg = \"That bonehead {author} should really hear your rage about this disgraceful result! Feel free to tell them at {email}\".format(author = __author__, email = __email__)\n        self.args = (msg, * self.args)\n", "code_toks_joined": "class NotImplementedYet ( NotImplementedError , VEOIBDSynapseError ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , msg = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if msg is None : <NEWLINE> <INDENT> msg = <STRING> . format ( author = __author__ , email = __email__ ) <NEWLINE> <DEDENT> self . args = ( msg , * self . args ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Raise when a section of code that has been left for another time is asked to execute.\"\"\"", "\"\"\"Set up the Exception.\"\"\"", "\"That bonehead {author} should really hear your rage about this disgraceful result! Feel free to tell them at {email}\""]}}], ["d3fb95496a9d668a2461882b81697d72", {"code_string": "import os\nimport pytest\nDEFAULT_POSTGRESQL_TEST_URL = '/parsec_test'\n", "code_toks_joined": "import os <NEWLINE> import pytest <NEWLINE> DEFAULT_POSTGRESQL_TEST_URL = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'/parsec_test'"]}}], ["1e31278a2f2b1dfc65f66ddac619c4d7", {"code_string": "\"\"\"REST API Documentation for the NRS TFRS Credit Trading Application\"\"\"\nimport datetime\nfrom django.db import models\nfrom django.utils import timezone\nfrom.FuelSupplierStatus import FuelSupplierStatus\nfrom.FuelSupplierActionsType import FuelSupplierActionsType\nfrom auditable.models import Auditable\n", "code_toks_joined": "<STRING> <NEWLINE> import datetime <NEWLINE> from django . db import models <NEWLINE> from django . utils import timezone <NEWLINE> from . FuelSupplierStatus import FuelSupplierStatus <NEWLINE> from . FuelSupplierActionsType import FuelSupplierActionsType <NEWLINE> from auditable . models import Auditable <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"REST API Documentation for the NRS TFRS Credit Trading Application\"\"\""]}}], ["7de57756f26f36cb7287ff749d00a64c", {"code_string": "class AnnSearchForm(SearchForm):\n    CHANNEL_CHOICES = []\n    for channel_pk, channel_str in channel_name.items():\n        CHANNEL_CHOICES.append((channel_pk, channel_str))\n    channel = forms.ChoiceField(choices = CHANNEL_CHOICES, initial = DEFAULT_CHANNEL)\n", "code_toks_joined": "class AnnSearchForm ( SearchForm ) : <NEWLINE> <INDENT> CHANNEL_CHOICES = [ ] <NEWLINE> for channel_pk , channel_str in channel_name . items ( ) : <NEWLINE> <INDENT> CHANNEL_CHOICES . append ( ( channel_pk , channel_str ) ) <NEWLINE> <DEDENT> channel = forms . ChoiceField ( choices = CHANNEL_CHOICES , initial = DEFAULT_CHANNEL ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["405d40aad9770a11c8abcb9ee7e78faf", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('stein', '0011_auto_20161008_1659'),\n    ]\n    operations = [\n        migrations.AlterField(\n            model_name = 'crystalsystem',\n            name = 'pressure',\n            field = models.IntegerField(blank = True, null = True, verbose_name = 'pressure'),\n        ),\n        migrations.AlterField(\n            model_name = 'crystalsystem',\n            name = 'temperature',\n            field = models.IntegerField(blank = True, null = True, verbose_name = 'temperature'),\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . AlterField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . IntegerField ( blank = True , null = True , verbose_name = <STRING> ) , <NEWLINE> <DEDENT> ) , <NEWLINE> migrations . AlterField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . IntegerField ( blank = True , null = True , verbose_name = <STRING> ) , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'stein'", "'0011_auto_20161008_1659'", "'crystalsystem'", "'pressure'", "'pressure'", "'crystalsystem'", "'temperature'", "'temperature'"]}}], ["3371f473ab7943e925a1dc1bb5df2340", {"code_string": "def build_job_script(self, builder, command):\n    ensure_galaxy_lib_available()\n    tool_dependency_manager = deps.build_dependency_manager(self)\n    dependencies = get_dependencies(builder)\n    handle_dependencies = \"\"\n    if dependencies:\n        handle_dependencies = \"\\n\".join(tool_dependency_manager.dependency_shell_commands(dependencies, job_directory = builder.tmpdir))\n    template_kwds = dict(handle_dependencies = handle_dependencies)\n    job_script = COMMAND_WITH_DEPENDENCIES_TEMPLATE.substitute(template_kwds)\n    return job_script\n", "code_toks_joined": "def build_job_script ( self , builder , command ) : <NEWLINE> <INDENT> ensure_galaxy_lib_available ( ) <NEWLINE> tool_dependency_manager = deps . build_dependency_manager ( self ) <NEWLINE> dependencies = get_dependencies ( builder ) <NEWLINE> handle_dependencies = <STRING> <NEWLINE> if dependencies : <NEWLINE> <INDENT> handle_dependencies = <STRING> . join ( tool_dependency_manager . dependency_shell_commands ( dependencies , job_directory = builder . tmpdir ) ) <NEWLINE> <DEDENT> template_kwds = dict ( handle_dependencies = handle_dependencies ) <NEWLINE> job_script = COMMAND_WITH_DEPENDENCIES_TEMPLATE . substitute ( template_kwds ) <NEWLINE> return job_script <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"", "\"\\n\""]}}], ["987772d8fdaf371e13498783958cc504", {"code_string": "def load_module(name):\n    \"\"\"Load module from name\"\"\"\n    mod = None\n    for mod_name in name.split('.'):\n        file, pathname, desc = imp.find_module(mod_name, mod and mod.__path__)\n        mod = imp.load_module(mod_name, file, pathname, desc)\n    return mod\n", "code_toks_joined": "def load_module ( name ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> mod = None <NEWLINE> for mod_name in name . split ( <STRING> ) : <NEWLINE> <INDENT> file , pathname , desc = imp . find_module ( mod_name , mod and mod . __path__ ) <NEWLINE> mod = imp . load_module ( mod_name , file , pathname , desc ) <NEWLINE> <DEDENT> return mod <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Load module from name\"\"\"", "'.'"]}}], ["189971922e62adbeb353c7e65faacde6", {"code_string": "def getkeymap(searchkey):\n    modmapraw = Popen([\"xmodmap\", \"-pke\"], stdout = PIPE).communicate()[0].decode('utf-8')\n    match = re.search(\".*\\\\b(\" + searchkey + \")\\\\b.*\", modmapraw)\n    if match:\n        return(int(re.search(\"keycode\\s+(\\\\d+)\", match.group(0)).group(1)), match.group(1))\n    else:\n        return False\n", "code_toks_joined": "def getkeymap ( searchkey ) : <NEWLINE> <INDENT> modmapraw = Popen ( [ <STRING> , <STRING> ] , stdout = PIPE ) . communicate ( ) [ 0 ] . decode ( <STRING> ) <NEWLINE> match = re . search ( <STRING> + searchkey + <STRING> , modmapraw ) <NEWLINE> if match : <NEWLINE> <INDENT> return ( int ( re . search ( <STRING> , match . group ( 0 ) ) . group ( 1 ) ) , match . group ( 1 ) ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"xmodmap\"", "\"-pke\"", "'utf-8'", "\".*\\\\b(\"", "\")\\\\b.*\"", "\"keycode\\s+(\\\\d+)\""]}}], ["a67c8f9cbcb1e258b465cb4534b86e0f", {"code_string": "def unpack_int(s):\n    \"\"\" Reads a packed integer from string <s> \"\"\"\n    ret = 0\n    i = 0\n    while True:\n        b = ord(s[i])\n        ret |=(b & 127) <<(i * 7)\n        i += 1\n        if b & 128 == 0:\n            break\n    return ret\n", "code_toks_joined": "def unpack_int ( s ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> ret = 0 <NEWLINE> i = 0 <NEWLINE> while True : <NEWLINE> <INDENT> b = ord ( s [ i ] ) <NEWLINE> ret |= ( b & 127 ) << ( i * 7 ) <NEWLINE> i += 1 <NEWLINE> if b & 128 == 0 : <NEWLINE> <INDENT> break <NEWLINE> <DEDENT> <DEDENT> return ret <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Reads a packed integer from string <s> \"\"\""]}}], ["1ec8ca244d6f304f068f01ff6a683872", {"code_string": "\"\"\" :mod: OperationHandlerBaseTests\"\"\"\n__RCSID__ = \"$Id $\"\nimport unittest\nfrom DIRAC.RequestManagementSystem.private.OperationHandlerBase import OperationHandlerBase\nfrom DIRAC.RequestManagementSystem.Client.Request import Request\nfrom DIRAC.RequestManagementSystem.Client.Operation import Operation\nfrom DIRAC.DataManagementSystem.Client.DataManager import DataManager\n", "code_toks_joined": "<STRING> <NEWLINE> __RCSID__ = <STRING> <NEWLINE> import unittest <NEWLINE> from DIRAC . RequestManagementSystem . private . OperationHandlerBase import OperationHandlerBase <NEWLINE> from DIRAC . RequestManagementSystem . Client . Request import Request <NEWLINE> from DIRAC . RequestManagementSystem . Client . Operation import Operation <NEWLINE> from DIRAC . DataManagementSystem . Client . DataManager import DataManager <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\" :mod: OperationHandlerBaseTests\"\"\"", "\"$Id $\""]}}], ["9af72cd8f32282aba0f923aa0563716c", {"code_string": "def __eq__(self, other):\n    \"\"\"Returns true if both objects are equal\"\"\"\n    if not isinstance(other, PostUiOpenwindowInformationInternalServerError):\n        return False\n    return self.__dict__ == other.__dict__\n", "code_toks_joined": "def __eq__ ( self , other ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if not isinstance ( other , PostUiOpenwindowInformationInternalServerError ) : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> return self . __dict__ == other . __dict__ <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Returns true if both objects are equal\"\"\""]}}], ["980418dd3b94cd45203fda87caf82692", {"code_string": "import pstats\np = pstats.Stats('cuonprofile')\np.sort_stats('time').print_stats(10)\n", "code_toks_joined": "import pstats <NEWLINE> p = pstats . Stats ( <STRING> ) <NEWLINE> p . sort_stats ( <STRING> ) . print_stats ( 10 ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'cuonprofile'", "'time'"]}}], ["8f22b0c638d05345acf08ff0c858ab39", {"code_string": "from pony.orm import *\nfrom datetime import datetime\nfrom model.group import Group\nfrom model.contact import Contact\nfrom pymysql.converters import encoders, decoders, convert_mysql_timestamp\n", "code_toks_joined": "from pony . orm import * <NEWLINE> from datetime import datetime <NEWLINE> from model . group import Group <NEWLINE> from model . contact import Contact <NEWLINE> from pymysql . converters import encoders , decoders , convert_mysql_timestamp <NEWLINE>", "anonymize_dict": {}}], ["1ab53be849e13fe5a17cfd8947f85007", {"code_string": "from senpy.plugins import SentimentPlugin\nfrom senpy.models import Response, Entry\nimport logging\nlogger = logging.getLogger(__name__)\n", "code_toks_joined": "from senpy . plugins import SentimentPlugin <NEWLINE> from senpy . models import Response , Entry <NEWLINE> import logging <NEWLINE> logger = logging . getLogger ( __name__ ) <NEWLINE>", "anonymize_dict": {}}], ["9006eda411193b7d81997e610d5fd282", {"code_string": "def _gen_times(base, size, delay_period = 0.05):\n    times = \"\"\n    j = 0\n    k = 0\n    two_places = decimal.Decimal('10') ** - 2\n    while j < size:\n        times += str(decimal.Decimal(base + delay_period * j).quantize(two_places)) + \" \"\n        j += 1\n    k = delay_period *(j - 1) + base\n    return k, times\n", "code_toks_joined": "def _gen_times ( base , size , delay_period = 0.05 ) : <NEWLINE> <INDENT> times = <STRING> <NEWLINE> j = 0 <NEWLINE> k = 0 <NEWLINE> two_places = decimal . Decimal ( <STRING> ) ** - 2 <NEWLINE> while j < size : <NEWLINE> <INDENT> times += str ( decimal . Decimal ( base + delay_period * j ) . quantize ( two_places ) ) + <STRING> <NEWLINE> j += 1 <NEWLINE> <DEDENT> k = delay_period * ( j - 1 ) + base <NEWLINE> return k , times <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"", "'10'", "\" \""]}}], ["f3f17165f5caa7d11739c2bfa99d8664", {"code_string": "import testbasenode\nimport testbdf\nimport testcv\nimport testdataset\nimport testedf\nimport testeegmontage\nimport testexpinfo\nimport testfiltering\nimport testmarkers\nimport testnonstat\nimport testparafac\nimport testperf\nimport testplots\nimport testpositions\nimport testsimple\nimport testslidingwindow\nimport testspatialfilter\nimport teststat\nimport testtimefreq\nimport testtrials\nimport testutils\n", "code_toks_joined": "import testbasenode <NEWLINE> import testbdf <NEWLINE> import testcv <NEWLINE> import testdataset <NEWLINE> import testedf <NEWLINE> import testeegmontage <NEWLINE> import testexpinfo <NEWLINE> import testfiltering <NEWLINE> import testmarkers <NEWLINE> import testnonstat <NEWLINE> import testparafac <NEWLINE> import testperf <NEWLINE> import testplots <NEWLINE> import testpositions <NEWLINE> import testsimple <NEWLINE> import testslidingwindow <NEWLINE> import testspatialfilter <NEWLINE> import teststat <NEWLINE> import testtimefreq <NEWLINE> import testtrials <NEWLINE> import testutils <NEWLINE>", "anonymize_dict": {}}], ["3c2b62fffa5133c09d9d33d7a400dc58", {"code_string": "def connectionMade(self):\n    self.out('Username: ')\n    self.state = 'USERNAME'\n", "code_toks_joined": "def connectionMade ( self ) : <NEWLINE> <INDENT> self . out ( <STRING> ) <NEWLINE> self . state = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Username: '", "'USERNAME'"]}}], ["2a43dfcaf07647cb4671966f139776f8", {"code_string": "class Upload(models.Model):\n    upload = models.FileField()\n    def __str__(self):\n        return self.upload.name\n", "code_toks_joined": "class Upload ( models . Model ) : <NEWLINE> <INDENT> upload = models . FileField ( ) <NEWLINE> def __str__ ( self ) : <NEWLINE> <INDENT> return self . upload . name <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["9a73ffe6d3114c07c95fd0879835fc8a", {"code_string": "def get_uptime(self):\n    bash_output = commands.getstatusoutput(\"uptime\")[1]\n    split_output = bash_output.split(\" \")\n    return split_output[4]\n", "code_toks_joined": "def get_uptime ( self ) : <NEWLINE> <INDENT> bash_output = commands . getstatusoutput ( <STRING> ) [ 1 ] <NEWLINE> split_output = bash_output . split ( <STRING> ) <NEWLINE> return split_output [ 4 ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"uptime\"", "\" \""]}}], ["1f155bd1ba4d9206e9eb623c42b464e7", {"code_string": "from setuptools import setup\nfrom setuptools import find_packages\nsetup(\n    name = 'pygeda',\n    version = '0.1',\n    description = 'EDA and PCB support for GEDA',\n    author = 'Markus Hutzler',\n    author_email = 'markus.hutzler@me.com',\n    classifiers = [\n        \"Development Status :: 2 - Pre Alpha\",\n        \"Intended Audience :: Developers\",\n        \"License :: GPL License\",\n        \"Topic :: Electronic Design :: Tools\",\n        \"Programming Language ::Python :: 2\",\n        \"Programming Language :: Python :: 2.6\",\n        \"Programming Language :: Python :: 2.7\",\n    ],\n    packages = find_packages(),\n    license = 'GPL3',\n    package_dir = {'pygeda': 'pygeda'},\n    entry_points = {\n        \"console_scripts\": [\n            \"pygeda=pygeda.main:main\",\n        ],\n    }\n)\n", "code_toks_joined": "from setuptools import setup <NEWLINE> from setuptools import find_packages <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> classifiers = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <DEDENT> ] , <NEWLINE> packages = find_packages ( ) , <NEWLINE> license = <STRING> , <NEWLINE> package_dir = { <STRING> : <STRING> } , <NEWLINE> entry_points = { <NEWLINE> <INDENT> <STRING> : [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <DEDENT> ] , <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'pygeda'", "'0.1'", "'EDA and PCB support for GEDA'", "'Markus Hutzler'", "'markus.hutzler@me.com'", "\"Development Status :: 2 - Pre Alpha\"", "\"Intended Audience :: Developers\"", "\"License :: GPL License\"", "\"Topic :: Electronic Design :: Tools\"", "\"Programming Language ::Python :: 2\"", "\"Programming Language :: Python :: 2.6\"", "\"Programming Language :: Python :: 2.7\"", "'GPL3'", "'pygeda'", "'pygeda'", "\"console_scripts\"", "\"pygeda=pygeda.main:main\""]}}], ["e4b0af3ee3f801db2dbd493a4dcd50f0", {"code_string": "def computeMatchProbability(string, GCContent):\n    probabilities = computeProbabilities(GCContent)\n    res = 1\n    for c in string:\n        res *= probabilities[c]\n    return commonLogarithm(res)\n", "code_toks_joined": "def computeMatchProbability ( string , GCContent ) : <NEWLINE> <INDENT> probabilities = computeProbabilities ( GCContent ) <NEWLINE> res = 1 <NEWLINE> for c in string : <NEWLINE> <INDENT> res *= probabilities [ c ] <NEWLINE> <DEDENT> return commonLogarithm ( res ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["a3842c8d3aaf4c4eb07fb57842c3a0d3", {"code_string": "def dbCursor(self):\n    \"\"\"Cursor to the catsim database connection. This is not reset if one\"\"\"\n    if self._dbCursor is None:\n        self._dbCursor = self.dbConnection.cursor()\n    return self._dbCursor\n", "code_toks_joined": "def dbCursor ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if self . _dbCursor is None : <NEWLINE> <INDENT> self . _dbCursor = self . dbConnection . cursor ( ) <NEWLINE> <DEDENT> return self . _dbCursor <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Cursor to the catsim database connection. This is not reset if one\"\"\""]}}], ["766bd86ae7b41e79b869fbac18086608", {"code_string": "import tagpy\nimport glob\nimport os\nimport sys\nimport re\n", "code_toks_joined": "import tagpy <NEWLINE> import glob <NEWLINE> import os <NEWLINE> import sys <NEWLINE> import re <NEWLINE>", "anonymize_dict": {}}], ["822ae673aaf6390166a5ed784b058516", {"code_string": "from redlib.api.misc import Retry\nfrom redlib.api.image import get_image_info\nfrom PIL import Image\nfrom.base import SourceError\nfrom..web.func import get, HttpError, exists\nfrom..db.app.config import Config\nfrom..util.logger import log\nfrom..util.printer import printer\n", "code_toks_joined": "from redlib . api . misc import Retry <NEWLINE> from redlib . api . image import get_image_info <NEWLINE> from PIL import Image <NEWLINE> from . base import SourceError <NEWLINE> from . . web . func import get , HttpError , exists <NEWLINE> from . . db . app . config import Config <NEWLINE> from . . util . logger import log <NEWLINE> from . . util . printer import printer <NEWLINE>", "anonymize_dict": {}}], ["40674d30c42c5f8a7d33cb2a5766683c", {"code_string": "import os\nimport sys\nfrom tempfile import mkdtemp\nfrom cement.core.foundation import CementApp\nfrom cement.core import exc as cement_exc\nfrom cement.utils import fs, misc\nfrom boss.core import exc as boss_exc\nCONFIG_DEFAULTS = misc.init_defaults('boss', 'answers')\nCONFIG_DEFAULTS['boss']['data_dir'] = '~/.boss/'\n", "code_toks_joined": "import os <NEWLINE> import sys <NEWLINE> from tempfile import mkdtemp <NEWLINE> from cement . core . foundation import CementApp <NEWLINE> from cement . core import exc as cement_exc <NEWLINE> from cement . utils import fs , misc <NEWLINE> from boss . core import exc as boss_exc <NEWLINE> CONFIG_DEFAULTS = misc . init_defaults ( <STRING> , <STRING> ) <NEWLINE> CONFIG_DEFAULTS [ <STRING> ] [ <STRING> ] = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'boss'", "'answers'", "'boss'", "'data_dir'", "'~/.boss/'"]}}], ["0abfc0efed8425969dde4c9cda3b7837", {"code_string": "def get_unique_variable(var_op_name):\n    \"\"\"Gets the variable uniquely identified by that var_op_name.\"\"\"\n    candidates = get_variables(scope = var_op_name)\n    if not candidates:\n        raise ValueError('Couldnt find variable %s' % var_op_name)\n    for candidate in candidates:\n        if candidate.op.name == var_op_name:\n            return candidate\n    raise ValueError('Variable %s does not uniquely identify a variable' %\n        var_op_name)\n", "code_toks_joined": "def get_unique_variable ( var_op_name ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> candidates = get_variables ( scope = var_op_name ) <NEWLINE> if not candidates : <NEWLINE> <INDENT> raise ValueError ( <STRING> % var_op_name ) <NEWLINE> <DEDENT> for candidate in candidates : <NEWLINE> <INDENT> if candidate . op . name == var_op_name : <NEWLINE> <INDENT> return candidate <NEWLINE> <DEDENT> <DEDENT> raise ValueError ( <STRING> % <NEWLINE> <INDENT> var_op_name ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Gets the variable uniquely identified by that var_op_name.\"\"\"", "'Couldnt find variable %s'", "'Variable %s does not uniquely identify a variable'"]}}], ["94c2d440b7b2bef585caf15ef0c597ec", {"code_string": "def matches_count(text, words):\n    text_words = flatten(text).split()\n    matches = {word: text_words.count(flatten(word)) for word in words}\n    return matches\n", "code_toks_joined": "def matches_count ( text , words ) : <NEWLINE> <INDENT> text_words = flatten ( text ) . split ( ) <NEWLINE> matches = { word : text_words . count ( flatten ( word ) ) for word in words } <NEWLINE> return matches <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["fbecec89f1da164ce54dae43540587f7", {"code_string": "def main():\n    parser = create_parsers()\n    args = vars(parser.parse_args())\n    in_f = args['i']\n    out_f = args['o']\n    convert_file(in_f, out_f)\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> parser = create_parsers ( ) <NEWLINE> args = vars ( parser . parse_args ( ) ) <NEWLINE> in_f = args [ <STRING> ] <NEWLINE> out_f = args [ <STRING> ] <NEWLINE> convert_file ( in_f , out_f ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'i'", "'o'"]}}], ["eccaa727e307919dcc3f75bf0389888e", {"code_string": "def setProtocol(self, protocol):\n    \"\"\"Set protocol for card connection.\"\"\"\n    self.defaultprotocol = protocol\n", "code_toks_joined": "def setProtocol ( self , protocol ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . defaultprotocol = protocol <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Set protocol for card connection.\"\"\""]}}], ["d1337c803efaa849772c54d64b75a719", {"code_string": "def buildResponseBody(response, request):\n    responseBody = {\n        'request_id': request['request_id'],\n        'status': 'SUCCESS',\n        'function_name': request['function_name'],\n        'response': response\n    }\n    return responseBody\n", "code_toks_joined": "def buildResponseBody ( response , request ) : <NEWLINE> <INDENT> responseBody = { <NEWLINE> <INDENT> <STRING> : request [ <STRING> ] , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : request [ <STRING> ] , <NEWLINE> <STRING> : response <NEWLINE> <DEDENT> } <NEWLINE> return responseBody <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'request_id'", "'request_id'", "'status'", "'SUCCESS'", "'function_name'", "'function_name'", "'response'"]}}], ["96817c155d2171634479ef5d9af1b4a7", {"code_string": "\"\"\"This module parses Ragout configuration file\"\"\"\nfrom collections import namedtuple\nimport re\nimport os\nimport logging\nfrom ragout.parsers.phylogeny_parser import get_leaves_names, PhyloException\nimport ragout.shared.config as config\nlogger = logging.getLogger()\n", "code_toks_joined": "<STRING> <NEWLINE> from collections import namedtuple <NEWLINE> import re <NEWLINE> import os <NEWLINE> import logging <NEWLINE> from ragout . parsers . phylogeny_parser import get_leaves_names , PhyloException <NEWLINE> import ragout . shared . config as config <NEWLINE> logger = logging . getLogger ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"This module parses Ragout configuration file\"\"\""]}}], ["dc18f0e0b90679e9af5ba0921551be9c", {"code_string": "from PyQt5 import QtCore\nfrom PyQt5.QtCore import QUrl\nfrom PyQt5.QtGui import QKeySequence\nfrom PyQt5.QtWidgets import QMainWindow, QTreeWidget, QTreeWidgetItem, QMenuBar, QAction\nimport os\n__all__ = ['SubtleMainWindow', ]\n", "code_toks_joined": "from PyQt5 import QtCore <NEWLINE> from PyQt5 . QtCore import QUrl <NEWLINE> from PyQt5 . QtGui import QKeySequence <NEWLINE> from PyQt5 . QtWidgets import QMainWindow , QTreeWidget , QTreeWidgetItem , QMenuBar , QAction <NEWLINE> import os <NEWLINE> __all__ = [ <STRING> , ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'SubtleMainWindow'"]}}], ["1edbb383b1b17fdddbbd08d45797a4d3", {"code_string": "def load_from_file(self):\n    events = validate_json(self.filename)\n    if events is False:\n        with open(filename, 'w') as f:\n            json.dump(TEMPLATE, f)\n            f.close()\n    return mergesort(events)\n", "code_toks_joined": "def load_from_file ( self ) : <NEWLINE> <INDENT> events = validate_json ( self . filename ) <NEWLINE> if events is False : <NEWLINE> <INDENT> with open ( filename , <STRING> ) as f : <NEWLINE> <INDENT> json . dump ( TEMPLATE , f ) <NEWLINE> f . close ( ) <NEWLINE> <DEDENT> <DEDENT> return mergesort ( events ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'w'"]}}], ["32f6435f90390ce41e0ee1a0251c82ab", {"code_string": "def submissions_zip_generator(submissions):\n    \"\"\" Generator to create the streaming response from the submissions \"\"\"\n    bytes_io = StreamingBytesIO()\n    with ZipFile(bytes_io, mode = \"w\", compression = ZIP_DEFLATED, allowZip64 = True) as zip_file:\n        for submission in submissions:\n            filename = os.path.basename(submission.student_document.name)\n            zip_file.writestr(filename, submission.student_document.read())\n            yield bytes_io.getvalue()\n            bytes_io.empty()\n    yield bytes_io.getvalue()\n", "code_toks_joined": "def submissions_zip_generator ( submissions ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> bytes_io = StreamingBytesIO ( ) <NEWLINE> with ZipFile ( bytes_io , mode = <STRING> , compression = ZIP_DEFLATED , allowZip64 = True ) as zip_file : <NEWLINE> <INDENT> for submission in submissions : <NEWLINE> <INDENT> filename = os . path . basename ( submission . student_document . name ) <NEWLINE> zip_file . writestr ( filename , submission . student_document . read ( ) ) <NEWLINE> yield bytes_io . getvalue ( ) <NEWLINE> bytes_io . empty ( ) <NEWLINE> <DEDENT> <DEDENT> yield bytes_io . getvalue ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Generator to create the streaming response from the submissions \"\"\"", "\"w\""]}}], ["16f9d5f18edd498a1f31c5256e93ca08", {"code_string": "class ZabbixNS(ProtocolDriver):\n    def recv_data(self, data):\n        return data\n    def send_data(self, data):\n        data[\"ns\"] = 0\n        return data\n", "code_toks_joined": "class ZabbixNS ( ProtocolDriver ) : <NEWLINE> <INDENT> def recv_data ( self , data ) : <NEWLINE> <INDENT> return data <NEWLINE> <DEDENT> def send_data ( self , data ) : <NEWLINE> <INDENT> data [ <STRING> ] = 0 <NEWLINE> return data <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"ns\""]}}], ["4750209741e98d36b07b3299f045ba76", {"code_string": "def __call__(self):\n    actors = self.actors()\n    directors = self.directors()\n    ratings = self.ratings()\n    return{\n        \"directors\": directors,\n        \"ratings\": ratings,\n        \"actors\": actors\n    }\n", "code_toks_joined": "def __call__ ( self ) : <NEWLINE> <INDENT> actors = self . actors ( ) <NEWLINE> directors = self . directors ( ) <NEWLINE> ratings = self . ratings ( ) <NEWLINE> return { <NEWLINE> <INDENT> <STRING> : directors , <NEWLINE> <STRING> : ratings , <NEWLINE> <STRING> : actors <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"directors\"", "\"ratings\"", "\"actors\""]}}], ["89ae07f095d35a0c223e49ff81b41c6d", {"code_string": "def extract_error_detail(self, login_response):\n    details_str = \"\"\n    try:\n        if login_response.content:\n            json_object = common.json_decode(login_response.content)\n            if 'details' in json_object:\n                details_str = json_object['details']\n        return details_str\n    except common.CoprHdError:\n        return details_str\n", "code_toks_joined": "def extract_error_detail ( self , login_response ) : <NEWLINE> <INDENT> details_str = <STRING> <NEWLINE> try : <NEWLINE> <INDENT> if login_response . content : <NEWLINE> <INDENT> json_object = common . json_decode ( login_response . content ) <NEWLINE> if <STRING> in json_object : <NEWLINE> <INDENT> details_str = json_object [ <STRING> ] <NEWLINE> <DEDENT> <DEDENT> return details_str <NEWLINE> <DEDENT> except common . CoprHdError : <NEWLINE> <INDENT> return details_str <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"", "'details'", "'details'"]}}], ["2dd57b4223e0889a1e53796c61178617", {"code_string": "from flask_restplus import reqparse\nnew_symbol = reqparse.RequestParser()\nnew_symbol.add_argument('name',\n    type = str,\n    required = False,\n    location = 'json',\n    help = \"Name of the symbol\")\nnew_symbol.add_argument('description',\n    type = str,\n    required = False,\n    location = 'json',\n    help = \"Description of the symbol\")\nadd_field = reqparse.RequestParser()\nadd_field.add_argument('fid_before_new',\n    type = str,\n    required = False,\n    location = 'json',\n    help = \"ID of the field the new field should be inserted after\")\n", "code_toks_joined": "from flask_restplus import reqparse <NEWLINE> new_symbol = reqparse . RequestParser ( ) <NEWLINE> new_symbol . add_argument ( <STRING> , <NEWLINE> <INDENT> type = str , <NEWLINE> required = False , <NEWLINE> location = <STRING> , <NEWLINE> help = <STRING> ) <NEWLINE> <DEDENT> new_symbol . add_argument ( <STRING> , <NEWLINE> <INDENT> type = str , <NEWLINE> required = False , <NEWLINE> location = <STRING> , <NEWLINE> help = <STRING> ) <NEWLINE> <DEDENT> add_field = reqparse . RequestParser ( ) <NEWLINE> add_field . add_argument ( <STRING> , <NEWLINE> <INDENT> type = str , <NEWLINE> required = False , <NEWLINE> location = <STRING> , <NEWLINE> help = <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'name'", "'json'", "\"Name of the symbol\"", "'description'", "'json'", "\"Description of the symbol\"", "'fid_before_new'", "'json'", "\"ID of the field the new field should be inserted after\""]}}], ["f2495828156289da49ac2c837b8efdad", {"code_string": "def append(self, font):\n    item = self._wrapFontForList(font)\n    super(FontList, self).append(item)\n", "code_toks_joined": "def append ( self , font ) : <NEWLINE> <INDENT> item = self . _wrapFontForList ( font ) <NEWLINE> super ( FontList , self ) . append ( item ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["9050f7180441569f79f502911833e144", {"code_string": "class ValuesGetterThread(QtCore.QThread):\n    \"\"\"Thread adapter dedicated for CrawlingSupervisor class\"\"\"\n    result = QtCore.Signal(str)\n    def __init__(self, crawling_supervisor):\n        QtCore.QThread.__init__(self)\n        self.cs = crawling_supervisor\n    def run(self):\n        \"\"\"Thread runner. Method called by PySide threading system.\"\"\"\n        for e in self.cs.do_crawling():\n            self.result.emit(e)\n    def stop(self):\n        \"\"\"Thread killer. Method called by PySide threading system or manually.\"\"\"\n        self.terminate()\n", "code_toks_joined": "class ValuesGetterThread ( QtCore . QThread ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> result = QtCore . Signal ( str ) <NEWLINE> def __init__ ( self , crawling_supervisor ) : <NEWLINE> <INDENT> QtCore . QThread . __init__ ( self ) <NEWLINE> self . cs = crawling_supervisor <NEWLINE> <DEDENT> def run ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> for e in self . cs . do_crawling ( ) : <NEWLINE> <INDENT> self . result . emit ( e ) <NEWLINE> <DEDENT> <DEDENT> def stop ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . terminate ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Thread adapter dedicated for CrawlingSupervisor class\"\"\"", "\"\"\"Thread runner. Method called by PySide threading system.\"\"\"", "\"\"\"Thread killer. Method called by PySide threading system or manually.\"\"\""]}}], ["9cad7a1b85b352e6b8f3be96437ab3f3", {"code_string": "def update_mem(self, size):\n    if not size:\n        size = _('Unknown')\n        fraction = 0\n    else:\n        fraction = size / self.total_mem\n        size = '%sB' % formatting.formatStorage(size)\n    self.mem.set_text(size)\n    self.mem.set_fraction(fraction)\n", "code_toks_joined": "def update_mem ( self , size ) : <NEWLINE> <INDENT> if not size : <NEWLINE> <INDENT> size = _ ( <STRING> ) <NEWLINE> fraction = 0 <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> fraction = size / self . total_mem <NEWLINE> size = <STRING> % formatting . formatStorage ( size ) <NEWLINE> <DEDENT> self . mem . set_text ( size ) <NEWLINE> self . mem . set_fraction ( fraction ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Unknown'", "'%sB'"]}}], ["975a30279d040e4d96bd5ca8fd831f8c", {"code_string": "def compress_group(string):\n    \"\"\"Returns a compressed two character string containing a character and a number.\"\"\"\n    return str(string[0]) + str(len(string))\n", "code_toks_joined": "def compress_group ( string ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return str ( string [ 0 ] ) + str ( len ( string ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Returns a compressed two character string containing a character and a number.\"\"\""]}}], ["c988337b15e1b541df28c04a8ea853de", {"code_string": "class Interval(object):\n    def __init__(self, gene_id, start, stop):\n        self.start = start\n        self.stop = stop\n        self.gene = gene_id\n    def __repr__(self):\n        return \"%s (%i, %i)\" %(self.gene, self.start, self.stop)\n", "code_toks_joined": "class Interval ( object ) : <NEWLINE> <INDENT> def __init__ ( self , gene_id , start , stop ) : <NEWLINE> <INDENT> self . start = start <NEWLINE> self . stop = stop <NEWLINE> self . gene = gene_id <NEWLINE> <DEDENT> def __repr__ ( self ) : <NEWLINE> <INDENT> return <STRING> % ( self . gene , self . start , self . stop ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"%s (%i, %i)\""]}}], ["bdc29829b2776048d67450aaabc4f08b", {"code_string": "def _select_file(self, item):\n    doc = self._diff_view.document()\n    cursor = doc.find(QRegExp(\"a/\" + item.text()))\n    cursor.movePosition(QTextCursor.StartOfLine)\n    self._diff_view.setTextCursor(cursor)\n    self._diff_view.centerCursor()\n", "code_toks_joined": "def _select_file ( self , item ) : <NEWLINE> <INDENT> doc = self . _diff_view . document ( ) <NEWLINE> cursor = doc . find ( QRegExp ( <STRING> + item . text ( ) ) ) <NEWLINE> cursor . movePosition ( QTextCursor . StartOfLine ) <NEWLINE> self . _diff_view . setTextCursor ( cursor ) <NEWLINE> self . _diff_view . centerCursor ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"a/\""]}}], ["1f4ded8229d9a314e9891d818c287281", {"code_string": "class Solution(object):\n    def shortestPalindrome(self, s):\n        r = s[: : - 1]\n        for i in range(len(s) + 1):\n            if s.startswith(r[i: ]):\n                return r[: i] + s\n", "code_toks_joined": "class Solution ( object ) : <NEWLINE> <INDENT> def shortestPalindrome ( self , s ) : <NEWLINE> <INDENT> r = s [ : : - 1 ] <NEWLINE> for i in range ( len ( s ) + 1 ) : <NEWLINE> <INDENT> if s . startswith ( r [ i : ] ) : <NEWLINE> <INDENT> return r [ : i ] + s <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["2c4e11f2c3d4721253073123eae0644e", {"code_string": "def _jsonb_io_factory(oid, typeio):\n    _pack = lambda x: jsonb_pack(x, typeio)\n    _unpack = lambda x: jsonb_unpack(x, typeio)\n    return(_pack, _unpack, str)\n", "code_toks_joined": "def _jsonb_io_factory ( oid , typeio ) : <NEWLINE> <INDENT> _pack = lambda x : jsonb_pack ( x , typeio ) <NEWLINE> _unpack = lambda x : jsonb_unpack ( x , typeio ) <NEWLINE> return ( _pack , _unpack , str ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["f74cd05c28e502446033ff279f803147", {"code_string": "'''Test cases for <add-function> with const char* as argument'''\nimport unittest\nfrom sample import Echo\n", "code_toks_joined": "<STRING> <NEWLINE> import unittest <NEWLINE> from sample import Echo <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Test cases for <add-function> with const char* as argument'''"]}}], ["87171de114596bb906008a56dcf5e6d9", {"code_string": "from distutils.core import setup\nsetup(name = \"TextSnippets\",\n    version = \"0.1.0\",\n    description = \"TextSnippets is a snippets program for linux using pygtk\",\n    author = \"Mark Harrison\",\n    author_email = \"mark@mivok.net\",\n    url = \"http://github.com/mivok/textsnippets\",\n    license = \"ISC\",\n    package_dir = {'': 'src'},\n    packages = ['textsnippets'],\n    package_data = {'textsnippets': ['data/*']},\n    scripts = ['src/tsnippets']\n)\n", "code_toks_joined": "from distutils . core import setup <NEWLINE> setup ( name = <STRING> , <NEWLINE> <INDENT> version = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> url = <STRING> , <NEWLINE> license = <STRING> , <NEWLINE> package_dir = { <STRING> : <STRING> } , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> package_data = { <STRING> : [ <STRING> ] } , <NEWLINE> scripts = [ <STRING> ] <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"TextSnippets\"", "\"0.1.0\"", "\"TextSnippets is a snippets program for linux using pygtk\"", "\"Mark Harrison\"", "\"mark@mivok.net\"", "\"http://github.com/mivok/textsnippets\"", "\"ISC\"", "''", "'src'", "'textsnippets'", "'textsnippets'", "'data/*'", "'src/tsnippets'"]}}], ["d89ac47b3a2dc16908ef77822ec2008c", {"code_string": "def diff_trees(left_version, right_version):\n    left_tree = RegNode.objects.get(tag = 'regulation', version = left_version)\n    right_tree = RegNode.objects.get(tag = 'regulation', version = right_version)\n    left_tree.get_descendants()\n    right_tree.get_descendants()\n    left_tree.compute_merkle_hash()\n    right_tree.compute_merkle_hash()\n    left_labels = set(gather_regnode_labels(left_tree))\n    right_labels = set(gather_regnode_labels(right_tree))\n    only_left_labels = left_labels - right_labels\n    only_right_labels = right_labels - left_labels\n    both_labels = left_labels & right_labels\n    for label in only_right_labels:\n        pass\n", "code_toks_joined": "def diff_trees ( left_version , right_version ) : <NEWLINE> <INDENT> left_tree = RegNode . objects . get ( tag = <STRING> , version = left_version ) <NEWLINE> right_tree = RegNode . objects . get ( tag = <STRING> , version = right_version ) <NEWLINE> left_tree . get_descendants ( ) <NEWLINE> right_tree . get_descendants ( ) <NEWLINE> left_tree . compute_merkle_hash ( ) <NEWLINE> right_tree . compute_merkle_hash ( ) <NEWLINE> left_labels = set ( gather_regnode_labels ( left_tree ) ) <NEWLINE> right_labels = set ( gather_regnode_labels ( right_tree ) ) <NEWLINE> only_left_labels = left_labels - right_labels <NEWLINE> only_right_labels = right_labels - left_labels <NEWLINE> both_labels = left_labels & right_labels <NEWLINE> for label in only_right_labels : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'regulation'", "'regulation'"]}}], ["7bda852256e0895892ab63172ec0f085", {"code_string": "def format_engine_status(engine = None):\n    status = get_engine_status(engine)\n    s = \"Execution engine status\\n\\n\"\n    for test, result in status['global']:\n        s += \"%-47s : %s\\n\" %(test, result)\n    s += \"\\n\"\n    for spider, tests in status['spiders'].items():\n        s += \"Spider: %s\\n\" % spider\n        for test, result in tests:\n            s += \"  %-50s : %s\\n\" %(test, result)\n    return s\n", "code_toks_joined": "def format_engine_status ( engine = None ) : <NEWLINE> <INDENT> status = get_engine_status ( engine ) <NEWLINE> s = <STRING> <NEWLINE> for test , result in status [ <STRING> ] : <NEWLINE> <INDENT> s += <STRING> % ( test , result ) <NEWLINE> <DEDENT> s += <STRING> <NEWLINE> for spider , tests in status [ <STRING> ] . items ( ) : <NEWLINE> <INDENT> s += <STRING> % spider <NEWLINE> for test , result in tests : <NEWLINE> <INDENT> s += <STRING> % ( test , result ) <NEWLINE> <DEDENT> <DEDENT> return s <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Execution engine status\\n\\n\"", "'global'", "\"%-47s : %s\\n\"", "\"\\n\"", "'spiders'", "\"Spider: %s\\n\"", "\"  %-50s : %s\\n\""]}}], ["63a9e04fd8d488a0a7bb63442f2785ce", {"code_string": "def infer_outcome(self, l, a, c, query):\n    c = asarray(c)\n    a = (asarray(a[0]), asarray(a[1]))\n    click_ids = where(c == 1)[0]\n    if not len(click_ids):\n        return 0\n    c1, c2 = self.check_constraints(l, a, click_ids)\n    return 1 if c1 > c2 else - 1 if c2 > c1 else 0\n", "code_toks_joined": "def infer_outcome ( self , l , a , c , query ) : <NEWLINE> <INDENT> c = asarray ( c ) <NEWLINE> a = ( asarray ( a [ 0 ] ) , asarray ( a [ 1 ] ) ) <NEWLINE> click_ids = where ( c == 1 ) [ 0 ] <NEWLINE> if not len ( click_ids ) : <NEWLINE> <INDENT> return 0 <NEWLINE> <DEDENT> c1 , c2 = self . check_constraints ( l , a , click_ids ) <NEWLINE> return 1 if c1 > c2 else - 1 if c2 > c1 else 0 <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["333342000d6c305669c07242c3caeb2c", {"code_string": "class VLANManualResourceModel(object):\n    def __init__(self):\n        self.access_mode = ''\n        self.isolation_level = ''\n        self.virtual_network = ''\n        self.virtual_network_attribute = ''\n        self.vlan_id = ''\n", "code_toks_joined": "class VLANManualResourceModel ( object ) : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> self . access_mode = <STRING> <NEWLINE> self . isolation_level = <STRING> <NEWLINE> self . virtual_network = <STRING> <NEWLINE> self . virtual_network_attribute = <STRING> <NEWLINE> self . vlan_id = <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["''", "''", "''", "''", "''"]}}], ["302d507980508141daa56f60ad7e1433", {"code_string": "\"\"\"Check that instantiating a class with `abc.ABCMeta` as ancestor fails if it\"\"\"\n__revision__ = 0\nimport abc\n", "code_toks_joined": "<STRING> <NEWLINE> __revision__ = 0 <NEWLINE> import abc <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Check that instantiating a class with `abc.ABCMeta` as ancestor fails if it\"\"\""]}}], ["4e0603cc52a433e4765c51fbbc0c9b44", {"code_string": "def test_const(injector):\n    call_check = Mock(return_value = None)\n    @ injector.factory('Feature', scope = scopes.Const)\n    def factory():\n        return call_check()\n    assert injector.get('Feature') == None\n    assert injector.get('Feature') == None\n    call_check.assert_called_once_with()\n", "code_toks_joined": "def test_const ( injector ) : <NEWLINE> <INDENT> call_check = Mock ( return_value = None ) <NEWLINE> @ injector . factory ( <STRING> , scope = scopes . Const ) <NEWLINE> def factory ( ) : <NEWLINE> <INDENT> return call_check ( ) <NEWLINE> <DEDENT> assert injector . get ( <STRING> ) == None <NEWLINE> assert injector . get ( <STRING> ) == None <NEWLINE> call_check . assert_called_once_with ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Feature'", "'Feature'", "'Feature'"]}}], ["76e472f2b869cb2a53101b7a48013e78", {"code_string": "def __init__(self, sqs_settings = None, processor = None, exception = None):\n    if not processor:\n        raise GatherException('missing event processor')\n    self._processor = processor\n    self._exception = exception if exception else processor.EXCEPTION_CLASS\n    self._settings = sqs_settings if sqs_settings else settings.AWS_SQS.get(processor.SETTINGS_NAME)\n    self._topicArn = self._settings.get('TOPIC_ARN')\n    self._queue = SQSQueue(settings = self._settings)\n    self._log = getLogger(__name__)\n", "code_toks_joined": "def __init__ ( self , sqs_settings = None , processor = None , exception = None ) : <NEWLINE> <INDENT> if not processor : <NEWLINE> <INDENT> raise GatherException ( <STRING> ) <NEWLINE> <DEDENT> self . _processor = processor <NEWLINE> self . _exception = exception if exception else processor . EXCEPTION_CLASS <NEWLINE> self . _settings = sqs_settings if sqs_settings else settings . AWS_SQS . get ( processor . SETTINGS_NAME ) <NEWLINE> self . _topicArn = self . _settings . get ( <STRING> ) <NEWLINE> self . _queue = SQSQueue ( settings = self . _settings ) <NEWLINE> self . _log = getLogger ( __name__ ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'missing event processor'", "'TOPIC_ARN'"]}}], ["0d1f9428e38e00ed5476f42ce90a558c", {"code_string": "class UcsmDisconnectFailed(exceptions.NeutronException):\n    message = _(\"Disconnect to UCS Manager %(ucsm_ip)s failed. \"\n        \"Reason: %(exc)s.\")\n", "code_toks_joined": "class UcsmDisconnectFailed ( exceptions . NeutronException ) : <NEWLINE> <INDENT> message = _ ( <STRING> <NEWLINE> <INDENT> <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Disconnect to UCS Manager %(ucsm_ip)s failed. \"", "\"Reason: %(exc)s.\""]}}], ["0faab5c0f956765b258975281727c8a4", {"code_string": "import project_source_info\nimport subprocess\nimport sys\nimport os\nUSE_QUIET = (os.environ.get(\"QUIET\", None) is not None)\nCHECKER_IGNORE_PREFIX = [\n    \"extern\",\n    \"intern/moto\",\n    ]\nCHECKER_BIN = \"python2\"\nCHECKER_ARGS = [\n    os.path.join(os.path.dirname(__file__), \"clang_array_check.py\"),\n    \"-I\" + os.path.join(project_source_info.SOURCE_DIR, \"extern\", \"glew\", \"include\"),\n    \"-Dbool=char\"\n    ]\n", "code_toks_joined": "import project_source_info <NEWLINE> import subprocess <NEWLINE> import sys <NEWLINE> import os <NEWLINE> USE_QUIET = ( os . environ . get ( <STRING> , None ) is not None ) <NEWLINE> CHECKER_IGNORE_PREFIX = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> ] <NEWLINE> <DEDENT> CHECKER_BIN = <STRING> <NEWLINE> CHECKER_ARGS = [ <NEWLINE> <INDENT> os . path . join ( os . path . dirname ( __file__ ) , <STRING> ) , <NEWLINE> <STRING> + os . path . join ( project_source_info . SOURCE_DIR , <STRING> , <STRING> , <STRING> ) , <NEWLINE> <STRING> <NEWLINE> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"QUIET\"", "\"extern\"", "\"intern/moto\"", "\"python2\"", "\"clang_array_check.py\"", "\"-I\"", "\"extern\"", "\"glew\"", "\"include\"", "\"-Dbool=char\""]}}], ["ef20342da2a9b65915268bfd6a3fcc7a", {"code_string": "def send_event_create_mail(event, users_emails):\n    current_site = Site.objects.get_current()\n    extra_context = {'event': event, 'review_url': get_event_review_url(event),\n        'site_url': '{}://{}'.format(settings.SITE_SCHEME, current_site.domain)}\n    send_email('FOSSEvents | ' + event.name[: 15] + ' published!',\n        'email/event_create_moderators_email.txt', users_emails,\n        extra_context, 'email/event_create_moderators_email.html')\n    send_email('FOSSEvents | ' + event.name[: 15] + ' published!',\n        'email/event_create_creator_email.txt', [event.owner_email],\n        extra_context, 'email/event_create_creator_email.html')\n", "code_toks_joined": "def send_event_create_mail ( event , users_emails ) : <NEWLINE> <INDENT> current_site = Site . objects . get_current ( ) <NEWLINE> extra_context = { <STRING> : event , <STRING> : get_event_review_url ( event ) , <NEWLINE> <INDENT> <STRING> : <STRING> . format ( settings . SITE_SCHEME , current_site . domain ) } <NEWLINE> <DEDENT> send_email ( <STRING> + event . name [ : 15 ] + <STRING> , <NEWLINE> <INDENT> <STRING> , users_emails , <NEWLINE> extra_context , <STRING> ) <NEWLINE> <DEDENT> send_email ( <STRING> + event . name [ : 15 ] + <STRING> , <NEWLINE> <INDENT> <STRING> , [ event . owner_email ] , <NEWLINE> extra_context , <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'event'", "'review_url'", "'site_url'", "'{}://{}'", "'FOSSEvents | '", "' published!'", "'email/event_create_moderators_email.txt'", "'email/event_create_moderators_email.html'", "'FOSSEvents | '", "' published!'", "'email/event_create_creator_email.txt'", "'email/event_create_creator_email.html'"]}}], ["5c791cc8693ab8ecdf52485b38e9f351", {"code_string": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\n", "code_toks_joined": "import numpy as np <NEWLINE> import matplotlib . pyplot as plt <NEWLINE> from sklearn import datasets <NEWLINE>", "anonymize_dict": {}}], ["8950c37296968a080ed4cb56ff86115f", {"code_string": "def _SetupPaths():\n    \"\"\"Setting path to find pyauto_functional.py.\"\"\"\n    tracing_dir = os.path.abspath(os.path.dirname(__file__))\n    sys.path.append(tracing_dir)\n    sys.path.append(os.path.normpath(os.path.join(tracing_dir, os.pardir)))\n", "code_toks_joined": "def _SetupPaths ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> tracing_dir = os . path . abspath ( os . path . dirname ( __file__ ) ) <NEWLINE> sys . path . append ( tracing_dir ) <NEWLINE> sys . path . append ( os . path . normpath ( os . path . join ( tracing_dir , os . pardir ) ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Setting path to find pyauto_functional.py.\"\"\""]}}], ["d321913da0dc37164fa02ba8a81a0e63", {"code_string": "def test_get_response_check(self):\n    t = operators.SimpleHttpOperator(\n        task_id = 'get_op',\n        method = 'GET',\n        endpoint = '/search',\n        data = {\"client\": \"ubuntu\", \"q\": \"airflow\"},\n        response_check = lambda response: (\"airbnb/airflow\" in response.text),\n        headers = {},\n        dag = self.dag)\n    t.run(start_date = DEFAULT_DATE, end_date = DEFAULT_DATE, force = True)\n", "code_toks_joined": "def test_get_response_check ( self ) : <NEWLINE> <INDENT> t = operators . SimpleHttpOperator ( <NEWLINE> <INDENT> task_id = <STRING> , <NEWLINE> method = <STRING> , <NEWLINE> endpoint = <STRING> , <NEWLINE> data = { <STRING> : <STRING> , <STRING> : <STRING> } , <NEWLINE> response_check = lambda response : ( <STRING> in response . text ) , <NEWLINE> headers = { } , <NEWLINE> dag = self . dag ) <NEWLINE> <DEDENT> t . run ( start_date = DEFAULT_DATE , end_date = DEFAULT_DATE , force = True ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'get_op'", "'GET'", "'/search'", "\"client\"", "\"ubuntu\"", "\"q\"", "\"airflow\"", "\"airbnb/airflow\""]}}], ["c44f93c85231581aba673f5b18907d0e", {"code_string": "def __init__(self, ignore_border, mode = 'max', ndim = 2):\n    self.ndim = ndim\n    self.ignore_border = ignore_border\n    self.mode = mode\n    CGpuKernelBase.__init__(self, ['pool_max_rop.c'],\n        'APPLY_SPECIFIC(max_pool_rop)')\n    assert mode == 'max'\n    assert ndim in[2, 3]\n", "code_toks_joined": "def __init__ ( self , ignore_border , mode = <STRING> , ndim = 2 ) : <NEWLINE> <INDENT> self . ndim = ndim <NEWLINE> self . ignore_border = ignore_border <NEWLINE> self . mode = mode <NEWLINE> CGpuKernelBase . __init__ ( self , [ <STRING> ] , <NEWLINE> <INDENT> <STRING> ) <NEWLINE> <DEDENT> assert mode == <STRING> <NEWLINE> assert ndim in [ 2 , 3 ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'max'", "'pool_max_rop.c'", "'APPLY_SPECIFIC(max_pool_rop)'", "'max'"]}}], ["9b0c77586d0b4b81d7f1b41236aafe70", {"code_string": "def add_owner(apps, schema_editor):\n    LieuAFO = apps.get_model('afo', 'LieuAFO')\n    EvenementAFO = apps.get_model('afo', 'EvenementAFO')\n    if not LieuAFO.objects.exists() and not EvenementAFO.objects.exists():\n        return\n    owner = apps.get_model('accounts', 'Hierarchicuser').objects.get(\n        username = 'afo')\n    LieuAFO.objects.update(owner = owner)\n    EvenementAFO.objects.update(owner = owner)\n", "code_toks_joined": "def add_owner ( apps , schema_editor ) : <NEWLINE> <INDENT> LieuAFO = apps . get_model ( <STRING> , <STRING> ) <NEWLINE> EvenementAFO = apps . get_model ( <STRING> , <STRING> ) <NEWLINE> if not LieuAFO . objects . exists ( ) and not EvenementAFO . objects . exists ( ) : <NEWLINE> <INDENT> return <NEWLINE> <DEDENT> owner = apps . get_model ( <STRING> , <STRING> ) . objects . get ( <NEWLINE> <INDENT> username = <STRING> ) <NEWLINE> <DEDENT> LieuAFO . objects . update ( owner = owner ) <NEWLINE> EvenementAFO . objects . update ( owner = owner ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'afo'", "'LieuAFO'", "'afo'", "'EvenementAFO'", "'accounts'", "'Hierarchicuser'", "'afo'"]}}], ["ced1607c860b9a6fcf37453566b8f731", {"code_string": "class AStarSearchModel:\n    \"\"\"Abstract model for implementation A-Star Search.\"\"\"\n    def __init__(self):\n        \"\"\"Default constructor.\"\"\"\n        pass\n    def getActionListWithMetric(self):\n        \"\"\"Method for getting list of available action with it's time metrics.\"\"\"\n        pass\n    def doAction(self, action):\n        \"\"\"Method for do action and changing internal state of object.\"\"\"\n        pass\n", "code_toks_joined": "class AStarSearchModel : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> pass <NEWLINE> <DEDENT> def getActionListWithMetric ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> pass <NEWLINE> <DEDENT> def doAction ( self , action ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> pass <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Abstract model for implementation A-Star Search.\"\"\"", "\"\"\"Default constructor.\"\"\"", "\"\"\"Method for getting list of available action with it's time metrics.\"\"\"", "\"\"\"Method for do action and changing internal state of object.\"\"\""]}}], ["e36b0bc4c3838f5411b8c9a175234168", {"code_string": "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\nimport glob\nimport os\nmodules = glob.glob(os.path.dirname(__file__) + \"/*.py\")\nALL_TABLES = [os.path.basename(f)[: - 3] for f in modules]\n", "code_toks_joined": "from __future__ import absolute_import <NEWLINE> from __future__ import division <NEWLINE> from __future__ import print_function <NEWLINE> from __future__ import unicode_literals <NEWLINE> import glob <NEWLINE> import os <NEWLINE> modules = glob . glob ( os . path . dirname ( __file__ ) + <STRING> ) <NEWLINE> ALL_TABLES = [ os . path . basename ( f ) [ : - 3 ] for f in modules ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"/*.py\""]}}], ["1075803e959d8d9f1ba3db08ad3b337b", {"code_string": "def test_oneway_C_SSL(self):\n    self._ssl_check()\n    self._do_oneway_test(MessengerReceiverC(), MessengerSenderC(), \"amqps\")\n", "code_toks_joined": "def test_oneway_C_SSL ( self ) : <NEWLINE> <INDENT> self . _ssl_check ( ) <NEWLINE> self . _do_oneway_test ( MessengerReceiverC ( ) , MessengerSenderC ( ) , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"amqps\""]}}], ["bb7eb2731dafb7d8b6161e2756b12263", {"code_string": "from.homepage import HomePage\nfrom.history import HistoryPage, DetailsPage, BillsPage\nfrom.login import LoginPage\n__all__ = ['LoginPage', 'HomePage', 'HistoryPage', 'DetailsPage', 'BillsPage']\n", "code_toks_joined": "from . homepage import HomePage <NEWLINE> from . history import HistoryPage , DetailsPage , BillsPage <NEWLINE> from . login import LoginPage <NEWLINE> __all__ = [ <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'LoginPage'", "'HomePage'", "'HistoryPage'", "'DetailsPage'", "'BillsPage'"]}}], ["030a7668df057c634609eee2fdc12329", {"code_string": "def accumulate_m2m_mapping(obj, container_key, item_key, container_coerce = identity, item_coerce = identity):\n    \"\"\"Turns a relation like this:\"\"\"\n    ret = {}\n    for item in obj:\n        container_id = container_coerce(item[container_key])\n        item_id = item_coerce(item[item_key])\n        if container_id in ret:\n            ret[container_id].append(item_id)\n        else:\n            ret[container_id] = [item_id]\n    return ret\n", "code_toks_joined": "def accumulate_m2m_mapping ( obj , container_key , item_key , container_coerce = identity , item_coerce = identity ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> ret = { } <NEWLINE> for item in obj : <NEWLINE> <INDENT> container_id = container_coerce ( item [ container_key ] ) <NEWLINE> item_id = item_coerce ( item [ item_key ] ) <NEWLINE> if container_id in ret : <NEWLINE> <INDENT> ret [ container_id ] . append ( item_id ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> ret [ container_id ] = [ item_id ] <NEWLINE> <DEDENT> <DEDENT> return ret <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Turns a relation like this:\"\"\""]}}], ["572237697841ed2674e378c95693ca89", {"code_string": "\"\"\"A. Theatre Square\"\"\"\nimport math\ndata = input()\nn, m, a = [int(x) for x in data.split()]\nx = math.ceil(n / a)\ny = math.ceil(m / a)\nprint(x * y)\n", "code_toks_joined": "<STRING> <NEWLINE> import math <NEWLINE> data = input ( ) <NEWLINE> n , m , a = [ int ( x ) for x in data . split ( ) ] <NEWLINE> x = math . ceil ( n / a ) <NEWLINE> y = math . ceil ( m / a ) <NEWLINE> print ( x * y ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"A. Theatre Square\"\"\""]}}], ["1379ecafba450201b309686cba3725a4", {"code_string": "import os\nimport shutil\nimport traceback\nfrom lib.FileManager.workers.baseUploadWorker import BaseUploadWorker\n", "code_toks_joined": "import os <NEWLINE> import shutil <NEWLINE> import traceback <NEWLINE> from lib . FileManager . workers . baseUploadWorker import BaseUploadWorker <NEWLINE>", "anonymize_dict": {}}], ["da0f3028118665eb195601d97205e9d2", {"code_string": "def post_receive(self, alert):\n    LOG.info('Sending message %s to SNS topic \"%s\"', alert.get_id(), self.topic_arn)\n    LOG.debug('Message: %s', alert.get_body())\n    response = self.connection.publish(topic = self.topic_arn, message = alert.get_body())\n    LOG.debug('Response: %s', response)\n", "code_toks_joined": "def post_receive ( self , alert ) : <NEWLINE> <INDENT> LOG . info ( <STRING> , alert . get_id ( ) , self . topic_arn ) <NEWLINE> LOG . debug ( <STRING> , alert . get_body ( ) ) <NEWLINE> response = self . connection . publish ( topic = self . topic_arn , message = alert . get_body ( ) ) <NEWLINE> LOG . debug ( <STRING> , response ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Sending message %s to SNS topic \"%s\"'", "'Message: %s'", "'Response: %s'"]}}], ["a3b4b7381d69cbfe8be75025c011ebb3", {"code_string": "\"\"\"Weakly connected components.\"\"\"\n__authors__ = \"\\n\".join(['Aric Hagberg (hagberg@lanl.gov)'\n    'Christopher Ellison'])\n__all__ = ['number_weakly_connected_components',\n    'weakly_connected_components',\n    'weakly_connected_component_subgraphs',\n    'is_weakly_connected'\n    ]\nimport networkx as nx\n", "code_toks_joined": "<STRING> <NEWLINE> __authors__ = <STRING> . join ( [ <STRING> <NEWLINE> <INDENT> <STRING> ] ) <NEWLINE> <DEDENT> __all__ = [ <STRING> , <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> <NEWLINE> ] <NEWLINE> <DEDENT> import networkx as nx <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Weakly connected components.\"\"\"", "\"\\n\"", "'Aric Hagberg (hagberg@lanl.gov)'", "'Christopher Ellison'", "'number_weakly_connected_components'", "'weakly_connected_components'", "'weakly_connected_component_subgraphs'", "'is_weakly_connected'"]}}], ["019b29a17d875a6e24d5ea6be07cdc29", {"code_string": "def find_index(vec_vals, target):\n    \"\"\"returns the first index of vec_vals that contains the value\"\"\"\n    target = np.atleast_1d(target)\n    vec_vals = np.array(vec_vals)\n    index_list = []\n    for item in target:\n        first_index = np.argmin(np.abs(vec_vals - item))\n        index_list.append(first_index)\n    return index_list\n", "code_toks_joined": "def find_index ( vec_vals , target ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> target = np . atleast_1d ( target ) <NEWLINE> vec_vals = np . array ( vec_vals ) <NEWLINE> index_list = [ ] <NEWLINE> for item in target : <NEWLINE> <INDENT> first_index = np . argmin ( np . abs ( vec_vals - item ) ) <NEWLINE> index_list . append ( first_index ) <NEWLINE> <DEDENT> return index_list <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"returns the first index of vec_vals that contains the value\"\"\""]}}], ["f869eeabacc46c6f2e12dd7e4d6e0828", {"code_string": "def test_lasso_zero():\n    X = [[0], [0], [0]]\n    y = [0, 0, 0]\n    clf = Lasso(alpha = 0.1).fit(X, y)\n    pred = clf.predict([[1], [2], [3]])\n    assert_array_almost_equal(clf.coef_, [0])\n    assert_array_almost_equal(pred, [0, 0, 0])\n    assert_almost_equal(clf.dual_gap_, 0)\n", "code_toks_joined": "def test_lasso_zero ( ) : <NEWLINE> <INDENT> X = [ [ 0 ] , [ 0 ] , [ 0 ] ] <NEWLINE> y = [ 0 , 0 , 0 ] <NEWLINE> clf = Lasso ( alpha = 0.1 ) . fit ( X , y ) <NEWLINE> pred = clf . predict ( [ [ 1 ] , [ 2 ] , [ 3 ] ] ) <NEWLINE> assert_array_almost_equal ( clf . coef_ , [ 0 ] ) <NEWLINE> assert_array_almost_equal ( pred , [ 0 , 0 , 0 ] ) <NEWLINE> assert_almost_equal ( clf . dual_gap_ , 0 ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["07c7246daed09f782b7e1256e3ebeb54", {"code_string": "class SystemCapabilities(Packet):\n    name = \"LLDPSystemCapabilities\"\n    fields_desc = [BitField(\"type\", 7, 7),\n        BitField(\"length\", 4, 9),\n        ShortField(\"systemcapabilities\", 2),\n        ShortField(\"enablecapabilities\", 1)]\n", "code_toks_joined": "class SystemCapabilities ( Packet ) : <NEWLINE> <INDENT> name = <STRING> <NEWLINE> fields_desc = [ BitField ( <STRING> , 7 , 7 ) , <NEWLINE> <INDENT> BitField ( <STRING> , 4 , 9 ) , <NEWLINE> ShortField ( <STRING> , 2 ) , <NEWLINE> ShortField ( <STRING> , 1 ) ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"LLDPSystemCapabilities\"", "\"type\"", "\"length\"", "\"systemcapabilities\"", "\"enablecapabilities\""]}}], ["1c1418f961404d03f0a6d36b43ae5485", {"code_string": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom pylab import *\nx = [- 5, - 3, - 4, - 6, - 5, - 3, 3, 4, 5]\ny = [- 3, - 4, - 5, 3, 5, 6, 7, 5, 5]\ncolor = [1, 1, 1, 2, 2, 2, 3, 3, 3]\nplt.scatter(x, y, c = color, s = 500)\nsavefig('question3.jpg')\nplt.show()\n", "code_toks_joined": "import numpy as np <NEWLINE> import matplotlib . pyplot as plt <NEWLINE> from pylab import * <NEWLINE> x = [ - 5 , - 3 , - 4 , - 6 , - 5 , - 3 , 3 , 4 , 5 ] <NEWLINE> y = [ - 3 , - 4 , - 5 , 3 , 5 , 6 , 7 , 5 , 5 ] <NEWLINE> color = [ 1 , 1 , 1 , 2 , 2 , 2 , 3 , 3 , 3 ] <NEWLINE> plt . scatter ( x , y , c = color , s = 500 ) <NEWLINE> savefig ( <STRING> ) <NEWLINE> plt . show ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'question3.jpg'"]}}], ["e146147000faffe18847d61513a0f918", {"code_string": "def __init__(self):\n    \"\"\"Class instantiation\"\"\"\n    self.input = \"default.html\"\n    self.output = \"stdout\"\n    self.env = None\n", "code_toks_joined": "def __init__ ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . input = <STRING> <NEWLINE> self . output = <STRING> <NEWLINE> self . env = None <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Class instantiation\"\"\"", "\"default.html\"", "\"stdout\""]}}], ["543a8268d9e4f2de62388516b94ea670", {"code_string": "'''Created on Jan 27, 2011'''\nimport numpy as np\nimport scipy.linalg as la\n", "code_toks_joined": "<STRING> <NEWLINE> import numpy as np <NEWLINE> import scipy . linalg as la <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Created on Jan 27, 2011'''"]}}], ["0d33b14bb79a0a4e8afa308903376b53", {"code_string": "class SystemctlSSRCommandLogicTests(TestCase, SystemctlCommandLogicMixin):\n    def _test_ssr(self, output, expected_error = False):\n        assertMethod = self.assertTrue if expected_error else self.assertFalse\n        with self.app.test_request_context():\n            with self.patch_getoutput(output):\n                error = systemctl_ssr_command('command', 'service')\n                assertMethod(error)\n    def test_no_error(self):\n        self._test_ssr('')\n    def test_error(self):\n        self._test_ssr(SYSTEMCTL_SSR_ERROR_OUTPUT, expected_error = True)\n", "code_toks_joined": "class SystemctlSSRCommandLogicTests ( TestCase , SystemctlCommandLogicMixin ) : <NEWLINE> <INDENT> def _test_ssr ( self , output , expected_error = False ) : <NEWLINE> <INDENT> assertMethod = self . assertTrue if expected_error else self . assertFalse <NEWLINE> with self . app . test_request_context ( ) : <NEWLINE> <INDENT> with self . patch_getoutput ( output ) : <NEWLINE> <INDENT> error = systemctl_ssr_command ( <STRING> , <STRING> ) <NEWLINE> assertMethod ( error ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> def test_no_error ( self ) : <NEWLINE> <INDENT> self . _test_ssr ( <STRING> ) <NEWLINE> <DEDENT> def test_error ( self ) : <NEWLINE> <INDENT> self . _test_ssr ( SYSTEMCTL_SSR_ERROR_OUTPUT , expected_error = True ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'command'", "'service'", "''"]}}], ["0f05edbc9b8b368a203cc5a209d64385", {"code_string": "import os\nimport logging\nfrom glob import glob\nimport fnmatch\nimport h5py\nfrom PIL import Image\nimport numpy as np\nimport pyglet\nfrom.roi import ROI\n", "code_toks_joined": "import os <NEWLINE> import logging <NEWLINE> from glob import glob <NEWLINE> import fnmatch <NEWLINE> import h5py <NEWLINE> from PIL import Image <NEWLINE> import numpy as np <NEWLINE> import pyglet <NEWLINE> from . roi import ROI <NEWLINE>", "anonymize_dict": {}}], ["63569fd0489b3937371b40c5ff1b314e", {"code_string": "def factorial(n):\n    factorial_total = 1\n    while n >= 1:\n        factorial_total = factorial_total * n\n        n = n - 1\n    return factorial_total\n", "code_toks_joined": "def factorial ( n ) : <NEWLINE> <INDENT> factorial_total = 1 <NEWLINE> while n >= 1 : <NEWLINE> <INDENT> factorial_total = factorial_total * n <NEWLINE> n = n - 1 <NEWLINE> <DEDENT> return factorial_total <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["019d55ca3a4d1c1b31bc93adf4e368ea", {"code_string": "def apply_to_one(f):\n    \"\"\" calls the function f with 1 as its argument\"\"\"\n    return f(1)\n", "code_toks_joined": "def apply_to_one ( f ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return f ( 1 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" calls the function f with 1 as its argument\"\"\""]}}], ["3f3e3863818c449f3fc4f9fafa3696d6", {"code_string": "import pymc\nx = pymc.Uniform(\"x\", lower = 0.0, upper = 1.0)\ny = pymc.Uniform(\"y\", lower = 0.0, upper = 1.0)\n", "code_toks_joined": "import pymc <NEWLINE> x = pymc . Uniform ( <STRING> , lower = 0.0 , upper = 1.0 ) <NEWLINE> y = pymc . Uniform ( <STRING> , lower = 0.0 , upper = 1.0 ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"x\"", "\"y\""]}}], ["49de06b882abe59fcd39476726563069", {"code_string": "\"\"\"Evaluates polynomial generator cost & derivatives.\"\"\"\nimport sys\nfrom numpy import zeros, arange, flatnonzero as find\nfrom pypower.idx_cost import MODEL, NCOST, PW_LINEAR, COST\n", "code_toks_joined": "<STRING> <NEWLINE> import sys <NEWLINE> from numpy import zeros , arange , flatnonzero as find <NEWLINE> from pypower . idx_cost import MODEL , NCOST , PW_LINEAR , COST <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Evaluates polynomial generator cost & derivatives.\"\"\""]}}], ["75b3684faed6f06b8dcc016de3b023e2", {"code_string": "def _get_elem_at_rank(rank, data, n_negative, n_zeros):\n    \"\"\"Find the value in data augmented with n_zeros for the given rank\"\"\"\n    if rank < n_negative:\n        return data[rank]\n    if rank - n_negative < n_zeros:\n        return 0\n    return data[rank - n_zeros]\n", "code_toks_joined": "def _get_elem_at_rank ( rank , data , n_negative , n_zeros ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if rank < n_negative : <NEWLINE> <INDENT> return data [ rank ] <NEWLINE> <DEDENT> if rank - n_negative < n_zeros : <NEWLINE> <INDENT> return 0 <NEWLINE> <DEDENT> return data [ rank - n_zeros ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Find the value in data augmented with n_zeros for the given rank\"\"\""]}}], ["f45aa0c62354e9a7f9d4196c87d82478", {"code_string": "def get_table_info(table_id):\n    config_instance = MIRNDataSourceConfig.from_dict(BIGQUERY_CONFIG)\n    table_info = None\n    for table_config in config_instance.data_table_list:\n        if table_config.internal_table_id == table_id:\n            table_info = table_config\n    return table_info\n", "code_toks_joined": "def get_table_info ( table_id ) : <NEWLINE> <INDENT> config_instance = MIRNDataSourceConfig . from_dict ( BIGQUERY_CONFIG ) <NEWLINE> table_info = None <NEWLINE> for table_config in config_instance . data_table_list : <NEWLINE> <INDENT> if table_config . internal_table_id == table_id : <NEWLINE> <INDENT> table_info = table_config <NEWLINE> <DEDENT> <DEDENT> return table_info <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["7dcd9ff1b4610960a973f388a0b1aae4", {"code_string": "from.api import API\nfrom.baseservice import BaseService\nfrom.defaults import Defaults\nLOCATOR_DEFAULT_ENDPOINTS = Defaults.locators\n", "code_toks_joined": "from . api import API <NEWLINE> from . baseservice import BaseService <NEWLINE> from . defaults import Defaults <NEWLINE> LOCATOR_DEFAULT_ENDPOINTS = Defaults . locators <NEWLINE>", "anonymize_dict": {}}], ["56d654fb211c5005c3dc81baa2d005ba", {"code_string": "def guest_required(f):\n    @ wraps(f)\n    def decorated_function(* args, ** kwargs):\n        if 'username' in session:\n            return redirect(url_for('meeple.index'))\n        return f(* args, ** kwargs)\n    return decorated_function\n", "code_toks_joined": "def guest_required ( f ) : <NEWLINE> <INDENT> @ wraps ( f ) <NEWLINE> def decorated_function ( * args , ** kwargs ) : <NEWLINE> <INDENT> if <STRING> in session : <NEWLINE> <INDENT> return redirect ( url_for ( <STRING> ) ) <NEWLINE> <DEDENT> return f ( * args , ** kwargs ) <NEWLINE> <DEDENT> return decorated_function <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'username'", "'meeple.index'"]}}], ["7de1a124df711d72de018282711a7cda", {"code_string": "def getUserConsentByUniqueID(self, uniqueID):\n    if self.getByUniqueID(uniqueID).date_signed is not None:\n        return True\n    else:\n        return False\n", "code_toks_joined": "def getUserConsentByUniqueID ( self , uniqueID ) : <NEWLINE> <INDENT> if self . getByUniqueID ( uniqueID ) . date_signed is not None : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["9a6601a3d5dd390ed28141485607ef05", {"code_string": "def make_public(modeladmin, request, queryset):\n    for obj in queryset.filter(is_public = False):\n        obj.__dict__.update(is_public = True, published_by_id = request.user.id)\n        obj.save()\n        if obj.speakers:\n            thread = SessionApprovedEmailThread(obj)\n            if thread.should_send:\n                SentEmail(email_thread = thread).save()\n                thread.start()\n", "code_toks_joined": "def make_public ( modeladmin , request , queryset ) : <NEWLINE> <INDENT> for obj in queryset . filter ( is_public = False ) : <NEWLINE> <INDENT> obj . __dict__ . update ( is_public = True , published_by_id = request . user . id ) <NEWLINE> obj . save ( ) <NEWLINE> if obj . speakers : <NEWLINE> <INDENT> thread = SessionApprovedEmailThread ( obj ) <NEWLINE> if thread . should_send : <NEWLINE> <INDENT> SentEmail ( email_thread = thread ) . save ( ) <NEWLINE> thread . start ( ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["2406c152606e04f326955f0371a0a876", {"code_string": "'''Copyright (C) 2008 10gen Inc.'''\nfrom _10gen import getglobal\nimport _10gen\n_10gen.pyX = getglobal('x')\n_10gen.pyY = getglobal('y')\n", "code_toks_joined": "<STRING> <NEWLINE> from _10gen import getglobal <NEWLINE> import _10gen <NEWLINE> _10gen . pyX = getglobal ( <STRING> ) <NEWLINE> _10gen . pyY = getglobal ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Copyright (C) 2008 10gen Inc.'''", "'x'", "'y'"]}}], ["d71c2737b679acb7b8be56db33c76c8a", {"code_string": "class IElementForStg(object):\n    def __init__(self, templates, settingsObject):\n        self.templatesRepository = templates\n        self.settingsObject = settingsObject\n        self.templateResolver = TemplateResolver(self.templatesRepository, self.getTemplateName())\n    def getType(self):\n        raise NotImplementedError(\"IElementForStg is an abstract class.\")\n    def getTemplateName(self):\n        raise NotImplementedError(\"IElementForStg is an abstract class.\")\n    def resolve(self):\n        return self.templateResolver.fill(self.settingsObject)\n", "code_toks_joined": "class IElementForStg ( object ) : <NEWLINE> <INDENT> def __init__ ( self , templates , settingsObject ) : <NEWLINE> <INDENT> self . templatesRepository = templates <NEWLINE> self . settingsObject = settingsObject <NEWLINE> self . templateResolver = TemplateResolver ( self . templatesRepository , self . getTemplateName ( ) ) <NEWLINE> <DEDENT> def getType ( self ) : <NEWLINE> <INDENT> raise NotImplementedError ( <STRING> ) <NEWLINE> <DEDENT> def getTemplateName ( self ) : <NEWLINE> <INDENT> raise NotImplementedError ( <STRING> ) <NEWLINE> <DEDENT> def resolve ( self ) : <NEWLINE> <INDENT> return self . templateResolver . fill ( self . settingsObject ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"IElementForStg is an abstract class.\"", "\"IElementForStg is an abstract class.\""]}}], ["a32bb8aa53ed23b8a9c4011a65adfdda", {"code_string": "def _delete_object_method(obj_name):\n    def del_obj(self, obj_id, ** kwargs):\n        url = '{url}/{obj_name}/{obj_id}/'\n        if not self.simulate:\n            full_url = url.format(url = self.api_base_url, obj_name = obj_name, obj_id = obj_id)\n            logging.debug('DELETE %s', full_url)\n            resp = requests.delete(\n                full_url,\n                headers = self.headers,\n                params = kwargs)\n            return self.handle_resp(resp, 200)\n        return{'id': obj_id}\n    return del_obj\n", "code_toks_joined": "def _delete_object_method ( obj_name ) : <NEWLINE> <INDENT> def del_obj ( self , obj_id , ** kwargs ) : <NEWLINE> <INDENT> url = <STRING> <NEWLINE> if not self . simulate : <NEWLINE> <INDENT> full_url = url . format ( url = self . api_base_url , obj_name = obj_name , obj_id = obj_id ) <NEWLINE> logging . debug ( <STRING> , full_url ) <NEWLINE> resp = requests . delete ( <NEWLINE> <INDENT> full_url , <NEWLINE> headers = self . headers , <NEWLINE> params = kwargs ) <NEWLINE> <DEDENT> return self . handle_resp ( resp , 200 ) <NEWLINE> <DEDENT> return { <STRING> : obj_id } <NEWLINE> <DEDENT> return del_obj <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'{url}/{obj_name}/{obj_id}/'", "'DELETE %s'", "'id'"]}}], ["213b91ab63cc700077263fd118ca5114", {"code_string": "import requests\nimport sys\nimport json\nimport time\nfrom portality.core import app\nconfig = app.config\nENDPOINT_TEMPLATE = \"http://{server}:9200/doaj/{type}/_search?q=*&size=1000&sort=created_date:desc\"\n", "code_toks_joined": "import requests <NEWLINE> import sys <NEWLINE> import json <NEWLINE> import time <NEWLINE> from portality . core import app <NEWLINE> config = app . config <NEWLINE> ENDPOINT_TEMPLATE = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"http://{server}:9200/doaj/{type}/_search?q=*&size=1000&sort=created_date:desc\""]}}], ["6ab8695560cd9fa677a575ee933a5722", {"code_string": "def django_version_after(available, limit):\n    \"\"\"If the current django version is later than the specified limit,\"\"\"\n    return StrictVersion(available) > StrictVersion(limit)\n", "code_toks_joined": "def django_version_after ( available , limit ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return StrictVersion ( available ) > StrictVersion ( limit ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"If the current django version is later than the specified limit,\"\"\""]}}], ["ce7072b71880495ea8eb8f834cff92e6", {"code_string": "def get_window(self):\n    \"\"\"Property\"\"\"\n    return self._window\n", "code_toks_joined": "def get_window ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . _window <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Property\"\"\""]}}], ["3fda5dfe1cadec16b439a8b8cd6a0118", {"code_string": "def add_default_values_to_help(parser):\n    for group in parser.option_groups +[parser]:\n        for option in group.option_list:\n            if option.default != NO_DEFAULT and option.help:\n                option.help += ' [default: %default]'\n", "code_toks_joined": "def add_default_values_to_help ( parser ) : <NEWLINE> <INDENT> for group in parser . option_groups + [ parser ] : <NEWLINE> <INDENT> for option in group . option_list : <NEWLINE> <INDENT> if option . default != NO_DEFAULT and option . help : <NEWLINE> <INDENT> option . help += <STRING> <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["' [default: %default]'"]}}], ["71923df5f013aa62da8d9341609106df", {"code_string": "class Fasta2Nexus(object):\n    \"\"\"\"\"\"\n    def __init__(self, infile, outfile, * args, ** kwargs):\n        \"\"\"\"\"\"\n        self.infile = infile\n        self.outfile = outfile\n    def __call__(self):\n        input_handle = open(self.infile, \"rU\")\n        output_handle = open(self.outfile, \"w\")\n        alignments = AlignIO.parse(input_handle, \"fasta\")\n        AlignIO.write(alignments, output_handle, \"nexus\")\n        output_handle.close()\n        input_handle.close()\n", "code_toks_joined": "class Fasta2Nexus ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , infile , outfile , * args , ** kwargs ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . infile = infile <NEWLINE> self . outfile = outfile <NEWLINE> <DEDENT> def __call__ ( self ) : <NEWLINE> <INDENT> input_handle = open ( self . infile , <STRING> ) <NEWLINE> output_handle = open ( self . outfile , <STRING> ) <NEWLINE> alignments = AlignIO . parse ( input_handle , <STRING> ) <NEWLINE> AlignIO . write ( alignments , output_handle , <STRING> ) <NEWLINE> output_handle . close ( ) <NEWLINE> input_handle . close ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"\"\"\"", "\"\"\"\"\"\"", "\"rU\"", "\"w\"", "\"fasta\"", "\"nexus\""]}}], ["e6cc1468b3b5c3d563c7f09d4add5d00", {"code_string": "class Facilitator(Person):\n    bio = models.TextField(max_length = 500)\n    twitter = models.CharField(max_length = 25)\n    def __str__(self):\n        return self.name\n", "code_toks_joined": "class Facilitator ( Person ) : <NEWLINE> <INDENT> bio = models . TextField ( max_length = 500 ) <NEWLINE> twitter = models . CharField ( max_length = 25 ) <NEWLINE> def __str__ ( self ) : <NEWLINE> <INDENT> return self . name <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["29a335b1994c5e4f46b63a01ef5ba37a", {"code_string": "from persistent import Persistent\nfrom zope.component.factory import Factory\nfrom zope.interface import implements\nfrom sparc.entity import SparcEntity\nfrom interfaces import IPerson\n", "code_toks_joined": "from persistent import Persistent <NEWLINE> from zope . component . factory import Factory <NEWLINE> from zope . interface import implements <NEWLINE> from sparc . entity import SparcEntity <NEWLINE> from interfaces import IPerson <NEWLINE>", "anonymize_dict": {}}], ["657469424cfa0cc43d2e38c007dd751e", {"code_string": "def Pull(self, request, context):\n    \"\"\"Pulls messages from the server. Returns an empty list if there are no\"\"\"\n    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n    context.set_details('Method not implemented!')\n    raise NotImplementedError('Method not implemented!')\n", "code_toks_joined": "def Pull ( self , request , context ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> context . set_code ( grpc . StatusCode . UNIMPLEMENTED ) <NEWLINE> context . set_details ( <STRING> ) <NEWLINE> raise NotImplementedError ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Pulls messages from the server. Returns an empty list if there are no\"\"\"", "'Method not implemented!'", "'Method not implemented!'"]}}], ["6345f6851c7e14295c7acc3de83443d9", {"code_string": "class CUDA_build_ext(build_ext):\n    \"\"\"Custom build_ext command that compiles CUDA files.\"\"\"\n    def build_extensions(self):\n        self.compiler.src_extensions.append('.cu')\n        self.compiler.set_executable('compiler_so', 'nvcc')\n        self.compiler.set_executable('linker_so', 'nvcc --shared')\n        build_ext.build_extensions(self)\n", "code_toks_joined": "class CUDA_build_ext ( build_ext ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def build_extensions ( self ) : <NEWLINE> <INDENT> self . compiler . src_extensions . append ( <STRING> ) <NEWLINE> self . compiler . set_executable ( <STRING> , <STRING> ) <NEWLINE> self . compiler . set_executable ( <STRING> , <STRING> ) <NEWLINE> build_ext . build_extensions ( self ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Custom build_ext command that compiles CUDA files.\"\"\"", "'.cu'", "'compiler_so'", "'nvcc'", "'linker_so'", "'nvcc --shared'"]}}], ["cfa255026cb4b07d08d5f95c68388b30", {"code_string": "class SelectionPane(TraitsDockPane):\n    id = 'pychron.repo.selection'\n    name = 'Repositories'\n    def traits_view(self):\n        origin_grp = VGroup(UItem('repository_names',\n            editor = ListStrEditor(selected = 'selected_repository_name',\n                editable = False)),\n                show_border = True, label = 'Origin')\n        local_grp = VGroup(UItem('local_names',\n            editor = ListStrEditor(selected = 'selected_local_repository_name',\n                editable = False)),\n                show_border = True, label = 'Local')\n        v = View(VGroup(local_grp, origin_grp))\n        return v\n", "code_toks_joined": "class SelectionPane ( TraitsDockPane ) : <NEWLINE> <INDENT> id = <STRING> <NEWLINE> name = <STRING> <NEWLINE> def traits_view ( self ) : <NEWLINE> <INDENT> origin_grp = VGroup ( UItem ( <STRING> , <NEWLINE> <INDENT> editor = ListStrEditor ( selected = <STRING> , <NEWLINE> <INDENT> editable = False ) ) , <NEWLINE> show_border = True , label = <STRING> ) <NEWLINE> <DEDENT> <DEDENT> local_grp = VGroup ( UItem ( <STRING> , <NEWLINE> <INDENT> editor = ListStrEditor ( selected = <STRING> , <NEWLINE> <INDENT> editable = False ) ) , <NEWLINE> show_border = True , label = <STRING> ) <NEWLINE> <DEDENT> <DEDENT> v = View ( VGroup ( local_grp , origin_grp ) ) <NEWLINE> return v <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'pychron.repo.selection'", "'Repositories'", "'repository_names'", "'selected_repository_name'", "'Origin'", "'local_names'", "'selected_local_repository_name'", "'Local'"]}}], ["71eafd8c0d588c0653f99d00ee616486", {"code_string": "from common import *\nfrom mayatools.transforms import transfer_global_transforms\nfrom mayatools.locators import bake_global_locators\n", "code_toks_joined": "from common import * <NEWLINE> from mayatools . transforms import transfer_global_transforms <NEWLINE> from mayatools . locators import bake_global_locators <NEWLINE>", "anonymize_dict": {}}], ["a630ff1b9e88b424fd3890a4fd13a18f", {"code_string": "class DisconnectError(Exception):\n    def __init__(self, reason_code, message):\n        self.reason_code = reason_code\n        self.message = message\n        super(DisconnectError, self).__init__(message)\n", "code_toks_joined": "class DisconnectError ( Exception ) : <NEWLINE> <INDENT> def __init__ ( self , reason_code , message ) : <NEWLINE> <INDENT> self . reason_code = reason_code <NEWLINE> self . message = message <NEWLINE> super ( DisconnectError , self ) . __init__ ( message ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["54dcba3dff165431265c13395606f631", {"code_string": "def _slug(self, url):\n    url = unquote(url)\n    fragments = urlparse(url)\n    directory = self._domain_to_directory(fragments.netloc)\n    path, file_fragment = os.path.split(fragments.path)\n    path = self._path_to_directory(path)\n    filename = file_fragment\n    path = os.path.join(directory, path, filename)\n    return self._remove_invaild_characters(path)\n", "code_toks_joined": "def _slug ( self , url ) : <NEWLINE> <INDENT> url = unquote ( url ) <NEWLINE> fragments = urlparse ( url ) <NEWLINE> directory = self . _domain_to_directory ( fragments . netloc ) <NEWLINE> path , file_fragment = os . path . split ( fragments . path ) <NEWLINE> path = self . _path_to_directory ( path ) <NEWLINE> filename = file_fragment <NEWLINE> path = os . path . join ( directory , path , filename ) <NEWLINE> return self . _remove_invaild_characters ( path ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["f3872db39792cc884478b4773c8bdb5c", {"code_string": "def path(f):\n    for d in os.listdir(f):\n        try:\n            for s in os.listdir(os.path.join(f, d)):\n                if s.endswith('.xml'):\n                    return os.path.join(f, d)\n        except:\n            pass\n    return None\n", "code_toks_joined": "def path ( f ) : <NEWLINE> <INDENT> for d in os . listdir ( f ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> for s in os . listdir ( os . path . join ( f , d ) ) : <NEWLINE> <INDENT> if s . endswith ( <STRING> ) : <NEWLINE> <INDENT> return os . path . join ( f , d ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> except : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT> return None <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'.xml'"]}}], ["30576a0363b52ab18cf752c162ffb54b", {"code_string": "def set_option(self, section, option, value):\n    try:\n        self.conf.set(section, option, value)\n        with open(self.file, 'w+') as configfile:\n            self.conf.write(configfile)\n    except Exception as err:\n        self.log.warning('Unable to set configuration option: %s' % err)\n", "code_toks_joined": "def set_option ( self , section , option , value ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> self . conf . set ( section , option , value ) <NEWLINE> with open ( self . file , <STRING> ) as configfile : <NEWLINE> <INDENT> self . conf . write ( configfile ) <NEWLINE> <DEDENT> <DEDENT> except Exception as err : <NEWLINE> <INDENT> self . log . warning ( <STRING> % err ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'w+'", "'Unable to set configuration option: %s'"]}}], ["4e27fa73e9899b6ae2bbe4367cafe54c", {"code_string": "from estrella_classes import *\nfrom sys import exit\nfrom os import getcwd\nimport matplotlib.pyplot as plt\n", "code_toks_joined": "from estrella_classes import * <NEWLINE> from sys import exit <NEWLINE> from os import getcwd <NEWLINE> import matplotlib . pyplot as plt <NEWLINE>", "anonymize_dict": {}}], ["c998e2aaeb33e92396f4273f7318da1c", {"code_string": "from glob import glob\nfrom os.path import join\nimport sys\nfrom setuptools import setup, find_packages\nimport bioframework\n", "code_toks_joined": "from glob import glob <NEWLINE> from os . path import join <NEWLINE> import sys <NEWLINE> from setuptools import setup , find_packages <NEWLINE> import bioframework <NEWLINE>", "anonymize_dict": {}}], ["5f75d9e1eda86bba175e2d00a11a20a8", {"code_string": "def download_image(auction_id, img_link):\n    if not os.path.exists(\"../auction_images\"):\n        os.system(\"mkdir ../auction_images\")\n    file_path = \"../auction_images/\" + auction_id + \".png\"\n    urlretrieve(img_link, file_path)\n    return file_path\n", "code_toks_joined": "def download_image ( auction_id , img_link ) : <NEWLINE> <INDENT> if not os . path . exists ( <STRING> ) : <NEWLINE> <INDENT> os . system ( <STRING> ) <NEWLINE> <DEDENT> file_path = <STRING> + auction_id + <STRING> <NEWLINE> urlretrieve ( img_link , file_path ) <NEWLINE> return file_path <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"../auction_images\"", "\"mkdir ../auction_images\"", "\"../auction_images/\"", "\".png\""]}}], ["57825f9fcb9d56a81092decee3dc56a4", {"code_string": "def post(path):\n    \"\"\"Define decorator @post('/path')\"\"\"\n    def decorator(func):\n        @ functools.wraps(func)\n        def wrapper(* args, ** kw):\n            return func(* args, ** kw)\n        wrapper.__method__ = 'POST'\n        wrapper.__path__ = path\n        return wrapper\n    return decorator\n", "code_toks_joined": "def post ( path ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def decorator ( func ) : <NEWLINE> <INDENT> @ functools . wraps ( func ) <NEWLINE> def wrapper ( * args , ** kw ) : <NEWLINE> <INDENT> return func ( * args , ** kw ) <NEWLINE> <DEDENT> wrapper . __method__ = <STRING> <NEWLINE> wrapper . __path__ = path <NEWLINE> return wrapper <NEWLINE> <DEDENT> return decorator <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Define decorator @post('/path')\"\"\"", "'POST'"]}}], ["ff77fb14ce2ef06dadc51c09e830c018", {"code_string": "from django import forms\nfrom django.conf import settings\nfrom django.contrib import admin\nfrom.models import Category, Link\n", "code_toks_joined": "from django import forms <NEWLINE> from django . conf import settings <NEWLINE> from django . contrib import admin <NEWLINE> from . models import Category , Link <NEWLINE>", "anonymize_dict": {}}], ["79d5c3386c99dd967e246cde47449be4", {"code_string": "def _sigterm(self, signum, frame):\n    log.info('Received SIGTERM')\n    self.stop()\n", "code_toks_joined": "def _sigterm ( self , signum , frame ) : <NEWLINE> <INDENT> log . info ( <STRING> ) <NEWLINE> self . stop ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Received SIGTERM'"]}}], ["1c2d3988697e6c69a80e0e5ffbb95d80", {"code_string": "class CommentsAdmin(admin.TabularInline):\n    model = Comments\n    extra = 3\n", "code_toks_joined": "class CommentsAdmin ( admin . TabularInline ) : <NEWLINE> <INDENT> model = Comments <NEWLINE> extra = 3 <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["6a19ecec4df172c6fc5ea0bc6db09eeb", {"code_string": "def unregister_db_events(self):\n    self._unregister_db_event(model_base.StandardAttribute,\n        'before_insert', self._add_timestamp)\n    self._unregister_db_event(se.Session, 'before_flush',\n        self.update_timestamp)\n", "code_toks_joined": "def unregister_db_events ( self ) : <NEWLINE> <INDENT> self . _unregister_db_event ( model_base . StandardAttribute , <NEWLINE> <INDENT> <STRING> , self . _add_timestamp ) <NEWLINE> <DEDENT> self . _unregister_db_event ( se . Session , <STRING> , <NEWLINE> <INDENT> self . update_timestamp ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'before_insert'", "'before_flush'"]}}], ["2ee834d4fd3e23bbf8c5c4d03c2549ea", {"code_string": "def x(a, b, * c):\n    print(\"\u7b2c\u4e00\u4e2a\u53c2\u6570: \" + str(a))\n    print(\"\u7b2c\u4e8c\u4e2a\u53c2\u6570: \" + str(b))\n    print(\"\u53c2\u6570c: \" + str(c))\n    print(\"\u7b2c\u4e09\u4e2a\u53c2\u6570\u4e3a: \" + str(c[0]))\n", "code_toks_joined": "def x ( a , b , * c ) : <NEWLINE> <INDENT> print ( <STRING> + str ( a ) ) <NEWLINE> print ( <STRING> + str ( b ) ) <NEWLINE> print ( <STRING> + str ( c ) ) <NEWLINE> print ( <STRING> + str ( c [ 0 ] ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\u7b2c\u4e00\u4e2a\u53c2\u6570: \"", "\"\u7b2c\u4e8c\u4e2a\u53c2\u6570: \"", "\"\u53c2\u6570c: \"", "\"\u7b2c\u4e09\u4e2a\u53c2\u6570\u4e3a: \""]}}], ["d47a0924c48e1f8716dcfe2f20065da2", {"code_string": "from __future__ import division\nfrom sys import stdin, stdout\nimport numpy as np\nfrom utils import *\nif __name__ == '__main__':\n    k, t = ReadIntegers()\n    text_list = ReadAllLines()\n    motifs = BruteForceMedianString(text_list, k)\n    PrintList(\n        motifs,\n        '\\n'\n    )\n", "code_toks_joined": "from __future__ import division <NEWLINE> from sys import stdin , stdout <NEWLINE> import numpy as np <NEWLINE> from utils import * <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> k , t = ReadIntegers ( ) <NEWLINE> text_list = ReadAllLines ( ) <NEWLINE> motifs = BruteForceMedianString ( text_list , k ) <NEWLINE> PrintList ( <NEWLINE> <INDENT> motifs , <NEWLINE> <STRING> <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'__main__'", "'\\n'"]}}], ["5724d6aaa3622505563be597f701fbbc", {"code_string": "class Builder(wayround_org.aipsetup.builder_scripts.std.Builder):\n    def builder_action_configure_define_opts(self, called_as, log):\n        return super().builder_action_configure_define_opts(called_as, log) +[\n            '--with-x',\n            '--enable-libaudit',\n            '--enable-dnotify',\n            '--enable-inotify',\n            '--enable-systemd',\n            ]\n", "code_toks_joined": "class Builder ( wayround_org . aipsetup . builder_scripts . std . Builder ) : <NEWLINE> <INDENT> def builder_action_configure_define_opts ( self , called_as , log ) : <NEWLINE> <INDENT> return super ( ) . builder_action_configure_define_opts ( called_as , log ) + [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> ] <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'--with-x'", "'--enable-libaudit'", "'--enable-dnotify'", "'--enable-inotify'", "'--enable-systemd'"]}}], ["f2eed46f6052320da451867ff7390671", {"code_string": "def has_fit_parameter(estimator, parameter):\n    \"\"\"Checks whether the estimator's fit method supports the given parameter.\"\"\"\n    return parameter in getargspec(estimator.fit)[0]\n", "code_toks_joined": "def has_fit_parameter ( estimator , parameter ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return parameter in getargspec ( estimator . fit ) [ 0 ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Checks whether the estimator's fit method supports the given parameter.\"\"\""]}}], ["3bfae2c66331c7300de109e83a0b87b9", {"code_string": "def __init__(self):\n    super(Article, self).__init__()\n    self.title = None\n    self.author = None\n    self.published = None\n    self.body = None\n    self.link = None\n", "code_toks_joined": "def __init__ ( self ) : <NEWLINE> <INDENT> super ( Article , self ) . __init__ ( ) <NEWLINE> self . title = None <NEWLINE> self . author = None <NEWLINE> self . published = None <NEWLINE> self . body = None <NEWLINE> self . link = None <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["8a13264811afe8a5eb68a57a4c486a33", {"code_string": "def tryPlainGetPhoton(p0, pvar, start, seed):\n    \"\"\"Try to generate a photon and returns 0 and 1 for donor and acceptor and -1 for failure\"\"\"\n    for curndx in range(start, len(pvar)):\n        rnd = random.random()\n        if rnd < p0:\n            return 0, curndx\n        if rnd < pvar[curndx]:\n            return 1, curndx\n    return - 1, len(pvar)\n", "code_toks_joined": "def tryPlainGetPhoton ( p0 , pvar , start , seed ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> for curndx in range ( start , len ( pvar ) ) : <NEWLINE> <INDENT> rnd = random . random ( ) <NEWLINE> if rnd < p0 : <NEWLINE> <INDENT> return 0 , curndx <NEWLINE> <DEDENT> if rnd < pvar [ curndx ] : <NEWLINE> <INDENT> return 1 , curndx <NEWLINE> <DEDENT> <DEDENT> return - 1 , len ( pvar ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Try to generate a photon and returns 0 and 1 for donor and acceptor and -1 for failure\"\"\""]}}], ["d477b980a30a8f98027accff83123190", {"code_string": "class UserProfile(models.Model):\n    user = models.OneToOneField(settings.AUTH_USER_MODEL,\n        primary_key = True, related_name = 'profile')\n    def __str__(self):\n        return self.user.username\n    class Meta:\n        verbose_name = 'UserProfile'\n        verbose_name_plural = 'UserProfiles'\n        db_table = 'user_profile'\n", "code_toks_joined": "class UserProfile ( models . Model ) : <NEWLINE> <INDENT> user = models . OneToOneField ( settings . AUTH_USER_MODEL , <NEWLINE> <INDENT> primary_key = True , related_name = <STRING> ) <NEWLINE> <DEDENT> def __str__ ( self ) : <NEWLINE> <INDENT> return self . user . username <NEWLINE> <DEDENT> class Meta : <NEWLINE> <INDENT> verbose_name = <STRING> <NEWLINE> verbose_name_plural = <STRING> <NEWLINE> db_table = <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'profile'", "'UserProfile'", "'UserProfiles'", "'user_profile'"]}}], ["39f30f787db56921f77abde5df728d88", {"code_string": "def dispose(self):\n    self.stack.clear()\n    self.length.clear()\n    self.isDisposed = True\n", "code_toks_joined": "def dispose ( self ) : <NEWLINE> <INDENT> self . stack . clear ( ) <NEWLINE> self . length . clear ( ) <NEWLINE> self . isDisposed = True <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["a1cab9cffe58f752de92c6e6ec9fe90b", {"code_string": "from Products.CMFCore.utils import getToolByName\nimport logging\nlogger = logging.getLogger('uwosh.policy.externalsite.setuphandlers')\n", "code_toks_joined": "from Products . CMFCore . utils import getToolByName <NEWLINE> import logging <NEWLINE> logger = logging . getLogger ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'uwosh.policy.externalsite.setuphandlers'"]}}], ["1f296bb063b5ea384995fa3b0cfa443a", {"code_string": "from django import forms\nfrom school_calendar.models import *\nfrom school_calendar.widgets import *\nfrom school_calendar.fields import *\nfrom dateutil import rrule\nDAY_CHOICES = (\n    (MO, \"Monday\"),\n    (TU, \"Tuesday\"),\n    (WE, \"Wednesday\"),\n    (TH, \"Thursday\"),\n    (FR, \"Friday\"),\n    (SA, \"Saturday\"),\n    (SU, \"Sunday\"),\n)\n", "code_toks_joined": "from django import forms <NEWLINE> from school_calendar . models import * <NEWLINE> from school_calendar . widgets import * <NEWLINE> from school_calendar . fields import * <NEWLINE> from dateutil import rrule <NEWLINE> DAY_CHOICES = ( <NEWLINE> <INDENT> ( MO , <STRING> ) , <NEWLINE> ( TU , <STRING> ) , <NEWLINE> ( WE , <STRING> ) , <NEWLINE> ( TH , <STRING> ) , <NEWLINE> ( FR , <STRING> ) , <NEWLINE> ( SA , <STRING> ) , <NEWLINE> ( SU , <STRING> ) , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"Monday\"", "\"Tuesday\"", "\"Wednesday\"", "\"Thursday\"", "\"Friday\"", "\"Saturday\"", "\"Sunday\""]}}], ["06ee3ae93d4576f0ee5cf35c52131732", {"code_string": "def setUp(self):\n    TestCase.setUp(self)\n    self.jane = self.make_user(\"jane\", group = 'cg_moderator')\n    self.bob = self.make_user(\"bob\", group = 'cg_moderator')\n    self.brian = self.make_user(\"brian\", group = 'cg_moderator')\n    self.stacy = self.make_user(\"stacy\")\n    self.channel = self.make_channel(self.stacy)\n", "code_toks_joined": "def setUp ( self ) : <NEWLINE> <INDENT> TestCase . setUp ( self ) <NEWLINE> self . jane = self . make_user ( <STRING> , group = <STRING> ) <NEWLINE> self . bob = self . make_user ( <STRING> , group = <STRING> ) <NEWLINE> self . brian = self . make_user ( <STRING> , group = <STRING> ) <NEWLINE> self . stacy = self . make_user ( <STRING> ) <NEWLINE> self . channel = self . make_channel ( self . stacy ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"jane\"", "'cg_moderator'", "\"bob\"", "'cg_moderator'", "\"brian\"", "'cg_moderator'", "\"stacy\""]}}], ["3eb0147bc5b17486538d60176672ad14", {"code_string": "\"\"\"This file is part of OpenSesame.\"\"\"\nimport sys\nif '--qt5' in sys.argv:\n    try:\n        import PyQt5\n        pyqt = 5\n    except:\n        pyqt = 4\nelse:\n    pyqt = 4\nif pyqt == 4:\n    import sip\n    sip.setapi(u'QString', 2)\n    sip.setapi(u'QVariant', 2)\n", "code_toks_joined": "<STRING> <NEWLINE> import sys <NEWLINE> if <STRING> in sys . argv : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> import PyQt5 <NEWLINE> pyqt = 5 <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> pyqt = 4 <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> pyqt = 4 <NEWLINE> <DEDENT> if pyqt == 4 : <NEWLINE> <INDENT> import sip <NEWLINE> sip . setapi ( <STRING> , 2 ) <NEWLINE> sip . setapi ( <STRING> , 2 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"This file is part of OpenSesame.\"\"\"", "'--qt5'", "u'QString'", "u'QVariant'"]}}], ["5b5456ee349ffda5223edc6c7de6c615", {"code_string": "\"\"\"Main script to write dirac.cfg for a new DIRAC installation and initial download of CAs and CRLs\"\"\"\n__RCSID__ = \"$Id$\"\nimport DIRAC\nfrom DIRAC.Core.Base import Script\nfrom DIRAC.Core.Security.ProxyInfo import getProxyInfo\nfrom DIRAC.ConfigurationSystem.Client.Helpers import cfgInstallPath, cfgPath, Resources, Registry\nimport sys, os\nlogLevel = None\nsetup = None\nconfigurationServer = None\nincludeAllServers = False\ngatewayServer = None\nsiteName = None\nuseServerCert = False\nskipCAChecks = False\nskipCADownload = False\nuseVersionsDir = False\narchitecture = None\nlocalSE = None\nceName = None\nvo = None\nupdate = False\n", "code_toks_joined": "<STRING> <NEWLINE> __RCSID__ = <STRING> <NEWLINE> import DIRAC <NEWLINE> from DIRAC . Core . Base import Script <NEWLINE> from DIRAC . Core . Security . ProxyInfo import getProxyInfo <NEWLINE> from DIRAC . ConfigurationSystem . Client . Helpers import cfgInstallPath , cfgPath , Resources , Registry <NEWLINE> import sys , os <NEWLINE> logLevel = None <NEWLINE> setup = None <NEWLINE> configurationServer = None <NEWLINE> includeAllServers = False <NEWLINE> gatewayServer = None <NEWLINE> siteName = None <NEWLINE> useServerCert = False <NEWLINE> skipCAChecks = False <NEWLINE> skipCADownload = False <NEWLINE> useVersionsDir = False <NEWLINE> architecture = None <NEWLINE> localSE = None <NEWLINE> ceName = None <NEWLINE> vo = None <NEWLINE> update = False <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Main script to write dirac.cfg for a new DIRAC installation and initial download of CAs and CRLs\"\"\"", "\"$Id$\""]}}], ["bced8d650d4b9a3553c573045418ac1b", {"code_string": "def test_count_frames(self):\n    f = inspect.currentframe()\n    frame_count = Mstack.count_frames(f)\n    self.assertTrue(Mstack.count_frames(f) > 2)\n    self.assertEqual(frame_count - 1, Mstack.count_frames(f.f_back))\n    self.assertEqual(frame_count - 1, Mstack.count_frames(f, 1))\n    return\n", "code_toks_joined": "def test_count_frames ( self ) : <NEWLINE> <INDENT> f = inspect . currentframe ( ) <NEWLINE> frame_count = Mstack . count_frames ( f ) <NEWLINE> self . assertTrue ( Mstack . count_frames ( f ) > 2 ) <NEWLINE> self . assertEqual ( frame_count - 1 , Mstack . count_frames ( f . f_back ) ) <NEWLINE> self . assertEqual ( frame_count - 1 , Mstack . count_frames ( f , 1 ) ) <NEWLINE> return <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["4c20d8b0ee009b8459e4f0e1353fbcfb", {"code_string": "def load():\n    allowed = [hardware.name for hardware in opas.hardwares if hardware.driver.poynting_type is not None]\n    return len(allowed) > 0\n", "code_toks_joined": "def load ( ) : <NEWLINE> <INDENT> allowed = [ hardware . name for hardware in opas . hardwares if hardware . driver . poynting_type is not None ] <NEWLINE> return len ( allowed ) > 0 <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["6bcd2551b748afdaf79bd668e9ee23c9", {"code_string": "def p_camkes(t):\n    '''camkes :'''\n    if len(t) == 1:\n        t[0] = []\n    else:\n        assert len(t) == 3\n        t[0] = t[1] + t[2]\n", "code_toks_joined": "def p_camkes ( t ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if len ( t ) == 1 : <NEWLINE> <INDENT> t [ 0 ] = [ ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> assert len ( t ) == 3 <NEWLINE> t [ 0 ] = t [ 1 ] + t [ 2 ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''camkes :'''"]}}], ["f89a7db9f7b8a85836c759354c4049d0", {"code_string": "def main():\n    barFeed = barfeed.CSVTradeFeed()\n    barFeed.addBarsFromCSV(\".\\\\data\\\\bitstampUSD.csv\", fromDateTime = datetime.datetime(2014, 1, 1))\n    resample.resample_to_csv(barFeed, bar.Frequency.MINUTE * 30, \"30min-bitstampUSD.csv\")\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> barFeed = barfeed . CSVTradeFeed ( ) <NEWLINE> barFeed . addBarsFromCSV ( <STRING> , fromDateTime = datetime . datetime ( 2014 , 1 , 1 ) ) <NEWLINE> resample . resample_to_csv ( barFeed , bar . Frequency . MINUTE * 30 , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\".\\\\data\\\\bitstampUSD.csv\"", "\"30min-bitstampUSD.csv\""]}}], ["8e6b1ad8350e00ab1c1ca43eb2bb2520", {"code_string": "def mark(h):\n    title = [\"Tittle\", \"Description\", \"Date\", \"Hour\"]\n    p = \"\"\n    for i in title:\n        p = p + '|' + i\n    p = p + '|  \\n'\n    izq = '---|'\n    p = p + '|' + izq + izq + izq + izq + '  \\n'\n    for j in h:\n        for i in j:\n            p = p + '|' + str(i)\n        p = p + '|' + '  \\n'\n    return p\n", "code_toks_joined": "def mark ( h ) : <NEWLINE> <INDENT> title = [ <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE> p = <STRING> <NEWLINE> for i in title : <NEWLINE> <INDENT> p = p + <STRING> + i <NEWLINE> <DEDENT> p = p + <STRING> <NEWLINE> izq = <STRING> <NEWLINE> p = p + <STRING> + izq + izq + izq + izq + <STRING> <NEWLINE> for j in h : <NEWLINE> <INDENT> for i in j : <NEWLINE> <INDENT> p = p + <STRING> + str ( i ) <NEWLINE> <DEDENT> p = p + <STRING> + <STRING> <NEWLINE> <DEDENT> return p <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Tittle\"", "\"Description\"", "\"Date\"", "\"Hour\"", "\"\"", "'|'", "'|  \\n'", "'---|'", "'|'", "'  \\n'", "'|'", "'|'", "'  \\n'"]}}], ["171cf36a98e670a99cdb2ab224112c9c", {"code_string": "def conditional_entropy(f1, f2):\n    \"\"\"This function calculates the conditional entropy, where ce = H(f1) - I(f1;f2)\"\"\"\n    ce = ee.entropyd(f1) - ee.midd(f1, f2)\n    return ce\n", "code_toks_joined": "def conditional_entropy ( f1 , f2 ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> ce = ee . entropyd ( f1 ) - ee . midd ( f1 , f2 ) <NEWLINE> return ce <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"This function calculates the conditional entropy, where ce = H(f1) - I(f1;f2)\"\"\""]}}], ["14c1006ae718e4cbf207aefa9253ac37", {"code_string": "def median(a_list):\n    \"\"\" Finds canonically defined median of list.\"\"\"\n    if not a_list:\n        return 0\n    sorted_list = sorted(a_list)\n    list_size = len(a_list)\n    index = (list_size - 1) // 2\n    if(list_size % 2):\n        return sorted_list[index]\n    return(sorted_list[index] + sorted_list[index + 1]) / 2.0\n", "code_toks_joined": "def median ( a_list ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if not a_list : <NEWLINE> <INDENT> return 0 <NEWLINE> <DEDENT> sorted_list = sorted ( a_list ) <NEWLINE> list_size = len ( a_list ) <NEWLINE> index = ( list_size - 1 ) // 2 <NEWLINE> if ( list_size % 2 ) : <NEWLINE> <INDENT> return sorted_list [ index ] <NEWLINE> <DEDENT> return ( sorted_list [ index ] + sorted_list [ index + 1 ] ) / 2.0 <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Finds canonically defined median of list.\"\"\""]}}], ["263b9f54373a8821303432a69d594461", {"code_string": "def get_help_uri(page = None):\n    here = os.path.dirname(__file__)\n    help_uri = os.path.abspath(os.path.join(here, '..', 'help', 'C'))\n    if not os.path.exists(help_uri):\n        help_uri = 'uberwriter'\n    if page is not None:\n        help_uri = '%s#%s' %(help_uri, page)\n    return help_uri\n", "code_toks_joined": "def get_help_uri ( page = None ) : <NEWLINE> <INDENT> here = os . path . dirname ( __file__ ) <NEWLINE> help_uri = os . path . abspath ( os . path . join ( here , <STRING> , <STRING> , <STRING> ) ) <NEWLINE> if not os . path . exists ( help_uri ) : <NEWLINE> <INDENT> help_uri = <STRING> <NEWLINE> <DEDENT> if page is not None : <NEWLINE> <INDENT> help_uri = <STRING> % ( help_uri , page ) <NEWLINE> <DEDENT> return help_uri <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'..'", "'help'", "'C'", "'uberwriter'", "'%s#%s'"]}}], ["07d1c790b13bbbe5de021936e45f31b5", {"code_string": "def disassociate(self, host, group):\n    \"\"\"Disassociate a group from this host.\"\"\"\n    return self._disassoc('groups', host, group)\n", "code_toks_joined": "def disassociate ( self , host , group ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . _disassoc ( <STRING> , host , group ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Disassociate a group from this host.\"\"\"", "'groups'"]}}], ["0cb98f28295e96da7faebc3ab6d81a09", {"code_string": "def glInitS3TcS3():\n    '''Return boolean indicating whether this extension is available'''\n    from OpenGL import extensions\n    return extensions.hasGLExtension(_EXTENSION_NAME)\n", "code_toks_joined": "def glInitS3TcS3 ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> from OpenGL import extensions <NEWLINE> return extensions . hasGLExtension ( _EXTENSION_NAME ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Return boolean indicating whether this extension is available'''"]}}], ["92f4ef3a0c66f92cd7b35ae917cbc981", {"code_string": "\"\"\"I provide configuration functions for the rdfrest Service.\"\"\"\nimport json\nimport logging\nimport logging.config\nfrom ConfigParser import NoOptionError, SafeConfigParser\nfrom..serializers import bind_prefix\n", "code_toks_joined": "<STRING> <NEWLINE> import json <NEWLINE> import logging <NEWLINE> import logging . config <NEWLINE> from ConfigParser import NoOptionError , SafeConfigParser <NEWLINE> from . . serializers import bind_prefix <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"I provide configuration functions for the rdfrest Service.\"\"\""]}}], ["7cd1d9df3b8919f89ce48d977024708a", {"code_string": "'''Created on Sep 14, 2016'''\nfrom sqlalchemy.orm import validates\nfrom sqlalchemy import Column, String\nfrom sqlalchemy.ext.declarative import declarative_base\nBase = declarative_base()\n", "code_toks_joined": "<STRING> <NEWLINE> from sqlalchemy . orm import validates <NEWLINE> from sqlalchemy import Column , String <NEWLINE> from sqlalchemy . ext . declarative import declarative_base <NEWLINE> Base = declarative_base ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Created on Sep 14, 2016'''"]}}], ["6e61d11362d29afae073984b3937592d", {"code_string": "class SSH101(Plugin):\n    @ classmethod\n    def can_handle_url(self, url):\n        return _url_re.match(url)\n    def _get_streams(self):\n        res = http.get(self.url, schema = _live_schema)\n        if not res:\n            return\n        if res[\"type\"] == \"hls\" and urlparse(res[\"url\"]).path.endswith(\"m3u8\"):\n            stream = HLSStream(self.session, res[\"url\"])\n            return dict(hls = stream)\n", "code_toks_joined": "class SSH101 ( Plugin ) : <NEWLINE> <INDENT> @ classmethod <NEWLINE> def can_handle_url ( self , url ) : <NEWLINE> <INDENT> return _url_re . match ( url ) <NEWLINE> <DEDENT> def _get_streams ( self ) : <NEWLINE> <INDENT> res = http . get ( self . url , schema = _live_schema ) <NEWLINE> if not res : <NEWLINE> <INDENT> return <NEWLINE> <DEDENT> if res [ <STRING> ] == <STRING> and urlparse ( res [ <STRING> ] ) . path . endswith ( <STRING> ) : <NEWLINE> <INDENT> stream = HLSStream ( self . session , res [ <STRING> ] ) <NEWLINE> return dict ( hls = stream ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"type\"", "\"hls\"", "\"url\"", "\"m3u8\"", "\"url\""]}}], ["78b7333721bbecdc3a3a6d1f720bcabf", {"code_string": "def __init__(self):\n    super(TemplateViewFactory, self).__init__()\n    self.__parent_class_list = []\n    self.__form_class = None\n    self.__model_class = None\n    self.__generic_parent_class = None\n    self.__exclude = []\n    self.__operation = \"\"\n", "code_toks_joined": "def __init__ ( self ) : <NEWLINE> <INDENT> super ( TemplateViewFactory , self ) . __init__ ( ) <NEWLINE> self . __parent_class_list = [ ] <NEWLINE> self . __form_class = None <NEWLINE> self . __model_class = None <NEWLINE> self . __generic_parent_class = None <NEWLINE> self . __exclude = [ ] <NEWLINE> self . __operation = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\""]}}], ["1d84a0c4864b509eb2a390f6c23bdbf6", {"code_string": "import unittest\nimport os\nfrom scimap.xrdstore import XRDStore\nfrom cases import HDFTestCase\n", "code_toks_joined": "import unittest <NEWLINE> import os <NEWLINE> from scimap . xrdstore import XRDStore <NEWLINE> from cases import HDFTestCase <NEWLINE>", "anonymize_dict": {}}], ["ee4021df820fb0c1fd94c481e131c582", {"code_string": "import sys\nimport socket\nimport struct\nimport toml\nimport SocketServer\n", "code_toks_joined": "import sys <NEWLINE> import socket <NEWLINE> import struct <NEWLINE> import toml <NEWLINE> import SocketServer <NEWLINE>", "anonymize_dict": {}}], ["512334a232c46ed47fbb9b98508b9cbc", {"code_string": "from __future__ import print_function\n__all__ = ['VignetteCorrector', 'AnalyseVignette']\n__docformat__ = 'restructuredtext en'\nimport math\nimport numpy\nfrom pyctools.core.config import ConfigEnum, ConfigFloat, ConfigInt\nfrom pyctools.core.base import Transformer\nfrom pyctools.core.types import pt_float\n", "code_toks_joined": "from __future__ import print_function <NEWLINE> __all__ = [ <STRING> , <STRING> ] <NEWLINE> __docformat__ = <STRING> <NEWLINE> import math <NEWLINE> import numpy <NEWLINE> from pyctools . core . config import ConfigEnum , ConfigFloat , ConfigInt <NEWLINE> from pyctools . core . base import Transformer <NEWLINE> from pyctools . core . types import pt_float <NEWLINE>", "anonymize_dict": {"<STRING>": ["'VignetteCorrector'", "'AnalyseVignette'", "'restructuredtext en'"]}}], ["8e70758651ea98a2ca715760dde0888f", {"code_string": "def getIntersection(keywords):\n    fixed = []\n    for keyword in keywords:\n        fixed.append(keyFormat.format(keyStringPrefix, keyword))\n    return keywordRedisDB.sinter(fixed)\n", "code_toks_joined": "def getIntersection ( keywords ) : <NEWLINE> <INDENT> fixed = [ ] <NEWLINE> for keyword in keywords : <NEWLINE> <INDENT> fixed . append ( keyFormat . format ( keyStringPrefix , keyword ) ) <NEWLINE> <DEDENT> return keywordRedisDB . sinter ( fixed ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ec732b9b8a16b128b4a6f41e9b730da0", {"code_string": "class CollectionCreationTesting(unittest.TestCase):\n    def setUp(self):\n        gludb.config.default_database(gludb.config.Database(\n            'postgresql',\n            conn_string = PG_CONN_STR\n        ))\n        delete_test_tables()\n    def tearDown(self):\n        delete_test_tables()\n        gludb.config.clear_database_config()\n    def test_repeated_creates(self):\n        SimpleStorage.ensure_table()\n        SimpleStorage.ensure_table()\n        SimpleStorage.ensure_table()\n        IndexedData.ensure_table()\n        IndexedData.ensure_table()\n        IndexedData.ensure_table()\n", "code_toks_joined": "class CollectionCreationTesting ( unittest . TestCase ) : <NEWLINE> <INDENT> def setUp ( self ) : <NEWLINE> <INDENT> gludb . config . default_database ( gludb . config . Database ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> conn_string = PG_CONN_STR <NEWLINE> <DEDENT> ) ) <NEWLINE> delete_test_tables ( ) <NEWLINE> <DEDENT> def tearDown ( self ) : <NEWLINE> <INDENT> delete_test_tables ( ) <NEWLINE> gludb . config . clear_database_config ( ) <NEWLINE> <DEDENT> def test_repeated_creates ( self ) : <NEWLINE> <INDENT> SimpleStorage . ensure_table ( ) <NEWLINE> SimpleStorage . ensure_table ( ) <NEWLINE> SimpleStorage . ensure_table ( ) <NEWLINE> IndexedData . ensure_table ( ) <NEWLINE> IndexedData . ensure_table ( ) <NEWLINE> IndexedData . ensure_table ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'postgresql'"]}}], ["23e50f4fd36a56db3b8f441d69f7b691", {"code_string": "\"\"\"Copyright (C) 2004-2015 Pivotal Software, Inc. All rights reserved.\"\"\"\nimport tinctest\nimport unittest2 as unittest\nfrom mpp.lib.config import GPDBConfig\nfrom mpp.lib.PSQL import PSQL\nfrom mpp.gpdb.tests.storage.walrepl.gpcrondump import BkupRestore\nfrom gppylib.commands.base import Command\nfrom mpp.gpdb.tests.storage.walrepl.gpinitstandby import GpinitStandby\nfrom mpp.gpdb.tests.storage.walrepl.gpactivatestandby import GpactivateStandby\nconfig = GPDBConfig()\n", "code_toks_joined": "<STRING> <NEWLINE> import tinctest <NEWLINE> import unittest2 as unittest <NEWLINE> from mpp . lib . config import GPDBConfig <NEWLINE> from mpp . lib . PSQL import PSQL <NEWLINE> from mpp . gpdb . tests . storage . walrepl . gpcrondump import BkupRestore <NEWLINE> from gppylib . commands . base import Command <NEWLINE> from mpp . gpdb . tests . storage . walrepl . gpinitstandby import GpinitStandby <NEWLINE> from mpp . gpdb . tests . storage . walrepl . gpactivatestandby import GpactivateStandby <NEWLINE> config = GPDBConfig ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Copyright (C) 2004-2015 Pivotal Software, Inc. All rights reserved.\"\"\""]}}], ["b4fba6087fffabaabc37e1c62125550e", {"code_string": "def handle_request(module, session, parameter):\n    \"\"\"This function handles the user request\"\"\"\n    func = module['func']\n    signature = module['signature']\n    try:\n        parameter = utils.validate_parameter(signature, parameter)\n    except Exception as e:\n        raise ParametersInvalid(str(e)) from None\n    return func(session, parameter)\n", "code_toks_joined": "def handle_request ( module , session , parameter ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> func = module [ <STRING> ] <NEWLINE> signature = module [ <STRING> ] <NEWLINE> try : <NEWLINE> <INDENT> parameter = utils . validate_parameter ( signature , parameter ) <NEWLINE> <DEDENT> except Exception as e : <NEWLINE> <INDENT> raise ParametersInvalid ( str ( e ) ) from None <NEWLINE> <DEDENT> return func ( session , parameter ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"This function handles the user request\"\"\"", "'func'", "'signature'"]}}], ["f399909e1201599c2bc931925b44908c", {"code_string": "\"\"\"Test for APRS parser. Accepts lines and prints the parsed form.\"\"\"\nfrom __future__ import absolute_import, division, unicode_literals\nimport string\nimport sys\nimport time\nfrom shinysdr.plugins import aprs\nif __name__ == '__main__':\n    for line in sys.stdin:\n        print(string.rstrip(line, '\\n'))\n        parsed = aprs.parse_tnc2(line, time.time())\n        for error in parsed.errors:\n            print('--!--', error)\n        for fact in parsed.facts:\n            print('     ', fact)\n        print\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import absolute_import , division , unicode_literals <NEWLINE> import string <NEWLINE> import sys <NEWLINE> import time <NEWLINE> from shinysdr . plugins import aprs <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> for line in sys . stdin : <NEWLINE> <INDENT> print ( string . rstrip ( line , <STRING> ) ) <NEWLINE> parsed = aprs . parse_tnc2 ( line , time . time ( ) ) <NEWLINE> for error in parsed . errors : <NEWLINE> <INDENT> print ( <STRING> , error ) <NEWLINE> <DEDENT> for fact in parsed . facts : <NEWLINE> <INDENT> print ( <STRING> , fact ) <NEWLINE> <DEDENT> print <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test for APRS parser. Accepts lines and prints the parsed form.\"\"\"", "'__main__'", "'\\n'", "'--!--'", "'     '"]}}], ["ef1b77c1ddb419bca21b5fbe91c21716", {"code_string": "def get_song_urls(self, page_num = 1):\n    \"\"\" Return a list of song urls from page page_num.\"\"\"\n    bsObj_list = self._get_songs_BSObj(page_num)\n    if bsObj_list is None:\n        return None\n    song_urls = []\n    for bsObj in bsObj_list:\n        anchor = bsObj.find(\"a\", {\"class\": \"song_link\"})\n        if anchor is not None:\n            url = anchor.attrs[\"href\"]\n            if url is not None:\n                song_urls +=[url]\n    return song_urls if len(song_urls) > 0 else None\n", "code_toks_joined": "def get_song_urls ( self , page_num = 1 ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> bsObj_list = self . _get_songs_BSObj ( page_num ) <NEWLINE> if bsObj_list is None : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> song_urls = [ ] <NEWLINE> for bsObj in bsObj_list : <NEWLINE> <INDENT> anchor = bsObj . find ( <STRING> , { <STRING> : <STRING> } ) <NEWLINE> if anchor is not None : <NEWLINE> <INDENT> url = anchor . attrs [ <STRING> ] <NEWLINE> if url is not None : <NEWLINE> <INDENT> song_urls += [ url ] <NEWLINE> <DEDENT> <DEDENT> <DEDENT> return song_urls if len ( song_urls ) > 0 else None <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Return a list of song urls from page page_num.\"\"\"", "\"a\"", "\"class\"", "\"song_link\"", "\"href\""]}}], ["2a2b5e3fe391cfe4caf9abbbb6076985", {"code_string": "def load(self, path):\n    try:\n        return self.__resources[path]\n    except KeyError:\n        return None\n", "code_toks_joined": "def load ( self , path ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> return self . __resources [ path ] <NEWLINE> <DEDENT> except KeyError : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["33677c30e380e8319c85e4ff39ede8e5", {"code_string": "import sys, os.path as path\nkroll_dir = path.join(path.abspath('.'), 'kroll', 'site_scons')\nsys.path.append(kroll_dir)\nimport kroll\n", "code_toks_joined": "import sys , os . path as path <NEWLINE> kroll_dir = path . join ( path . abspath ( <STRING> ) , <STRING> , <STRING> ) <NEWLINE> sys . path . append ( kroll_dir ) <NEWLINE> import kroll <NEWLINE>", "anonymize_dict": {"<STRING>": ["'.'", "'kroll'", "'site_scons'"]}}], ["9d2fa19bbbb1b949b2d2cd0f48f07a0e", {"code_string": "import os\nimport sys\nparent_dir = os.path.dirname(os.path.abspath(__file__))\nsys.path.insert(0, os.path.join(parent_dir, 'email_confirm_la/'))\nsys.path.insert(1, os.path.join(parent_dir, 'test_project/'))\nos.environ['DJANGO_SETTINGS_MODULE'] = 'test_project.settings'\nfrom django.conf import settings\nimport django\n", "code_toks_joined": "import os <NEWLINE> import sys <NEWLINE> parent_dir = os . path . dirname ( os . path . abspath ( __file__ ) ) <NEWLINE> sys . path . insert ( 0 , os . path . join ( parent_dir , <STRING> ) ) <NEWLINE> sys . path . insert ( 1 , os . path . join ( parent_dir , <STRING> ) ) <NEWLINE> os . environ [ <STRING> ] = <STRING> <NEWLINE> from django . conf import settings <NEWLINE> import django <NEWLINE>", "anonymize_dict": {"<STRING>": ["'email_confirm_la/'", "'test_project/'", "'DJANGO_SETTINGS_MODULE'", "'test_project.settings'"]}}], ["e54c849ff5eb429111f2264477735709", {"code_string": "class PistonHelpers:\n    GET_REVIEWS = \"piston_get_reviews_helper.py\"\n    GET_REVIEW_STATS = \"piston_get_review_stats_helper.py\"\n    GET_USEFUL_VOTES = \"piston_get_useful_votes_helper.py\"\n    SOFTWARE_CENTER_AGENT = \"piston_get_scagent_available_apps.py\"\n", "code_toks_joined": "class PistonHelpers : <NEWLINE> <INDENT> GET_REVIEWS = <STRING> <NEWLINE> GET_REVIEW_STATS = <STRING> <NEWLINE> GET_USEFUL_VOTES = <STRING> <NEWLINE> SOFTWARE_CENTER_AGENT = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"piston_get_reviews_helper.py\"", "\"piston_get_review_stats_helper.py\"", "\"piston_get_useful_votes_helper.py\"", "\"piston_get_scagent_available_apps.py\""]}}], ["170726169b1a9e9de7592ae0d28fa0f7", {"code_string": "__title__ = 'torte'\n__version__ = '0.1.0'\n__build__ = 0x000101\n__author__ = 'Matt Olan'\n__copyright__ = 'Copyright 2014 Matt Olan'\nfrom.torte import Torte\n", "code_toks_joined": "__title__ = <STRING> <NEWLINE> __version__ = <STRING> <NEWLINE> __build__ = 0x000101 <NEWLINE> __author__ = <STRING> <NEWLINE> __copyright__ = <STRING> <NEWLINE> from . torte import Torte <NEWLINE>", "anonymize_dict": {"<STRING>": ["'torte'", "'0.1.0'", "'Matt Olan'", "'Copyright 2014 Matt Olan'"]}}], ["a69e1796f39a026b43300b023ea0c0ea", {"code_string": "def get_thread(self, _id):\n    for t in self.iter_threads():\n        if t.id == _id:\n            return t\n", "code_toks_joined": "def get_thread ( self , _id ) : <NEWLINE> <INDENT> for t in self . iter_threads ( ) : <NEWLINE> <INDENT> if t . id == _id : <NEWLINE> <INDENT> return t <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["b36623c4314a67b1ecf69b3e17d00a2d", {"code_string": "def isEmpty(self, geom):\n    try:\n        ogr.Geometry.IsEmpty\n    except:\n        return 'skip'\n    if(geom.IsEmpty() == False):\n        geom.Destroy()\n        gdaltest.post_reason(\"IsEmpty returning false for an empty geometry\")\n        return 'fail'\n    return 'success'\n", "code_toks_joined": "def isEmpty ( self , geom ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> ogr . Geometry . IsEmpty <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> if ( geom . IsEmpty ( ) == False ) : <NEWLINE> <INDENT> geom . Destroy ( ) <NEWLINE> gdaltest . post_reason ( <STRING> ) <NEWLINE> return <STRING> <NEWLINE> <DEDENT> return <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'skip'", "\"IsEmpty returning false for an empty geometry\"", "'fail'", "'success'"]}}], ["47804a6cd060714a36ba755969e8032a", {"code_string": "def _dropout_from_layer(rng, layer, p):\n    \"\"\"p is the probablity of dropping a unit\"\"\"\n    srng = theano.tensor.shared_randomstreams.RandomStreams(\n        rng.randint(999999))\n    mask = srng.binomial(n = 1, p = 1 - p, size = layer.shape)\n    output = layer * T.cast(mask, theano.config.floatX)\n    return output\n", "code_toks_joined": "def _dropout_from_layer ( rng , layer , p ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> srng = theano . tensor . shared_randomstreams . RandomStreams ( <NEWLINE> <INDENT> rng . randint ( 999999 ) ) <NEWLINE> <DEDENT> mask = srng . binomial ( n = 1 , p = 1 - p , size = layer . shape ) <NEWLINE> output = layer * T . cast ( mask , theano . config . floatX ) <NEWLINE> return output <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"p is the probablity of dropping a unit\"\"\""]}}], ["b2f58a05dec88771df79b599623d1404", {"code_string": "class VertexModification(object):\n    def __init__(self, vertex_index, displacement):\n        self.vertex_index = vertex_index\n        self.displacement = displacement\n", "code_toks_joined": "class VertexModification ( object ) : <NEWLINE> <INDENT> def __init__ ( self , vertex_index , displacement ) : <NEWLINE> <INDENT> self . vertex_index = vertex_index <NEWLINE> self . displacement = displacement <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["b4afa40953671a638e2394f4baa316d3", {"code_string": "def clear_buffer(buffer):\n    \"\"\"Clears the buffer.\"\"\"\n    del buffer[: ]\n", "code_toks_joined": "def clear_buffer ( buffer ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> del buffer [ : ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Clears the buffer.\"\"\""]}}], ["62d82ece4c51a632e93d1f5d4a4b7288", {"code_string": "class MyModel(Model):\n    obj = AdHocClass()\n    __observables__ = (\"obj\", )\n    def __init__(self):\n        Model.__init__(self)\n        return\n    pass\n", "code_toks_joined": "class MyModel ( Model ) : <NEWLINE> <INDENT> obj = AdHocClass ( ) <NEWLINE> __observables__ = ( <STRING> , ) <NEWLINE> def __init__ ( self ) : <NEWLINE> <INDENT> Model . __init__ ( self ) <NEWLINE> return <NEWLINE> <DEDENT> pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"obj\""]}}], ["5188410940cf31c5fe71644b0350a69b", {"code_string": "from flask_restful import Resource\nfrom project.db import db, User\nfrom project.utils.auth import get_token, require_admin\nfrom sqlalchemy.exc import IntegrityError\nfrom project.utils.status import return_error, return_ok\nfrom.parsers import RegisterParser, LoginParser\n", "code_toks_joined": "from flask_restful import Resource <NEWLINE> from project . db import db , User <NEWLINE> from project . utils . auth import get_token , require_admin <NEWLINE> from sqlalchemy . exc import IntegrityError <NEWLINE> from project . utils . status import return_error , return_ok <NEWLINE> from . parsers import RegisterParser , LoginParser <NEWLINE>", "anonymize_dict": {}}], ["aaf0d6265a89bd1bf56962702f453fc1", {"code_string": "def with_amex(self):\n    self.digesters.append(AmexNotificationDigester(self.new_charge_summary))\n    return self\n", "code_toks_joined": "def with_amex ( self ) : <NEWLINE> <INDENT> self . digesters . append ( AmexNotificationDigester ( self . new_charge_summary ) ) <NEWLINE> return self <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["c40bd7c852bd45b5642d81097e01d2e5", {"code_string": "from consts import *\nfrom Button import Button\nfrom RawHTML import RawHTML\nfrom Container import Container\nfrom TextArea import TextArea\nfrom TextField import TextField\nfrom PageCleaner import Uniq_Block\nfrom Server import get_server\nHEADER = ['<script type=\"text/javascript\" src=\"/CTK/js/Submitter.js\"></script>']\nHTML = \"\"\"<div id=\"%(id)s\" class=\"submitter\">\"\"\"\nJS_INIT = \"\"\"$(\"#%(id)s\").Submitter ('%(url)s', '%(optional)s')\"\"\"\nJS_FOCUS = \"\"\"if ($(\"input:first\").hasClass('filter')) {\"\"\"\n", "code_toks_joined": "from consts import * <NEWLINE> from Button import Button <NEWLINE> from RawHTML import RawHTML <NEWLINE> from Container import Container <NEWLINE> from TextArea import TextArea <NEWLINE> from TextField import TextField <NEWLINE> from PageCleaner import Uniq_Block <NEWLINE> from Server import get_server <NEWLINE> HEADER = [ <STRING> ] <NEWLINE> HTML = <STRING> <NEWLINE> JS_INIT = <STRING> <NEWLINE> JS_FOCUS = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'<script type=\"text/javascript\" src=\"/CTK/js/Submitter.js\"></script>'", "\"\"\"<div id=\"%(id)s\" class=\"submitter\">\"\"\"", "\"\"\"$(\"#%(id)s\").Submitter ('%(url)s', '%(optional)s')\"\"\"", "\"\"\"if ($(\"input:first\").hasClass('filter')) {\"\"\""]}}], ["3b29f03cbf33dd74e63df61869a9696d", {"code_string": "def load_quotes_by_range(self, code, start_date, end_date):\n    idx_start = self.find_date_idx(code, start_date)\n    idx_end = self.find_date_idx(code, end_date) + 1\n    return self.quote_range(code, idx_start, idx_end)\n", "code_toks_joined": "def load_quotes_by_range ( self , code , start_date , end_date ) : <NEWLINE> <INDENT> idx_start = self . find_date_idx ( code , start_date ) <NEWLINE> idx_end = self . find_date_idx ( code , end_date ) + 1 <NEWLINE> return self . quote_range ( code , idx_start , idx_end ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["a7f442640685a842cd811e7cc0e36c5e", {"code_string": "def test_authorization_header_empty(self, get_key_secret):\n    \"\"\"Request Authorization header has no value.\"\"\"\n    request = Request(self.environ)\n    request.authorization = \"bad authorization header\"\n    request.body = self.get_request_body()\n    response = self.xmodule.grade_handler(request, '')\n    real_response = self.get_response_values(response)\n    expected_response = {\n        'action': None,\n        'code_major': 'failure',\n        'description': 'OAuth verification error: Malformed authorization header',\n        'messageIdentifier': self.DEFAULTS['messageIdentifier'],\n    }\n    self.assertEqual(response.status_code, 200)\n    self.assertDictEqual(expected_response, real_response)\n", "code_toks_joined": "def test_authorization_header_empty ( self , get_key_secret ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> request = Request ( self . environ ) <NEWLINE> request . authorization = <STRING> <NEWLINE> request . body = self . get_request_body ( ) <NEWLINE> response = self . xmodule . grade_handler ( request , <STRING> ) <NEWLINE> real_response = self . get_response_values ( response ) <NEWLINE> expected_response = { <NEWLINE> <INDENT> <STRING> : None , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : self . DEFAULTS [ <STRING> ] , <NEWLINE> <DEDENT> } <NEWLINE> self . assertEqual ( response . status_code , 200 ) <NEWLINE> self . assertDictEqual ( expected_response , real_response ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Request Authorization header has no value.\"\"\"", "\"bad authorization header\"", "''", "'action'", "'code_major'", "'failure'", "'description'", "'OAuth verification error: Malformed authorization header'", "'messageIdentifier'", "'messageIdentifier'"]}}], ["0aa7f91367c3ec88671b002faf1bc00e", {"code_string": "import sys\nfrom misura.client import iutils, browser, live\nimport multiprocessing\nif __name__ == '__main__':\n    multiprocessing.freeze_support()\n    iutils.initApp()\n    live.registry.toggle_run(False)\n    app = iutils.app\n    mw = browser.MainWindow()\n    if len(sys.argv) > 1:\n        mw.open_file(sys.argv[1])\n    mw.show()\n    sys.exit(app.exec_())\n", "code_toks_joined": "import sys <NEWLINE> from misura . client import iutils , browser , live <NEWLINE> import multiprocessing <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> multiprocessing . freeze_support ( ) <NEWLINE> iutils . initApp ( ) <NEWLINE> live . registry . toggle_run ( False ) <NEWLINE> app = iutils . app <NEWLINE> mw = browser . MainWindow ( ) <NEWLINE> if len ( sys . argv ) > 1 : <NEWLINE> <INDENT> mw . open_file ( sys . argv [ 1 ] ) <NEWLINE> <DEDENT> mw . show ( ) <NEWLINE> sys . exit ( app . exec_ ( ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'__main__'"]}}], ["285dee8e78a354b878df10acb3a48f74", {"code_string": "def ii_open_with_config_test():\n    print(\"Running ImageInput::open() (overload) tests...\")\n    print(\"Unimplemented yet\")\n    print\n    pic_owc = oiio.ImageInput.create(\"../../../oiio-images/tahoe-gps.jpg\", plugin_path)\n    if pic_owc == None:\n        print(\"Can't open test image, skipping open_with_config() tests\")\n        print\n        return\n    spec_owc = oiio.ImageSpec()\n", "code_toks_joined": "def ii_open_with_config_test ( ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> print <NEWLINE> pic_owc = oiio . ImageInput . create ( <STRING> , plugin_path ) <NEWLINE> if pic_owc == None : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> print <NEWLINE> return <NEWLINE> <DEDENT> spec_owc = oiio . ImageSpec ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Running ImageInput::open() (overload) tests...\"", "\"Unimplemented yet\"", "\"../../../oiio-images/tahoe-gps.jpg\"", "\"Can't open test image, skipping open_with_config() tests\""]}}], ["81bf0536c6310a82d44500af30e294af", {"code_string": "class UrlEncoded(validatorBase):\n    def validate(self):\n        from urllib import quote, unquote\n        import re\n        for value in self.value.split():\n            if type(value) == unicode: value = value.encode('utf-8')\n            value = re.sub('%\\w\\w', lambda x: x.group(0).upper(), value)\n            if value != quote(unquote(value)):\n                self.log(NotURLEncoded({}))\n                break\n", "code_toks_joined": "class UrlEncoded ( validatorBase ) : <NEWLINE> <INDENT> def validate ( self ) : <NEWLINE> <INDENT> from urllib import quote , unquote <NEWLINE> import re <NEWLINE> for value in self . value . split ( ) : <NEWLINE> <INDENT> if type ( value ) == unicode : value = value . encode ( <STRING> ) <NEWLINE> value = re . sub ( <STRING> , lambda x : x . group ( 0 ) . upper ( ) , value ) <NEWLINE> if value != quote ( unquote ( value ) ) : <NEWLINE> <INDENT> self . log ( NotURLEncoded ( { } ) ) <NEWLINE> break <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'utf-8'", "'%\\w\\w'"]}}], ["66c47568b10e108609a20720861cbba8", {"code_string": "def test_add_group(app, json_groups):\n    group = json_groups\n    old_groups = app.group.get_group_list()\n    app.group.create(group)\n    assert len(old_groups) + 1 == app.group.count()\n    new_groups = app.group.get_group_list()\n    old_groups.append(group)\n    assert sorted(old_groups, key = Group.id_or_max) == sorted(new_groups, key = Group.id_or_max)\n", "code_toks_joined": "def test_add_group ( app , json_groups ) : <NEWLINE> <INDENT> group = json_groups <NEWLINE> old_groups = app . group . get_group_list ( ) <NEWLINE> app . group . create ( group ) <NEWLINE> assert len ( old_groups ) + 1 == app . group . count ( ) <NEWLINE> new_groups = app . group . get_group_list ( ) <NEWLINE> old_groups . append ( group ) <NEWLINE> assert sorted ( old_groups , key = Group . id_or_max ) == sorted ( new_groups , key = Group . id_or_max ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["35f51d9e9ade7673abc92bc48da0f8b5", {"code_string": "def entuple(* args):\n    \"\"\"returns args as a tuple\"\"\"\n    return tuple(args)\n", "code_toks_joined": "def entuple ( * args ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return tuple ( args ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"returns args as a tuple\"\"\""]}}], ["e07fc807401c8835215ea943716bf52e", {"code_string": "i = 20\nwhile i != 0:\n    print(i)\n    i -= 1\n", "code_toks_joined": "i = 20 <NEWLINE> while i != 0 : <NEWLINE> <INDENT> print ( i ) <NEWLINE> i -= 1 <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["1e5c533e37578885c771a8773adcf54d", {"code_string": "def test__validate_requests(self):\n    get_requests = self.get_securetrading_requests\n    get_request = self.get_securetrading_request\n    tests = [([], None, None),\n        ([get_request({\"a\": \"b\"})], None, None),\n        ([{\"a\": \"b\"}], AssertionError, \"Invalid requests specified\")\n        ]\n    for requests_list, exp_exception, exp_message in tests:\n        if exp_exception is None:\n            requests = get_requests(requests_list)\n        else:\n            self.assertRaisesRegexp(exp_exception, exp_message,\n                get_requests,\n                requests_list)\n", "code_toks_joined": "def test__validate_requests ( self ) : <NEWLINE> <INDENT> get_requests = self . get_securetrading_requests <NEWLINE> get_request = self . get_securetrading_request <NEWLINE> tests = [ ( [ ] , None , None ) , <NEWLINE> <INDENT> ( [ get_request ( { <STRING> : <STRING> } ) ] , None , None ) , <NEWLINE> ( [ { <STRING> : <STRING> } ] , AssertionError , <STRING> ) <NEWLINE> ] <NEWLINE> <DEDENT> for requests_list , exp_exception , exp_message in tests : <NEWLINE> <INDENT> if exp_exception is None : <NEWLINE> <INDENT> requests = get_requests ( requests_list ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . assertRaisesRegexp ( exp_exception , exp_message , <NEWLINE> <INDENT> get_requests , <NEWLINE> requests_list ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"a\"", "\"b\"", "\"a\"", "\"b\"", "\"Invalid requests specified\""]}}], ["7b9d724650dc280ce9526d021fce9781", {"code_string": "import json\nimport time\nimport os\nimport base58\nfrom stp_core.common.constants import ZMQ_NETWORK_PROTOCOL\nfrom stp_core.common.log import getlogger\nlogger = getlogger()\n", "code_toks_joined": "import json <NEWLINE> import time <NEWLINE> import os <NEWLINE> import base58 <NEWLINE> from stp_core . common . constants import ZMQ_NETWORK_PROTOCOL <NEWLINE> from stp_core . common . log import getlogger <NEWLINE> logger = getlogger ( ) <NEWLINE>", "anonymize_dict": {}}], ["748d34b73a2aa6c2895273eef54fd1e9", {"code_string": "def setUpClass(cls):\n    handlers = {\n        'QBP^Q22^QBP_Q21': (PDQHandler, ),\n        'QBP^ZV1^QBP_Q21': (CustomArgsPDQHandler, True),\n        'ERR': (ErrorHandler, )\n    }\n    cls.server, cls.thread = launch_server(HOST, PORT, handlers)\n", "code_toks_joined": "def setUpClass ( cls ) : <NEWLINE> <INDENT> handlers = { <NEWLINE> <INDENT> <STRING> : ( PDQHandler , ) , <NEWLINE> <STRING> : ( CustomArgsPDQHandler , True ) , <NEWLINE> <STRING> : ( ErrorHandler , ) <NEWLINE> <DEDENT> } <NEWLINE> cls . server , cls . thread = launch_server ( HOST , PORT , handlers ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'QBP^Q22^QBP_Q21'", "'QBP^ZV1^QBP_Q21'", "'ERR'"]}}], ["96d7f08ba22cac74fd632f3e7dc47c8f", {"code_string": "class Item(models.Model):\n    title = models.CharField(max_length = 255)\n    content = models.TextField(default = '')\n    owner = models.ForeignKey(User, null = True)\n    publish_date = models.DateTimeField(auto_now_add = True)\n    price = models.DecimalField(max_digits = 7, decimal_places = 2)\n    contect_email = models.EmailField()\n", "code_toks_joined": "class Item ( models . Model ) : <NEWLINE> <INDENT> title = models . CharField ( max_length = 255 ) <NEWLINE> content = models . TextField ( default = <STRING> ) <NEWLINE> owner = models . ForeignKey ( User , null = True ) <NEWLINE> publish_date = models . DateTimeField ( auto_now_add = True ) <NEWLINE> price = models . DecimalField ( max_digits = 7 , decimal_places = 2 ) <NEWLINE> contect_email = models . EmailField ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["''"]}}], ["4d083906be35bade96eacdf403df5787", {"code_string": "class Book(models.Model):\n    title = models.CharField(max_length = 100)\n    price = models.DecimalField(max_digits = 6, decimal_places = 2)\n    average_rating = models.FloatField()\n    def __unicode__(self):\n        return self.title\n", "code_toks_joined": "class Book ( models . Model ) : <NEWLINE> <INDENT> title = models . CharField ( max_length = 100 ) <NEWLINE> price = models . DecimalField ( max_digits = 6 , decimal_places = 2 ) <NEWLINE> average_rating = models . FloatField ( ) <NEWLINE> def __unicode__ ( self ) : <NEWLINE> <INDENT> return self . title <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["ec532ae80422660fa543f597f3e6a7bb", {"code_string": "from._delete import PaymentMethodDeleteView, ShippingMethodDeleteView\nfrom._edit import PaymentMethodEditView, ShippingMethodEditView\nfrom._list import PaymentMethodListView, ShippingMethodListView\n__all__ = [\n    \"PaymentMethodDeleteView\",\n    \"PaymentMethodEditView\",\n    \"PaymentMethodListView\",\n    \"ShippingMethodDeleteView\",\n    \"ShippingMethodEditView\",\n    \"ShippingMethodListView\"\n]\n", "code_toks_joined": "from . _delete import PaymentMethodDeleteView , ShippingMethodDeleteView <NEWLINE> from . _edit import PaymentMethodEditView , ShippingMethodEditView <NEWLINE> from . _list import PaymentMethodListView , ShippingMethodListView <NEWLINE> __all__ = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"PaymentMethodDeleteView\"", "\"PaymentMethodEditView\"", "\"PaymentMethodListView\"", "\"ShippingMethodDeleteView\"", "\"ShippingMethodEditView\"", "\"ShippingMethodListView\""]}}], ["25f4c832e245a15d3aff0e88b0c85546", {"code_string": "from django.contrib.admin import SimpleListFilter\nfrom django.utils.translation import ugettext_lazy as _\nfrom django.contrib.contenttypes.models import ContentType\nfrom efenua.models import Favorite\n", "code_toks_joined": "from django . contrib . admin import SimpleListFilter <NEWLINE> from django . utils . translation import ugettext_lazy as _ <NEWLINE> from django . contrib . contenttypes . models import ContentType <NEWLINE> from efenua . models import Favorite <NEWLINE>", "anonymize_dict": {}}], ["b86556af1075c7fcac251b758dcc6b93", {"code_string": "class Delegate:\n    \"\"\"Base class for objects that dispatch ``self``-lookups.\"\"\"\n    def __init__(self, master):\n        \"\"\"Initialize a :class:`Delegate` instance.\"\"\"\n        object.__setattr__(self, \"master\", master)\n    def __getattr__(self, name):\n        \"\"\"Return value of master attribute.\"\"\"\n        return getattr(self.master, name)\n    def __setattr__(self, name, value):\n        \"\"\"Set value of master attribute.\"\"\"\n        if hasattr(self.master, name):\n            return setattr(self.master, name, value)\n        return object.__setattr__(self, name, value)\n", "code_toks_joined": "class Delegate : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , master ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> object . __setattr__ ( self , <STRING> , master ) <NEWLINE> <DEDENT> def __getattr__ ( self , name ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return getattr ( self . master , name ) <NEWLINE> <DEDENT> def __setattr__ ( self , name , value ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if hasattr ( self . master , name ) : <NEWLINE> <INDENT> return setattr ( self . master , name , value ) <NEWLINE> <DEDENT> return object . __setattr__ ( self , name , value ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Base class for objects that dispatch ``self``-lookups.\"\"\"", "\"\"\"Initialize a :class:`Delegate` instance.\"\"\"", "\"master\"", "\"\"\"Return value of master attribute.\"\"\"", "\"\"\"Set value of master attribute.\"\"\""]}}], ["a86b00a21fc2e2a1e884a5c81262a29f", {"code_string": "def uri(x):\n    y = int(x)\n    for i in range(0, 10):\n        print('N[{}] = {}'.format(i, y))\n        y *= 2\n", "code_toks_joined": "def uri ( x ) : <NEWLINE> <INDENT> y = int ( x ) <NEWLINE> for i in range ( 0 , 10 ) : <NEWLINE> <INDENT> print ( <STRING> . format ( i , y ) ) <NEWLINE> y *= 2 <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'N[{}] = {}'"]}}], ["7f8bc29b42fbe2b7c652c470ae992892", {"code_string": "\"\"\"Logging utilities.\"\"\"\nimport logging\nimport dialog\nfrom certbot.display import util as display_util\n", "code_toks_joined": "<STRING> <NEWLINE> import logging <NEWLINE> import dialog <NEWLINE> from certbot . display import util as display_util <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Logging utilities.\"\"\""]}}], ["eff62951942f38ab71c785d5ca3e2c69", {"code_string": "from logging import getLogger\nfrom os import access, R_OK\nfrom os.path import join, normpath\nfrom mimetypes import guess_type\nfrom paste.fileapp import FileApp\nfrom turbulenz_local.models.gamelist import GameList\nfrom turbulenz_local.tools import get_absolute_path\nLOG = getLogger(__name__)\n", "code_toks_joined": "from logging import getLogger <NEWLINE> from os import access , R_OK <NEWLINE> from os . path import join , normpath <NEWLINE> from mimetypes import guess_type <NEWLINE> from paste . fileapp import FileApp <NEWLINE> from turbulenz_local . models . gamelist import GameList <NEWLINE> from turbulenz_local . tools import get_absolute_path <NEWLINE> LOG = getLogger ( __name__ ) <NEWLINE>", "anonymize_dict": {}}], ["78e2f9f7f698e53b1e92ff67677b894e", {"code_string": "def parse_site_distribution(site_distribution):\n    \"\"\"Converts a site distribution using species labels into one using integer labels.\"\"\"\n    numeric_site_distribution = {}\n    numeric_site_mapping = {}\n    for i, k in enumerate(site_distribution.keys()):\n        numeric_site_distribution[i] = site_distribution[k]\n        numeric_site_mapping[i] = k\n    return numeric_site_distribution, numeric_site_mapping\n", "code_toks_joined": "def parse_site_distribution ( site_distribution ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> numeric_site_distribution = { } <NEWLINE> numeric_site_mapping = { } <NEWLINE> for i , k in enumerate ( site_distribution . keys ( ) ) : <NEWLINE> <INDENT> numeric_site_distribution [ i ] = site_distribution [ k ] <NEWLINE> numeric_site_mapping [ i ] = k <NEWLINE> <DEDENT> return numeric_site_distribution , numeric_site_mapping <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Converts a site distribution using species labels into one using integer labels.\"\"\""]}}], ["8dec501b9da19d86ac870a8ba5322f94", {"code_string": "def add_bookmark(self, torrent_id):\n    \"\"\" Get bookmarks of user \"\"\"\n    return self.call('/bookmarks/save/%s' % torrent_id)\n", "code_toks_joined": "def add_bookmark ( self , torrent_id ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . call ( <STRING> % torrent_id ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Get bookmarks of user \"\"\"", "'/bookmarks/save/%s'"]}}], ["dc3323cdbbcad0d824a52edff29f6744", {"code_string": "class beta_zeros(object):\n    def initialize(self, beta_count):\n        betas = np.zeros(beta_count)\n        return betas\n", "code_toks_joined": "class beta_zeros ( object ) : <NEWLINE> <INDENT> def initialize ( self , beta_count ) : <NEWLINE> <INDENT> betas = np . zeros ( beta_count ) <NEWLINE> return betas <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["9a761eea97d1983c7051412d293f7eea", {"code_string": "import sys\nimport os\nimport time\nimport re\nif j.core.platformtype.myplatform.isUnix():\n    import fcntl\nfrom JumpScale import j\n", "code_toks_joined": "import sys <NEWLINE> import os <NEWLINE> import time <NEWLINE> import re <NEWLINE> if j . core . platformtype . myplatform . isUnix ( ) : <NEWLINE> <INDENT> import fcntl <NEWLINE> <DEDENT> from JumpScale import j <NEWLINE>", "anonymize_dict": {}}], ["9729a9fbe5aa12d4502961801ee97098", {"code_string": "\"\"\" A code generator (needed by ModToolAdd) \"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import unicode_literals\nfrom mako.template import Template\nfrom.templates import Templates\nfrom.util_functions import str_to_fancyc_comment\nfrom.util_functions import str_to_python_comment\nfrom.util_functions import strip_default_values\nfrom.util_functions import strip_arg_types\nfrom.util_functions import strip_arg_types_grc\nGRTYPELIST = {\n    'sync': 'sync_block',\n    'sink': 'sync_block',\n    'source': 'sync_block',\n    'decimator': 'sync_decimator',\n    'interpolator': 'sync_interpolator',\n    'general': 'block',\n    'tagged_stream': 'tagged_stream_block',\n    'hier': 'hier_block2',\n    'noblock': ''\n}\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import absolute_import <NEWLINE> from __future__ import unicode_literals <NEWLINE> from mako . template import Template <NEWLINE> from . templates import Templates <NEWLINE> from . util_functions import str_to_fancyc_comment <NEWLINE> from . util_functions import str_to_python_comment <NEWLINE> from . util_functions import strip_default_values <NEWLINE> from . util_functions import strip_arg_types <NEWLINE> from . util_functions import strip_arg_types_grc <NEWLINE> GRTYPELIST = { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> <NEWLINE> <DEDENT> } <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\" A code generator (needed by ModToolAdd) \"\"\"", "'sync'", "'sync_block'", "'sink'", "'sync_block'", "'source'", "'sync_block'", "'decimator'", "'sync_decimator'", "'interpolator'", "'sync_interpolator'", "'general'", "'block'", "'tagged_stream'", "'tagged_stream_block'", "'hier'", "'hier_block2'", "'noblock'", "''"]}}], ["44f08f48ca943841e62fd56cff5ae60a", {"code_string": "\"\"\"Django settings for saefacto project.\"\"\"\nimport os\nfrom os.path import join\ntry:\n    from S3 import CallingFormat\n    AWS_CALLING_FORMAT = CallingFormat.SUBDOMAIN\nexcept ImportError:\n    pass\nfrom configurations import Configuration, values\nBASE_DIR = os.path.dirname(os.path.dirname(__file__))\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> from os . path import join <NEWLINE> try : <NEWLINE> <INDENT> from S3 import CallingFormat <NEWLINE> AWS_CALLING_FORMAT = CallingFormat . SUBDOMAIN <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> from configurations import Configuration , values <NEWLINE> BASE_DIR = os . path . dirname ( os . path . dirname ( __file__ ) ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Django settings for saefacto project.\"\"\""]}}], ["1c53e12c004f542b5293f7250f7f4e8e", {"code_string": "def print_verbose(self, pkg, cfile):\n    \"Format for full output.\"\n    file_str = pp.path(format_filetype(cfile, pkg.parsed_contents()[cfile]))\n    if self.name_only:\n        name = pkg.cp\n    else:\n        name = str(pkg.cpv)\n    pp.uprint(pp.cpv(name), \"(\" + file_str + \")\")\n", "code_toks_joined": "def print_verbose ( self , pkg , cfile ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> file_str = pp . path ( format_filetype ( cfile , pkg . parsed_contents ( ) [ cfile ] ) ) <NEWLINE> if self . name_only : <NEWLINE> <INDENT> name = pkg . cp <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> name = str ( pkg . cpv ) <NEWLINE> <DEDENT> pp . uprint ( pp . cpv ( name ) , <STRING> + file_str + <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Format for full output.\"", "\"(\"", "\")\""]}}], ["b6133cfca710241d4741646d384c2a06", {"code_string": "def is_installed(package):\n    try:\n        __import__(package)\n        return True\n    except ImportError:\n        return False\n", "code_toks_joined": "def is_installed ( package ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> __import__ ( package ) <NEWLINE> return True <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["afa5e1cc6f9adf1d4c928bd48d459713", {"code_string": "def pull_by_url(cls, url):\n    res = cls.query(q = {\"query\": {\"term\": {'url.exact': url}}})\n    if res.get('hits', {}).get('total', 0) == 1:\n        return cls(** res['hits']['hits'][0]['_source'])\n    else:\n        return None\n", "code_toks_joined": "def pull_by_url ( cls , url ) : <NEWLINE> <INDENT> res = cls . query ( q = { <STRING> : { <STRING> : { <STRING> : url } } } ) <NEWLINE> if res . get ( <STRING> , { } ) . get ( <STRING> , 0 ) == 1 : <NEWLINE> <INDENT> return cls ( ** res [ <STRING> ] [ <STRING> ] [ 0 ] [ <STRING> ] ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"query\"", "\"term\"", "'url.exact'", "'hits'", "'total'", "'hits'", "'hits'", "'_source'"]}}], ["1e8f436363d88dd7e6396aec6b9429e9", {"code_string": "def amax(a, axis = None, out = None):\n    \"\"\"Return the maximum of 'a' along dimension axis.\"\"\"\n    try:\n        amax = a.max\n    except AttributeError:\n        return _wrapit(a, 'max', axis, out)\n    return amax(axis, out)\n", "code_toks_joined": "def amax ( a , axis = None , out = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> try : <NEWLINE> <INDENT> amax = a . max <NEWLINE> <DEDENT> except AttributeError : <NEWLINE> <INDENT> return _wrapit ( a , <STRING> , axis , out ) <NEWLINE> <DEDENT> return amax ( axis , out ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Return the maximum of 'a' along dimension axis.\"\"\"", "'max'"]}}], ["32c71a87e9d8f5b235a0b7798ef50671", {"code_string": "def new_language_value_change(self, listbox, row):\n    \"\"\"Changes the \"self.new_language\" into the current selected language row\"\"\"\n    if row is not None:\n        self.new_language = {\n            \"Index\": row.get_index(), \"Name\": row.get_child().get_text()\n        }\n", "code_toks_joined": "def new_language_value_change ( self , listbox , row ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if row is not None : <NEWLINE> <INDENT> self . new_language = { <NEWLINE> <INDENT> <STRING> : row . get_index ( ) , <STRING> : row . get_child ( ) . get_text ( ) <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Changes the \"self.new_language\" into the current selected language row\"\"\"", "\"Index\"", "\"Name\""]}}], ["211c7a9924b9c18a15cb93561961bb99", {"code_string": "def fetch_csv(self, date, label):\n    datestr = date.strftime('%Y%m%d')\n    url = '%s/%s/%s%s.csv' %(self.base_url, label, datestr, label)\n    result = self.request(url)\n    return result.text\n", "code_toks_joined": "def fetch_csv ( self , date , label ) : <NEWLINE> <INDENT> datestr = date . strftime ( <STRING> ) <NEWLINE> url = <STRING> % ( self . base_url , label , datestr , label ) <NEWLINE> result = self . request ( url ) <NEWLINE> return result . text <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'%Y%m%d'", "'%s/%s/%s%s.csv'"]}}], ["99df666d13b5ae8af4dac02b0f59c00f", {"code_string": "def __init__(self, cls, attr_dict):\n    self.my_class = cls\n    self.name = attr_dict[\"name\"]\n    self.d_type = attr_dict[\"type\"]\n    self.visibility = self.visibility_dict[attr_dict[\"visibility\"]]\n    self.abstract_flag = attr_dict[\"abstract\"]\n    self.static_flag = attr_dict[\"class_scope\"]\n    self.comment = attr_dict[\"comment\"]\n    self.value = None\n    if attr_dict[\"value\"] != \"\":\n        self.value = attr_dict[\"value\"]\n", "code_toks_joined": "def __init__ ( self , cls , attr_dict ) : <NEWLINE> <INDENT> self . my_class = cls <NEWLINE> self . name = attr_dict [ <STRING> ] <NEWLINE> self . d_type = attr_dict [ <STRING> ] <NEWLINE> self . visibility = self . visibility_dict [ attr_dict [ <STRING> ] ] <NEWLINE> self . abstract_flag = attr_dict [ <STRING> ] <NEWLINE> self . static_flag = attr_dict [ <STRING> ] <NEWLINE> self . comment = attr_dict [ <STRING> ] <NEWLINE> self . value = None <NEWLINE> if attr_dict [ <STRING> ] != <STRING> : <NEWLINE> <INDENT> self . value = attr_dict [ <STRING> ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"name\"", "\"type\"", "\"visibility\"", "\"abstract\"", "\"class_scope\"", "\"comment\"", "\"value\"", "\"\"", "\"value\""]}}], ["35c4cbe0b80c18147d724103bedd377f", {"code_string": "from supriya import osctools\nfrom supriya import servertools\nfrom supriya import synthdefs\nfrom supriya import systemtools\n", "code_toks_joined": "from supriya import osctools <NEWLINE> from supriya import servertools <NEWLINE> from supriya import synthdefs <NEWLINE> from supriya import systemtools <NEWLINE>", "anonymize_dict": {}}], ["f6137adabfe2f5b9dd458fa6e1b6a9ea", {"code_string": "class Import(models.Model):\n    \"\"\"Class to register the import of Changesets.\"\"\"\n    start = models.IntegerField()\n    end = models.IntegerField()\n    date = models.DateTimeField(_('Date of the import'), auto_now_add = True)\n    def __str__(self):\n        return '%s %i - %i' %(_('Import'), self.start, self.end)\n    def save(self, * args, ** kwargs):\n        self.full_clean()\n        super(Import, self).save(* args, ** kwargs)\n", "code_toks_joined": "class Import ( models . Model ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> start = models . IntegerField ( ) <NEWLINE> end = models . IntegerField ( ) <NEWLINE> date = models . DateTimeField ( _ ( <STRING> ) , auto_now_add = True ) <NEWLINE> def __str__ ( self ) : <NEWLINE> <INDENT> return <STRING> % ( _ ( <STRING> ) , self . start , self . end ) <NEWLINE> <DEDENT> def save ( self , * args , ** kwargs ) : <NEWLINE> <INDENT> self . full_clean ( ) <NEWLINE> super ( Import , self ) . save ( * args , ** kwargs ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Class to register the import of Changesets.\"\"\"", "'Date of the import'", "'%s %i - %i'", "'Import'"]}}], ["9d9b2c1ce6c03f951dd2a76af2012740", {"code_string": "\"\"\" Deploy and install a package to a target\"\"\"\nimport os\nimport sys\nimport zipfile\nfrom qisys import ui\nimport qisys.command\nimport qisys.parsers\nimport qipkg.parsers\nimport qipkg.package\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> import sys <NEWLINE> import zipfile <NEWLINE> from qisys import ui <NEWLINE> import qisys . command <NEWLINE> import qisys . parsers <NEWLINE> import qipkg . parsers <NEWLINE> import qipkg . package <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\" Deploy and install a package to a target\"\"\""]}}], ["d096d5ec70cc33be3f9a1011bb67a346", {"code_string": "def test_get_sections_by_crn(self):\n    s1, s2, s3, s4 = SectionPeriodFactory.create_batch(4)\n    json = self.json_get(\n        'v4:sections',\n        get = '?crn=%d&crn=%d' %(s1.section.crn, s3.section.crn),\n        status_code = 200)\n    self.assertEqual(json, {\n        u\"version\": 4,\n        u\"success\": True,\n        u\"result\": [\n            self.to_dict(s1),\n            self.to_dict(s3),\n        ]\n    })\n", "code_toks_joined": "def test_get_sections_by_crn ( self ) : <NEWLINE> <INDENT> s1 , s2 , s3 , s4 = SectionPeriodFactory . create_batch ( 4 ) <NEWLINE> json = self . json_get ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> get = <STRING> % ( s1 . section . crn , s3 . section . crn ) , <NEWLINE> status_code = 200 ) <NEWLINE> <DEDENT> self . assertEqual ( json , { <NEWLINE> <INDENT> <STRING> : 4 , <NEWLINE> <STRING> : True , <NEWLINE> <STRING> : [ <NEWLINE> <INDENT> self . to_dict ( s1 ) , <NEWLINE> self . to_dict ( s3 ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT> } ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'v4:sections'", "'?crn=%d&crn=%d'", "u\"version\"", "u\"success\"", "u\"result\""]}}], ["95d501f1fcacaf29eb84119b85c585af", {"code_string": "from runners.baseRunner import BaseRunner\nimport ha_engine.ha_infra as infra\nimport time\nimport subprocess\nLOG = infra.ha_logging(__name__)\n", "code_toks_joined": "from runners . baseRunner import BaseRunner <NEWLINE> import ha_engine . ha_infra as infra <NEWLINE> import time <NEWLINE> import subprocess <NEWLINE> LOG = infra . ha_logging ( __name__ ) <NEWLINE>", "anonymize_dict": {}}], ["2d2b70e10963c93040d4b034f409a1e0", {"code_string": "def show_branches_panel(self, repo, on_selection, * args, ** kwargs):\n    branches, choices = self.get_branch_choices(repo, * args, ** kwargs)\n    def on_done(idx):\n        if idx != - 1:\n            branch = branches[idx]\n            on_selection(branch)\n    self.window.show_quick_panel(choices, on_done, sublime.MONOSPACE_FONT)\n", "code_toks_joined": "def show_branches_panel ( self , repo , on_selection , * args , ** kwargs ) : <NEWLINE> <INDENT> branches , choices = self . get_branch_choices ( repo , * args , ** kwargs ) <NEWLINE> def on_done ( idx ) : <NEWLINE> <INDENT> if idx != - 1 : <NEWLINE> <INDENT> branch = branches [ idx ] <NEWLINE> on_selection ( branch ) <NEWLINE> <DEDENT> <DEDENT> self . window . show_quick_panel ( choices , on_done , sublime . MONOSPACE_FONT ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["d63353b26380cd31b3b8cdd7eb229260", {"code_string": "def before_request():\n    if 'session_start' not in session:\n        session['session_start'] = datetime.datetime.now()\n    session['last_action'] = datetime.datetime.now()\n", "code_toks_joined": "def before_request ( ) : <NEWLINE> <INDENT> if <STRING> not in session : <NEWLINE> <INDENT> session [ <STRING> ] = datetime . datetime . now ( ) <NEWLINE> <DEDENT> session [ <STRING> ] = datetime . datetime . now ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'session_start'", "'session_start'", "'last_action'"]}}], ["1163cafe8d85de8e6bdff651de3c1d42", {"code_string": "def test_no_favorite_position(self):\n    result = self.bot._get_pos_by_fav_location(\"NOT_EXIST\")\n    self.assertEqual(result, None)\n", "code_toks_joined": "def test_no_favorite_position ( self ) : <NEWLINE> <INDENT> result = self . bot . _get_pos_by_fav_location ( <STRING> ) <NEWLINE> self . assertEqual ( result , None ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"NOT_EXIST\""]}}], ["555c9e2b223fb5e526749bf9f0307b4a", {"code_string": "def _get_ranking(self):\n    \"\"\"Get aspect display rank.\"\"\"\n    return self._ranking\n", "code_toks_joined": "def _get_ranking ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . _ranking <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Get aspect display rank.\"\"\""]}}], ["83b75af5d804c0aa3e1dac90161f9938", {"code_string": "def now():\n    \"\"\"Returns the date and time right now.\"\"\"\n    return datetime.datetime.utcnow()\n", "code_toks_joined": "def now ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return datetime . datetime . utcnow ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Returns the date and time right now.\"\"\""]}}], ["9c9a157f99a881eb7766cc1323a075ad", {"code_string": "class UnitOfMeasure(UnleashedResource):\n    __endpoint__ = 'UnitOfMeasures'\n    Guid = fields.FieldGuid(required = True)\n    Name = fields.FieldString(length = 20, required = True)\n", "code_toks_joined": "class UnitOfMeasure ( UnleashedResource ) : <NEWLINE> <INDENT> __endpoint__ = <STRING> <NEWLINE> Guid = fields . FieldGuid ( required = True ) <NEWLINE> Name = fields . FieldString ( length = 20 , required = True ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'UnitOfMeasures'"]}}], ["ebd0486b52424965659cd3c4b0ae31b5", {"code_string": "def __le__(self, other):\n    for a, b in zip(self, other):\n        if a != b:\n            return a < b\n    return len(self) <= len(other)\n", "code_toks_joined": "def __le__ ( self , other ) : <NEWLINE> <INDENT> for a , b in zip ( self , other ) : <NEWLINE> <INDENT> if a != b : <NEWLINE> <INDENT> return a < b <NEWLINE> <DEDENT> <DEDENT> return len ( self ) <= len ( other ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["fa0ca5ec9639cabe01012ed0638cc3ee", {"code_string": "def init_methods(self):\n    \"\"\"returns the setup relation method\"\"\"\n    cls_member = lambda x: x.inner_class == self\n    return self(InitMethod, filter = cls_member, cut = True)\n", "code_toks_joined": "def init_methods ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> cls_member = lambda x : x . inner_class == self <NEWLINE> return self ( InitMethod , filter = cls_member , cut = True ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"returns the setup relation method\"\"\""]}}], ["fd53c185254dffe3c17fdbe11cbd6304", {"code_string": "def test_video_start_time_and_end_time(self):\n    \"\"\"Scenario: Start time and end time work together for Youtube video.\"\"\"\n    data = {'start_time': '00:00:10', 'end_time': '00:00:15'}\n    self.metadata = self.metadata_for_mode('youtube', additional_data = data)\n    self.navigate_to_video()\n    self.assertEqual(self.video.position, '0:10')\n    self.video.click_player_button('play')\n    self.video.wait_for_state('pause')\n    self.assertIn(self.video.position, ('0:15', '0:16'))\n", "code_toks_joined": "def test_video_start_time_and_end_time ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> data = { <STRING> : <STRING> , <STRING> : <STRING> } <NEWLINE> self . metadata = self . metadata_for_mode ( <STRING> , additional_data = data ) <NEWLINE> self . navigate_to_video ( ) <NEWLINE> self . assertEqual ( self . video . position , <STRING> ) <NEWLINE> self . video . click_player_button ( <STRING> ) <NEWLINE> self . video . wait_for_state ( <STRING> ) <NEWLINE> self . assertIn ( self . video . position , ( <STRING> , <STRING> ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Scenario: Start time and end time work together for Youtube video.\"\"\"", "'start_time'", "'00:00:10'", "'end_time'", "'00:00:15'", "'youtube'", "'0:10'", "'play'", "'pause'", "'0:15'", "'0:16'"]}}], ["7026620c8288a1212e4c40c4b14a803f", {"code_string": "import threading\nfrom swiftclient import client as swift_client\nfrom swiftclient import ClientException\nfrom nose.plugins.attrib import attr\nfrom storlets.tools.utils import get_member_auth\nfrom tests.functional.java import StorletJavaFunctionalTest\nimport unittest\n", "code_toks_joined": "import threading <NEWLINE> from swiftclient import client as swift_client <NEWLINE> from swiftclient import ClientException <NEWLINE> from nose . plugins . attrib import attr <NEWLINE> from storlets . tools . utils import get_member_auth <NEWLINE> from tests . functional . java import StorletJavaFunctionalTest <NEWLINE> import unittest <NEWLINE>", "anonymize_dict": {}}], ["77705d8af047c740c3f788c26b27680d", {"code_string": "class Persona(models.Model):\n    nickname = models.CharField(max_length = 100)\n    company = models.ForeignKey(Company, related_name = 'personas')\n    speaker = models.ForeignKey(Speaker, related_name = 'personas')\n    def __str__(self):\n        return self.nickname + \" (\" + str(self.speaker) + \")\"\n", "code_toks_joined": "class Persona ( models . Model ) : <NEWLINE> <INDENT> nickname = models . CharField ( max_length = 100 ) <NEWLINE> company = models . ForeignKey ( Company , related_name = <STRING> ) <NEWLINE> speaker = models . ForeignKey ( Speaker , related_name = <STRING> ) <NEWLINE> def __str__ ( self ) : <NEWLINE> <INDENT> return self . nickname + <STRING> + str ( self . speaker ) + <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'personas'", "'personas'", "\" (\"", "\")\""]}}], ["3be717129be0910315893af0f61b0fe4", {"code_string": "def set_verifier(self, verifier = None):\n    if verifier is not None:\n        self.verifier = verifier\n    else:\n        self.verifier = generate_verifier()\n", "code_toks_joined": "def set_verifier ( self , verifier = None ) : <NEWLINE> <INDENT> if verifier is not None : <NEWLINE> <INDENT> self . verifier = verifier <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . verifier = generate_verifier ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["0438860ab5122ed2ec69fab9e1edc9ff", {"code_string": "import os\nimport ycm_core\nflags = [\n'-Wall',\n'-Wextra',\n'-Werror',\n'-Wno-long-long',\n'-Wno-variadic-macros',\n'-fexceptions',\n'-DNDEBUG',\n'-DUSE_CLANG_COMPLETER',\n'-std=c++11',\n'-x',\n'c++',\n'-I',\n'src',\n'-I',\n'gtest/include',\n'-I',\n'build/raft'\n]\ncompilation_database_folder = ''\nif compilation_database_folder:\n    database = ycm_core.CompilationDatabase(compilation_database_folder)\nelse:\n    database = None\n", "code_toks_joined": "import os <NEWLINE> import ycm_core <NEWLINE> flags = [ <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> <NEWLINE> ] <NEWLINE> compilation_database_folder = <STRING> <NEWLINE> if compilation_database_folder : <NEWLINE> <INDENT> database = ycm_core . CompilationDatabase ( compilation_database_folder ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> database = None <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'-Wall'", "'-Wextra'", "'-Werror'", "'-Wno-long-long'", "'-Wno-variadic-macros'", "'-fexceptions'", "'-DNDEBUG'", "'-DUSE_CLANG_COMPLETER'", "'-std=c++11'", "'-x'", "'c++'", "'-I'", "'src'", "'-I'", "'gtest/include'", "'-I'", "'build/raft'", "''"]}}], ["91dfcfd005fc3922d3c28a5d282082c3", {"code_string": "import markdown\nfrom django import forms\nfrom django.utils.html import escape\nfrom django.utils.safestring import mark_safe\nfrom django.utils.translation import ugettext_lazy as _\nfrom shuup.xtheme.plugins._base import Plugin\nfrom shuup.xtheme.plugins.forms import TranslatableField\n", "code_toks_joined": "import markdown <NEWLINE> from django import forms <NEWLINE> from django . utils . html import escape <NEWLINE> from django . utils . safestring import mark_safe <NEWLINE> from django . utils . translation import ugettext_lazy as _ <NEWLINE> from shuup . xtheme . plugins . _base import Plugin <NEWLINE> from shuup . xtheme . plugins . forms import TranslatableField <NEWLINE>", "anonymize_dict": {}}], ["9b51996c8821ccb03b03e6a675fbc881", {"code_string": "def __vector_to_string(self, vector):\n    \"\"\" Returns string representation of vector. \"\"\"\n    return numpy.array_str(vector)\n", "code_toks_joined": "def __vector_to_string ( self , vector ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return numpy . array_str ( vector ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Returns string representation of vector. \"\"\""]}}], ["8daeb2d497dd5752b3d73070156c9b5e", {"code_string": "def test_with_request_type_post(self):\n    self.setUpWithRequestTypeMethodScraper('post')\n    self.rpt_mp.method = \"POST\"\n    self.rpt_mp.save()\n    self.run_event_spider(1)\n    self.assertEqual(len(Event.objects.all()), 4)\n", "code_toks_joined": "def test_with_request_type_post ( self ) : <NEWLINE> <INDENT> self . setUpWithRequestTypeMethodScraper ( <STRING> ) <NEWLINE> self . rpt_mp . method = <STRING> <NEWLINE> self . rpt_mp . save ( ) <NEWLINE> self . run_event_spider ( 1 ) <NEWLINE> self . assertEqual ( len ( Event . objects . all ( ) ) , 4 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'post'", "\"POST\""]}}], ["2f84126a98a009e32ed4d7ed43a677aa", {"code_string": "class Cleaner(Task):\n    \"\"\"Clean all current build products.\"\"\"\n    def execute(self):\n        safe_rmtree(self.get_options().pants_workdir)\n", "code_toks_joined": "class Cleaner ( Task ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def execute ( self ) : <NEWLINE> <INDENT> safe_rmtree ( self . get_options ( ) . pants_workdir ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Clean all current build products.\"\"\""]}}], ["bb424d6e78afc8a296d6b0c767f26026", {"code_string": "def P(x):\n    '''Non-normalized probability distribution'''\n    return math.exp(- beta * x ** 2 / 2.0)\n", "code_toks_joined": "def P ( x ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return math . exp ( - beta * x ** 2 / 2.0 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Non-normalized probability distribution'''"]}}], ["35814e21ec97f2350b678bfcadbe72a7", {"code_string": "def suite():\n    \"Test suite\"\n    test_suite = unittest.TestSuite()\n    test_suite.addTests(\n        unittest.TestLoader().loadTestsFromTestCase(TestProduct)\n    )\n    return test_suite\n", "code_toks_joined": "def suite ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> test_suite = unittest . TestSuite ( ) <NEWLINE> test_suite . addTests ( <NEWLINE> <INDENT> unittest . TestLoader ( ) . loadTestsFromTestCase ( TestProduct ) <NEWLINE> <DEDENT> ) <NEWLINE> return test_suite <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Test suite\""]}}], ["eb0066922925477771180c3185af8dc1", {"code_string": "class Number(Literal):\n    def set_fields(self, number):\n        self.value = decimal.Decimal(number)\n", "code_toks_joined": "class Number ( Literal ) : <NEWLINE> <INDENT> def set_fields ( self , number ) : <NEWLINE> <INDENT> self . value = decimal . Decimal ( number ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["5c6d809dad66676d5f07199fa9a6db8c", {"code_string": "class allPayController(http.Controller):\n    _return_url = '/payment/allpay/return/'\n    @ http.route('/payment/allpay/return', type = 'http', auth = \"none\", methods = ['POST', 'GET'])\n    def allpay_return(self, ** post):\n        _logger.info('Beginning Adyen form_feedback with post data %s', pprint.pformat(post))\n        if post.get('RtnCode') in['1', '800']:\n            request.registry['payment.transaction'].form_feedback(request.cr, SUPERUSER_ID, post, 'allpay',\n                context = request.context)\n", "code_toks_joined": "class allPayController ( http . Controller ) : <NEWLINE> <INDENT> _return_url = <STRING> <NEWLINE> @ http . route ( <STRING> , type = <STRING> , auth = <STRING> , methods = [ <STRING> , <STRING> ] ) <NEWLINE> def allpay_return ( self , ** post ) : <NEWLINE> <INDENT> _logger . info ( <STRING> , pprint . pformat ( post ) ) <NEWLINE> if post . get ( <STRING> ) in [ <STRING> , <STRING> ] : <NEWLINE> <INDENT> request . registry [ <STRING> ] . form_feedback ( request . cr , SUPERUSER_ID , post , <STRING> , <NEWLINE> <INDENT> context = request . context ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/payment/allpay/return/'", "'/payment/allpay/return'", "'http'", "\"none\"", "'POST'", "'GET'", "'Beginning Adyen form_feedback with post data %s'", "'RtnCode'", "'1'", "'800'", "'payment.transaction'", "'allpay'"]}}], ["b978e75acf572c0ccb0ca607ef438277", {"code_string": "class Chord:\n    def __init__(self):\n        self.degree = None\n        self.weights = [1.6, .3, 1.5, .6, 1.4, .4, .2]\n", "code_toks_joined": "class Chord : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> self . degree = None <NEWLINE> self . weights = [ 1.6 , .3 , 1.5 , .6 , 1.4 , .4 , .2 ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["5f6af943691ba19bcbbcfeaf39b0a78b", {"code_string": "def handlefiles(self, dirname, filenames):\n    for filename in filenames:\n        pathname = os.path.join(dirname, filename)\n        if os.path.isdir(pathname):\n            self.handledir(pathname)\n        else:\n            self.handlefile(pathname)\n", "code_toks_joined": "def handlefiles ( self , dirname , filenames ) : <NEWLINE> <INDENT> for filename in filenames : <NEWLINE> <INDENT> pathname = os . path . join ( dirname , filename ) <NEWLINE> if os . path . isdir ( pathname ) : <NEWLINE> <INDENT> self . handledir ( pathname ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . handlefile ( pathname ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["97927c0cae9ece06e343b93605067713", {"code_string": "def post_init(self):\n    \"\"\"Initialize any cross-plugin state.\"\"\"\n    pass\n", "code_toks_joined": "def post_init ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Initialize any cross-plugin state.\"\"\""]}}], ["2a24463021d74f7d1aa890b73013a5cd", {"code_string": "class AdminReadonlyField(LayoutNode):\n    \"\"\"Layout wrapper node for admin read-only field.\"\"\"\n    template_name = 'fields/django_adminreadonlyfield.html'\n    def __init__(self, fieldset_field):\n        self.fieldset_field = fieldset_field\n    def get_context_data(self, context):\n        return{'fieldset_field': self.fieldset_field}\n", "code_toks_joined": "class AdminReadonlyField ( LayoutNode ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> template_name = <STRING> <NEWLINE> def __init__ ( self , fieldset_field ) : <NEWLINE> <INDENT> self . fieldset_field = fieldset_field <NEWLINE> <DEDENT> def get_context_data ( self , context ) : <NEWLINE> <INDENT> return { <STRING> : self . fieldset_field } <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Layout wrapper node for admin read-only field.\"\"\"", "'fields/django_adminreadonlyfield.html'", "'fieldset_field'"]}}], ["9e37424a37347d47fe3037b593115c4b", {"code_string": "def send(self, data):\n    \"\"\"Returns None on success\"\"\"\n    if not self.is_connected():\n        return True\n    return self.sock.sendall(data)\n", "code_toks_joined": "def send ( self , data ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if not self . is_connected ( ) : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> return self . sock . sendall ( data ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Returns None on success\"\"\""]}}], ["cbcebed7b14da98a8dffde14cef1b681", {"code_string": "def testPos(self):\n    fn = os.path.join(CBCF_DATADIR, self.filename)\n    v = pysam.VariantFile(fn)\n    pos = [rec.pos for rec in v]\n    self.assertEqual(pos, [1230237, 14370, 17330, 1110696, 1234567])\n", "code_toks_joined": "def testPos ( self ) : <NEWLINE> <INDENT> fn = os . path . join ( CBCF_DATADIR , self . filename ) <NEWLINE> v = pysam . VariantFile ( fn ) <NEWLINE> pos = [ rec . pos for rec in v ] <NEWLINE> self . assertEqual ( pos , [ 1230237 , 14370 , 17330 , 1110696 , 1234567 ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["85d10cb967373661a87c6dd895d9392e", {"code_string": "def start(self):\n    if self._current_state == self.FINAL:\n        self._navIntr.start()\n        self._current_state = self.DEFAULT_MODE\n    else:\n        pass\n", "code_toks_joined": "def start ( self ) : <NEWLINE> <INDENT> if self . _current_state == self . FINAL : <NEWLINE> <INDENT> self . _navIntr . start ( ) <NEWLINE> self . _current_state = self . DEFAULT_MODE <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["08a218257cf2aae1eebaec5d8321eb11", {"code_string": "def compute_amount_in(hivemindd, txinfo):\n    result = Decimal(\"0.0\")\n    for vin in txinfo['vin']:\n        in_info = hivemindd.getrawtransaction(vin['txid'], 1)\n        vout = in_info['vout'][vin['vout']]\n        result = result + vout['value']\n    return result\n", "code_toks_joined": "def compute_amount_in ( hivemindd , txinfo ) : <NEWLINE> <INDENT> result = Decimal ( <STRING> ) <NEWLINE> for vin in txinfo [ <STRING> ] : <NEWLINE> <INDENT> in_info = hivemindd . getrawtransaction ( vin [ <STRING> ] , 1 ) <NEWLINE> vout = in_info [ <STRING> ] [ vin [ <STRING> ] ] <NEWLINE> result = result + vout [ <STRING> ] <NEWLINE> <DEDENT> return result <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"0.0\"", "'vin'", "'txid'", "'vout'", "'vout'", "'value'"]}}], ["797e8571c92a5a847aefc9487d83c2f8", {"code_string": "class Home(BaseHandler):\n    def get(self):\n        params = {}\n        return self.render_template('admin/home.html', ** params)\n    def post(self):\n        pass\n        self.redirect_to('/admin/')\n", "code_toks_joined": "class Home ( BaseHandler ) : <NEWLINE> <INDENT> def get ( self ) : <NEWLINE> <INDENT> params = { } <NEWLINE> return self . render_template ( <STRING> , ** params ) <NEWLINE> <DEDENT> def post ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> self . redirect_to ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'admin/home.html'", "'/admin/'"]}}], ["612429a73fffb08ec76d6d587cb18d7a", {"code_string": "'''Created on 18. aug. 2011'''\nimport unittest\nimport scipy as sp\nimport framework.mynumpy as np\nimport framework.linalg.matrixDecomp as md\nimport framework.linalg.linearSolve as ls\nfrom framework.gfuncs import is_np_type\nFLOATING_PRECISION = 32\n", "code_toks_joined": "<STRING> <NEWLINE> import unittest <NEWLINE> import scipy as sp <NEWLINE> import framework . mynumpy as np <NEWLINE> import framework . linalg . matrixDecomp as md <NEWLINE> import framework . linalg . linearSolve as ls <NEWLINE> from framework . gfuncs import is_np_type <NEWLINE> FLOATING_PRECISION = 32 <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Created on 18. aug. 2011'''"]}}], ["43f502178b6172e4127b19c2f1a77054", {"code_string": "def _get_connection(self, connection):\n    \"\"\"Create connection strategy\"\"\"\n    if not connection:\n        connection = self.default_connection\n    if isinstance(connection, str):\n        connection = {'hostname': connection}\n    if isinstance(connection, dict):\n        connection = Connection(** connection)\n    return connection\n", "code_toks_joined": "def _get_connection ( self , connection ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if not connection : <NEWLINE> <INDENT> connection = self . default_connection <NEWLINE> <DEDENT> if isinstance ( connection , str ) : <NEWLINE> <INDENT> connection = { <STRING> : connection } <NEWLINE> <DEDENT> if isinstance ( connection , dict ) : <NEWLINE> <INDENT> connection = Connection ( ** connection ) <NEWLINE> <DEDENT> return connection <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Create connection strategy\"\"\"", "'hostname'"]}}], ["ecbde1a70f1f71646e03e637d3883110", {"code_string": "\"\"\"Basic text read, organize by column.\"\"\"\nimport csv\ncsv_name = 'Test_01.csv'\nstate_ide = []\nstate_dur = []\nfile = open(csv_name)\ndata = csv.DictReader(file)\nfor row in data:\n    state_ide.append(int(row['stimulus']))\n    state_dur.append(int(row['duration']))\nfile.close()\nprint('Block types    : ', state_ide)\nprint('Block durations: ', state_dur)\n", "code_toks_joined": "<STRING> <NEWLINE> import csv <NEWLINE> csv_name = <STRING> <NEWLINE> state_ide = [ ] <NEWLINE> state_dur = [ ] <NEWLINE> file = open ( csv_name ) <NEWLINE> data = csv . DictReader ( file ) <NEWLINE> for row in data : <NEWLINE> <INDENT> state_ide . append ( int ( row [ <STRING> ] ) ) <NEWLINE> state_dur . append ( int ( row [ <STRING> ] ) ) <NEWLINE> <DEDENT> file . close ( ) <NEWLINE> print ( <STRING> , state_ide ) <NEWLINE> print ( <STRING> , state_dur ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Basic text read, organize by column.\"\"\"", "'Test_01.csv'", "'stimulus'", "'duration'", "'Block types    : '", "'Block durations: '"]}}], ["e7de628f3ea33b4be78b00805644cee5", {"code_string": "def multiRing(coordinates):\n    values = []\n    for lineString in coordinates:\n        values.append(\"({0})\".format(linearRing(lineString)))\n    return \", \".join(values)\n", "code_toks_joined": "def multiRing ( coordinates ) : <NEWLINE> <INDENT> values = [ ] <NEWLINE> for lineString in coordinates : <NEWLINE> <INDENT> values . append ( <STRING> . format ( linearRing ( lineString ) ) ) <NEWLINE> <DEDENT> return <STRING> . join ( values ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"({0})\"", "\", \""]}}], ["9d910e417b0ede8cecdd200bbf9f2c12", {"code_string": "def set_verbosity(self, level):\n    \"\"\"Set the verbosity level.\"\"\"\n    self.set_option(pycurl.VERBOSE, level)\n", "code_toks_joined": "def set_verbosity ( self , level ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . set_option ( pycurl . VERBOSE , level ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Set the verbosity level.\"\"\""]}}], ["bde8b92beb69e7841f2e42c46c6bd50f", {"code_string": "def clean_nombre(self):\n    \"\"\"Valida que el nombre no sea menor a 5 caracteres\"\"\"\n    nombre = self.cleaned_data['nombre']\n    if len(nombre) < 5:\n        raise forms.ValidationError(\n            \"Debe de tener un m\u00ednimo de 5 caracteres\")\n    elif len(nombre) > 15:\n        raise forms.ValidationError(\n            \"Debe de tener un max\u00edmo de 15 caracteres\")\n    return nombre\n", "code_toks_joined": "def clean_nombre ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> nombre = self . cleaned_data [ <STRING> ] <NEWLINE> if len ( nombre ) < 5 : <NEWLINE> <INDENT> raise forms . ValidationError ( <NEWLINE> <INDENT> <STRING> ) <NEWLINE> <DEDENT> <DEDENT> elif len ( nombre ) > 15 : <NEWLINE> <INDENT> raise forms . ValidationError ( <NEWLINE> <INDENT> <STRING> ) <NEWLINE> <DEDENT> <DEDENT> return nombre <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Valida que el nombre no sea menor a 5 caracteres\"\"\"", "'nombre'", "\"Debe de tener un m\u00ednimo de 5 caracteres\"", "\"Debe de tener un max\u00edmo de 15 caracteres\""]}}], ["ba866c4449d57e463361d3e7cebb8db4", {"code_string": "from django.conf import settings\nfrom questionnaire import *\nfrom django.utils.translation import ugettext as _\nimport simple\nimport choice\nimport range\nimport timeperiod\nimport custom\n", "code_toks_joined": "from django . conf import settings <NEWLINE> from questionnaire import * <NEWLINE> from django . utils . translation import ugettext as _ <NEWLINE> import simple <NEWLINE> import choice <NEWLINE> import range <NEWLINE> import timeperiod <NEWLINE> import custom <NEWLINE>", "anonymize_dict": {}}], ["6683e6c10cac77c8f084efd4065f714d", {"code_string": "def handleEvents(self, event, fpsClock):\n    \"\"\"Called when an event occurs\"\"\"\n    return False\n", "code_toks_joined": "def handleEvents ( self , event , fpsClock ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return False <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Called when an event occurs\"\"\""]}}], ["34472cc4ec897a9bfa973da194a3a643", {"code_string": "def get_fragment(self, ** kwargs):\n    \"\"\"Return a complete fragment.\"\"\"\n    gen, namespaces, plan = self.get_fragment_generator(** kwargs)\n    graph = ConjunctiveGraph()\n    [graph.bind(prefix, u) for(prefix, u) in namespaces]\n    [graph.add((s, p, o)) for(_, s, p, o) in gen]\n    return graph\n", "code_toks_joined": "def get_fragment ( self , ** kwargs ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> gen , namespaces , plan = self . get_fragment_generator ( ** kwargs ) <NEWLINE> graph = ConjunctiveGraph ( ) <NEWLINE> [ graph . bind ( prefix , u ) for ( prefix , u ) in namespaces ] <NEWLINE> [ graph . add ( ( s , p , o ) ) for ( _ , s , p , o ) in gen ] <NEWLINE> return graph <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Return a complete fragment.\"\"\""]}}], ["bc03823289cee6703021543dbee668dd", {"code_string": "class AstLeaf(AstNode):\n    \"\"\"A leaf node which just runs the base operator in input data\"\"\"\n    def bind(self, inputs):\n        self.op = self.op(inputs)\n        operators.Operator.__init__(self, inputs, self.op.outputs)\n    def process(self, data):\n        return self.op(data)\n", "code_toks_joined": "class AstLeaf ( AstNode ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def bind ( self , inputs ) : <NEWLINE> <INDENT> self . op = self . op ( inputs ) <NEWLINE> operators . Operator . __init__ ( self , inputs , self . op . outputs ) <NEWLINE> <DEDENT> def process ( self , data ) : <NEWLINE> <INDENT> return self . op ( data ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"A leaf node which just runs the base operator in input data\"\"\""]}}], ["194a6f19c11d6785145f26e73a3ae33e", {"code_string": "import factory\nfrom core.tests.factories import ExtendedFactory\nfrom organization.tests.factories import ProjectFactory\nfrom spatial.models import SpatialUnit, SpatialRelationship\n", "code_toks_joined": "import factory <NEWLINE> from core . tests . factories import ExtendedFactory <NEWLINE> from organization . tests . factories import ProjectFactory <NEWLINE> from spatial . models import SpatialUnit , SpatialRelationship <NEWLINE>", "anonymize_dict": {}}], ["511470b1fe19cb2b280674288ae30cd1", {"code_string": "def assertExpressionEqual(self, left, right):\n    \"\"\"Asserts that the `left` and `right` statement expressions are equal\"\"\"\n    stmt = sa.select([left.label(\"value\")], from_obj = self.table)\n    result = self.engine.execute(stmt)\n    left_result = [row[\"value\"] for row in result]\n    stmt = sa.select([right.label(\"value\")], from_obj = self.table)\n    result = self.engine.execute(stmt)\n    right_result = [row[\"value\"] for row in result]\n    self.assertCountEqual(left_result, right_result)\n", "code_toks_joined": "def assertExpressionEqual ( self , left , right ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> stmt = sa . select ( [ left . label ( <STRING> ) ] , from_obj = self . table ) <NEWLINE> result = self . engine . execute ( stmt ) <NEWLINE> left_result = [ row [ <STRING> ] for row in result ] <NEWLINE> stmt = sa . select ( [ right . label ( <STRING> ) ] , from_obj = self . table ) <NEWLINE> result = self . engine . execute ( stmt ) <NEWLINE> right_result = [ row [ <STRING> ] for row in result ] <NEWLINE> self . assertCountEqual ( left_result , right_result ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Asserts that the `left` and `right` statement expressions are equal\"\"\"", "\"value\"", "\"value\"", "\"value\"", "\"value\""]}}], ["6c2a3d5e25116f7ff6deafd3dba1186d", {"code_string": "\"\"\"Module exports :class:`RietbrockEtAl2013MDHTT`.\"\"\"\nfrom __future__ import division\nimport numpy as np\nfrom scipy.constants import g\nfrom openquake.hazardlib.gsim.rietbrock_et_al_2013 import RietbrockEtAl2013MD\nfrom openquake.hazardlib.gsim.base import CoeffsTable\nfrom openquake.hazardlib.imt import PGA, SA\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import division <NEWLINE> import numpy as np <NEWLINE> from scipy . constants import g <NEWLINE> from openquake . hazardlib . gsim . rietbrock_et_al_2013 import RietbrockEtAl2013MD <NEWLINE> from openquake . hazardlib . gsim . base import CoeffsTable <NEWLINE> from openquake . hazardlib . imt import PGA , SA <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Module exports :class:`RietbrockEtAl2013MDHTT`.\"\"\""]}}], ["4dd981f37a07d880774fc8ec8d407c83", {"code_string": "def get(self, * args):\n    url = formatUrl(self.host, args)\n    logger.debug(\"Sending GET to %s\", url)\n    response = requests.get(url, verify = False,\n        headers = self.headers,\n        auth = (self.user, self.passwd))\n    checkResponse(response)\n    return response\n", "code_toks_joined": "def get ( self , * args ) : <NEWLINE> <INDENT> url = formatUrl ( self . host , args ) <NEWLINE> logger . debug ( <STRING> , url ) <NEWLINE> response = requests . get ( url , verify = False , <NEWLINE> <INDENT> headers = self . headers , <NEWLINE> auth = ( self . user , self . passwd ) ) <NEWLINE> <DEDENT> checkResponse ( response ) <NEWLINE> return response <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Sending GET to %s\""]}}], ["f6571850b83a39147f95f63f73d66d3a", {"code_string": "class ExternalNode(gpi.NodeAPI):\n    \"\"\"A node for sharing data, code, and the joy of GPI with others.\"\"\"\n    def initUI(self):\n        self.addWidget('WebBox', 'Facebook', val = 'https://www.facebook.com')\n        self.addWidget('WebBox', 'Twitter', val = 'https://twitter.com')\n    def execType(self):\n        return gpi.GPI_THREAD\n", "code_toks_joined": "class ExternalNode ( gpi . NodeAPI ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def initUI ( self ) : <NEWLINE> <INDENT> self . addWidget ( <STRING> , <STRING> , val = <STRING> ) <NEWLINE> self . addWidget ( <STRING> , <STRING> , val = <STRING> ) <NEWLINE> <DEDENT> def execType ( self ) : <NEWLINE> <INDENT> return gpi . GPI_THREAD <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"A node for sharing data, code, and the joy of GPI with others.\"\"\"", "'WebBox'", "'Facebook'", "'https://www.facebook.com'", "'WebBox'", "'Twitter'", "'https://twitter.com'"]}}], ["88c4c8e85aed7c513320659e0c122a4d", {"code_string": "def check_proc_acl(path):\n    if str(path) == \"/proc/foo\":\n        raise AclException(\"Path %s not allowed\" % path)\n", "code_toks_joined": "def check_proc_acl ( path ) : <NEWLINE> <INDENT> if str ( path ) == <STRING> : <NEWLINE> <INDENT> raise AclException ( <STRING> % path ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"/proc/foo\"", "\"Path %s not allowed\""]}}], ["59940e0c793de9fc661f7ffcf3a304bd", {"code_string": "import unittest\nfrom mobly import suite_runner\nfrom tests.lib import integration_test\nfrom tests.lib import integration2_test\n", "code_toks_joined": "import unittest <NEWLINE> from mobly import suite_runner <NEWLINE> from tests . lib import integration_test <NEWLINE> from tests . lib import integration2_test <NEWLINE>", "anonymize_dict": {}}], ["2f28ecf1c1c21aaaebebb5477a65adbd", {"code_string": "class ParentAdmin(MPTTModelAdmin, reversion.VersionAdmin):\n    fieldsets = [\n        ('', {'fields': ['title', 'parent', 'slug', 'data', 'content_type']}),\n        ]\n    list_display = ('title', 'parent', 'level')\n    list_filter = ['parent']\n    search_fields = ['title']\n    form = ParentForm\n    ordering = ['title']\n    prepopulated_fields = {'slug': ('title', ), }\n", "code_toks_joined": "class ParentAdmin ( MPTTModelAdmin , reversion . VersionAdmin ) : <NEWLINE> <INDENT> fieldsets = [ <NEWLINE> <INDENT> ( <STRING> , { <STRING> : [ <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ] } ) , <NEWLINE> ] <NEWLINE> <DEDENT> list_display = ( <STRING> , <STRING> , <STRING> ) <NEWLINE> list_filter = [ <STRING> ] <NEWLINE> search_fields = [ <STRING> ] <NEWLINE> form = ParentForm <NEWLINE> ordering = [ <STRING> ] <NEWLINE> prepopulated_fields = { <STRING> : ( <STRING> , ) , } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["''", "'fields'", "'title'", "'parent'", "'slug'", "'data'", "'content_type'", "'title'", "'parent'", "'level'", "'parent'", "'title'", "'title'", "'slug'", "'title'"]}}], ["471817d0e0c5cb6edeb7c5238125b95d", {"code_string": "def getDirList(p):\n    p = str(p)\n    if p == \"\":\n        return[]\n    a = os.listdir(p)\n    b = [x for x in a if os.path.isdir(p + x)]\n    return b\n", "code_toks_joined": "def getDirList ( p ) : <NEWLINE> <INDENT> p = str ( p ) <NEWLINE> if p == <STRING> : <NEWLINE> <INDENT> return [ ] <NEWLINE> <DEDENT> a = os . listdir ( p ) <NEWLINE> b = [ x for x in a if os . path . isdir ( p + x ) ] <NEWLINE> return b <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\""]}}], ["fd82b76aa49272be5b213d80e0496609", {"code_string": "class DiaryProduct(Product):\n    isbn = models.CharField(max_length = 255)\n    number_of_pages = models.IntegerField()\n", "code_toks_joined": "class DiaryProduct ( Product ) : <NEWLINE> <INDENT> isbn = models . CharField ( max_length = 255 ) <NEWLINE> number_of_pages = models . IntegerField ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["c06bbde352d19427c206e110ee7c40b8", {"code_string": "def _get_sendfile():\n    try:\n        from importlib import import_module\n    except ImportError:\n        from django.utils.importlib import import_module\n    from django.conf import settings\n    from django.core.exceptions import ImproperlyConfigured\n    backend = getattr(settings, 'SENDFILE_BACKEND', None)\n    if not backend:\n        raise ImproperlyConfigured('You must specify a value for SENDFILE_BACKEND')\n    module = import_module(backend)\n    return module.sendfile\n", "code_toks_joined": "def _get_sendfile ( ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> from importlib import import_module <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> from django . utils . importlib import import_module <NEWLINE> <DEDENT> from django . conf import settings <NEWLINE> from django . core . exceptions import ImproperlyConfigured <NEWLINE> backend = getattr ( settings , <STRING> , None ) <NEWLINE> if not backend : <NEWLINE> <INDENT> raise ImproperlyConfigured ( <STRING> ) <NEWLINE> <DEDENT> module = import_module ( backend ) <NEWLINE> return module . sendfile <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'SENDFILE_BACKEND'", "'You must specify a value for SENDFILE_BACKEND'"]}}], ["fe17779adfd51711da61a52708307d74", {"code_string": "import MySQLdb\nimport sys\nsys.path.append(\"..\")\nimport config\ndb = MySQLdb.connect(host = config.DB_HOST,\n    port = config.DB_PORT,\n    user = config.DB_USER,\n    passwd = config.DB_PASSWD,\n    db = config.DB_NAME,\n    charset = \"utf8\"\n    )\ndb.autocommit(True)\n", "code_toks_joined": "import MySQLdb <NEWLINE> import sys <NEWLINE> sys . path . append ( <STRING> ) <NEWLINE> import config <NEWLINE> db = MySQLdb . connect ( host = config . DB_HOST , <NEWLINE> <INDENT> port = config . DB_PORT , <NEWLINE> user = config . DB_USER , <NEWLINE> passwd = config . DB_PASSWD , <NEWLINE> db = config . DB_NAME , <NEWLINE> charset = <STRING> <NEWLINE> ) <NEWLINE> <DEDENT> db . autocommit ( True ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"..\"", "\"utf8\""]}}], ["83c0948d17f95f7c70a6bea30df22161", {"code_string": "def space_info(array):\n    \"\"\" Get space and capacity information about the FlashArray\"\"\"\n    return array.get(space = True)\n", "code_toks_joined": "def space_info ( array ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return array . get ( space = True ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Get space and capacity information about the FlashArray\"\"\""]}}], ["a3317ac99c6119176fed24b64964318c", {"code_string": "from..import excepttypes\nfrom..constraints import ObjectConstraint, maybeThrow\nfrom.base import BaseOp\n", "code_toks_joined": "from . . import excepttypes <NEWLINE> from . . constraints import ObjectConstraint , maybeThrow <NEWLINE> from . base import BaseOp <NEWLINE>", "anonymize_dict": {}}], ["28b60e31c9d9fec25b1d93d60af2423c", {"code_string": "class O_Item(scrapy.Item):\n    \"\"\" An item that will hold the content scraped by O_Spider \"\"\"\n    url = scrapy.Field()\n    title = scrapy.Field()\n    links = scrapy.Field()\n    timestamp = scrapy.Field()\n    page_size = scrapy.Field()\n    full_html = scrapy.Field()\n    full_text = scrapy.Field()\n    secure = scrapy.Field()\n    cid = scrapy.Field()\n    domain = scrapy.Field()\n    tab = scrapy.Field()\n", "code_toks_joined": "class O_Item ( scrapy . Item ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> url = scrapy . Field ( ) <NEWLINE> title = scrapy . Field ( ) <NEWLINE> links = scrapy . Field ( ) <NEWLINE> timestamp = scrapy . Field ( ) <NEWLINE> page_size = scrapy . Field ( ) <NEWLINE> full_html = scrapy . Field ( ) <NEWLINE> full_text = scrapy . Field ( ) <NEWLINE> secure = scrapy . Field ( ) <NEWLINE> cid = scrapy . Field ( ) <NEWLINE> domain = scrapy . Field ( ) <NEWLINE> tab = scrapy . Field ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" An item that will hold the content scraped by O_Spider \"\"\""]}}], ["bf840ef84a582c135970f20b7d869c7e", {"code_string": "\"\"\"Add a description of the plugin (to be presented to the user inside the wizard)\"\"\"\nimport supybot\nimport supybot.world as world\n__version__ = \"\"\n__author__ = 'reticulatingspline'\n__contributors__ = {}\n__url__ = 'https://github.com/reticulatingspline/WolframAlpha'\nfrom.import config\nfrom.import plugin\nfrom imp import reload\nreload(config)\nreload(plugin)\nif world.testing:\n    import test\nClass = plugin.Class\nconfigure = config.configure\n", "code_toks_joined": "<STRING> <NEWLINE> import supybot <NEWLINE> import supybot . world as world <NEWLINE> __version__ = <STRING> <NEWLINE> __author__ = <STRING> <NEWLINE> __contributors__ = { } <NEWLINE> __url__ = <STRING> <NEWLINE> from . import config <NEWLINE> from . import plugin <NEWLINE> from imp import reload <NEWLINE> reload ( config ) <NEWLINE> reload ( plugin ) <NEWLINE> if world . testing : <NEWLINE> <INDENT> import test <NEWLINE> <DEDENT> Class = plugin . Class <NEWLINE> configure = config . configure <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Add a description of the plugin (to be presented to the user inside the wizard)\"\"\"", "\"\"", "'reticulatingspline'", "'https://github.com/reticulatingspline/WolframAlpha'"]}}], ["08e8cc0af433d5b604fa14b6a5e035f8", {"code_string": "try:\n    from gtts import gTTS\n    import urllib\n    import speech_recognition as sr\n    from pydub import AudioSegment\nexcept ImportError as e:\n    print(str(e))\n", "code_toks_joined": "try : <NEWLINE> <INDENT> from gtts import gTTS <NEWLINE> import urllib <NEWLINE> import speech_recognition as sr <NEWLINE> from pydub import AudioSegment <NEWLINE> <DEDENT> except ImportError as e : <NEWLINE> <INDENT> print ( str ( e ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["a882a3b92902d5775175db851e3e44e5", {"code_string": "def build_arguments(self, parser):\n    parser.add_argument('-n', '--number', type = int, default = 18,\n        help = \"\"\"number of mfccs to calculate (default:\"\"\")\n    parser.add_argument('infile', type = argparse.FileType('rb'),\n        help = \"\"\"file containing spectrogram\"\"\")\n    parser.add_argument('outfile', type = argparse.FileType('wb'),\n        help = \"\"\"output track file\"\"\")\n", "code_toks_joined": "def build_arguments ( self , parser ) : <NEWLINE> <INDENT> parser . add_argument ( <STRING> , <STRING> , type = int , default = 18 , <NEWLINE> <INDENT> help = <STRING> ) <NEWLINE> <DEDENT> parser . add_argument ( <STRING> , type = argparse . FileType ( <STRING> ) , <NEWLINE> <INDENT> help = <STRING> ) <NEWLINE> <DEDENT> parser . add_argument ( <STRING> , type = argparse . FileType ( <STRING> ) , <NEWLINE> <INDENT> help = <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'-n'", "'--number'", "\"\"\"number of mfccs to calculate (default:\"\"\"", "'infile'", "'rb'", "\"\"\"file containing spectrogram\"\"\"", "'outfile'", "'wb'", "\"\"\"output track file\"\"\""]}}], ["424ede7220119b10439b10a2e4070aec", {"code_string": "def save(self):\n    if self.delay_save_count > 0:\n        return\n    if datetime.datetime.now() - self.load_time > datetime.timedelta(seconds = 5):\n        logger.warning(\"Warning, time elapsed between loading and saving project %s was %s\", self.name, str(datetime.datetime.now() - self.load_time))\n    self.datasource.save_project(self)\n", "code_toks_joined": "def save ( self ) : <NEWLINE> <INDENT> if self . delay_save_count > 0 : <NEWLINE> <INDENT> return <NEWLINE> <DEDENT> if datetime . datetime . now ( ) - self . load_time > datetime . timedelta ( seconds = 5 ) : <NEWLINE> <INDENT> logger . warning ( <STRING> , self . name , str ( datetime . datetime . now ( ) - self . load_time ) ) <NEWLINE> <DEDENT> self . datasource . save_project ( self ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Warning, time elapsed between loading and saving project %s was %s\""]}}], ["baf11afbc83f524fe2cd6640f4a17d1a", {"code_string": "def decreet_get_chapters(documentID, chaptertype = False):\n    url = decreeturl + str(documentID)\n    print(url)\n    r = requests.get(url)\n    print(r)\n    data = json.loads(r.content[1: len(r.content) - 2])\n    print(data)\n    h = []\n    for value in data:\n        chapter = Chapter(value['RecID'], value['TitelParsed'], value['ChildCount'], value['ArtikelCount'], chaptertype)\n        h.append(chapter)\n    return h\n", "code_toks_joined": "def decreet_get_chapters ( documentID , chaptertype = False ) : <NEWLINE> <INDENT> url = decreeturl + str ( documentID ) <NEWLINE> print ( url ) <NEWLINE> r = requests . get ( url ) <NEWLINE> print ( r ) <NEWLINE> data = json . loads ( r . content [ 1 : len ( r . content ) - 2 ] ) <NEWLINE> print ( data ) <NEWLINE> h = [ ] <NEWLINE> for value in data : <NEWLINE> <INDENT> chapter = Chapter ( value [ <STRING> ] , value [ <STRING> ] , value [ <STRING> ] , value [ <STRING> ] , chaptertype ) <NEWLINE> h . append ( chapter ) <NEWLINE> <DEDENT> return h <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'RecID'", "'TitelParsed'", "'ChildCount'", "'ArtikelCount'"]}}], ["8017e9ee5606367961353747034c3b2a", {"code_string": "def expand_model_fields(model, field_names):\n    model_class = type(model)\n    try:\n        trans_field_mapping = translator.get_options_for_model(model_class).fields\n    except modeltranslation.translator.NotRegistered:\n        return field_names\n    def expand_field(field_name):\n        translated_versions = trans_field_mapping.get(field_name)\n        if translated_versions is not None:\n            return(f.name for f in translated_versions)\n        else:\n            return[field_name]\n    return[expanded\n        for unexpanded in field_names\n        for expanded in expand_field(unexpanded)]\n", "code_toks_joined": "def expand_model_fields ( model , field_names ) : <NEWLINE> <INDENT> model_class = type ( model ) <NEWLINE> try : <NEWLINE> <INDENT> trans_field_mapping = translator . get_options_for_model ( model_class ) . fields <NEWLINE> <DEDENT> except modeltranslation . translator . NotRegistered : <NEWLINE> <INDENT> return field_names <NEWLINE> <DEDENT> def expand_field ( field_name ) : <NEWLINE> <INDENT> translated_versions = trans_field_mapping . get ( field_name ) <NEWLINE> if translated_versions is not None : <NEWLINE> <INDENT> return ( f . name for f in translated_versions ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return [ field_name ] <NEWLINE> <DEDENT> <DEDENT> return [ expanded <NEWLINE> <INDENT> for unexpanded in field_names <NEWLINE> for expanded in expand_field ( unexpanded ) ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["850775c89ecc9c689fe420da39b5ae1e", {"code_string": "from distutils.core import setup\nsetup(name = \"pyDes\",\n    version = \"2.0.1\",\n    description = \"Pure python implementation of DES and TRIPLE DES encryption algorithm\",\n    author = \"Todd Whiteman\",\n    author_email = \"twhitema@gmail.com\",\n    license = 'MIT',\n    url = \"http://twhiteman.netfirms.com/des.html\",\n    classifiers = [\n        'Development Status :: 6 - Mature'\n        'License :: OSI Approved :: MIT License',\n        'Programming Language :: Python',\n        'Programming Language :: Python :: 2',\n        'Programming Language :: Python :: 3',\n        'Topic :: Security :: Cryptography',\n    ],\n    platforms = [\"All\"],\n    keywords = [\"DES\", \"TRIPLE-DES\", \"ENCRYPTION\", \"ALGORITHM\", \"SECURITY\"],\n    py_modules = [\"pyDes\"]\n)\n", "code_toks_joined": "from distutils . core import setup <NEWLINE> setup ( name = <STRING> , <NEWLINE> <INDENT> version = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> license = <STRING> , <NEWLINE> url = <STRING> , <NEWLINE> classifiers = [ <NEWLINE> <INDENT> <STRING> <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <DEDENT> ] , <NEWLINE> platforms = [ <STRING> ] , <NEWLINE> keywords = [ <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ] , <NEWLINE> py_modules = [ <STRING> ] <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"pyDes\"", "\"2.0.1\"", "\"Pure python implementation of DES and TRIPLE DES encryption algorithm\"", "\"Todd Whiteman\"", "\"twhitema@gmail.com\"", "'MIT'", "\"http://twhiteman.netfirms.com/des.html\"", "'Development Status :: 6 - Mature'", "'License :: OSI Approved :: MIT License'", "'Programming Language :: Python'", "'Programming Language :: Python :: 2'", "'Programming Language :: Python :: 3'", "'Topic :: Security :: Cryptography'", "\"All\"", "\"DES\"", "\"TRIPLE-DES\"", "\"ENCRYPTION\"", "\"ALGORITHM\"", "\"SECURITY\"", "\"pyDes\""]}}], ["66d43c7232978a43fa2b67c43be2c81a", {"code_string": "from __future__ import print_function\nfrom json import dumps\nfrom getpass import getuser\nfrom.base.base_drmaa import BaseDrmaaManager\nfrom.util.sudo import sudo_popen\nfrom..managers import status\nfrom galaxy.tools.deps.commands import which\nfrom logging import getLogger\nlog = getLogger(__name__)\nDEFAULT_CHOWN_WORKING_DIRECTORY_SCRIPT = \"scripts/chown_working_directory.bash\"\nDEFAULT_DRMAA_KILL_SCRIPT = \"scripts/drmaa_kill.bash\"\nDEFAULT_DRMAA_LAUNCH_SCRIPT = \"scripts/drmaa_launch.bash\"\n", "code_toks_joined": "from __future__ import print_function <NEWLINE> from json import dumps <NEWLINE> from getpass import getuser <NEWLINE> from . base . base_drmaa import BaseDrmaaManager <NEWLINE> from . util . sudo import sudo_popen <NEWLINE> from . . managers import status <NEWLINE> from galaxy . tools . deps . commands import which <NEWLINE> from logging import getLogger <NEWLINE> log = getLogger ( __name__ ) <NEWLINE> DEFAULT_CHOWN_WORKING_DIRECTORY_SCRIPT = <STRING> <NEWLINE> DEFAULT_DRMAA_KILL_SCRIPT = <STRING> <NEWLINE> DEFAULT_DRMAA_LAUNCH_SCRIPT = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"scripts/chown_working_directory.bash\"", "\"scripts/drmaa_kill.bash\"", "\"scripts/drmaa_launch.bash\""]}}], ["30418e2f988d9859053b070f655c47cc", {"code_string": "import os\nimport sys\nparent = os.path.join(os.path.dirname(__file__), '..')\nsys.path.insert(0, parent)\nif __name__ == \"__main__\":\n    os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"settings\")\n    from django.core.management import execute_from_command_line\n    execute_from_command_line(sys.argv)\n", "code_toks_joined": "import os <NEWLINE> import sys <NEWLINE> parent = os . path . join ( os . path . dirname ( __file__ ) , <STRING> ) <NEWLINE> sys . path . insert ( 0 , parent ) <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> os . environ . setdefault ( <STRING> , <STRING> ) <NEWLINE> from django . core . management import execute_from_command_line <NEWLINE> execute_from_command_line ( sys . argv ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'..'", "\"__main__\"", "\"DJANGO_SETTINGS_MODULE\"", "\"settings\""]}}], ["114fab7050c6acf8387f71d9df56b0a2", {"code_string": "from django.conf.urls import url\nfrom orders.views import CheckoutFormView, ConfirmationView\nurlpatterns = [\n    url(r'^$', CheckoutFormView.as_view(), name = 'main'),\n    url(r'^complete/', ConfirmationView.as_view(), name = 'confirmation'),\n]\n", "code_toks_joined": "from django . conf . urls import url <NEWLINE> from orders . views import CheckoutFormView , ConfirmationView <NEWLINE> urlpatterns = [ <NEWLINE> <INDENT> url ( <STRING> , CheckoutFormView . as_view ( ) , name = <STRING> ) , <NEWLINE> url ( <STRING> , ConfirmationView . as_view ( ) , name = <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["r'^$'", "'main'", "r'^complete/'", "'confirmation'"]}}], ["1210c87e70930fcf02079175e655679d", {"code_string": "def handle_testcase(params):\n    data = {}\n    for param in params:\n        parts = param.split('=')\n        if len(parts) == 2:\n            key, value = parts\n            key = key.lower()\n            data[key] = value\n        else:\n            raise JobError(\n                \"Ignoring malformed parameter for signal: \\\"%s\\\". \" % param)\n    return data\n", "code_toks_joined": "def handle_testcase ( params ) : <NEWLINE> <INDENT> data = { } <NEWLINE> for param in params : <NEWLINE> <INDENT> parts = param . split ( <STRING> ) <NEWLINE> if len ( parts ) == 2 : <NEWLINE> <INDENT> key , value = parts <NEWLINE> key = key . lower ( ) <NEWLINE> data [ key ] = value <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> raise JobError ( <NEWLINE> <INDENT> <STRING> % param ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> return data <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'='", "\"Ignoring malformed parameter for signal: \\\"%s\\\". \""]}}], ["c2c90cebe61dd8f5a5c51a0d378a5202", {"code_string": "\"\"\"sphinx.search.fr\"\"\"\nfrom sphinx.search import SearchLanguage, parse_stop_word\nimport snowballstemmer\nfrench_stopwords = parse_stop_word(u'''| source: http://snowball.tartarus.org/algorithms/french/stop.txt''')\njs_stemmer = u\"\"\"var JSX={};(function(l){function m(b,e){var a=function(){};a.prototype=e.prototype;var c=new a;for(var d in b){b[d].prototype=c}}function P(c,b){for(var a in b.prototype)if(b.prototype.hasOwnProperty(a))c.prototype[a]=b.prototype[a]}function g(a,b,d){function c(a,b,c){delete a[b];a[b]=c;return c}Object.defineProperty(a,b,{get:function(){return c(a,b,d())},set:function(d){c(a,b,d)},enumerable:true,configurable:true})}function O(a,b,c){return a[b]=a[b]/c|0}var u=parseInt;var v=parseFloat;function N(a){return a!==a}var x=isFinite;var y=encodeURIComponent;var z=decodeURIComponent;var A=encodeURI;var B=decodeURI;var C=Object.prototype.toString;var D=Object.prototype.hasOwnProperty;function k(){}l.require=function(b){var a=q[b];return a!==undefined?a:null};l.profilerIsRunning=function(){return k.getResults!=null};l.getProfileResults=function(){return(k.getResults||function(){return{}})()};l.postProfileResults=function(a,b){if(k.postResults==null)throw new Error('profiler has not been turned on');return k.postResults(a,b)};l.resetProfileResults=function(){if(k.resetResults==null)throw new Error('profiler has not been turned on');return k.resetResults()};l.DEBUG=false;function G(){};m([G],Error);function a(a,b,c){this.F=a.length;this.K=a;this.L=b;this.I=c;this.H=null;this.P=null};m([a],Object);function p(){};m([p],Object);function i(){var a;var b;var c;this.G={};a=this.E='';b=this._=0;c=this.A=a.length;this.B=0;this.D=b;this.C=c};m([i],p);function s(a,b){a.E=b.E;a._=b._;a.A=b.A;a.B=b.B;a.D=b.D;a.C=b.C};function e(b,d,c,e){var a;if(b._>=b.A){return false}a=b.E.charCodeAt(b._);if(a>e||a<c){return false}a-=c;if((d[a>>>3]&1<<(a&7))===0){return false}b._++;return true};function r(b,d,c,e){var a;if(b._<=b.B){return false}a=b.E.charCodeAt(b._-1);if(a>e||a<c){return false}a-=c;if((d[a>>>3]&1<<(a&7))===0){return false}b._--;return true};function o(a,d,c,e){var b;if(a._>=a.A){return false}b=a.E.charCodeAt(a._);if(b>e||b<c){a._++;return true}b-=c;if((d[b>>>3]&1<<(b&7))===0){a._++;return true}return false};function j(a,d,c,e){var b;if(a._<=a.B){return false}b=a.E.charCodeAt(a._-1);if(b>e||b<c){a._--;return true}b-=c;if((d[b>>>3]&1<<(b&7))===0){a._--;return true}return false};function h(a,b,d){var c;if(a.A-a._<b){return false}if(a.E.slice(c=a._,c+b)!==d){return false}a._+=b;return true};function d(a,b,d){var c;if(a._-a.B<b){return false}if(a.E.slice((c=a._)-b,c)!==d){return false}a._-=b;return true};function n(f,m,p){var b;var d;var e;var n;var g;var k;var l;var i;var h;var c;var a;var j;var o;b=0;d=p;e=f._;n=f.A;g=0;k=0;l=false;while(true){i=b+(d-b>>>1);h=0;c=g<k?g:k;a=m[i];for(j=c;j<a.F;j++){if(e+c===n){h=-1;break}h=f.E.charCodeAt(e+c)-a.K.charCodeAt(j);if(h!==0){break}c++}if(h<0){d=i;k=c}else{b=i;g=c}if(d-b<=1){if(b>0){break}if(d===b){break}if(l){break}l=true}}while(true){a=m[b];if(g>=a.F){f._=e+a.F|0;if(a.H==null){return a.I}o=a.H(a.P);f._=e+a.F|0;if(o){return a.I}}b=a.L;if(b<0){return 0}}return-1};function f(d,m,p){var b;var g;var e;var n;var f;var k;var l;var i;var h;var c;var a;var j;var o;b=0;g=p;e=d._;n=d.B;f=0;k=0;l=false;while(true){i=b+(g-b>>1);h=0;c=f<k?f:k;a=m[i];for(j=a.F-1-c;j>=0;j--){if(e-c===n){h=-1;break}h=d.E.charCodeAt(e-1-c)-a.K.charCodeAt(j);if(h!==0){break}c++}if(h<0){g=i;k=c}else{b=i;f=c}if(g-b<=1){if(b>0){break}if(g===b){break}if(l){break}l=true}}while(true){a=m[b];if(f>=a.F){d._=e-a.F|0;if(a.H==null){return a.I}o=a.H(d);d._=e-a.F|0;if(o){return a.I}}b=a.L;if(b<0){return 0}}return-1};function E(a,b,d,e){var c;c=e.length-(d-b);a.E=a.E.slice(0,b)+e+a.E.slice(d);a.A+=c|0;if(a._>=d){a._+=c|0}else if(a._>b){a._=b}return c|0};function c(a,f){var b;var c;var d;var e;b=false;if((c=a.D)<0||c>(d=a.C)||d>(e=a.A)||e>a.E.length?false:true){E(a,a.D,a.C,f);b=true}return b};i.prototype.J=function(){return false};i.prototype.c=function(b){var a;var c;var d;var e;a=this.G['.'+b];if(a==null){c=this.E=b;d=this._=0;e=this.A=c.length;this.B=0;this.D=d;this.C=e;this.J();a=this.E;this.G['.'+b]=a}return a};i.prototype.stemWord=i.prototype.c;i.prototype.d=function(e){var d;var b;var c;var a;var f;var g;var h;d=[];for(b=0;b<e.length;b++){c=e[b];a=this.G['.'+c];if(a==null){f=this.E=c;g=this._=0;h=this.A=f.length;this.B=0;this.D=g;this.C=h;this.J();a=this.E;this.G['.'+c]=a}d.push(a)}return d};i.prototype.stemWords=i.prototype.d;function b(){i.call(this);this.I_p2=0;this.I_p1=0;this.I_pV=0};m([b],i);b.prototype.M=function(a){this.I_p2=a.I_p2;this.I_p1=a.I_p1;this.I_pV=a.I_pV;s(this,a)};b.prototype.copy_from=b.prototype.M;b.prototype.W=function(){var p;var j;var f;var g;var i;var a;var d;var k;var l;var m;var n;var o;var q;a:while(true){p=this._;i=true;g:while(i===true){i=false;h:while(true){j=this._;a=true;b:while(a===true){a=false;d=true;c:while(d===true){d=false;f=this._;k=true;d:while(k===true){k=false;if(!e(this,b.g_v,97,251)){break d}this.D=this._;l=true;e:while(l===true){l=false;g=this._;m=true;f:while(m===true){m=false;if(!h(this,1,'u')){break f}this.C=this._;if(!e(this,b.g_v,97,251)){break f}if(!c(this,'U')){return false}break e}this._=g;n=true;f:while(n===true){n=false;if(!h(this,1,'i')){break f}this.C=this._;if(!e(this,b.g_v,97,251)){break f}if(!c(this,'I')){return false}break e}this._=g;if(!h(this,1,'y')){break d}this.C=this._;if(!c(this,'Y')){return false}}break c}this._=f;o=true;d:while(o===true){o=false;this.D=this._;if(!h(this,1,'y')){break d}this.C=this._;if(!e(this,b.g_v,97,251)){break d}if(!c(this,'Y')){return false}break c}this._=f;if(!h(this,1,'q')){break b}this.D=this._;if(!h(this,1,'u')){break b}this.C=this._;if(!c(this,'U')){return false}}this._=j;break h}q=this._=j;if(q>=this.A){break g}this._++}continue a}this._=p;break a}return true};b.prototype.r_prelude=b.prototype.W;function H(a){var q;var k;var f;var g;var i;var j;var d;var l;var m;var n;var o;var p;var r;a:while(true){q=a._;i=true;g:while(i===true){i=false;h:while(true){k=a._;j=true;b:while(j===true){j=false;d=true;c:while(d===true){d=false;f=a._;l=true;d:while(l===true){l=false;if(!e(a,b.g_v,97,251)){break d}a.D=a._;m=true;e:while(m===true){m=false;g=a._;n=true;f:while(n===true){n=false;if(!h(a,1,'u')){break f}a.C=a._;if(!e(a,b.g_v,97,251)){break f}if(!c(a,'U')){return false}break e}a._=g;o=true;f:while(o===true){o=false;if(!h(a,1,'i')){break f}a.C=a._;if(!e(a,b.g_v,97,251)){break f}if(!c(a,'I')){return false}break e}a._=g;if(!h(a,1,'y')){break d}a.C=a._;if(!c(a,'Y')){return false}}break c}a._=f;p=true;d:while(p===true){p=false;a.D=a._;if(!h(a,1,'y')){break d}a.C=a._;if(!e(a,b.g_v,97,251)){break d}if(!c(a,'Y')){return false}break c}a._=f;if(!h(a,1,'q')){break b}a.D=a._;if(!h(a,1,'u')){break b}a.C=a._;if(!c(a,'U')){return false}}a._=k;break h}r=a._=k;if(r>=a.A){break g}a._++}continue a}a._=q;break a}return true};b.prototype.U=function(){var t;var i;var r;var d;var f;var g;var h;var c;var a;var j;var k;var l;var m;var s;var p;var q;this.I_pV=p=this.A;this.I_p1=p;this.I_p2=p;t=this._;d=true;b:while(d===true){d=false;f=true;c:while(f===true){f=false;i=this._;g=true;a:while(g===true){g=false;if(!e(this,b.g_v,97,251)){break a}if(!e(this,b.g_v,97,251)){break a}if(this._>=this.A){break a}this._++;break c}this._=i;h=true;a:while(h===true){h=false;if(n(this,b.a_0,3)===0){break a}break c}s=this._=i;if(s>=this.A){break b}this._++;a:while(true){c=true;d:while(c===true){c=false;if(!e(this,b.g_v,97,251)){break d}break a}if(this._>=this.A){break b}this._++}}this.I_pV=this._}q=this._=t;r=q;a=true;a:while(a===true){a=false;c:while(true){j=true;b:while(j===true){j=false;if(!e(this,b.g_v,97,251)){break b}break c}if(this._>=this.A){break a}this._++}b:while(true){k=true;c:while(k===true){k=false;if(!o(this,b.g_v,97,251)){break c}break b}if(this._>=this.A){break a}this._++}this.I_p1=this._;b:while(true){l=true;c:while(l===true){l=false;if(!e(this,b.g_v,97,251)){break c}break b}if(this._>=this.A){break a}this._++}c:while(true){m=true;b:while(m===true){m=false;if(!o(this,b.g_v,97,251)){break b}break c}if(this._>=this.A){break a}this._++}this.I_p2=this._}this._=r;return true};b.prototype.r_mark_regions=b.prototype.U;function I(a){var s;var i;var r;var d;var f;var g;var h;var c;var j;var k;var l;var m;var p;var t;var q;var u;a.I_pV=q=a.A;a.I_p1=q;a.I_p2=q;s=a._;d=true;b:while(d===true){d=false;f=true;c:while(f===true){f=false;i=a._;g=true;a:while(g===true){g=false;if(!e(a,b.g_v,97,251)){break a}if(!e(a,b.g_v,97,251)){break a}if(a._>=a.A){break a}a._++;break c}a._=i;h=true;a:while(h===true){h=false;if(n(a,b.a_0,3)===0){break a}break c}t=a._=i;if(t>=a.A){break b}a._++;a:while(true){c=true;d:while(c===true){c=false;if(!e(a,b.g_v,97,251)){break d}break a}if(a._>=a.A){break b}a._++}}a.I_pV=a._}u=a._=s;r=u;j=true;a:while(j===true){j=false;c:while(true){k=true;b:while(k===true){k=false;if(!e(a,b.g_v,97,251)){break b}break c}if(a._>=a.A){break a}a._++}b:while(true){l=true;c:while(l===true){l=false;if(!o(a,b.g_v,97,251)){break c}break b}if(a._>=a.A){break a}a._++}a.I_p1=a._;b:while(true){m=true;c:while(m===true){m=false;if(!e(a,b.g_v,97,251)){break c}break b}if(a._>=a.A){break a}a._++}c:while(true){p=true;b:while(p===true){p=false;if(!o(a,b.g_v,97,251)){break b}break c}if(a._>=a.A){break a}a._++}a.I_p2=a._}a._=r;return true};b.prototype.V=function(){var a;var e;var d;b:while(true){e=this._;d=true;a:while(d===true){d=false;this.D=this._;a=n(this,b.a_1,4);if(a===0){break a}this.C=this._;switch(a){case 0:break a;case 1:if(!c(this,'i')){return false}break;case 2:if(!c(this,'u')){return false}break;case 3:if(!c(this,'y')){return false}break;case 4:if(this._>=this.A){break a}this._++;break}continue b}this._=e;break b}return true};b.prototype.r_postlude=b.prototype.V;function J(a){var d;var f;var e;b:while(true){f=a._;e=true;a:while(e===true){e=false;a.D=a._;d=n(a,b.a_1,4);if(d===0){break a}a.C=a._;switch(d){case 0:break a;case 1:if(!c(a,'i')){return false}break;case 2:if(!c(a,'u')){return false}break;case 3:if(!c(a,'y')){return false}break;case 4:if(a._>=a.A){break a}a._++;break}continue b}a._=f;break b}return true};b.prototype.S=function(){return!(this.I_pV<=this._)?false:true};b.prototype.r_RV=b.prototype.S;b.prototype.Q=function(){return!(this.I_p1<=this._)?false:true};b.prototype.r_R1=b.prototype.Q;b.prototype.R=function(){return!(this.I_p2<=this._)?false:true};b.prototype.r_R2=b.prototype.R;b.prototype.Y=function(){var a;var E;var H;var e;var D;var g;var F;var G;var h;var I;var A;var B;var p;var k;var l;var m;var n;var o;var i;var q;var s;var t;var u;var v;var w;var x;var y;var z;var J;var K;var L;var C;this.C=this._;a=f(this,b.a_4,43);if(a===0){return false}this.D=this._;switch(a){case 0:return false;case 1:if(!(!(this.I_p2<=this._)?false:true)){return false}if(!c(this,'')){return false}break;case 2:if(!(!(this.I_p2<=this._)?false:true)){return false}if(!c(this,'')){return false}E=this.A-this._;p=true;c:while(p===true){p=false;this.C=this._;if(!d(this,2,'ic')){this._=this.A-E;break c}this.D=this._;k=true;b:while(k===true){k=false;H=this.A-this._;l=true;a:while(l===true){l=false;if(!(!(this.I_p2<=this._)?false:true)){break a}if(!c(this,'')){return false}break b}this._=this.A-H;if(!c(this,'iqU')){return false}}}break;case 3:if(!(!(this.I_p2<=this._)?false:true)){return false}if(!c(this,'log')){return false}break;case 4:if(!(!(this.I_p2<=this._)?false:true)){return false}if(!c(this,'u')){return false}break;case 5:if(!(!(this.I_p2<=this._)?false:true)){return false}if(!c(this,'ent')){return false}break;case 6:if(!(!(this.I_pV<=this._)?false:true)){return false}if(!c(this,'')){return false}e=this.A-this._;m=true;a:while(m===true){m=false;this.C=this._;a=f(this,b.a_2,6);if(a===0){this._=this.A-e;break a}this.D=this._;switch(a){case 0:this._=this.A-e;break a;case 1:if(!(!(this.I_p2<=this._)?false:true)){this._=this.A-e;break a}if(!c(this,'')){return false}this.C=this._;if(!d(this,2,'at')){this._=this.A-e;break a}this.D=J=this._;if(!(!(this.I_p2<=J)?false:true)){this._=this.A-e;break a}if(!c(this,'')){return false}break;case 2:n=true;b:while(n===true){n=false;D=this.A-this._;o=true;c:while(o===true){o=false;if(!(!(this.I_p2<=this._)?false:true)){break c}if(!c(this,'')){return false}break b}K=this._=this.A-D;if(!(!(this.I_p1<=K)?false:true)){this._=this.A-e;break a}if(!c(this,'eux')){return false}}break;case 3:if(!(!(this.I_p2<=this._)?false:true)){this._=this.A-e;break a}if(!c(this,'')){return false}break;case 4:if(!(!(this.I_pV<=this._)?false:true)){this._=this.A-e;break a}if(!c(this,'i')){return false}break}}break;case 7:if(!(!(this.I_p2<=this._)?false:true)){return false}if(!c(this,'')){return false}g=this.A-this._;i=true;a:while(i===true){i=false;this.C=this._;a=f(this,b.a_3,3);if(a===0){this._=this.A-g;break a}this.D=this._;switch(a){case 0:this._=this.A-g;break a;case 1:q=true;c:while(q===true){q=false;F=this.A-this._;s=true;b:while(s===true){s=false;if(!(!(this.I_p2<=this._)?false:true)){break b}if(!c(this,'')){return false}break c}this._=this.A-F;if(!c(this,'abl')){return false}}break;case 2:t=true;b:while(t===true){t=false;G=this.A-this._;u=true;c:while(u===true){u=false;if(!(!(this.I_p2<=this._)?false:true)){break c}if(!c(this,'')){return false}break b}this._=this.A-G;if(!c(this,'iqU')){return false}}break;case 3:if(!(!(this.I_p2<=this._)?false:true)){this._=this.A-g;break a}if(!c(this,'')){return false}break}}break;case 8:if(!(!(this.I_p2<=this._)?false:true)){return false}if(!c(this,'')){return false}h=this.A-this._;v=true;a:while(v===true){v=false;this.C=this._;if(!d(this,2,'at')){this._=this.A-h;break a}this.D=L=this._;if(!(!(this.I_p2<=L)?false:true)){this._=this.A-h;break a}if(!c(this,'')){return false}this.C=this._;if(!d(this,2,'ic')){this._=this.A-h;break a}this.D=this._;w=true;b:while(w===true){w=false;I=this.A-this._;x=true;c:while(x===true){x=false;if(!(!(this.I_p2<=this._)?false:true)){break c}if(!c(this,'')){return false}break b}this._=this.A-I;if(!c(this,'iqU')){return false}}}break;case 9:if(!c(this,'eau')){return false}break;case 10:if(!(!(this.I_p1<=this._)?false:true)){return false}if(!c(this,'al')){return false}break;case 11:y=true;a:while(y===true){y=false;A=this.A-this._;z=true;b:while(z===true){z=false;if(!(!(this.I_p2<=this._)?false:true)){break b}if(!c(this,'')){return false}break a}C=this._=this.A-A;if(!(!(this.I_p1<=C)?false:true)){return false}if(!c(this,'eux')){return false}}break;case 12:if(!(!(this.I_p1<=this._)?false:true)){return false}if(!j(this,b.g_v,97,251)){return false}if(!c(this,'')){return false}break;case 13:if(!(!(this.I_pV<=this._)?false:true)){return false}if(!c(this,'ant')){return false}return false;case 14:if(!(!(this.I_pV<=this._)?false:true)){return false}if(!c(this,'ent')){return false}return false;case 15:B=this.A-this._;if(!r(this,b.g_v,97,251)){return false}if(!(!(this.I_pV<=this._)?false:true)){return false}this._=this.A-B;if(!c(this,'')){return false}return false}return true};b.prototype.r_standard_suffix=b.prototype.Y;function K(a){var g;var F;var I;var e;var E;var h;var G;var H;var i;var J;var B;var C;var p;var l;var m;var n;var o;var k;var q;var s;var t;var u;var v;var w;var x;var y;var z;var A;var K;var L;var M;var D;a.C=a._;g=f(a,b.a_4,43);if(g===0){return false}a.D=a._;switch(g){case 0:return false;case 1:if(!(!(a.I_p2<=a._)?false:true)){return false}if(!c(a,'')){return false}break;case 2:if(!(!(a.I_p2<=a._)?false:true)){return false}if(!c(a,'')){return false}F=a.A-a._;p=true;c:while(p===true){p=false;a.C=a._;if(!d(a,2,'ic')){a._=a.A-F;break c}a.D=a._;l=true;b:while(l===true){l=false;I=a.A-a._;m=true;a:while(m===true){m=false;if(!(!(a.I_p2<=a._)?false:true)){break a}if(!c(a,'')){return false}break b}a._=a.A-I;if(!c(a,'iqU')){return false}}}break;case 3:if(!(!(a.I_p2<=a._)?false:true)){return false}if(!c(a,'log')){return false}break;case 4:if(!(!(a.I_p2<=a._)?false:true)){return false}if(!c(a,'u')){return false}break;case 5:if(!(!(a.I_p2<=a._)?false:true)){return false}if(!c(a,'ent')){return false}break;case 6:if(!(!(a.I_pV<=a._)?false:true)){return false}if(!c(a,'')){return false}e=a.A-a._;n=true;a:while(n===true){n=false;a.C=a._;g=f(a,b.a_2,6);if(g===0){a._=a.A-e;break a}a.D=a._;switch(g){case 0:a._=a.A-e;break a;case 1:if(!(!(a.I_p2<=a._)?false:true)){a._=a.A-e;break a}if(!c(a,'')){return false}a.C=a._;if(!d(a,2,'at')){a._=a.A-e;break a}a.D=K=a._;if(!(!(a.I_p2<=K)?false:true)){a._=a.A-e;break a}if(!c(a,'')){return false}break;case 2:o=true;b:while(o===true){o=false;E=a.A-a._;k=true;c:while(k===true){k=false;if(!(!(a.I_p2<=a._)?false:true)){break c}if(!c(a,'')){return false}break b}L=a._=a.A-E;if(!(!(a.I_p1<=L)?false:true)){a._=a.A-e;break a}if(!c(a,'eux')){return false}}break;case 3:if(!(!(a.I_p2<=a._)?false:true)){a._=a.A-e;break a}if(!c(a,'')){return false}break;case 4:if(!(!(a.I_pV<=a._)?false:true)){a._=a.A-e;break a}if(!c(a,'i')){return false}break}}break;case 7:if(!(!(a.I_p2<=a._)?false:true)){return false}if(!c(a,'')){return false}h=a.A-a._;q=true;a:while(q===true){q=false;a.C=a._;g=f(a,b.a_3,3);if(g===0){a._=a.A-h;break a}a.D=a._;switch(g){case 0:a._=a.A-h;break a;case 1:s=true;c:while(s===true){s=false;G=a.A-a._;t=true;b:while(t===true){t=false;if(!(!(a.I_p2<=a._)?false:true)){break b}if(!c(a,'')){return false}break c}a._=a.A-G;if(!c(a,'abl')){return false}}break;case 2:u=true;b:while(u===true){u=false;H=a.A-a._;v=true;c:while(v===true){v=false;if(!(!(a.I_p2<=a._)?false:true)){break c}if(!c(a,'')){return false}break b}a._=a.A-H;if(!c(a,'iqU')){return false}}break;case 3:if(!(!(a.I_p2<=a._)?false:true)){a._=a.A-h;break a}if(!c(a,'')){return false}break}}break;case 8:if(!(!(a.I_p2<=a._)?false:true)){return false}if(!c(a,'')){return false}i=a.A-a._;w=true;a:while(w===true){w=false;a.C=a._;if(!d(a,2,'at')){a._=a.A-i;break a}a.D=M=a._;if(!(!(a.I_p2<=M)?false:true)){a._=a.A-i;break a}if(!c(a,'')){return false}a.C=a._;if(!d(a,2,'ic')){a._=a.A-i;break a}a.D=a._;x=true;b:while(x===true){x=false;J=a.A-a._;y=true;c:while(y===true){y=false;if(!(!(a.I_p2<=a._)?false:true)){break c}if(!c(a,'')){return false}break b}a._=a.A-J;if(!c(a,'iqU')){return false}}}break;case 9:if(!c(a,'eau')){return false}break;case 10:if(!(!(a.I_p1<=a._)?false:true)){return false}if(!c(a,'al')){return false}break;case 11:z=true;a:while(z===true){z=false;B=a.A-a._;A=true;b:while(A===true){A=false;if(!(!(a.I_p2<=a._)?false:true)){break b}if(!c(a,'')){return false}break a}D=a._=a.A-B;if(!(!(a.I_p1<=D)?false:true)){return false}if(!c(a,'eux')){return false}}break;case 12:if(!(!(a.I_p1<=a._)?false:true)){return false}if(!j(a,b.g_v,97,251)){return false}if(!c(a,'')){return false}break;case 13:if(!(!(a.I_pV<=a._)?false:true)){return false}if(!c(a,'ant')){return false}return false;case 14:if(!(!(a.I_pV<=a._)?false:true)){return false}if(!c(a,'ent')){return false}return false;case 15:C=a.A-a._;if(!r(a,b.g_v,97,251)){return false}if(!(!(a.I_pV<=a._)?false:true)){return false}a._=a.A-C;if(!c(a,'')){return false}return false}return true};b.prototype.T=function(){var d;var e;var a;var g;var h;var i;e=this.A-(g=this._);if(g<this.I_pV){return false}h=this._=this.I_pV;a=this.B;this.B=h;i=this._=this.A-e;this.C=i;d=f(this,b.a_5,35);if(d===0){this.B=a;return false}this.D=this._;switch(d){case 0:this.B=a;return false;case 1:if(!j(this,b.g_v,97,251)){this.B=a;return false}if(!c(this,'')){return false}break}this.B=a;return true};b.prototype.r_i_verb_suffix=b.prototype.T;function L(a){var e;var g;var d;var h;var i;var k;g=a.A-(h=a._);if(h<a.I_pV){return false}i=a._=a.I_pV;d=a.B;a.B=i;k=a._=a.A-g;a.C=k;e=f(a,b.a_5,35);if(e===0){a.B=d;return false}a.D=a._;switch(e){case 0:a.B=d;return false;case 1:if(!j(a,b.g_v,97,251)){a.B=d;return false}if(!c(a,'')){return false}break}a.B=d;return true};b.prototype.b=function(){var e;var h;var a;var i;var g;var j;var k;var l;h=this.A-(j=this._);if(j<this.I_pV){return false}k=this._=this.I_pV;a=this.B;this.B=k;l=this._=this.A-h;this.C=l;e=f(this,b.a_6,38);if(e===0){this.B=a;return false}this.D=this._;switch(e){case 0:this.B=a;return false;case 1:if(!(!(this.I_p2<=this._)?false:true)){this.B=a;return false}if(!c(this,'')){return false}break;case 2:if(!c(this,'')){return false}break;case 3:if(!c(this,'')){return false}i=this.A-this._;g=true;a:while(g===true){g=false;this.C=this._;if(!d(this,1,'e')){this._=this.A-i;break a}this.D=this._;if(!c(this,'')){return false}}break}this.B=a;return true};b.prototype.r_verb_suffix=b.prototype.b;function M(a){var g;var i;var e;var j;var h;var k;var l;var m;i=a.A-(k=a._);if(k<a.I_pV){return false}l=a._=a.I_pV;e=a.B;a.B=l;m=a._=a.A-i;a.C=m;g=f(a,b.a_6,38);if(g===0){a.B=e;return false}a.D=a._;switch(g){case 0:a.B=e;return false;case 1:if(!(!(a.I_p2<=a._)?false:true)){a.B=e;return false}if(!c(a,'')){return false}break;case 2:if(!c(a,'')){return false}break;case 3:if(!c(a,'')){return false}j=a.A-a._;h=true;a:while(h===true){h=false;a.C=a._;if(!d(a,1,'e')){a._=a.A-j;break a}a.D=a._;if(!c(a,'')){return false}}break}a.B=e;return true};b.prototype.X=function(){var h;var g;var m;var n;var a;var l;var e;var i;var k;var p;var q;var r;var o;g=this.A-this._;e=true;a:while(e===true){e=false;this.C=this._;if(!d(this,1,'s')){this._=this.A-g;break a}this.D=p=this._;m=this.A-p;if(!j(this,b.g_keep_with_s,97,232)){this._=this.A-g;break a}this._=this.A-m;if(!c(this,'')){return false}}n=this.A-(q=this._);if(q<this.I_pV){return false}r=this._=this.I_pV;a=this.B;this.B=r;o=this._=this.A-n;this.C=o;h=f(this,b.a_7,7);if(h===0){this.B=a;return false}this.D=this._;switch(h){case 0:this.B=a;return false;case 1:if(!(!(this.I_p2<=this._)?false:true)){this.B=a;return false}i=true;a:while(i===true){i=false;l=this.A-this._;k=true;b:while(k===true){k=false;if(!d(this,1,'s')){break b}break a}this._=this.A-l;if(!d(this,1,'t')){this.B=a;return false}}if(!c(this,'')){return false}break;case 2:if(!c(this,'i')){return false}break;case 3:if(!c(this,'')){return false}break;case 4:if(!d(this,2,'gu')){this.B=a;return false}if(!c(this,'')){return false}break}this.B=a;return true};b.prototype.r_residual_suffix=b.prototype.X;function w(a){var g;var h;var p;var n;var e;var m;var i;var k;var l;var q;var r;var s;var o;h=a.A-a._;i=true;a:while(i===true){i=false;a.C=a._;if(!d(a,1,'s')){a._=a.A-h;break a}a.D=q=a._;p=a.A-q;if(!j(a,b.g_keep_with_s,97,232)){a._=a.A-h;break a}a._=a.A-p;if(!c(a,'')){return false}}n=a.A-(r=a._);if(r<a.I_pV){return false}s=a._=a.I_pV;e=a.B;a.B=s;o=a._=a.A-n;a.C=o;g=f(a,b.a_7,7);if(g===0){a.B=e;return false}a.D=a._;switch(g){case 0:a.B=e;return false;case 1:if(!(!(a.I_p2<=a._)?false:true)){a.B=e;return false}k=true;a:while(k===true){k=false;m=a.A-a._;l=true;b:while(l===true){l=false;if(!d(a,1,'s')){break b}break a}a._=a.A-m;if(!d(a,1,'t')){a.B=e;return false}}if(!c(a,'')){return false}break;case 2:if(!c(a,'i')){return false}break;case 3:if(!c(a,'')){return false}break;case 4:if(!d(a,2,'gu')){a.B=e;return false}if(!c(a,'')){return false}break}a.B=e;return true};b.prototype.a=function(){var d;var a;d=this.A-this._;if(f(this,b.a_8,5)===0){return false}a=this._=this.A-d;this.C=a;if(a<=this.B){return false}this._--;this.D=this._;return!c(this,'')?false:true};b.prototype.r_un_double=b.prototype.a;function t(a){var e;var d;e=a.A-a._;if(f(a,b.a_8,5)===0){return false}d=a._=a.A-e;a.C=d;if(d<=a.B){return false}a._--;a.D=a._;return!c(a,'')?false:true};b.prototype.Z=function(){var h;var a;var e;var f;var g;a=1;a:while(true){e=true;b:while(e===true){e=false;if(!j(this,b.g_v,97,251)){break b}a--;continue a}break a}if(a>0){return false}this.C=this._;f=true;a:while(f===true){f=false;h=this.A-this._;g=true;b:while(g===true){g=false;if(!d(this,1,'\u00e9')){break b}break a}this._=this.A-h;if(!d(this,1,'\u00e8')){return false}}this.D=this._;return!c(this,'e')?false:true};b.prototype.r_un_accent=b.prototype.Z;function F(a){var i;var e;var f;var g;var h;e=1;a:while(true){f=true;b:while(f===true){f=false;if(!j(a,b.g_v,97,251)){break b}e--;continue a}break a}if(e>0){return false}a.C=a._;g=true;a:while(g===true){g=false;i=a.A-a._;h=true;b:while(h===true){h=false;if(!d(a,1,'\u00e9')){break b}break a}a._=a.A-i;if(!d(a,1,'\u00e8')){return false}}a.D=a._;return!c(a,'e')?false:true};b.prototype.J=function(){var u;var z;var A;var B;var C;var j;var s;var v;var x;var y;var e;var f;var g;var h;var i;var a;var b;var k;var l;var m;var n;var o;var p;var q;var D;var E;var G;var N;var O;var P;var Q;var R;var r;u=this._;e=true;a:while(e===true){e=false;if(!H(this)){break a}}D=this._=u;z=D;f=true;a:while(f===true){f=false;if(!I(this)){break a}}N=this._=z;this.B=N;P=this._=O=this.A;A=O-P;g=true;c:while(g===true){g=false;h=true;d:while(h===true){h=false;B=this.A-this._;i=true;e:while(i===true){i=false;C=this.A-this._;a=true;a:while(a===true){a=false;j=this.A-this._;b=true;b:while(b===true){b=false;if(!K(this)){break b}break a}this._=this.A-j;k=true;b:while(k===true){k=false;if(!L(this)){break b}break a}this._=this.A-j;if(!M(this)){break e}}G=this._=(E=this.A)-C;s=E-G;l=true;a:while(l===true){l=false;this.C=this._;m=true;b:while(m===true){m=false;v=this.A-this._;n=true;f:while(n===true){n=false;if(!d(this,1,'Y')){break f}this.D=this._;if(!c(this,'i')){return false}break b}this._=this.A-v;if(!d(this,1,'\u00e7')){this._=this.A-s;break a}this.D=this._;if(!c(this,'c')){return false}}}break d}this._=this.A-B;if(!w(this)){break c}}}R=this._=(Q=this.A)-A;x=Q-R;o=true;a:while(o===true){o=false;if(!t(this)){break a}}this._=this.A-x;p=true;a:while(p===true){p=false;if(!F(this)){break a}}r=this._=this.B;y=r;q=true;a:while(q===true){q=false;if(!J(this)){break a}}this._=y;return true};b.prototype.stem=b.prototype.J;b.prototype.N=function(a){return a instanceof b};b.prototype.equals=b.prototype.N;b.prototype.O=function(){var c;var a;var b;var d;c='FrenchStemmer';a=0;for(b=0;b<c.length;b++){d=c.charCodeAt(b);a=(a<<5)-a+d;a=a&a}return a|0};b.prototype.hashCode=b.prototype.O;b.serialVersionUID=1;g(b,'methodObject',function(){return new b});g(b,'a_0',function(){return[new a('col',-1,-1),new a('par',-1,-1),new a('tap',-1,-1)]});g(b,'a_1',function(){return[new a('',-1,4),new a('I',0,1),new a('U',0,2),new a('Y',0,3)]});g(b,'a_2',function(){return[new a('iqU',-1,3),new a('abl',-1,3),new a('I\u00e8r',-1,4),new a('i\u00e8r',-1,4),new a('eus',-1,2),new a('iv',-1,1)]});g(b,'a_3',function(){return[new a('ic',-1,2),new a('abil',-1,1),new a('iv',-1,3)]});g(b,'a_4',function(){return[new a('iqUe',-1,1),new a('atrice',-1,2),new a('ance',-1,1),new a('ence',-1,5),new a('logie',-1,3),new a('able',-1,1),new a('isme',-1,1),new a('euse',-1,11),new a('iste',-1,1),new a('ive',-1,8),new a('if',-1,8),new a('usion',-1,4),new a('ation',-1,2),new a('ution',-1,4),new a('ateur',-1,2),new a('iqUes',-1,1),new a('atrices',-1,2),new a('ances',-1,1),new a('ences',-1,5),new a('logies',-1,3),new a('ables',-1,1),new a('ismes',-1,1),new a('euses',-1,11),new a('istes',-1,1),new a('ives',-1,8),new a('ifs',-1,8),new a('usions',-1,4),new a('ations',-1,2),new a('utions',-1,4),new a('ateurs',-1,2),new a('ments',-1,15),new a('ements',30,6),new a('issements',31,12),new a('it\u00e9s',-1,7),new a('ment',-1,15),new a('ement',34,6),new a('issement',35,12),new a('amment',34,13),new a('emment',34,14),new a('aux',-1,10),new a('eaux',39,9),new a('eux',-1,1),new a('it\u00e9',-1,7)]});g(b,'a_5',function(){return[new a('ira',-1,1),new a('ie',-1,1),new a('isse',-1,1),new a('issante',-1,1),new a('i',-1,1),new a('irai',4,1),new a('ir',-1,1),new a('iras',-1,1),new a('ies',-1,1),new a('\u00eemes',-1,1),new a('isses',-1,1),new a('issantes',-1,1),new a('\u00eetes',-1,1),new a('is',-1,1),new a('irais',13,1),new a('issais',13,1),new a('irions',-1,1),new a('issions',-1,1),new a('irons',-1,1),new a('issons',-1,1),new a('issants',-1,1),new a('it',-1,1),new a('irait',21,1),new a('issait',21,1),new a('issant',-1,1),new a('iraIent',-1,1),new a('issaIent',-1,1),new a('irent',-1,1),new a('issent',-1,1),new a('iront',-1,1),new a('\u00eet',-1,1),new a('iriez',-1,1),new a('issiez',-1,1),new a('irez',-1,1),new a('issez',-1,1)]});g(b,'a_6',function(){return[new a('a',-1,3),new a('era',0,2),new a('asse',-1,3),new a('ante',-1,3),new a('\u00e9e',-1,2),new a('ai',-1,3),new a('erai',5,2),new a('er',-1,2),new a('as',-1,3),new a('eras',8,2),new a('\u00e2mes',-1,3),new a('asses',-1,3),new a('antes',-1,3),new a('\u00e2tes',-1,3),new a('\u00e9es',-1,2),new a('ais',-1,3),new a('erais',15,2),new a('ions',-1,1),new a('erions',17,2),new a('assions',17,3),new a('erons',-1,2),new a('ants',-1,3),new a('\u00e9s',-1,2),new a('ait',-1,3),new a('erait',23,2),new a('ant',-1,3),new a('aIent',-1,3),new a('eraIent',26,2),new a('\u00e8rent',-1,2),new a('assent',-1,3),new a('eront',-1,2),new a('\u00e2t',-1,3),new a('ez',-1,2),new a('iez',32,2),new a('eriez',33,2),new a('assiez',33,3),new a('erez',32,2),new a('\u00e9',-1,2)]});g(b,'a_7',function(){return[new a('e',-1,3),new a('I\u00e8re',0,2),new a('i\u00e8re',0,2),new a('ion',-1,1),new a('Ier',-1,2),new a('ier',-1,2),new a('\u00eb',-1,4)]});g(b,'a_8',function(){return[new a('ell',-1,-1),new a('eill',-1,-1),new a('enn',-1,-1),new a('onn',-1,-1),new a('ett',-1,-1)]});g(b,'g_v',function(){return[17,65,16,1,0,0,0,0,0,0,0,0,0,0,0,128,130,103,8,5]});g(b,'g_keep_with_s',function(){return[1,65,20,0,0,0,0,0,0,0,0,0,0,0,0,0,128]});var q={'src/stemmer.jsx':{Stemmer:p},'src/french-stemmer.jsx':{FrenchStemmer:b}}}(JSX))\"\"\"\n", "code_toks_joined": "<STRING> <NEWLINE> from sphinx . search import SearchLanguage , parse_stop_word <NEWLINE> import snowballstemmer <NEWLINE> french_stopwords = parse_stop_word ( <STRING> ) <NEWLINE> js_stemmer = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"sphinx.search.fr\"\"\"", "u'''| source: http://snowball.tartarus.org/algorithms/french/stop.txt'''", "u\"\"\"var JSX={};(function(l){function m(b,e){var a=function(){};a.prototype=e.prototype;var c=new a;for(var d in b){b[d].prototype=c}}function P(c,b){for(var a in b.prototype)if(b.prototype.hasOwnProperty(a))c.prototype[a]=b.prototype[a]}function g(a,b,d){function c(a,b,c){delete a[b];a[b]=c;return c}Object.defineProperty(a,b,{get:function(){return c(a,b,d())},set:function(d){c(a,b,d)},enumerable:true,configurable:true})}function O(a,b,c){return a[b]=a[b]/c|0}var u=parseInt;var v=parseFloat;function N(a){return a!==a}var x=isFinite;var y=encodeURIComponent;var z=decodeURIComponent;var A=encodeURI;var B=decodeURI;var C=Object.prototype.toString;var D=Object.prototype.hasOwnProperty;function k(){}l.require=function(b){var a=q[b];return a!==undefined?a:null};l.profilerIsRunning=function(){return k.getResults!=null};l.getProfileResults=function(){return(k.getResults||function(){return{}})()};l.postProfileResults=function(a,b){if(k.postResults==null)throw new Error('profiler has not been turned on');return k.postResults(a,b)};l.resetProfileResults=function(){if(k.resetResults==null)throw new Error('profiler has not been turned on');return k.resetResults()};l.DEBUG=false;function G(){};m([G],Error);function a(a,b,c){this.F=a.length;this.K=a;this.L=b;this.I=c;this.H=null;this.P=null};m([a],Object);function p(){};m([p],Object);function i(){var a;var b;var c;this.G={};a=this.E='';b=this._=0;c=this.A=a.length;this.B=0;this.D=b;this.C=c};m([i],p);function s(a,b){a.E=b.E;a._=b._;a.A=b.A;a.B=b.B;a.D=b.D;a.C=b.C};function e(b,d,c,e){var a;if(b._>=b.A){return false}a=b.E.charCodeAt(b._);if(a>e||a<c){return false}a-=c;if((d[a>>>3]&1<<(a&7))===0){return false}b._++;return true};function r(b,d,c,e){var a;if(b._<=b.B){return false}a=b.E.charCodeAt(b._-1);if(a>e||a<c){return false}a-=c;if((d[a>>>3]&1<<(a&7))===0){return false}b._--;return true};function o(a,d,c,e){var b;if(a._>=a.A){return false}b=a.E.charCodeAt(a._);if(b>e||b<c){a._++;return true}b-=c;if((d[b>>>3]&1<<(b&7))===0){a._++;return true}return false};function j(a,d,c,e){var b;if(a._<=a.B){return false}b=a.E.charCodeAt(a._-1);if(b>e||b<c){a._--;return true}b-=c;if((d[b>>>3]&1<<(b&7))===0){a._--;return true}return false};function h(a,b,d){var c;if(a.A-a._<b){return false}if(a.E.slice(c=a._,c+b)!==d){return false}a._+=b;return true};function d(a,b,d){var c;if(a._-a.B<b){return false}if(a.E.slice((c=a._)-b,c)!==d){return false}a._-=b;return true};function n(f,m,p){var b;var d;var e;var n;var g;var k;var l;var i;var h;var c;var a;var j;var o;b=0;d=p;e=f._;n=f.A;g=0;k=0;l=false;while(true){i=b+(d-b>>>1);h=0;c=g<k?g:k;a=m[i];for(j=c;j<a.F;j++){if(e+c===n){h=-1;break}h=f.E.charCodeAt(e+c)-a.K.charCodeAt(j);if(h!==0){break}c++}if(h<0){d=i;k=c}else{b=i;g=c}if(d-b<=1){if(b>0){break}if(d===b){break}if(l){break}l=true}}while(true){a=m[b];if(g>=a.F){f._=e+a.F|0;if(a.H==null){return a.I}o=a.H(a.P);f._=e+a.F|0;if(o){return a.I}}b=a.L;if(b<0){return 0}}return-1};function f(d,m,p){var b;var g;var e;var n;var f;var k;var l;var i;var h;var c;var a;var j;var o;b=0;g=p;e=d._;n=d.B;f=0;k=0;l=false;while(true){i=b+(g-b>>1);h=0;c=f<k?f:k;a=m[i];for(j=a.F-1-c;j>=0;j--){if(e-c===n){h=-1;break}h=d.E.charCodeAt(e-1-c)-a.K.charCodeAt(j);if(h!==0){break}c++}if(h<0){g=i;k=c}else{b=i;f=c}if(g-b<=1){if(b>0){break}if(g===b){break}if(l){break}l=true}}while(true){a=m[b];if(f>=a.F){d._=e-a.F|0;if(a.H==null){return a.I}o=a.H(d);d._=e-a.F|0;if(o){return a.I}}b=a.L;if(b<0){return 0}}return-1};function E(a,b,d,e){var c;c=e.length-(d-b);a.E=a.E.slice(0,b)+e+a.E.slice(d);a.A+=c|0;if(a._>=d){a._+=c|0}else if(a._>b){a._=b}return c|0};function c(a,f){var b;var c;var d;var e;b=false;if((c=a.D)<0||c>(d=a.C)||d>(e=a.A)||e>a.E.length?false:true){E(a,a.D,a.C,f);b=true}return b};i.prototype.J=function(){return false};i.prototype.c=function(b){var a;var c;var d;var e;a=this.G['.'+b];if(a==null){c=this.E=b;d=this._=0;e=this.A=c.length;this.B=0;this.D=d;this.C=e;this.J();a=this.E;this.G['.'+b]=a}return a};i.prototype.stemWord=i.prototype.c;i.prototype.d=function(e){var d;var b;var c;var a;var f;var g;var h;d=[];for(b=0;b<e.length;b++){c=e[b];a=this.G['.'+c];if(a==null){f=this.E=c;g=this._=0;h=this.A=f.length;this.B=0;this.D=g;this.C=h;this.J();a=this.E;this.G['.'+c]=a}d.push(a)}return d};i.prototype.stemWords=i.prototype.d;function b(){i.call(this);this.I_p2=0;this.I_p1=0;this.I_pV=0};m([b],i);b.prototype.M=function(a){this.I_p2=a.I_p2;this.I_p1=a.I_p1;this.I_pV=a.I_pV;s(this,a)};b.prototype.copy_from=b.prototype.M;b.prototype.W=function(){var p;var j;var f;var g;var i;var a;var d;var k;var l;var m;var n;var o;var q;a:while(true){p=this._;i=true;g:while(i===true){i=false;h:while(true){j=this._;a=true;b:while(a===true){a=false;d=true;c:while(d===true){d=false;f=this._;k=true;d:while(k===true){k=false;if(!e(this,b.g_v,97,251)){break d}this.D=this._;l=true;e:while(l===true){l=false;g=this._;m=true;f:while(m===true){m=false;if(!h(this,1,'u')){break f}this.C=this._;if(!e(this,b.g_v,97,251)){break f}if(!c(this,'U')){return false}break e}this._=g;n=true;f:while(n===true){n=false;if(!h(this,1,'i')){break f}this.C=this._;if(!e(this,b.g_v,97,251)){break f}if(!c(this,'I')){return false}break e}this._=g;if(!h(this,1,'y')){break d}this.C=this._;if(!c(this,'Y')){return false}}break c}this._=f;o=true;d:while(o===true){o=false;this.D=this._;if(!h(this,1,'y')){break d}this.C=this._;if(!e(this,b.g_v,97,251)){break d}if(!c(this,'Y')){return false}break c}this._=f;if(!h(this,1,'q')){break b}this.D=this._;if(!h(this,1,'u')){break b}this.C=this._;if(!c(this,'U')){return false}}this._=j;break h}q=this._=j;if(q>=this.A){break g}this._++}continue a}this._=p;break a}return true};b.prototype.r_prelude=b.prototype.W;function H(a){var q;var k;var f;var g;var i;var j;var d;var l;var m;var n;var o;var p;var r;a:while(true){q=a._;i=true;g:while(i===true){i=false;h:while(true){k=a._;j=true;b:while(j===true){j=false;d=true;c:while(d===true){d=false;f=a._;l=true;d:while(l===true){l=false;if(!e(a,b.g_v,97,251)){break d}a.D=a._;m=true;e:while(m===true){m=false;g=a._;n=true;f:while(n===true){n=false;if(!h(a,1,'u')){break f}a.C=a._;if(!e(a,b.g_v,97,251)){break f}if(!c(a,'U')){return false}break e}a._=g;o=true;f:while(o===true){o=false;if(!h(a,1,'i')){break f}a.C=a._;if(!e(a,b.g_v,97,251)){break f}if(!c(a,'I')){return false}break e}a._=g;if(!h(a,1,'y')){break d}a.C=a._;if(!c(a,'Y')){return false}}break c}a._=f;p=true;d:while(p===true){p=false;a.D=a._;if(!h(a,1,'y')){break d}a.C=a._;if(!e(a,b.g_v,97,251)){break d}if(!c(a,'Y')){return false}break c}a._=f;if(!h(a,1,'q')){break b}a.D=a._;if(!h(a,1,'u')){break b}a.C=a._;if(!c(a,'U')){return false}}a._=k;break h}r=a._=k;if(r>=a.A){break g}a._++}continue a}a._=q;break a}return true};b.prototype.U=function(){var t;var i;var r;var d;var f;var g;var h;var c;var a;var j;var k;var l;var m;var s;var p;var q;this.I_pV=p=this.A;this.I_p1=p;this.I_p2=p;t=this._;d=true;b:while(d===true){d=false;f=true;c:while(f===true){f=false;i=this._;g=true;a:while(g===true){g=false;if(!e(this,b.g_v,97,251)){break a}if(!e(this,b.g_v,97,251)){break a}if(this._>=this.A){break a}this._++;break c}this._=i;h=true;a:while(h===true){h=false;if(n(this,b.a_0,3)===0){break a}break c}s=this._=i;if(s>=this.A){break b}this._++;a:while(true){c=true;d:while(c===true){c=false;if(!e(this,b.g_v,97,251)){break d}break a}if(this._>=this.A){break b}this._++}}this.I_pV=this._}q=this._=t;r=q;a=true;a:while(a===true){a=false;c:while(true){j=true;b:while(j===true){j=false;if(!e(this,b.g_v,97,251)){break b}break c}if(this._>=this.A){break a}this._++}b:while(true){k=true;c:while(k===true){k=false;if(!o(this,b.g_v,97,251)){break c}break b}if(this._>=this.A){break a}this._++}this.I_p1=this._;b:while(true){l=true;c:while(l===true){l=false;if(!e(this,b.g_v,97,251)){break c}break b}if(this._>=this.A){break a}this._++}c:while(true){m=true;b:while(m===true){m=false;if(!o(this,b.g_v,97,251)){break b}break c}if(this._>=this.A){break a}this._++}this.I_p2=this._}this._=r;return true};b.prototype.r_mark_regions=b.prototype.U;function I(a){var s;var i;var r;var d;var f;var g;var h;var c;var j;var k;var l;var m;var p;var t;var q;var u;a.I_pV=q=a.A;a.I_p1=q;a.I_p2=q;s=a._;d=true;b:while(d===true){d=false;f=true;c:while(f===true){f=false;i=a._;g=true;a:while(g===true){g=false;if(!e(a,b.g_v,97,251)){break a}if(!e(a,b.g_v,97,251)){break a}if(a._>=a.A){break a}a._++;break c}a._=i;h=true;a:while(h===true){h=false;if(n(a,b.a_0,3)===0){break a}break c}t=a._=i;if(t>=a.A){break b}a._++;a:while(true){c=true;d:while(c===true){c=false;if(!e(a,b.g_v,97,251)){break d}break a}if(a._>=a.A){break b}a._++}}a.I_pV=a._}u=a._=s;r=u;j=true;a:while(j===true){j=false;c:while(true){k=true;b:while(k===true){k=false;if(!e(a,b.g_v,97,251)){break b}break c}if(a._>=a.A){break a}a._++}b:while(true){l=true;c:while(l===true){l=false;if(!o(a,b.g_v,97,251)){break c}break b}if(a._>=a.A){break a}a._++}a.I_p1=a._;b:while(true){m=true;c:while(m===true){m=false;if(!e(a,b.g_v,97,251)){break c}break b}if(a._>=a.A){break a}a._++}c:while(true){p=true;b:while(p===true){p=false;if(!o(a,b.g_v,97,251)){break b}break c}if(a._>=a.A){break a}a._++}a.I_p2=a._}a._=r;return true};b.prototype.V=function(){var a;var e;var d;b:while(true){e=this._;d=true;a:while(d===true){d=false;this.D=this._;a=n(this,b.a_1,4);if(a===0){break a}this.C=this._;switch(a){case 0:break a;case 1:if(!c(this,'i')){return false}break;case 2:if(!c(this,'u')){return false}break;case 3:if(!c(this,'y')){return false}break;case 4:if(this._>=this.A){break a}this._++;break}continue b}this._=e;break b}return true};b.prototype.r_postlude=b.prototype.V;function J(a){var d;var f;var e;b:while(true){f=a._;e=true;a:while(e===true){e=false;a.D=a._;d=n(a,b.a_1,4);if(d===0){break a}a.C=a._;switch(d){case 0:break a;case 1:if(!c(a,'i')){return false}break;case 2:if(!c(a,'u')){return false}break;case 3:if(!c(a,'y')){return false}break;case 4:if(a._>=a.A){break a}a._++;break}continue b}a._=f;break b}return true};b.prototype.S=function(){return!(this.I_pV<=this._)?false:true};b.prototype.r_RV=b.prototype.S;b.prototype.Q=function(){return!(this.I_p1<=this._)?false:true};b.prototype.r_R1=b.prototype.Q;b.prototype.R=function(){return!(this.I_p2<=this._)?false:true};b.prototype.r_R2=b.prototype.R;b.prototype.Y=function(){var a;var E;var H;var e;var D;var g;var F;var G;var h;var I;var A;var B;var p;var k;var l;var m;var n;var o;var i;var q;var s;var t;var u;var v;var w;var x;var y;var z;var J;var K;var L;var C;this.C=this._;a=f(this,b.a_4,43);if(a===0){return false}this.D=this._;switch(a){case 0:return false;case 1:if(!(!(this.I_p2<=this._)?false:true)){return false}if(!c(this,'')){return false}break;case 2:if(!(!(this.I_p2<=this._)?false:true)){return false}if(!c(this,'')){return false}E=this.A-this._;p=true;c:while(p===true){p=false;this.C=this._;if(!d(this,2,'ic')){this._=this.A-E;break c}this.D=this._;k=true;b:while(k===true){k=false;H=this.A-this._;l=true;a:while(l===true){l=false;if(!(!(this.I_p2<=this._)?false:true)){break a}if(!c(this,'')){return false}break b}this._=this.A-H;if(!c(this,'iqU')){return false}}}break;case 3:if(!(!(this.I_p2<=this._)?false:true)){return false}if(!c(this,'log')){return false}break;case 4:if(!(!(this.I_p2<=this._)?false:true)){return false}if(!c(this,'u')){return false}break;case 5:if(!(!(this.I_p2<=this._)?false:true)){return false}if(!c(this,'ent')){return false}break;case 6:if(!(!(this.I_pV<=this._)?false:true)){return false}if(!c(this,'')){return false}e=this.A-this._;m=true;a:while(m===true){m=false;this.C=this._;a=f(this,b.a_2,6);if(a===0){this._=this.A-e;break a}this.D=this._;switch(a){case 0:this._=this.A-e;break a;case 1:if(!(!(this.I_p2<=this._)?false:true)){this._=this.A-e;break a}if(!c(this,'')){return false}this.C=this._;if(!d(this,2,'at')){this._=this.A-e;break a}this.D=J=this._;if(!(!(this.I_p2<=J)?false:true)){this._=this.A-e;break a}if(!c(this,'')){return false}break;case 2:n=true;b:while(n===true){n=false;D=this.A-this._;o=true;c:while(o===true){o=false;if(!(!(this.I_p2<=this._)?false:true)){break c}if(!c(this,'')){return false}break b}K=this._=this.A-D;if(!(!(this.I_p1<=K)?false:true)){this._=this.A-e;break a}if(!c(this,'eux')){return false}}break;case 3:if(!(!(this.I_p2<=this._)?false:true)){this._=this.A-e;break a}if(!c(this,'')){return false}break;case 4:if(!(!(this.I_pV<=this._)?false:true)){this._=this.A-e;break a}if(!c(this,'i')){return false}break}}break;case 7:if(!(!(this.I_p2<=this._)?false:true)){return false}if(!c(this,'')){return false}g=this.A-this._;i=true;a:while(i===true){i=false;this.C=this._;a=f(this,b.a_3,3);if(a===0){this._=this.A-g;break a}this.D=this._;switch(a){case 0:this._=this.A-g;break a;case 1:q=true;c:while(q===true){q=false;F=this.A-this._;s=true;b:while(s===true){s=false;if(!(!(this.I_p2<=this._)?false:true)){break b}if(!c(this,'')){return false}break c}this._=this.A-F;if(!c(this,'abl')){return false}}break;case 2:t=true;b:while(t===true){t=false;G=this.A-this._;u=true;c:while(u===true){u=false;if(!(!(this.I_p2<=this._)?false:true)){break c}if(!c(this,'')){return false}break b}this._=this.A-G;if(!c(this,'iqU')){return false}}break;case 3:if(!(!(this.I_p2<=this._)?false:true)){this._=this.A-g;break a}if(!c(this,'')){return false}break}}break;case 8:if(!(!(this.I_p2<=this._)?false:true)){return false}if(!c(this,'')){return false}h=this.A-this._;v=true;a:while(v===true){v=false;this.C=this._;if(!d(this,2,'at')){this._=this.A-h;break a}this.D=L=this._;if(!(!(this.I_p2<=L)?false:true)){this._=this.A-h;break a}if(!c(this,'')){return false}this.C=this._;if(!d(this,2,'ic')){this._=this.A-h;break a}this.D=this._;w=true;b:while(w===true){w=false;I=this.A-this._;x=true;c:while(x===true){x=false;if(!(!(this.I_p2<=this._)?false:true)){break c}if(!c(this,'')){return false}break b}this._=this.A-I;if(!c(this,'iqU')){return false}}}break;case 9:if(!c(this,'eau')){return false}break;case 10:if(!(!(this.I_p1<=this._)?false:true)){return false}if(!c(this,'al')){return false}break;case 11:y=true;a:while(y===true){y=false;A=this.A-this._;z=true;b:while(z===true){z=false;if(!(!(this.I_p2<=this._)?false:true)){break b}if(!c(this,'')){return false}break a}C=this._=this.A-A;if(!(!(this.I_p1<=C)?false:true)){return false}if(!c(this,'eux')){return false}}break;case 12:if(!(!(this.I_p1<=this._)?false:true)){return false}if(!j(this,b.g_v,97,251)){return false}if(!c(this,'')){return false}break;case 13:if(!(!(this.I_pV<=this._)?false:true)){return false}if(!c(this,'ant')){return false}return false;case 14:if(!(!(this.I_pV<=this._)?false:true)){return false}if(!c(this,'ent')){return false}return false;case 15:B=this.A-this._;if(!r(this,b.g_v,97,251)){return false}if(!(!(this.I_pV<=this._)?false:true)){return false}this._=this.A-B;if(!c(this,'')){return false}return false}return true};b.prototype.r_standard_suffix=b.prototype.Y;function K(a){var g;var F;var I;var e;var E;var h;var G;var H;var i;var J;var B;var C;var p;var l;var m;var n;var o;var k;var q;var s;var t;var u;var v;var w;var x;var y;var z;var A;var K;var L;var M;var D;a.C=a._;g=f(a,b.a_4,43);if(g===0){return false}a.D=a._;switch(g){case 0:return false;case 1:if(!(!(a.I_p2<=a._)?false:true)){return false}if(!c(a,'')){return false}break;case 2:if(!(!(a.I_p2<=a._)?false:true)){return false}if(!c(a,'')){return false}F=a.A-a._;p=true;c:while(p===true){p=false;a.C=a._;if(!d(a,2,'ic')){a._=a.A-F;break c}a.D=a._;l=true;b:while(l===true){l=false;I=a.A-a._;m=true;a:while(m===true){m=false;if(!(!(a.I_p2<=a._)?false:true)){break a}if(!c(a,'')){return false}break b}a._=a.A-I;if(!c(a,'iqU')){return false}}}break;case 3:if(!(!(a.I_p2<=a._)?false:true)){return false}if(!c(a,'log')){return false}break;case 4:if(!(!(a.I_p2<=a._)?false:true)){return false}if(!c(a,'u')){return false}break;case 5:if(!(!(a.I_p2<=a._)?false:true)){return false}if(!c(a,'ent')){return false}break;case 6:if(!(!(a.I_pV<=a._)?false:true)){return false}if(!c(a,'')){return false}e=a.A-a._;n=true;a:while(n===true){n=false;a.C=a._;g=f(a,b.a_2,6);if(g===0){a._=a.A-e;break a}a.D=a._;switch(g){case 0:a._=a.A-e;break a;case 1:if(!(!(a.I_p2<=a._)?false:true)){a._=a.A-e;break a}if(!c(a,'')){return false}a.C=a._;if(!d(a,2,'at')){a._=a.A-e;break a}a.D=K=a._;if(!(!(a.I_p2<=K)?false:true)){a._=a.A-e;break a}if(!c(a,'')){return false}break;case 2:o=true;b:while(o===true){o=false;E=a.A-a._;k=true;c:while(k===true){k=false;if(!(!(a.I_p2<=a._)?false:true)){break c}if(!c(a,'')){return false}break b}L=a._=a.A-E;if(!(!(a.I_p1<=L)?false:true)){a._=a.A-e;break a}if(!c(a,'eux')){return false}}break;case 3:if(!(!(a.I_p2<=a._)?false:true)){a._=a.A-e;break a}if(!c(a,'')){return false}break;case 4:if(!(!(a.I_pV<=a._)?false:true)){a._=a.A-e;break a}if(!c(a,'i')){return false}break}}break;case 7:if(!(!(a.I_p2<=a._)?false:true)){return false}if(!c(a,'')){return false}h=a.A-a._;q=true;a:while(q===true){q=false;a.C=a._;g=f(a,b.a_3,3);if(g===0){a._=a.A-h;break a}a.D=a._;switch(g){case 0:a._=a.A-h;break a;case 1:s=true;c:while(s===true){s=false;G=a.A-a._;t=true;b:while(t===true){t=false;if(!(!(a.I_p2<=a._)?false:true)){break b}if(!c(a,'')){return false}break c}a._=a.A-G;if(!c(a,'abl')){return false}}break;case 2:u=true;b:while(u===true){u=false;H=a.A-a._;v=true;c:while(v===true){v=false;if(!(!(a.I_p2<=a._)?false:true)){break c}if(!c(a,'')){return false}break b}a._=a.A-H;if(!c(a,'iqU')){return false}}break;case 3:if(!(!(a.I_p2<=a._)?false:true)){a._=a.A-h;break a}if(!c(a,'')){return false}break}}break;case 8:if(!(!(a.I_p2<=a._)?false:true)){return false}if(!c(a,'')){return false}i=a.A-a._;w=true;a:while(w===true){w=false;a.C=a._;if(!d(a,2,'at')){a._=a.A-i;break a}a.D=M=a._;if(!(!(a.I_p2<=M)?false:true)){a._=a.A-i;break a}if(!c(a,'')){return false}a.C=a._;if(!d(a,2,'ic')){a._=a.A-i;break a}a.D=a._;x=true;b:while(x===true){x=false;J=a.A-a._;y=true;c:while(y===true){y=false;if(!(!(a.I_p2<=a._)?false:true)){break c}if(!c(a,'')){return false}break b}a._=a.A-J;if(!c(a,'iqU')){return false}}}break;case 9:if(!c(a,'eau')){return false}break;case 10:if(!(!(a.I_p1<=a._)?false:true)){return false}if(!c(a,'al')){return false}break;case 11:z=true;a:while(z===true){z=false;B=a.A-a._;A=true;b:while(A===true){A=false;if(!(!(a.I_p2<=a._)?false:true)){break b}if(!c(a,'')){return false}break a}D=a._=a.A-B;if(!(!(a.I_p1<=D)?false:true)){return false}if(!c(a,'eux')){return false}}break;case 12:if(!(!(a.I_p1<=a._)?false:true)){return false}if(!j(a,b.g_v,97,251)){return false}if(!c(a,'')){return false}break;case 13:if(!(!(a.I_pV<=a._)?false:true)){return false}if(!c(a,'ant')){return false}return false;case 14:if(!(!(a.I_pV<=a._)?false:true)){return false}if(!c(a,'ent')){return false}return false;case 15:C=a.A-a._;if(!r(a,b.g_v,97,251)){return false}if(!(!(a.I_pV<=a._)?false:true)){return false}a._=a.A-C;if(!c(a,'')){return false}return false}return true};b.prototype.T=function(){var d;var e;var a;var g;var h;var i;e=this.A-(g=this._);if(g<this.I_pV){return false}h=this._=this.I_pV;a=this.B;this.B=h;i=this._=this.A-e;this.C=i;d=f(this,b.a_5,35);if(d===0){this.B=a;return false}this.D=this._;switch(d){case 0:this.B=a;return false;case 1:if(!j(this,b.g_v,97,251)){this.B=a;return false}if(!c(this,'')){return false}break}this.B=a;return true};b.prototype.r_i_verb_suffix=b.prototype.T;function L(a){var e;var g;var d;var h;var i;var k;g=a.A-(h=a._);if(h<a.I_pV){return false}i=a._=a.I_pV;d=a.B;a.B=i;k=a._=a.A-g;a.C=k;e=f(a,b.a_5,35);if(e===0){a.B=d;return false}a.D=a._;switch(e){case 0:a.B=d;return false;case 1:if(!j(a,b.g_v,97,251)){a.B=d;return false}if(!c(a,'')){return false}break}a.B=d;return true};b.prototype.b=function(){var e;var h;var a;var i;var g;var j;var k;var l;h=this.A-(j=this._);if(j<this.I_pV){return false}k=this._=this.I_pV;a=this.B;this.B=k;l=this._=this.A-h;this.C=l;e=f(this,b.a_6,38);if(e===0){this.B=a;return false}this.D=this._;switch(e){case 0:this.B=a;return false;case 1:if(!(!(this.I_p2<=this._)?false:true)){this.B=a;return false}if(!c(this,'')){return false}break;case 2:if(!c(this,'')){return false}break;case 3:if(!c(this,'')){return false}i=this.A-this._;g=true;a:while(g===true){g=false;this.C=this._;if(!d(this,1,'e')){this._=this.A-i;break a}this.D=this._;if(!c(this,'')){return false}}break}this.B=a;return true};b.prototype.r_verb_suffix=b.prototype.b;function M(a){var g;var i;var e;var j;var h;var k;var l;var m;i=a.A-(k=a._);if(k<a.I_pV){return false}l=a._=a.I_pV;e=a.B;a.B=l;m=a._=a.A-i;a.C=m;g=f(a,b.a_6,38);if(g===0){a.B=e;return false}a.D=a._;switch(g){case 0:a.B=e;return false;case 1:if(!(!(a.I_p2<=a._)?false:true)){a.B=e;return false}if(!c(a,'')){return false}break;case 2:if(!c(a,'')){return false}break;case 3:if(!c(a,'')){return false}j=a.A-a._;h=true;a:while(h===true){h=false;a.C=a._;if(!d(a,1,'e')){a._=a.A-j;break a}a.D=a._;if(!c(a,'')){return false}}break}a.B=e;return true};b.prototype.X=function(){var h;var g;var m;var n;var a;var l;var e;var i;var k;var p;var q;var r;var o;g=this.A-this._;e=true;a:while(e===true){e=false;this.C=this._;if(!d(this,1,'s')){this._=this.A-g;break a}this.D=p=this._;m=this.A-p;if(!j(this,b.g_keep_with_s,97,232)){this._=this.A-g;break a}this._=this.A-m;if(!c(this,'')){return false}}n=this.A-(q=this._);if(q<this.I_pV){return false}r=this._=this.I_pV;a=this.B;this.B=r;o=this._=this.A-n;this.C=o;h=f(this,b.a_7,7);if(h===0){this.B=a;return false}this.D=this._;switch(h){case 0:this.B=a;return false;case 1:if(!(!(this.I_p2<=this._)?false:true)){this.B=a;return false}i=true;a:while(i===true){i=false;l=this.A-this._;k=true;b:while(k===true){k=false;if(!d(this,1,'s')){break b}break a}this._=this.A-l;if(!d(this,1,'t')){this.B=a;return false}}if(!c(this,'')){return false}break;case 2:if(!c(this,'i')){return false}break;case 3:if(!c(this,'')){return false}break;case 4:if(!d(this,2,'gu')){this.B=a;return false}if(!c(this,'')){return false}break}this.B=a;return true};b.prototype.r_residual_suffix=b.prototype.X;function w(a){var g;var h;var p;var n;var e;var m;var i;var k;var l;var q;var r;var s;var o;h=a.A-a._;i=true;a:while(i===true){i=false;a.C=a._;if(!d(a,1,'s')){a._=a.A-h;break a}a.D=q=a._;p=a.A-q;if(!j(a,b.g_keep_with_s,97,232)){a._=a.A-h;break a}a._=a.A-p;if(!c(a,'')){return false}}n=a.A-(r=a._);if(r<a.I_pV){return false}s=a._=a.I_pV;e=a.B;a.B=s;o=a._=a.A-n;a.C=o;g=f(a,b.a_7,7);if(g===0){a.B=e;return false}a.D=a._;switch(g){case 0:a.B=e;return false;case 1:if(!(!(a.I_p2<=a._)?false:true)){a.B=e;return false}k=true;a:while(k===true){k=false;m=a.A-a._;l=true;b:while(l===true){l=false;if(!d(a,1,'s')){break b}break a}a._=a.A-m;if(!d(a,1,'t')){a.B=e;return false}}if(!c(a,'')){return false}break;case 2:if(!c(a,'i')){return false}break;case 3:if(!c(a,'')){return false}break;case 4:if(!d(a,2,'gu')){a.B=e;return false}if(!c(a,'')){return false}break}a.B=e;return true};b.prototype.a=function(){var d;var a;d=this.A-this._;if(f(this,b.a_8,5)===0){return false}a=this._=this.A-d;this.C=a;if(a<=this.B){return false}this._--;this.D=this._;return!c(this,'')?false:true};b.prototype.r_un_double=b.prototype.a;function t(a){var e;var d;e=a.A-a._;if(f(a,b.a_8,5)===0){return false}d=a._=a.A-e;a.C=d;if(d<=a.B){return false}a._--;a.D=a._;return!c(a,'')?false:true};b.prototype.Z=function(){var h;var a;var e;var f;var g;a=1;a:while(true){e=true;b:while(e===true){e=false;if(!j(this,b.g_v,97,251)){break b}a--;continue a}break a}if(a>0){return false}this.C=this._;f=true;a:while(f===true){f=false;h=this.A-this._;g=true;b:while(g===true){g=false;if(!d(this,1,'\u00e9')){break b}break a}this._=this.A-h;if(!d(this,1,'\u00e8')){return false}}this.D=this._;return!c(this,'e')?false:true};b.prototype.r_un_accent=b.prototype.Z;function F(a){var i;var e;var f;var g;var h;e=1;a:while(true){f=true;b:while(f===true){f=false;if(!j(a,b.g_v,97,251)){break b}e--;continue a}break a}if(e>0){return false}a.C=a._;g=true;a:while(g===true){g=false;i=a.A-a._;h=true;b:while(h===true){h=false;if(!d(a,1,'\u00e9')){break b}break a}a._=a.A-i;if(!d(a,1,'\u00e8')){return false}}a.D=a._;return!c(a,'e')?false:true};b.prototype.J=function(){var u;var z;var A;var B;var C;var j;var s;var v;var x;var y;var e;var f;var g;var h;var i;var a;var b;var k;var l;var m;var n;var o;var p;var q;var D;var E;var G;var N;var O;var P;var Q;var R;var r;u=this._;e=true;a:while(e===true){e=false;if(!H(this)){break a}}D=this._=u;z=D;f=true;a:while(f===true){f=false;if(!I(this)){break a}}N=this._=z;this.B=N;P=this._=O=this.A;A=O-P;g=true;c:while(g===true){g=false;h=true;d:while(h===true){h=false;B=this.A-this._;i=true;e:while(i===true){i=false;C=this.A-this._;a=true;a:while(a===true){a=false;j=this.A-this._;b=true;b:while(b===true){b=false;if(!K(this)){break b}break a}this._=this.A-j;k=true;b:while(k===true){k=false;if(!L(this)){break b}break a}this._=this.A-j;if(!M(this)){break e}}G=this._=(E=this.A)-C;s=E-G;l=true;a:while(l===true){l=false;this.C=this._;m=true;b:while(m===true){m=false;v=this.A-this._;n=true;f:while(n===true){n=false;if(!d(this,1,'Y')){break f}this.D=this._;if(!c(this,'i')){return false}break b}this._=this.A-v;if(!d(this,1,'\u00e7')){this._=this.A-s;break a}this.D=this._;if(!c(this,'c')){return false}}}break d}this._=this.A-B;if(!w(this)){break c}}}R=this._=(Q=this.A)-A;x=Q-R;o=true;a:while(o===true){o=false;if(!t(this)){break a}}this._=this.A-x;p=true;a:while(p===true){p=false;if(!F(this)){break a}}r=this._=this.B;y=r;q=true;a:while(q===true){q=false;if(!J(this)){break a}}this._=y;return true};b.prototype.stem=b.prototype.J;b.prototype.N=function(a){return a instanceof b};b.prototype.equals=b.prototype.N;b.prototype.O=function(){var c;var a;var b;var d;c='FrenchStemmer';a=0;for(b=0;b<c.length;b++){d=c.charCodeAt(b);a=(a<<5)-a+d;a=a&a}return a|0};b.prototype.hashCode=b.prototype.O;b.serialVersionUID=1;g(b,'methodObject',function(){return new b});g(b,'a_0',function(){return[new a('col',-1,-1),new a('par',-1,-1),new a('tap',-1,-1)]});g(b,'a_1',function(){return[new a('',-1,4),new a('I',0,1),new a('U',0,2),new a('Y',0,3)]});g(b,'a_2',function(){return[new a('iqU',-1,3),new a('abl',-1,3),new a('I\u00e8r',-1,4),new a('i\u00e8r',-1,4),new a('eus',-1,2),new a('iv',-1,1)]});g(b,'a_3',function(){return[new a('ic',-1,2),new a('abil',-1,1),new a('iv',-1,3)]});g(b,'a_4',function(){return[new a('iqUe',-1,1),new a('atrice',-1,2),new a('ance',-1,1),new a('ence',-1,5),new a('logie',-1,3),new a('able',-1,1),new a('isme',-1,1),new a('euse',-1,11),new a('iste',-1,1),new a('ive',-1,8),new a('if',-1,8),new a('usion',-1,4),new a('ation',-1,2),new a('ution',-1,4),new a('ateur',-1,2),new a('iqUes',-1,1),new a('atrices',-1,2),new a('ances',-1,1),new a('ences',-1,5),new a('logies',-1,3),new a('ables',-1,1),new a('ismes',-1,1),new a('euses',-1,11),new a('istes',-1,1),new a('ives',-1,8),new a('ifs',-1,8),new a('usions',-1,4),new a('ations',-1,2),new a('utions',-1,4),new a('ateurs',-1,2),new a('ments',-1,15),new a('ements',30,6),new a('issements',31,12),new a('it\u00e9s',-1,7),new a('ment',-1,15),new a('ement',34,6),new a('issement',35,12),new a('amment',34,13),new a('emment',34,14),new a('aux',-1,10),new a('eaux',39,9),new a('eux',-1,1),new a('it\u00e9',-1,7)]});g(b,'a_5',function(){return[new a('ira',-1,1),new a('ie',-1,1),new a('isse',-1,1),new a('issante',-1,1),new a('i',-1,1),new a('irai',4,1),new a('ir',-1,1),new a('iras',-1,1),new a('ies',-1,1),new a('\u00eemes',-1,1),new a('isses',-1,1),new a('issantes',-1,1),new a('\u00eetes',-1,1),new a('is',-1,1),new a('irais',13,1),new a('issais',13,1),new a('irions',-1,1),new a('issions',-1,1),new a('irons',-1,1),new a('issons',-1,1),new a('issants',-1,1),new a('it',-1,1),new a('irait',21,1),new a('issait',21,1),new a('issant',-1,1),new a('iraIent',-1,1),new a('issaIent',-1,1),new a('irent',-1,1),new a('issent',-1,1),new a('iront',-1,1),new a('\u00eet',-1,1),new a('iriez',-1,1),new a('issiez',-1,1),new a('irez',-1,1),new a('issez',-1,1)]});g(b,'a_6',function(){return[new a('a',-1,3),new a('era',0,2),new a('asse',-1,3),new a('ante',-1,3),new a('\u00e9e',-1,2),new a('ai',-1,3),new a('erai',5,2),new a('er',-1,2),new a('as',-1,3),new a('eras',8,2),new a('\u00e2mes',-1,3),new a('asses',-1,3),new a('antes',-1,3),new a('\u00e2tes',-1,3),new a('\u00e9es',-1,2),new a('ais',-1,3),new a('erais',15,2),new a('ions',-1,1),new a('erions',17,2),new a('assions',17,3),new a('erons',-1,2),new a('ants',-1,3),new a('\u00e9s',-1,2),new a('ait',-1,3),new a('erait',23,2),new a('ant',-1,3),new a('aIent',-1,3),new a('eraIent',26,2),new a('\u00e8rent',-1,2),new a('assent',-1,3),new a('eront',-1,2),new a('\u00e2t',-1,3),new a('ez',-1,2),new a('iez',32,2),new a('eriez',33,2),new a('assiez',33,3),new a('erez',32,2),new a('\u00e9',-1,2)]});g(b,'a_7',function(){return[new a('e',-1,3),new a('I\u00e8re',0,2),new a('i\u00e8re',0,2),new a('ion',-1,1),new a('Ier',-1,2),new a('ier',-1,2),new a('\u00eb',-1,4)]});g(b,'a_8',function(){return[new a('ell',-1,-1),new a('eill',-1,-1),new a('enn',-1,-1),new a('onn',-1,-1),new a('ett',-1,-1)]});g(b,'g_v',function(){return[17,65,16,1,0,0,0,0,0,0,0,0,0,0,0,128,130,103,8,5]});g(b,'g_keep_with_s',function(){return[1,65,20,0,0,0,0,0,0,0,0,0,0,0,0,0,128]});var q={'src/stemmer.jsx':{Stemmer:p},'src/french-stemmer.jsx':{FrenchStemmer:b}}}(JSX))\"\"\""]}}], ["7125d74177f4d83a52201324045aa4fa", {"code_string": "\"\"\"!@brief Unit-tests for X-Means algorithm.\"\"\"\nimport unittest;\nfrom pyclustering.cluster.tests.xmeans_templates import XmeansTestTemplates;\nfrom pyclustering.cluster.xmeans import splitting_type;\nfrom pyclustering.samples.definitions import SIMPLE_SAMPLES, FCPS_SAMPLES;\n", "code_toks_joined": "<STRING> <NEWLINE> import unittest ; <NEWLINE> from pyclustering . cluster . tests . xmeans_templates import XmeansTestTemplates ; <NEWLINE> from pyclustering . cluster . xmeans import splitting_type ; <NEWLINE> from pyclustering . samples . definitions import SIMPLE_SAMPLES , FCPS_SAMPLES ; <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"!@brief Unit-tests for X-Means algorithm.\"\"\""]}}], ["0a1c5aefeb58d8fed23f36345523de0f", {"code_string": "class BaseService(object):\n    model = None\n    model_proxy = None\n    @ classmethod\n    def all(cls, klass, db_session = None):\n        \"\"\"returns all objects of specific type - will work correctly with\"\"\"\n        db_session = get_db_session(db_session)\n        return db_session.query(klass)\n    @ classmethod\n    def base_query(cls, db_session = None):\n        \"\"\"returns base query for specific service\"\"\"\n        db_session = get_db_session(db_session)\n        return db_session.query(cls.model)\n", "code_toks_joined": "class BaseService ( object ) : <NEWLINE> <INDENT> model = None <NEWLINE> model_proxy = None <NEWLINE> @ classmethod <NEWLINE> def all ( cls , klass , db_session = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> db_session = get_db_session ( db_session ) <NEWLINE> return db_session . query ( klass ) <NEWLINE> <DEDENT> @ classmethod <NEWLINE> def base_query ( cls , db_session = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> db_session = get_db_session ( db_session ) <NEWLINE> return db_session . query ( cls . model ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"returns all objects of specific type - will work correctly with\"\"\"", "\"\"\"returns base query for specific service\"\"\""]}}], ["3631510c6c248228e7c08ac21d4b3f29", {"code_string": "def update_chassis(self, chassis, values):\n    session = get_session()\n    with session.begin():\n        query = model_query(models.Chassis, session = session)\n        query = add_identity_filter(query, chassis)\n        count = query.update(values)\n        if count != 1:\n            raise exception.ChassisNotFound(chassis = chassis)\n        ref = query.one()\n    return ref\n", "code_toks_joined": "def update_chassis ( self , chassis , values ) : <NEWLINE> <INDENT> session = get_session ( ) <NEWLINE> with session . begin ( ) : <NEWLINE> <INDENT> query = model_query ( models . Chassis , session = session ) <NEWLINE> query = add_identity_filter ( query , chassis ) <NEWLINE> count = query . update ( values ) <NEWLINE> if count != 1 : <NEWLINE> <INDENT> raise exception . ChassisNotFound ( chassis = chassis ) <NEWLINE> <DEDENT> ref = query . one ( ) <NEWLINE> <DEDENT> return ref <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["6d0c42e6a1713b8ee802d8f72757559e", {"code_string": "__author__ = 'Van'\nimport os\nimport pymongo\nimport datetime\nMONGODB_HOST = os.getenv(\"MONGODB_HOST\", '127.0.0.1')\nMONGODB_PORT = os.getenv(\"MONGODB_PORT\", 27017)\nmongodb_client = pymongo.MongoClient(MONGODB_HOST, MONGODB_PORT)\n", "code_toks_joined": "__author__ = <STRING> <NEWLINE> import os <NEWLINE> import pymongo <NEWLINE> import datetime <NEWLINE> MONGODB_HOST = os . getenv ( <STRING> , <STRING> ) <NEWLINE> MONGODB_PORT = os . getenv ( <STRING> , 27017 ) <NEWLINE> mongodb_client = pymongo . MongoClient ( MONGODB_HOST , MONGODB_PORT ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'Van'", "\"MONGODB_HOST\"", "'127.0.0.1'", "\"MONGODB_PORT\""]}}], ["af6c345f9a56f61db7250814961752b6", {"code_string": "def label_logical_ties_in_expr_with_logical_tie_durations(\n    expr, markup_direction = Down):\n    r'''Label logical ties in `expr` with both written logical tie duration'''\n    from abjad.tools import labeltools\n    return labeltools.label_leaves_in_expr_with_leaf_durations(\n        expr,\n        label_durations = True,\n        label_written_durations = True,\n        markup_direction = markup_direction,\n        )\n", "code_toks_joined": "def label_logical_ties_in_expr_with_logical_tie_durations ( <NEWLINE> <INDENT> expr , markup_direction = Down ) : <NEWLINE> <STRING> <NEWLINE> from abjad . tools import labeltools <NEWLINE> return labeltools . label_leaves_in_expr_with_leaf_durations ( <NEWLINE> <INDENT> expr , <NEWLINE> label_durations = True , <NEWLINE> label_written_durations = True , <NEWLINE> markup_direction = markup_direction , <NEWLINE> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["r'''Label logical ties in `expr` with both written logical tie duration'''"]}}], ["982eea8d69753461ed6ebc2f581f9fd4", {"code_string": "def execute(commands):\n    p = subprocess.Popen(commands, shell = True, stdout = subprocess.PIPE)\n    out, err = p.communicate()\n    return out\n", "code_toks_joined": "def execute ( commands ) : <NEWLINE> <INDENT> p = subprocess . Popen ( commands , shell = True , stdout = subprocess . PIPE ) <NEWLINE> out , err = p . communicate ( ) <NEWLINE> return out <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["fca61c8dee63b80c18c645c7ce9c8c32", {"code_string": "\"\"\"Treadmill API Lookup REST API\"\"\"\nimport flask_restplus as restplus\nfrom flask_restplus import fields\nfrom treadmill import webutils\nfrom treadmill.api import api_lookup\n", "code_toks_joined": "<STRING> <NEWLINE> import flask_restplus as restplus <NEWLINE> from flask_restplus import fields <NEWLINE> from treadmill import webutils <NEWLINE> from treadmill . api import api_lookup <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Treadmill API Lookup REST API\"\"\""]}}], ["c0a8068b65165ae2a5be6c4da2c6d427", {"code_string": "class lims_oligos_io(lims_oligos_query, sbaas_template_io):\n    def import_oligosStorage_add(self, filename):\n        '''table adds'''\n        data = base_importData();\n        data.read_csv(filename);\n        data.format_data();\n        self.add_oligosStorage(data.data);\n        data.clear_data();\n    def import_oligosDescription_add(self, filename):\n        '''table adds'''\n        data = base_importData();\n        data.read_csv(filename);\n        data.format_data();\n        self.add_oligosDescription(data.data);\n        data.clear_data();\n", "code_toks_joined": "class lims_oligos_io ( lims_oligos_query , sbaas_template_io ) : <NEWLINE> <INDENT> def import_oligosStorage_add ( self , filename ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> data = base_importData ( ) ; <NEWLINE> data . read_csv ( filename ) ; <NEWLINE> data . format_data ( ) ; <NEWLINE> self . add_oligosStorage ( data . data ) ; <NEWLINE> data . clear_data ( ) ; <NEWLINE> <DEDENT> def import_oligosDescription_add ( self , filename ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> data = base_importData ( ) ; <NEWLINE> data . read_csv ( filename ) ; <NEWLINE> data . format_data ( ) ; <NEWLINE> self . add_oligosDescription ( data . data ) ; <NEWLINE> data . clear_data ( ) ; <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''table adds'''", "'''table adds'''"]}}], ["115b9b3af3955d0b0ed236ebdfeb1e72", {"code_string": "def test_implicit_subscribed(self):\n    user = self.create_user()\n    group = self.create_group()\n    result = serialize(group, user)\n    assert result['isSubscribed']\n", "code_toks_joined": "def test_implicit_subscribed ( self ) : <NEWLINE> <INDENT> user = self . create_user ( ) <NEWLINE> group = self . create_group ( ) <NEWLINE> result = serialize ( group , user ) <NEWLINE> assert result [ <STRING> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'isSubscribed'"]}}], ["8f3afc701a7d5b403307ff18b60d0191", {"code_string": "import os\nimport pandas as pd\nfname = '000'\npath = os.getcwd()\nfiles = os.listdir(path)\nfiles_xls = [f for f in files if f[: 3] == fname]\ndf = pd.DataFrame()\nfor f in files_xls:\n    data = pd.read_excel(f, 'Sheet1')\n    df = df.append(data)\ndf.sort_index(inplace = True)\ndf = df.sort(['from_to'])\ndf.to_excel('Pandas' + fname + '.xlsx')\nprint(\"Done!\")\n", "code_toks_joined": "import os <NEWLINE> import pandas as pd <NEWLINE> fname = <STRING> <NEWLINE> path = os . getcwd ( ) <NEWLINE> files = os . listdir ( path ) <NEWLINE> files_xls = [ f for f in files if f [ : 3 ] == fname ] <NEWLINE> df = pd . DataFrame ( ) <NEWLINE> for f in files_xls : <NEWLINE> <INDENT> data = pd . read_excel ( f , <STRING> ) <NEWLINE> df = df . append ( data ) <NEWLINE> <DEDENT> df . sort_index ( inplace = True ) <NEWLINE> df = df . sort ( [ <STRING> ] ) <NEWLINE> df . to_excel ( <STRING> + fname + <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'000'", "'Sheet1'", "'from_to'", "'Pandas'", "'.xlsx'", "\"Done!\""]}}], ["32240803ab2e8ad8072411befdffa8e7", {"code_string": "def addnettunnels(self):\n    \"\"\"Add GreTaps between network devices on different machines.\"\"\"\n    logger.info(\"adding network tunnels for nodes: %s\", self.network_nodes)\n    for n in self.network_nodes:\n        self.addnettunnel(n)\n", "code_toks_joined": "def addnettunnels ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> logger . info ( <STRING> , self . network_nodes ) <NEWLINE> for n in self . network_nodes : <NEWLINE> <INDENT> self . addnettunnel ( n ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Add GreTaps between network devices on different machines.\"\"\"", "\"adding network tunnels for nodes: %s\""]}}], ["30423140ae64c95e831d125b71e5e48a", {"code_string": "def returnFromInitialAuthorization(self):\n    rtmom_net.getInternetConnector().connectAuthorizedClicked(self.conn, self.tokenPath)\n    self._myrtmom.updateFromNet(netConnector)\n    self._myrtmom.doSaveToFile(self._fileHandler)\n    self.rtmom_page.promote()\n    self._finishOffInit()\n", "code_toks_joined": "def returnFromInitialAuthorization ( self ) : <NEWLINE> <INDENT> rtmom_net . getInternetConnector ( ) . connectAuthorizedClicked ( self . conn , self . tokenPath ) <NEWLINE> self . _myrtmom . updateFromNet ( netConnector ) <NEWLINE> self . _myrtmom . doSaveToFile ( self . _fileHandler ) <NEWLINE> self . rtmom_page . promote ( ) <NEWLINE> self . _finishOffInit ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["e9d3adef367b5130e1f92a278cc4f55c", {"code_string": "def test_unpacking_images_returns_correct_img_type():\n    test_cases = [\n        ('ole_object_bmp', 'bmp'),\n        ('ole_object_png', 'png'),\n        ('ole_object_jpg', 'jpeg')\n    ]\n    for ole_obj_filename, img_ext in test_cases:\n        ole = get_test_data_file_contents(ole_obj_filename)\n        assert oleh.unpack(ole).what == img_ext\n", "code_toks_joined": "def test_unpacking_images_returns_correct_img_type ( ) : <NEWLINE> <INDENT> test_cases = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) <NEWLINE> <DEDENT> ] <NEWLINE> for ole_obj_filename , img_ext in test_cases : <NEWLINE> <INDENT> ole = get_test_data_file_contents ( ole_obj_filename ) <NEWLINE> assert oleh . unpack ( ole ) . what == img_ext <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'ole_object_bmp'", "'bmp'", "'ole_object_png'", "'png'", "'ole_object_jpg'", "'jpeg'"]}}], ["c9965fd8f5a25d1cc0d51d2657082dbb", {"code_string": "\"\"\" Simple example of analog output\"\"\"\nfrom PyDAQmx import Task\nimport numpy as np\nvalue = 1.3\ntask = Task()\ntask.CreateAOVoltageChan(\"/TestDevice/ao0\", \"\", - 10.0, 10.0, PyDAQmx.DAQmx_Val_Volts, None)\ntask.StartTask()\ntask.WriteAnalogScalarF64(1, 10.0, value, None)\ntask.StopTask()\n", "code_toks_joined": "<STRING> <NEWLINE> from PyDAQmx import Task <NEWLINE> import numpy as np <NEWLINE> value = 1.3 <NEWLINE> task = Task ( ) <NEWLINE> task . CreateAOVoltageChan ( <STRING> , <STRING> , - 10.0 , 10.0 , PyDAQmx . DAQmx_Val_Volts , None ) <NEWLINE> task . StartTask ( ) <NEWLINE> task . WriteAnalogScalarF64 ( 1 , 10.0 , value , None ) <NEWLINE> task . StopTask ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\" Simple example of analog output\"\"\"", "\"/TestDevice/ao0\"", "\"\""]}}], ["82f60277f4352bf9a0f7959b6b966356", {"code_string": "def __init__(self):\n    BaseCT2Device.__init__(self)\n    device_name = self.card_config['tango name']\n    self.__tango_device = PyTango.gevent.DeviceProxy(device_name)\n    self.__tango_device.subscribe_event(\"acq_status\",\n        PyTango.EventType.CHANGE_EVENT,\n        self.__on_status)\n    self.__tango_device.subscribe_event(\"last_point_nb\",\n        PyTango.EventType.CHANGE_EVENT,\n        self.__on_point_nb)\n    self.__tango_device.subscribe_event(\"last_error\",\n        PyTango.EventType.CHANGE_EVENT,\n        self.__on_error)\n", "code_toks_joined": "def __init__ ( self ) : <NEWLINE> <INDENT> BaseCT2Device . __init__ ( self ) <NEWLINE> device_name = self . card_config [ <STRING> ] <NEWLINE> self . __tango_device = PyTango . gevent . DeviceProxy ( device_name ) <NEWLINE> self . __tango_device . subscribe_event ( <STRING> , <NEWLINE> <INDENT> PyTango . EventType . CHANGE_EVENT , <NEWLINE> self . __on_status ) <NEWLINE> <DEDENT> self . __tango_device . subscribe_event ( <STRING> , <NEWLINE> <INDENT> PyTango . EventType . CHANGE_EVENT , <NEWLINE> self . __on_point_nb ) <NEWLINE> <DEDENT> self . __tango_device . subscribe_event ( <STRING> , <NEWLINE> <INDENT> PyTango . EventType . CHANGE_EVENT , <NEWLINE> self . __on_error ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'tango name'", "\"acq_status\"", "\"last_point_nb\"", "\"last_error\""]}}], ["24bd7c044424b8e39d3bdc0185cf0e9a", {"code_string": "from django.dispatch import Signal\ninstance_created = Signal(providing_args = ['model', 'instance', 'committed'])\n", "code_toks_joined": "from django . dispatch import Signal <NEWLINE> instance_created = Signal ( providing_args = [ <STRING> , <STRING> , <STRING> ] ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'model'", "'instance'", "'committed'"]}}], ["ac2e6a221f79a5f41a76ee84b330937c", {"code_string": "def api_delete_server_repositories(hostname):\n    db_session = DBSession()\n    delete_server_repository(db_session, hostname)\n    return jsonify(**{RESPONSE_ENVELOPE: {KEY_HOSTNAME: hostname, RESPONSE_STATUS: APIStatus.SUCCESS}})\n", "code_toks_joined": "def api_delete_server_repositories ( hostname ) : <NEWLINE> <INDENT> db_session = DBSession ( ) <NEWLINE> delete_server_repository ( db_session , hostname ) <NEWLINE> return jsonify ( ** { RESPONSE_ENVELOPE : { KEY_HOSTNAME : hostname , RESPONSE_STATUS : APIStatus . SUCCESS } } ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["1eef9006b26fcb2b5d7b1e5919b0943b", {"code_string": "def get_lang(extension):\n    if not extension:\n        extension = \"py\"\n    return LEXER_MAP.get(extension, \"\")\n", "code_toks_joined": "def get_lang ( extension ) : <NEWLINE> <INDENT> if not extension : <NEWLINE> <INDENT> extension = <STRING> <NEWLINE> <DEDENT> return LEXER_MAP . get ( extension , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"py\"", "\"\""]}}], ["584b181eb018b4d8b83bcf3d66001b4a", {"code_string": "list = [1, 2, 3, 4, 5]\nproductItems = 1\nfor item in list:\n    productItems *= item\nprint(\"Product of all items:\", productItems)\n", "code_toks_joined": "list = [ 1 , 2 , 3 , 4 , 5 ] <NEWLINE> productItems = 1 <NEWLINE> for item in list : <NEWLINE> <INDENT> productItems *= item <NEWLINE> <DEDENT> print ( <STRING> , productItems ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"Product of all items:\""]}}], ["fa6d33534b7a6c2283a9c05e44bfdb4e", {"code_string": "class UserSerializer(serializers.HyperlinkedModelSerializer):\n    measurements = serializers.HyperlinkedRelatedField(\n        queryset = Measurement.objects.all(),\n        view_name = 'measurement-detail',\n        many = True)\n    class Meta:\n        model = User\n        fields = ('url', 'email', 'measurements')\n", "code_toks_joined": "class UserSerializer ( serializers . HyperlinkedModelSerializer ) : <NEWLINE> <INDENT> measurements = serializers . HyperlinkedRelatedField ( <NEWLINE> <INDENT> queryset = Measurement . objects . all ( ) , <NEWLINE> view_name = <STRING> , <NEWLINE> many = True ) <NEWLINE> <DEDENT> class Meta : <NEWLINE> <INDENT> model = User <NEWLINE> fields = ( <STRING> , <STRING> , <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'measurement-detail'", "'url'", "'email'", "'measurements'"]}}], ["9766df218191a37c3fb1d4c8dd65500f", {"code_string": "\"\"\"Utility functions for Fourier transforms on regularly sampled data.\"\"\"\nfrom __future__ import print_function, division, absolute_import\nfrom future import standard_library\nstandard_library.install_aliases()\nfrom builtins import range\nimport numpy as np\nfrom odl.discr import(\n    uniform_grid, DiscreteLp, uniform_partition_fromgrid,\n    uniform_discr_frompartition)\nfrom odl.set import RealNumbers\nfrom odl.util import(\n    fast_1d_tensor_mult,\n    is_real_dtype, is_scalar_dtype, is_real_floating_dtype,\n    is_complex_floating_dtype, complex_dtype, dtype_repr,\n    conj_exponent,\n    normalized_scalar_param_list, normalized_axes_tuple)\n__all__ = ('reciprocal_grid', 'realspace_grid',\n    'reciprocal_space',\n    'dft_preprocess_data', 'dft_postprocess_data')\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import print_function , division , absolute_import <NEWLINE> from future import standard_library <NEWLINE> standard_library . install_aliases ( ) <NEWLINE> from builtins import range <NEWLINE> import numpy as np <NEWLINE> from odl . discr import ( <NEWLINE> <INDENT> uniform_grid , DiscreteLp , uniform_partition_fromgrid , <NEWLINE> uniform_discr_frompartition ) <NEWLINE> <DEDENT> from odl . set import RealNumbers <NEWLINE> from odl . util import ( <NEWLINE> <INDENT> fast_1d_tensor_mult , <NEWLINE> is_real_dtype , is_scalar_dtype , is_real_floating_dtype , <NEWLINE> is_complex_floating_dtype , complex_dtype , dtype_repr , <NEWLINE> conj_exponent , <NEWLINE> normalized_scalar_param_list , normalized_axes_tuple ) <NEWLINE> <DEDENT> __all__ = ( <STRING> , <STRING> , <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Utility functions for Fourier transforms on regularly sampled data.\"\"\"", "'reciprocal_grid'", "'realspace_grid'", "'reciprocal_space'", "'dft_preprocess_data'", "'dft_postprocess_data'"]}}], ["c1f0a79382307e4c3f51c81a0a985bf5", {"code_string": "import fabric\nfabricClient = fabric.createClient()\nop = fabricClient.DependencyGraph.createOperator(\"op\")\nop.setEntryPoint('entry')\nop.setSourceCode(\"operator entry( io Scalar input[][] ) {}\")\nbinding = fabricClient.DependencyGraph.createBinding()\nbinding.setOperator(op)\nbinding.setParameterLayout([\"self.input\"])\nnode = fabricClient.DependencyGraph.createNode(\"node\")\nnode.addMember(\"input\", \"Scalar[]\")\nnode.bindings.append(binding)\nnode.setData(\"input\", [17])\nprint(node.getErrors())\nfabricClient.close()\n", "code_toks_joined": "import fabric <NEWLINE> fabricClient = fabric . createClient ( ) <NEWLINE> op = fabricClient . DependencyGraph . createOperator ( <STRING> ) <NEWLINE> op . setEntryPoint ( <STRING> ) <NEWLINE> op . setSourceCode ( <STRING> ) <NEWLINE> binding = fabricClient . DependencyGraph . createBinding ( ) <NEWLINE> binding . setOperator ( op ) <NEWLINE> binding . setParameterLayout ( [ <STRING> ] ) <NEWLINE> node = fabricClient . DependencyGraph . createNode ( <STRING> ) <NEWLINE> node . addMember ( <STRING> , <STRING> ) <NEWLINE> node . bindings . append ( binding ) <NEWLINE> node . setData ( <STRING> , [ 17 ] ) <NEWLINE> print ( node . getErrors ( ) ) <NEWLINE> fabricClient . close ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"op\"", "'entry'", "\"operator entry( io Scalar input[][] ) {}\"", "\"self.input\"", "\"node\"", "\"input\"", "\"Scalar[]\"", "\"input\""]}}], ["061a57935922e03c38934410af237fa2", {"code_string": "def test_previous_after_working_day_end(self):\n    dt = self.utc.localize(datetime.datetime(2016, 1, 25, 18, 00, 0))\n    self.assertEqual(\n        self.workdayrule.previous(dt),\n        (\n            self.utc.localize(datetime.datetime(2016, 1, 25, 9, 0, 0)),\n            self.utc.localize(datetime.datetime(2016, 1, 25, 17, 0, 0)),\n        )\n    )\n", "code_toks_joined": "def test_previous_after_working_day_end ( self ) : <NEWLINE> <INDENT> dt = self . utc . localize ( datetime . datetime ( 2016 , 1 , 25 , 18 , 00 , 0 ) ) <NEWLINE> self . assertEqual ( <NEWLINE> <INDENT> self . workdayrule . previous ( dt ) , <NEWLINE> ( <NEWLINE> <INDENT> self . utc . localize ( datetime . datetime ( 2016 , 1 , 25 , 9 , 0 , 0 ) ) , <NEWLINE> self . utc . localize ( datetime . datetime ( 2016 , 1 , 25 , 17 , 0 , 0 ) ) , <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ef448ced829765e89072e6d09b164307", {"code_string": "import requests\nfrom database import db\nfrom database import db_models\nR = db_models.Rep\n", "code_toks_joined": "import requests <NEWLINE> from database import db <NEWLINE> from database import db_models <NEWLINE> R = db_models . Rep <NEWLINE>", "anonymize_dict": {}}], ["611a6ac084f4cafd2ae49a7d76a96d43", {"code_string": "def do_setup():\n    kwargs = package_data.copy()\n    kwargs['classifiers'] = classifiers\n    kwargs['cmdclass'] = {'build_data': build_data,\n        'install_data': smart_install_data}\n    if sys.version_info >=(3, ):\n        kwargs['cmdclass']['build_py'] = copy_build_py_2to3\n    else:\n        kwargs['cmdclass']['build_py'] = build_py\n    dist = setup(** kwargs)\n    return dist\n", "code_toks_joined": "def do_setup ( ) : <NEWLINE> <INDENT> kwargs = package_data . copy ( ) <NEWLINE> kwargs [ <STRING> ] = classifiers <NEWLINE> kwargs [ <STRING> ] = { <STRING> : build_data , <NEWLINE> <INDENT> <STRING> : smart_install_data } <NEWLINE> <DEDENT> if sys . version_info >= ( 3 , ) : <NEWLINE> <INDENT> kwargs [ <STRING> ] [ <STRING> ] = copy_build_py_2to3 <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> kwargs [ <STRING> ] [ <STRING> ] = build_py <NEWLINE> <DEDENT> dist = setup ( ** kwargs ) <NEWLINE> return dist <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'classifiers'", "'cmdclass'", "'build_data'", "'install_data'", "'cmdclass'", "'build_py'", "'cmdclass'", "'build_py'"]}}], ["c336f433fcc0ea70f86ee663a9188c4b", {"code_string": "def median_absolute_deviation(x, M = None):\n    if M is None:\n        M = np.median(x)\n    return np.median(abs(x - M))\n", "code_toks_joined": "def median_absolute_deviation ( x , M = None ) : <NEWLINE> <INDENT> if M is None : <NEWLINE> <INDENT> M = np . median ( x ) <NEWLINE> <DEDENT> return np . median ( abs ( x - M ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["c8e3b001932dcdc8e1a935f3b5bf353c", {"code_string": "SourceDirPath = \"/data/data1\"\nBackupDirPath = \"/media\"\nimport Tkinter, tkFileDialog, tkMessageBox\nimport subprocess\nimport os\n", "code_toks_joined": "SourceDirPath = <STRING> <NEWLINE> BackupDirPath = <STRING> <NEWLINE> import Tkinter , tkFileDialog , tkMessageBox <NEWLINE> import subprocess <NEWLINE> import os <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"/data/data1\"", "\"/media\""]}}], ["4ea83043e7d55c5490b2854fbd52700a", {"code_string": "from couchpotato.core.helpers.encoding import tryUrlencode\nfrom couchpotato.core.logger import CPLog\nfrom couchpotato.core.event import fireEvent\nfrom couchpotato.core.media._base.providers.torrent.bithdtv import Base\nfrom couchpotato.core.media.movie.providers.base import MovieProvider\nlog = CPLog(__name__)\nautoload = 'BiTHDTV'\n", "code_toks_joined": "from couchpotato . core . helpers . encoding import tryUrlencode <NEWLINE> from couchpotato . core . logger import CPLog <NEWLINE> from couchpotato . core . event import fireEvent <NEWLINE> from couchpotato . core . media . _base . providers . torrent . bithdtv import Base <NEWLINE> from couchpotato . core . media . movie . providers . base import MovieProvider <NEWLINE> log = CPLog ( __name__ ) <NEWLINE> autoload = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'BiTHDTV'"]}}], ["e49a50b8c01d9df36f0f5a6152d72d94", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('payments', '0001_initial'),\n    ]\n    operations = [\n        migrations.AddField(\n            model_name = 'payment',\n            name = 'is_security_token_assigned',\n            field = models.BooleanField(default = False, editable = False, verbose_name = 'is security token used'),\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . AddField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . BooleanField ( default = False , editable = False , verbose_name = <STRING> ) , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'payments'", "'0001_initial'", "'payment'", "'is_security_token_assigned'", "'is security token used'"]}}], ["226eefcb09dda0f4c4c9fc3dd3522ac4", {"code_string": "def redirect_if_authorized(func):\n    \"\"\"Redirects user to the given view (identified by 'view_name' parameter)\"\"\"\n    @ wraps(func)\n    def _decorator(request, * args, ** kwargs):\n        if request.user.is_authenticated():\n            return redirect(settings.LOGIN_REDIRECT_URL)\n        else:\n            return func(request, * args, ** kwargs)\n    return _decorator\n", "code_toks_joined": "def redirect_if_authorized ( func ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> @ wraps ( func ) <NEWLINE> def _decorator ( request , * args , ** kwargs ) : <NEWLINE> <INDENT> if request . user . is_authenticated ( ) : <NEWLINE> <INDENT> return redirect ( settings . LOGIN_REDIRECT_URL ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return func ( request , * args , ** kwargs ) <NEWLINE> <DEDENT> <DEDENT> return _decorator <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Redirects user to the given view (identified by 'view_name' parameter)\"\"\""]}}], ["265752f1a06f1e33b5028d19896d01d0", {"code_string": "class Solution(object):\n    def majorityElement(self, nums):\n        \"\"\":type nums: List[int]\"\"\"\n        hash = {}\n        output = nums[0]\n        for i in range(len(nums)):\n            val = nums[i]\n            if val in hash:\n                hash[val] += 1\n                if hash[val] > len(nums) / 2:\n                    output = val\n                    break\n            else:\n                hash[val] = 1\n        return output\n", "code_toks_joined": "class Solution ( object ) : <NEWLINE> <INDENT> def majorityElement ( self , nums ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> hash = { } <NEWLINE> output = nums [ 0 ] <NEWLINE> for i in range ( len ( nums ) ) : <NEWLINE> <INDENT> val = nums [ i ] <NEWLINE> if val in hash : <NEWLINE> <INDENT> hash [ val ] += 1 <NEWLINE> if hash [ val ] > len ( nums ) / 2 : <NEWLINE> <INDENT> output = val <NEWLINE> break <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> hash [ val ] = 1 <NEWLINE> <DEDENT> <DEDENT> return output <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\":type nums: List[int]\"\"\""]}}], ["faa0707be2705e7e60866f9c8a77c4cf", {"code_string": "\"\"\"Convert an LAS LIDAR file to a shapefile\"\"\"\nimport cPickle\nimport os\nimport time\nimport math\nimport numpy as np\nimport shapefile\nfrom laspy.file import File\nimport voronoi\nsource = \"clippedLAS.las\"\ntarget = \"mesh\"\narchive = \"triangles.p\"\npyshp = \"mesh_pyshp.p\"\n", "code_toks_joined": "<STRING> <NEWLINE> import cPickle <NEWLINE> import os <NEWLINE> import time <NEWLINE> import math <NEWLINE> import numpy as np <NEWLINE> import shapefile <NEWLINE> from laspy . file import File <NEWLINE> import voronoi <NEWLINE> source = <STRING> <NEWLINE> target = <STRING> <NEWLINE> archive = <STRING> <NEWLINE> pyshp = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Convert an LAS LIDAR file to a shapefile\"\"\"", "\"clippedLAS.las\"", "\"mesh\"", "\"triangles.p\"", "\"mesh_pyshp.p\""]}}], ["2239e546ba0f4224e39b098b7729cc54", {"code_string": "\"\"\"testingfun.py\"\"\"\nfrom cdbifunc import *\nfrom cdbfunctions import *\nfrom datetime import date\n", "code_toks_joined": "<STRING> <NEWLINE> from cdbifunc import * <NEWLINE> from cdbfunctions import * <NEWLINE> from datetime import date <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"testingfun.py\"\"\""]}}], ["5c3f620aa5a27ed593faf4d7e1f2c7cf", {"code_string": "\"\"\"Tests for portable filesystem access.\"\"\"\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nimport win32security\nfrom chevah.compat.testing import(\n    mk,\n    TEST_ACCOUNT_GROUP,\n    TEST_DOMAIN,\n    TEST_PDC,\n    TestUser,\n    )\nfrom chevah.compat.testing.testcase import OSAccountFileSystemTestCase\nfrom chevah.compat.tests.mixin.filesystem import SymbolicLinksMixin\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import print_function <NEWLINE> from __future__ import division <NEWLINE> from __future__ import absolute_import <NEWLINE> import win32security <NEWLINE> from chevah . compat . testing import ( <NEWLINE> <INDENT> mk , <NEWLINE> TEST_ACCOUNT_GROUP , <NEWLINE> TEST_DOMAIN , <NEWLINE> TEST_PDC , <NEWLINE> TestUser , <NEWLINE> ) <NEWLINE> <DEDENT> from chevah . compat . testing . testcase import OSAccountFileSystemTestCase <NEWLINE> from chevah . compat . tests . mixin . filesystem import SymbolicLinksMixin <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Tests for portable filesystem access.\"\"\""]}}], ["2e6a968064f42c3dcb9317bf42c839a3", {"code_string": "from anymarkup_core import AnyMarkupError, parse, parse_file, serialize, serialize_file\n__version__ = '0.7.0'\n", "code_toks_joined": "from anymarkup_core import AnyMarkupError , parse , parse_file , serialize , serialize_file <NEWLINE> __version__ = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'0.7.0'"]}}], ["6256ee9a22abbf92c9393f6efc228fba", {"code_string": "def test_anonymous(self):\n    m = mmap.mmap(- 1, PAGESIZE)\n    for x in xrange(PAGESIZE):\n        self.assertEqual(m[x], '\\0', \"anonymously mmap'ed contents should be zero\")\n    for x in xrange(PAGESIZE):\n        m[x] = ch = chr(x & 255)\n        self.assertEqual(m[x], ch)\n", "code_toks_joined": "def test_anonymous ( self ) : <NEWLINE> <INDENT> m = mmap . mmap ( - 1 , PAGESIZE ) <NEWLINE> for x in xrange ( PAGESIZE ) : <NEWLINE> <INDENT> self . assertEqual ( m [ x ] , <STRING> , <STRING> ) <NEWLINE> <DEDENT> for x in xrange ( PAGESIZE ) : <NEWLINE> <INDENT> m [ x ] = ch = chr ( x & 255 ) <NEWLINE> self . assertEqual ( m [ x ] , ch ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'\\0'", "\"anonymously mmap'ed contents should be zero\""]}}], ["b882071255f524abf68c2b0cea75bdad", {"code_string": "from core import httptools\nfrom core import logger\nfrom core import scrapertools\n", "code_toks_joined": "from core import httptools <NEWLINE> from core import logger <NEWLINE> from core import scrapertools <NEWLINE>", "anonymize_dict": {}}], ["fc2c4a3125413bedf7bc5b27cee59154", {"code_string": "def main():\n    set_title(evdh_title)\n    print_free()\n    start_evdh()\n    wait_pause()\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> set_title ( evdh_title ) <NEWLINE> print_free ( ) <NEWLINE> start_evdh ( ) <NEWLINE> wait_pause ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["5892a5c6ec6491b243ccf4f31e2feb14", {"code_string": "\"\"\"Ops for building neural network seq2seq decoders and losses.\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport sys\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import absolute_import <NEWLINE> from __future__ import division <NEWLINE> from __future__ import print_function <NEWLINE> import sys <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Ops for building neural network seq2seq decoders and losses.\"\"\""]}}], ["535bed8901aa77ce0a1f3657cc373290", {"code_string": "class APIClient(Client):\n    def patch(self, path, data = '', content_type = MULTIPART_CONTENT,\n        follow = False, ** extra):\n        return self.generic('PATCH', path, data, content_type, ** extra)\n    def options(self, path, data = '', content_type = MULTIPART_CONTENT,\n        follow = False, ** extra):\n        return self.generic('OPTIONS', path, data, content_type, ** extra)\n", "code_toks_joined": "class APIClient ( Client ) : <NEWLINE> <INDENT> def patch ( self , path , data = <STRING> , content_type = MULTIPART_CONTENT , <NEWLINE> <INDENT> follow = False , ** extra ) : <NEWLINE> return self . generic ( <STRING> , path , data , content_type , ** extra ) <NEWLINE> <DEDENT> def options ( self , path , data = <STRING> , content_type = MULTIPART_CONTENT , <NEWLINE> <INDENT> follow = False , ** extra ) : <NEWLINE> return self . generic ( <STRING> , path , data , content_type , ** extra ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["''", "'PATCH'", "''", "'OPTIONS'"]}}], ["fff28b46ec96f8012aa245abcd76bbbf", {"code_string": "def fail_test(sock, handle, thing):\n    print('ERROR: recv(' + str(thing) + ') blocked')\n    sock.close()\n    stopcomm(handle)\n    mycontext['keep_testing'] = False\n    exitall()\n", "code_toks_joined": "def fail_test ( sock , handle , thing ) : <NEWLINE> <INDENT> print ( <STRING> + str ( thing ) + <STRING> ) <NEWLINE> sock . close ( ) <NEWLINE> stopcomm ( handle ) <NEWLINE> mycontext [ <STRING> ] = False <NEWLINE> exitall ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'ERROR: recv('", "') blocked'", "'keep_testing'"]}}], ["6bb457d2091a517b68b2733d17c5f85a", {"code_string": "def handle_endtag(self, tag):\n    if tag == 'td' or tag == 'a':\n        self.starting = False\n", "code_toks_joined": "def handle_endtag ( self , tag ) : <NEWLINE> <INDENT> if tag == <STRING> or tag == <STRING> : <NEWLINE> <INDENT> self . starting = False <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'td'", "'a'"]}}], ["bcc883cf149c2c1f012a5a11dc570983", {"code_string": "import tensorflow as tf\nv1 = tf.Variable(tf.constant(1.0, shape = [1]), name = 'v1')\nv2 = tf.Variable(tf.constant(2.0, shape = [1]), name = 'v2')\nresult = v1 + v2\ninit_op = tf.global_variables_initializer()\nsaver = tf.train.Saver()\nwith tf.Session() as sess:\n    sess.run(init_op)\n    saver.save(sess, \"Saved_model/model.ckpt\")\n", "code_toks_joined": "import tensorflow as tf <NEWLINE> v1 = tf . Variable ( tf . constant ( 1.0 , shape = [ 1 ] ) , name = <STRING> ) <NEWLINE> v2 = tf . Variable ( tf . constant ( 2.0 , shape = [ 1 ] ) , name = <STRING> ) <NEWLINE> result = v1 + v2 <NEWLINE> init_op = tf . global_variables_initializer ( ) <NEWLINE> saver = tf . train . Saver ( ) <NEWLINE> with tf . Session ( ) as sess : <NEWLINE> <INDENT> sess . run ( init_op ) <NEWLINE> saver . save ( sess , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'v1'", "'v2'", "\"Saved_model/model.ckpt\""]}}], ["8e53118b7d6d1fb438313d62024c40bf", {"code_string": "def get_pydoc_text(module):\n    \"Returns pydoc generated output as text\"\n    doc = pydoc.TextDoc()\n    loc = doc.getdocloc(pydoc_mod) or \"\"\n    if loc:\n        loc = \"\\nMODULE DOCS\\n    \" + loc + \"\\n\"\n    output = doc.docmodule(module)\n    patt = re.compile('\\b.')\n    output = patt.sub('', output)\n    return output.strip(), loc\n", "code_toks_joined": "def get_pydoc_text ( module ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> doc = pydoc . TextDoc ( ) <NEWLINE> loc = doc . getdocloc ( pydoc_mod ) or <STRING> <NEWLINE> if loc : <NEWLINE> <INDENT> loc = <STRING> + loc + <STRING> <NEWLINE> <DEDENT> output = doc . docmodule ( module ) <NEWLINE> patt = re . compile ( <STRING> ) <NEWLINE> output = patt . sub ( <STRING> , output ) <NEWLINE> return output . strip ( ) , loc <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Returns pydoc generated output as text\"", "\"\"", "\"\\nMODULE DOCS\\n    \"", "\"\\n\"", "'\\b.'", "''"]}}], ["c5837c6b4d35d9fd33a7fa5b92e0e85b", {"code_string": "def createHTML(self, outputFile, algData):\n    with codecs.open(outputFile, 'w', encoding = 'utf-8') as f:\n        f.write('<html><head>')\n        f.write('<meta http-equiv=\"Content-Type\" content=\"text/html;  charset=utf-8\" /></head><body>')\n        f.write(self.tr('<p>Total unique values: ') + str(len(algData)) + '</p>')\n        f.write(self.tr('<p>Unique values:</p>'))\n        f.write('<ul>')\n        for s in algData:\n            f.write('<li>' + str(s) + '</li>')\n        f.write('</ul></body></html>')\n", "code_toks_joined": "def createHTML ( self , outputFile , algData ) : <NEWLINE> <INDENT> with codecs . open ( outputFile , <STRING> , encoding = <STRING> ) as f : <NEWLINE> <INDENT> f . write ( <STRING> ) <NEWLINE> f . write ( <STRING> ) <NEWLINE> f . write ( self . tr ( <STRING> ) + str ( len ( algData ) ) + <STRING> ) <NEWLINE> f . write ( self . tr ( <STRING> ) ) <NEWLINE> f . write ( <STRING> ) <NEWLINE> for s in algData : <NEWLINE> <INDENT> f . write ( <STRING> + str ( s ) + <STRING> ) <NEWLINE> <DEDENT> f . write ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'w'", "'utf-8'", "'<html><head>'", "'<meta http-equiv=\"Content-Type\" content=\"text/html;  charset=utf-8\" /></head><body>'", "'<p>Total unique values: '", "'</p>'", "'<p>Unique values:</p>'", "'<ul>'", "'<li>'", "'</li>'", "'</ul></body></html>'"]}}], ["a27e5c61fbbce2ebb4471d27bdba31d5", {"code_string": "def get_data_from_quickbooks_where(self, where):\n    query = \"SELECT \" + self.build_quickbooks_select_fields() + \" FROM \" + self.qodbc_table + \" WHERE \" + where\n    return self.qodbc.query(query)\n", "code_toks_joined": "def get_data_from_quickbooks_where ( self , where ) : <NEWLINE> <INDENT> query = <STRING> + self . build_quickbooks_select_fields ( ) + <STRING> + self . qodbc_table + <STRING> + where <NEWLINE> return self . qodbc . query ( query ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"SELECT \"", "\" FROM \"", "\" WHERE \""]}}], ["20694123c506d3486aecbdb174a811f9", {"code_string": "class HookSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = Hook\n        read_only_fields = ('user', )\n", "code_toks_joined": "class HookSerializer ( serializers . ModelSerializer ) : <NEWLINE> <INDENT> class Meta : <NEWLINE> <INDENT> model = Hook <NEWLINE> read_only_fields = ( <STRING> , ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'user'"]}}], ["7ee19029485cb5f1f20717ab08f5e721", {"code_string": "\"\"\"Created on Sun Mar 30 13:05:14 2014\"\"\"\nfrom __future__ import print_function\nimport logging\nimport sys\nimport os\nimport cPickle\nimport numpy as np\nfrom scipy.sparse import dok_matrix\nfrom scipy.io import mmwrite, mmread\nimport text_entail.dictionary as td\nimport text_entail.io as tio\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import print_function <NEWLINE> import logging <NEWLINE> import sys <NEWLINE> import os <NEWLINE> import cPickle <NEWLINE> import numpy as np <NEWLINE> from scipy . sparse import dok_matrix <NEWLINE> from scipy . io import mmwrite , mmread <NEWLINE> import text_entail . dictionary as td <NEWLINE> import text_entail . io as tio <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Created on Sun Mar 30 13:05:14 2014\"\"\""]}}], ["109d24dedf1c9fd7406269e59736d407", {"code_string": "import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\nfrom gi.repository import Gdk\nfrom gi.repository import GObject\nimport logging\nfrom gettext import gettext as _\nfrom Editing_View import Editing_View\nfrom Gallery_View import Gallery_View\nfrom infoslicer.processing.Article import Article\nlogger = logging.getLogger('infoslicer')\n", "code_toks_joined": "import gi <NEWLINE> gi . require_version ( <STRING> , <STRING> ) <NEWLINE> from gi . repository import Gtk <NEWLINE> from gi . repository import Gdk <NEWLINE> from gi . repository import GObject <NEWLINE> import logging <NEWLINE> from gettext import gettext as _ <NEWLINE> from Editing_View import Editing_View <NEWLINE> from Gallery_View import Gallery_View <NEWLINE> from infoslicer . processing . Article import Article <NEWLINE> logger = logging . getLogger ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'Gtk'", "'3.0'", "'infoslicer'"]}}], ["0618efa289de53050b72ae0c8d771550", {"code_string": "import urllib\nusername = 'aj4vd'\npassword = 'oogabooga'\nsession = ''\n", "code_toks_joined": "import urllib <NEWLINE> username = <STRING> <NEWLINE> password = <STRING> <NEWLINE> session = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'aj4vd'", "'oogabooga'", "''"]}}], ["e46f9c26fcaaf02d4dde88397c18c8c2", {"code_string": "def _get_persistent_cmd(self, attr_name, cmd_name, * args, ** kwargs):\n    cur_val = getattr(self, attr_name)\n    if cur_val is not None:\n        return cur_val\n    options = {\"istream\": PIPE, \"as_process\": True}\n    options.update(kwargs)\n    cmd = self._call_process(cmd_name, * args, ** options)\n    setattr(self, attr_name, cmd)\n    return cmd\n", "code_toks_joined": "def _get_persistent_cmd ( self , attr_name , cmd_name , * args , ** kwargs ) : <NEWLINE> <INDENT> cur_val = getattr ( self , attr_name ) <NEWLINE> if cur_val is not None : <NEWLINE> <INDENT> return cur_val <NEWLINE> <DEDENT> options = { <STRING> : PIPE , <STRING> : True } <NEWLINE> options . update ( kwargs ) <NEWLINE> cmd = self . _call_process ( cmd_name , * args , ** options ) <NEWLINE> setattr ( self , attr_name , cmd ) <NEWLINE> return cmd <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"istream\"", "\"as_process\""]}}], ["9824e0aaad2f5f3aef9b360243237b4a", {"code_string": "def get_os_full_version(self):\n    \"\"\"This is an auto-generated method for the PySwitchLib.\"\"\"\n    return self._os_full_ver\n", "code_toks_joined": "def get_os_full_version ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . _os_full_ver <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"This is an auto-generated method for the PySwitchLib.\"\"\""]}}], ["b3c28bb1fa60d6b75b9720af0338d416", {"code_string": "from.import ux\nfrom.import autoimport\nfrom.loggers import Loggers\n", "code_toks_joined": "from . import ux <NEWLINE> from . import autoimport <NEWLINE> from . loggers import Loggers <NEWLINE>", "anonymize_dict": {}}], ["f4ee3404b2db126965ea78d76bac26cd", {"code_string": "from __future__ import unicode_literals, division, absolute_import\nimport logging\nimport re\nfrom flexget import plugin\nfrom flexget.event import event\nfrom flexget.utils.cached_input import cached\nfrom flexget.entry import Entry\nfrom flexget.utils.soup import get_soup\nlog = logging.getLogger('anidb_list')\nUSER_ID_RE = r'^\\d{1,6}$'\n", "code_toks_joined": "from __future__ import unicode_literals , division , absolute_import <NEWLINE> import logging <NEWLINE> import re <NEWLINE> from flexget import plugin <NEWLINE> from flexget . event import event <NEWLINE> from flexget . utils . cached_input import cached <NEWLINE> from flexget . entry import Entry <NEWLINE> from flexget . utils . soup import get_soup <NEWLINE> log = logging . getLogger ( <STRING> ) <NEWLINE> USER_ID_RE = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'anidb_list'", "r'^\\d{1,6}$'"]}}], ["0e4f3e1dc6e626f495c9cfa6bf887490", {"code_string": "def __getstate__(self):\n    newdict = super(WorkflowWorker, self).__getstate__()\n    del newdict['_workflows']\n    return newdict\n", "code_toks_joined": "def __getstate__ ( self ) : <NEWLINE> <INDENT> newdict = super ( WorkflowWorker , self ) . __getstate__ ( ) <NEWLINE> del newdict [ <STRING> ] <NEWLINE> return newdict <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'_workflows'"]}}], ["10ea4c9b8b0bcd6d6784f6b7c3d6847e", {"code_string": "def setUp(self):\n    super(AutoscalingLoadBalancerv2Test, self).setUp()\n    self.template_name = 'test_autoscaling_lbv2_neutron.yaml'\n    self.app_server_template_name = 'app_server_lbv2_neutron.yaml'\n    self.webapp_template_name = 'netcat-webapp.yaml'\n    if not self.is_network_extension_supported('lbaasv2'):\n        self.skipTest('LBaasv2 extension not available, skipping')\n", "code_toks_joined": "def setUp ( self ) : <NEWLINE> <INDENT> super ( AutoscalingLoadBalancerv2Test , self ) . setUp ( ) <NEWLINE> self . template_name = <STRING> <NEWLINE> self . app_server_template_name = <STRING> <NEWLINE> self . webapp_template_name = <STRING> <NEWLINE> if not self . is_network_extension_supported ( <STRING> ) : <NEWLINE> <INDENT> self . skipTest ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'test_autoscaling_lbv2_neutron.yaml'", "'app_server_lbv2_neutron.yaml'", "'netcat-webapp.yaml'", "'lbaasv2'", "'LBaasv2 extension not available, skipping'"]}}], ["7cd53f5a5398a49ac38afa86f018cf0c", {"code_string": "__doc__ = \"\"\"OracleSrvInst\"\"\"\n__version__ = \"$Revision: 1.0 $\"[11: - 2]\nfrom Globals import InitializeClass\nfrom Products.ZenModel.ZenossSecurity import *\nfrom ZenPacks.community.RDBMS.DBSrvInst import DBSrvInst\n", "code_toks_joined": "__doc__ = <STRING> <NEWLINE> __version__ = <STRING> [ 11 : - 2 ] <NEWLINE> from Globals import InitializeClass <NEWLINE> from Products . ZenModel . ZenossSecurity import * <NEWLINE> from ZenPacks . community . RDBMS . DBSrvInst import DBSrvInst <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"OracleSrvInst\"\"\"", "\"$Revision: 1.0 $\""]}}], ["4adb0b7eb71e82f32a40f02a5627003d", {"code_string": "c = get_config()\nc.NotebookApp.ip = '192.168.10.150'\nc.NotebookApp.open_browser = False\nc.NotebookApp.port = 8880\nimport os\nimport sys\nspark_home = os.environ.get('SPARK_HOME', None)\nif not spark_home:\n    raise ValueError('SPARK_HOME environment variable is not set')\nos.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-csv_2.11:1.4.0 --master local[*] --driver-memory 12g --num-executors 2 --executor-cores 2 --executor-memory 12g  pyspark-shell'\nos.environ['HADOOP_CONF_DIR'] = '/home/shlomo/dev/'\nsys.path.insert(0, os.path.join(spark_home, 'python'))\nsys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.9-src.zip'))\n", "code_toks_joined": "c = get_config ( ) <NEWLINE> c . NotebookApp . ip = <STRING> <NEWLINE> c . NotebookApp . open_browser = False <NEWLINE> c . NotebookApp . port = 8880 <NEWLINE> import os <NEWLINE> import sys <NEWLINE> spark_home = os . environ . get ( <STRING> , None ) <NEWLINE> if not spark_home : <NEWLINE> <INDENT> raise ValueError ( <STRING> ) <NEWLINE> <DEDENT> os . environ [ <STRING> ] = <STRING> <NEWLINE> os . environ [ <STRING> ] = <STRING> <NEWLINE> sys . path . insert ( 0 , os . path . join ( spark_home , <STRING> ) ) <NEWLINE> sys . path . insert ( 0 , os . path . join ( spark_home , <STRING> ) ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'192.168.10.150'", "'SPARK_HOME'", "'SPARK_HOME environment variable is not set'", "'PYSPARK_SUBMIT_ARGS'", "'--packages com.databricks:spark-csv_2.11:1.4.0 --master local[*] --driver-memory 12g --num-executors 2 --executor-cores 2 --executor-memory 12g  pyspark-shell'", "'HADOOP_CONF_DIR'", "'/home/shlomo/dev/'", "'python'", "'python/lib/py4j-0.9-src.zip'"]}}], ["e10ee3dddb2027907b024ad01e802387", {"code_string": "import numpy as np\nimport sys\nfrom utils import logging\n", "code_toks_joined": "import numpy as np <NEWLINE> import sys <NEWLINE> from utils import logging <NEWLINE>", "anonymize_dict": {}}], ["9beb8ca609a513e82fd7fe3fa04fff69", {"code_string": "from django.conf.urls import patterns, url\nfrom views import *\nurlpatterns = patterns('',\n    url(r'playlists/$', playlists, name = \"youtube-playlists\"),\n    url(r'videos/(?P<playlist>.*)/$', videos, name = \"youtube-videos\"),\n)\n", "code_toks_joined": "from django . conf . urls import patterns , url <NEWLINE> from views import * <NEWLINE> urlpatterns = patterns ( <STRING> , <NEWLINE> <INDENT> url ( <STRING> , playlists , name = <STRING> ) , <NEWLINE> url ( <STRING> , videos , name = <STRING> ) , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["''", "r'playlists/$'", "\"youtube-playlists\"", "r'videos/(?P<playlist>.*)/$'", "\"youtube-videos\""]}}], ["6240a6cf4b6bcbda31f3ee6b562e21ab", {"code_string": "\"\"\"Main program for running keyboard agent without annoying malmo stuff :)\"\"\"\n__author__ = \"Liyan Chen\"\n__copyright__ = \"Copyright (c) 2017 Malmactor\"\n__license__ = \"MIT\"\nimport Agent as AG\nimport SuperMarioBros as SMB\nimport Utility as UT\nconfig = SMB.simulation_config\nconfig.update(SMB.render_config)\nlayout = SMB.layout_fromdefault()\nrender = UT.TKRender(layout, config = config)\nsimulation = SMB.MarioSimulation(layout, config = config)\nkeypoller = SMB.KeyPoller()\nAG.keyboard_agent(simulation, keypoller, render, config = config)\n", "code_toks_joined": "<STRING> <NEWLINE> __author__ = <STRING> <NEWLINE> __copyright__ = <STRING> <NEWLINE> __license__ = <STRING> <NEWLINE> import Agent as AG <NEWLINE> import SuperMarioBros as SMB <NEWLINE> import Utility as UT <NEWLINE> config = SMB . simulation_config <NEWLINE> config . update ( SMB . render_config ) <NEWLINE> layout = SMB . layout_fromdefault ( ) <NEWLINE> render = UT . TKRender ( layout , config = config ) <NEWLINE> simulation = SMB . MarioSimulation ( layout , config = config ) <NEWLINE> keypoller = SMB . KeyPoller ( ) <NEWLINE> AG . keyboard_agent ( simulation , keypoller , render , config = config ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Main program for running keyboard agent without annoying malmo stuff :)\"\"\"", "\"Liyan Chen\"", "\"Copyright (c) 2017 Malmactor\"", "\"MIT\""]}}], ["d339db50962fbc923882d240186c0a6d", {"code_string": "def custom_signup(self, request, user):\n    custom_form = super(BaseSignupForm, self)\n    if hasattr(custom_form, 'signup') and callable(custom_form.signup):\n        custom_form.signup(request, user)\n    else:\n        warnings.warn(\"The custom signup form must offer\"\n            \" a `def signup(self, request, user)` method\",\n            DeprecationWarning)\n        custom_form.save(user)\n", "code_toks_joined": "def custom_signup ( self , request , user ) : <NEWLINE> <INDENT> custom_form = super ( BaseSignupForm , self ) <NEWLINE> if hasattr ( custom_form , <STRING> ) and callable ( custom_form . signup ) : <NEWLINE> <INDENT> custom_form . signup ( request , user ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> warnings . warn ( <STRING> <NEWLINE> <INDENT> <STRING> , <NEWLINE> DeprecationWarning ) <NEWLINE> <DEDENT> custom_form . save ( user ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'signup'", "\"The custom signup form must offer\"", "\" a `def signup(self, request, user)` method\""]}}], ["f778dbfd6329f82999ae928898ef6436", {"code_string": "def testGEQOver(self):\n    var1, var2, var3 = (Variable(list(range(0, 3))) for x in range(0, 3))\n    model = NativeModel()\n    model.add_constraint(var1 >= var2)\n    model.add_constraint(var2 >= var3)\n    model.add_constraint(var1 >= var3)\n    solver = Solver(model)\n    assert(solver.solve())\n", "code_toks_joined": "def testGEQOver ( self ) : <NEWLINE> <INDENT> var1 , var2 , var3 = ( Variable ( list ( range ( 0 , 3 ) ) ) for x in range ( 0 , 3 ) ) <NEWLINE> model = NativeModel ( ) <NEWLINE> model . add_constraint ( var1 >= var2 ) <NEWLINE> model . add_constraint ( var2 >= var3 ) <NEWLINE> model . add_constraint ( var1 >= var3 ) <NEWLINE> solver = Solver ( model ) <NEWLINE> assert ( solver . solve ( ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["d52ea96550c90707e493f259303f4d49", {"code_string": "def source_writer(self, buffered = True):\n    '''Returns source index writer (by default buffered).'''\n    if not buffered:\n        return self.source().writer()\n    if self._source_writer is None:\n        self._source_writer = BufferedWriter(self.source())\n    return self._source_writer\n", "code_toks_joined": "def source_writer ( self , buffered = True ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if not buffered : <NEWLINE> <INDENT> return self . source ( ) . writer ( ) <NEWLINE> <DEDENT> if self . _source_writer is None : <NEWLINE> <INDENT> self . _source_writer = BufferedWriter ( self . source ( ) ) <NEWLINE> <DEDENT> return self . _source_writer <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Returns source index writer (by default buffered).'''"]}}], ["ef9548a9fc5cef1c8442fa350e25d644", {"code_string": "from __future__ import print_function\nfrom pybel.constants import HAS_PRODUCT, HAS_REACTANT, HAS_VARIANT, HAS_COMPONENT, TRANSCRIBED_TO, TRANSLATED_TO\nIS_PRODUCT_OF = 'isProductOf'\nIS_REACTANT_OF = 'isReactantOf'\nIS_VARIANT_OF = 'isVariantOf'\nIS_COMPONENT_OF = 'isComponentOf'\nTRANSCRIBED_FROM = 'transcribedFrom'\nTRANSLATED_FROM = 'translatedFrom'\nINFERRED_INVERSE = {\n    HAS_PRODUCT: IS_PRODUCT_OF,\n    HAS_REACTANT: IS_REACTANT_OF,\n    HAS_VARIANT: IS_VARIANT_OF,\n    HAS_COMPONENT: IS_COMPONENT_OF,\n    TRANSCRIBED_TO: TRANSCRIBED_FROM,\n    TRANSLATED_TO: TRANSLATED_FROM\n}\nabstract_url_fmt = \"http://togows.dbcls.jp/entry/ncbi-pubmed/{}/abstract\"\ntitle_url_fmt = \"http://togows.dbcls.jp/entry/ncbi-pubmed/{}/title\"\nso_url_fmt = \"http://togows.dbcls.jp/entry/ncbi-pubmed/{}/so\"\ncitation_format = 'SET Citation = {{\"PubMed\",\"{}\",\"{}\"}}'\nevidence_format = 'SET Evidence = \"{}\"'\n", "code_toks_joined": "from __future__ import print_function <NEWLINE> from pybel . constants import HAS_PRODUCT , HAS_REACTANT , HAS_VARIANT , HAS_COMPONENT , TRANSCRIBED_TO , TRANSLATED_TO <NEWLINE> IS_PRODUCT_OF = <STRING> <NEWLINE> IS_REACTANT_OF = <STRING> <NEWLINE> IS_VARIANT_OF = <STRING> <NEWLINE> IS_COMPONENT_OF = <STRING> <NEWLINE> TRANSCRIBED_FROM = <STRING> <NEWLINE> TRANSLATED_FROM = <STRING> <NEWLINE> INFERRED_INVERSE = { <NEWLINE> <INDENT> HAS_PRODUCT : IS_PRODUCT_OF , <NEWLINE> HAS_REACTANT : IS_REACTANT_OF , <NEWLINE> HAS_VARIANT : IS_VARIANT_OF , <NEWLINE> HAS_COMPONENT : IS_COMPONENT_OF , <NEWLINE> TRANSCRIBED_TO : TRANSCRIBED_FROM , <NEWLINE> TRANSLATED_TO : TRANSLATED_FROM <NEWLINE> <DEDENT> } <NEWLINE> abstract_url_fmt = <STRING> <NEWLINE> title_url_fmt = <STRING> <NEWLINE> so_url_fmt = <STRING> <NEWLINE> citation_format = <STRING> <NEWLINE> evidence_format = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'isProductOf'", "'isReactantOf'", "'isVariantOf'", "'isComponentOf'", "'transcribedFrom'", "'translatedFrom'", "\"http://togows.dbcls.jp/entry/ncbi-pubmed/{}/abstract\"", "\"http://togows.dbcls.jp/entry/ncbi-pubmed/{}/title\"", "\"http://togows.dbcls.jp/entry/ncbi-pubmed/{}/so\"", "'SET Citation = {{\"PubMed\",\"{}\",\"{}\"}}'", "'SET Evidence = \"{}\"'"]}}], ["94223b86eb02a3d2d35b1fb19ff7f15d", {"code_string": "def get_hash(__arcfile, __hashtype):\n    '''return the hash of a file.'''\n    __res = getattr(hashlib, __hashtype)(__arcfile.read()).hexdigest()\n    __arcfile.close()\n    return __res\n", "code_toks_joined": "def get_hash ( __arcfile , __hashtype ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> __res = getattr ( hashlib , __hashtype ) ( __arcfile . read ( ) ) . hexdigest ( ) <NEWLINE> __arcfile . close ( ) <NEWLINE> return __res <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''return the hash of a file.'''"]}}], ["9adf5bb112b125cb3af70662ac987748", {"code_string": "from sqlalchemy import create_engine, Column, BigInteger, Boolean\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\nBase = declarative_base()\n", "code_toks_joined": "from sqlalchemy import create_engine , Column , BigInteger , Boolean <NEWLINE> from sqlalchemy . ext . declarative import declarative_base <NEWLINE> from sqlalchemy . orm import sessionmaker <NEWLINE> Base = declarative_base ( ) <NEWLINE>", "anonymize_dict": {}}], ["58b41dc1b4654fa2711aa0c471cdcbd8", {"code_string": "def setUp(self):\n    super(PostgreSQLTestBase, self).setUp()\n    if not self.__class__._is_postgres:\n        raise unittest.SkipTest('Postgres tests are disabled.')\n", "code_toks_joined": "def setUp ( self ) : <NEWLINE> <INDENT> super ( PostgreSQLTestBase , self ) . setUp ( ) <NEWLINE> if not self . __class__ . _is_postgres : <NEWLINE> <INDENT> raise unittest . SkipTest ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Postgres tests are disabled.'"]}}], ["52f39a4af9ff82c5c8e00cb5d043679c", {"code_string": "from spyre import server\nimport pandas as pd\nimport numpy as np\nfrom bokeh import resources as r\nfrom bokeh.resources import CDN\nfrom bokeh.embed import components\nfrom bokeh.plotting import line\nfrom bokeh.sampledata import us_counties, unemployment\nfrom bokeh.plotting import *\nfrom bokeh.objects import HoverTool\nfrom collections import OrderedDict\n", "code_toks_joined": "from spyre import server <NEWLINE> import pandas as pd <NEWLINE> import numpy as np <NEWLINE> from bokeh import resources as r <NEWLINE> from bokeh . resources import CDN <NEWLINE> from bokeh . embed import components <NEWLINE> from bokeh . plotting import line <NEWLINE> from bokeh . sampledata import us_counties , unemployment <NEWLINE> from bokeh . plotting import * <NEWLINE> from bokeh . objects import HoverTool <NEWLINE> from collections import OrderedDict <NEWLINE>", "anonymize_dict": {}}], ["4aa9041013ad0bdd444dbfde4e6643bc", {"code_string": "import paramiko\nfrom getpass import getpass\nip_addr = raw_input(\"Enter IP Address:  \")\nusername = raw_input(\"Enter username:  \")\nprint(\"Enter password:  \")\npassword = getpass()\nremote_conn_pre = paramiko.SSHClient()\nremote_conn_pre.load_host_keys('/home/scotth/.ssh/known_hosts')\nremote_conn_pre.connect(ip_addr, username = username, password = password,\n    look_for_keys = False, allow_agent = False)\nremote_conn = remote_conn_pre.invoke_shell()\nremote_conn.settimeout(4.0)\n", "code_toks_joined": "import paramiko <NEWLINE> from getpass import getpass <NEWLINE> ip_addr = raw_input ( <STRING> ) <NEWLINE> username = raw_input ( <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> password = getpass ( ) <NEWLINE> remote_conn_pre = paramiko . SSHClient ( ) <NEWLINE> remote_conn_pre . load_host_keys ( <STRING> ) <NEWLINE> remote_conn_pre . connect ( ip_addr , username = username , password = password , <NEWLINE> <INDENT> look_for_keys = False , allow_agent = False ) <NEWLINE> <DEDENT> remote_conn = remote_conn_pre . invoke_shell ( ) <NEWLINE> remote_conn . settimeout ( 4.0 ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"Enter IP Address:  \"", "\"Enter username:  \"", "\"Enter password:  \"", "'/home/scotth/.ssh/known_hosts'"]}}], ["a2cc4c35d10482eeff31e9d84acfbbba", {"code_string": "from.import(\n    csv,\n    fwt,\n    json,\n    onelinejson,\n    xml,\n    yaml,\n    sqlalchemy,\n    excel\n)\n", "code_toks_joined": "from . import ( <NEWLINE> <INDENT> csv , <NEWLINE> fwt , <NEWLINE> json , <NEWLINE> onelinejson , <NEWLINE> xml , <NEWLINE> yaml , <NEWLINE> sqlalchemy , <NEWLINE> excel <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {}}], ["b3c77f2105f4923b6622ebe51143a071", {"code_string": "def __init__(self, expression, start_pos, end_pos, text):\n    \"\"\"Initialize the class with specific expression, starting position, end position\"\"\"\n    self.__expr = expression\n    self.__s_pos = start_pos\n    self.__e_pos = end_pos\n    self.__txt = text\n", "code_toks_joined": "def __init__ ( self , expression , start_pos , end_pos , text ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . __expr = expression <NEWLINE> self . __s_pos = start_pos <NEWLINE> self . __e_pos = end_pos <NEWLINE> self . __txt = text <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Initialize the class with specific expression, starting position, end position\"\"\""]}}], ["3c3b567fa3663d044d8e37d1c4e33540", {"code_string": "def log(logt, * text):\n    print(\"%s:  %s\" %(logt, ' '.join(text)))\n    Log(logt).append(* text)\n", "code_toks_joined": "def log ( logt , * text ) : <NEWLINE> <INDENT> print ( <STRING> % ( logt , <STRING> . join ( text ) ) ) <NEWLINE> Log ( logt ) . append ( * text ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"%s:  %s\"", "' '"]}}], ["18eccc9f8600692c31690b75b71fe129", {"code_string": "u\"\"\"\u0420\u0435\u0433\u0438\u0441\u0442\u0440\u0430\u0446\u0438\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\u043e\u0432 url-\u0430\u0434\u0440\u0435\u0441\u043e\u0432 \u0434\u043b\u044f django.\"\"\"\nimport django\nif django.get_version() < '1.4':\n    from django.conf.urls.defaults import patterns, url\nelse:\n    from django.conf.urls import patterns, url\nfrom ssosp.views import sso_acs, sso_login, sso_logout\nurlpatterns = patterns('',\n    url(r'^acs/$', sso_acs, name = \"acs\"),\n    url(r'^login/$', sso_login, name = \"login\"),\n    url(r'^logout/$', sso_logout, name = \"logout\"),\n)\n", "code_toks_joined": "<STRING> <NEWLINE> import django <NEWLINE> if django . get_version ( ) < <STRING> : <NEWLINE> <INDENT> from django . conf . urls . defaults import patterns , url <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> from django . conf . urls import patterns , url <NEWLINE> <DEDENT> from ssosp . views import sso_acs , sso_login , sso_logout <NEWLINE> urlpatterns = patterns ( <STRING> , <NEWLINE> <INDENT> url ( <STRING> , sso_acs , name = <STRING> ) , <NEWLINE> url ( <STRING> , sso_login , name = <STRING> ) , <NEWLINE> url ( <STRING> , sso_logout , name = <STRING> ) , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["u\"\"\"\u0420\u0435\u0433\u0438\u0441\u0442\u0440\u0430\u0446\u0438\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\u043e\u0432 url-\u0430\u0434\u0440\u0435\u0441\u043e\u0432 \u0434\u043b\u044f django.\"\"\"", "'1.4'", "''", "r'^acs/$'", "\"acs\"", "r'^login/$'", "\"login\"", "r'^logout/$'", "\"logout\""]}}], ["fedcf16f321c5db799d2265ddb85a1e2", {"code_string": "def fale_conosco(request):\n    email_enviado = False\n    if request.method == 'POST':\n        form = FaleConoscoForm(request.POST)\n        if form.is_valid():\n            human = True\n            form.enviar()\n            email_enviado = True\n            form = FaleConoscoForm()\n    else:\n        form = FaleConoscoForm()\n    return render_to_response('blog/fale-conosco.html', locals(), context_instance = RequestContext(request))\n", "code_toks_joined": "def fale_conosco ( request ) : <NEWLINE> <INDENT> email_enviado = False <NEWLINE> if request . method == <STRING> : <NEWLINE> <INDENT> form = FaleConoscoForm ( request . POST ) <NEWLINE> if form . is_valid ( ) : <NEWLINE> <INDENT> human = True <NEWLINE> form . enviar ( ) <NEWLINE> email_enviado = True <NEWLINE> form = FaleConoscoForm ( ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> form = FaleConoscoForm ( ) <NEWLINE> <DEDENT> return render_to_response ( <STRING> , locals ( ) , context_instance = RequestContext ( request ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'POST'", "'blog/fale-conosco.html'"]}}], ["b3bdaf61dbe559870f3bbcac7a0579a9", {"code_string": "def _exit_code(self):\n    try:\n        main(Arguments)\n    except SystemExit as e:\n        return e.code\n", "code_toks_joined": "def _exit_code ( self ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> main ( Arguments ) <NEWLINE> <DEDENT> except SystemExit as e : <NEWLINE> <INDENT> return e . code <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["f04dd37641c03e5c255621ef66beb870", {"code_string": "def __setitem__(self, key, value):\n    assert(key not in self.thedict)\n    self.thedict[key] = value\n", "code_toks_joined": "def __setitem__ ( self , key , value ) : <NEWLINE> <INDENT> assert ( key not in self . thedict ) <NEWLINE> self . thedict [ key ] = value <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["60e2f8736d70ef5efaa5871827fd0685", {"code_string": "class ClientTest(utils.TestCase):\n    def test_get_client_class_v1(self):\n        output = cinderclient.client.get_client_class('1')\n        self.assertEqual(output, cinderclient.v1.client.Client)\n    def test_get_client_class_v2(self):\n        output = cinderclient.client.get_client_class('2')\n        self.assertEqual(output, cinderclient.v2.client.Client)\n    def test_get_client_class_unknown(self):\n        self.assertRaises(cinderclient.exceptions.UnsupportedVersion,\n            cinderclient.client.get_client_class, '0')\n", "code_toks_joined": "class ClientTest ( utils . TestCase ) : <NEWLINE> <INDENT> def test_get_client_class_v1 ( self ) : <NEWLINE> <INDENT> output = cinderclient . client . get_client_class ( <STRING> ) <NEWLINE> self . assertEqual ( output , cinderclient . v1 . client . Client ) <NEWLINE> <DEDENT> def test_get_client_class_v2 ( self ) : <NEWLINE> <INDENT> output = cinderclient . client . get_client_class ( <STRING> ) <NEWLINE> self . assertEqual ( output , cinderclient . v2 . client . Client ) <NEWLINE> <DEDENT> def test_get_client_class_unknown ( self ) : <NEWLINE> <INDENT> self . assertRaises ( cinderclient . exceptions . UnsupportedVersion , <NEWLINE> <INDENT> cinderclient . client . get_client_class , <STRING> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'1'", "'2'", "'0'"]}}], ["620df66123a6657492258a02caf26b05", {"code_string": "def __error(self):\n    try:\n        content = \"Invalid request\"\n        self.send_response(500)\n        self.send_header(\"Content-length\", len(content))\n        self.send_header(\"Content-type\", \"text/plain\")\n        self.end_headers()\n        self.wfile.write(content)\n    except:\n        pass\n", "code_toks_joined": "def __error ( self ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> content = <STRING> <NEWLINE> self . send_response ( 500 ) <NEWLINE> self . send_header ( <STRING> , len ( content ) ) <NEWLINE> self . send_header ( <STRING> , <STRING> ) <NEWLINE> self . end_headers ( ) <NEWLINE> self . wfile . write ( content ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Invalid request\"", "\"Content-length\"", "\"Content-type\"", "\"text/plain\""]}}], ["8b4db5600fcfd285c4e9d445b5ac640f", {"code_string": "from time import sleep\nfrom gi.repository import GLib\nfrom ulauncher.util.decorator.run_async import run_async\nfrom.BaseAction import BaseAction\n", "code_toks_joined": "from time import sleep <NEWLINE> from gi . repository import GLib <NEWLINE> from ulauncher . util . decorator . run_async import run_async <NEWLINE> from . BaseAction import BaseAction <NEWLINE>", "anonymize_dict": {}}], ["8f96e6e524611fe843225397c473060a", {"code_string": "def toHex(buffer):\n    \"\"\"Used for debugging.  Output a sting in hex format\"\"\"\n    result = \"\\n\"\n    cpt1 = 0\n    cpt2 = 0\n    for byte in buffer:\n        result += hex(ord(byte))[2: ].zfill(2)\n        cpt1 += 1\n        if cpt1 >= 4:\n            result += \" \"\n            cpt1 = 0\n            cpt2 += 1\n        if cpt2 >= 10:\n            result += \"\\n\"\n            cpt2 = 0\n    return result\n", "code_toks_joined": "def toHex ( buffer ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> result = <STRING> <NEWLINE> cpt1 = 0 <NEWLINE> cpt2 = 0 <NEWLINE> for byte in buffer : <NEWLINE> <INDENT> result += hex ( ord ( byte ) ) [ 2 : ] . zfill ( 2 ) <NEWLINE> cpt1 += 1 <NEWLINE> if cpt1 >= 4 : <NEWLINE> <INDENT> result += <STRING> <NEWLINE> cpt1 = 0 <NEWLINE> cpt2 += 1 <NEWLINE> <DEDENT> if cpt2 >= 10 : <NEWLINE> <INDENT> result += <STRING> <NEWLINE> cpt2 = 0 <NEWLINE> <DEDENT> <DEDENT> return result <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Used for debugging.  Output a sting in hex format\"\"\"", "\"\\n\"", "\" \"", "\"\\n\""]}}], ["28a1211972d85db725ff00ae665e5380", {"code_string": "\"\"\"\"\"\"\nfrom corporachar import settings\nfrom corporachar.utils.db_manager import DBConnect\nimport json\nimport requests\nfrom os import walk, path\nimport textract\nfrom joblib import Parallel, delayed\nimport click\nfrom unidecode import unidecode\nimport itertools\n", "code_toks_joined": "<STRING> <NEWLINE> from corporachar import settings <NEWLINE> from corporachar . utils . db_manager import DBConnect <NEWLINE> import json <NEWLINE> import requests <NEWLINE> from os import walk , path <NEWLINE> import textract <NEWLINE> from joblib import Parallel , delayed <NEWLINE> import click <NEWLINE> from unidecode import unidecode <NEWLINE> import itertools <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"\"\"\""]}}], ["15e235226a55f98890f3cae4bf1c4903", {"code_string": "from.import account_tax\nfrom.import account_payment\nfrom.import account_tax_withholding_rule\nfrom.import account_payment_group\nfrom.import res_company\n", "code_toks_joined": "from . import account_tax <NEWLINE> from . import account_payment <NEWLINE> from . import account_tax_withholding_rule <NEWLINE> from . import account_payment_group <NEWLINE> from . import res_company <NEWLINE>", "anonymize_dict": {}}], ["40a0e3229cd86fc4ca8ac2cbd5c46e55", {"code_string": "def on_accept(self, sock, mask):\n    conn, addr = self.main_socket.accept()\n    logging.info('accepted connection from {0}'.format(addr))\n    conn.setblocking(False)\n    self.current_peers[conn.fileno()] = conn.getpeername()\n    self.selector.register(fileobj = conn, events = selectors.EVENT_READ,\n        data = self.on_read)\n", "code_toks_joined": "def on_accept ( self , sock , mask ) : <NEWLINE> <INDENT> conn , addr = self . main_socket . accept ( ) <NEWLINE> logging . info ( <STRING> . format ( addr ) ) <NEWLINE> conn . setblocking ( False ) <NEWLINE> self . current_peers [ conn . fileno ( ) ] = conn . getpeername ( ) <NEWLINE> self . selector . register ( fileobj = conn , events = selectors . EVENT_READ , <NEWLINE> <INDENT> data = self . on_read ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'accepted connection from {0}'"]}}], ["346ac3ee7c0df43cd80fe72aa4bb6e26", {"code_string": "\"\"\"Tests for webplatformcompat/tasks.py.\"\"\"\nfrom django.test.utils import override_settings\nimport mock\nfrom webplatformcompat.models import Maturity, Specification\nfrom webplatformcompat.tasks import update_cache_for_instance\nfrom.base import TestCase\n", "code_toks_joined": "<STRING> <NEWLINE> from django . test . utils import override_settings <NEWLINE> import mock <NEWLINE> from webplatformcompat . models import Maturity , Specification <NEWLINE> from webplatformcompat . tasks import update_cache_for_instance <NEWLINE> from . base import TestCase <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Tests for webplatformcompat/tasks.py.\"\"\""]}}], ["23e36d9550981a101a25a4189fd304a3", {"code_string": "def write_pretty_json(path, data):\n    with open(path, 'w') as fd:\n        fd.write(json.dumps(data,\n            sort_keys = True,\n            separators = (',', ':'),\n            indent = 2))\n        fd.flush()\n        os.fsync(fd)\n", "code_toks_joined": "def write_pretty_json ( path , data ) : <NEWLINE> <INDENT> with open ( path , <STRING> ) as fd : <NEWLINE> <INDENT> fd . write ( json . dumps ( data , <NEWLINE> <INDENT> sort_keys = True , <NEWLINE> separators = ( <STRING> , <STRING> ) , <NEWLINE> indent = 2 ) ) <NEWLINE> <DEDENT> fd . flush ( ) <NEWLINE> os . fsync ( fd ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'w'", "','", "':'"]}}], ["ce1ec1d4fe7a7cd57f37f7d878870069", {"code_string": "\"\"\"Alternative interpreters deployed in parallel\"\"\"\nimport logging\nfrom cpy2py.kernel import kernel_state\nfrom cpy2py.twinterpreter import group_state\n", "code_toks_joined": "<STRING> <NEWLINE> import logging <NEWLINE> from cpy2py . kernel import kernel_state <NEWLINE> from cpy2py . twinterpreter import group_state <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Alternative interpreters deployed in parallel\"\"\""]}}], ["0ce89bd2c616fb90543976fdd1263eac", {"code_string": "class SymbolPrimitives(Primitives):\n    def install_primitives(self):\n        self._install_instance_primitive(Primitive(\"asString\", self._universe,\n            _asString))\n", "code_toks_joined": "class SymbolPrimitives ( Primitives ) : <NEWLINE> <INDENT> def install_primitives ( self ) : <NEWLINE> <INDENT> self . _install_instance_primitive ( Primitive ( <STRING> , self . _universe , <NEWLINE> <INDENT> _asString ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"asString\""]}}], ["bdbd11092d67670e6021cb8997774726", {"code_string": "from m5.SimObject import SimObject\nfrom m5.defines import buildEnv\nfrom m5.params import *\nfrom m5.proxy import *\nfrom SimpleMemory import *\nclass MemoryMode(Enum): vals = ['invalid', 'atomic', 'timing']\n", "code_toks_joined": "from m5 . SimObject import SimObject <NEWLINE> from m5 . defines import buildEnv <NEWLINE> from m5 . params import * <NEWLINE> from m5 . proxy import * <NEWLINE> from SimpleMemory import * <NEWLINE> class MemoryMode ( Enum ) : vals = [ <STRING> , <STRING> , <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'invalid'", "'atomic'", "'timing'"]}}], ["c70c1a58d17a6a989e6c6fc870bf0840", {"code_string": "from team import Team\n__all__ = [\n    Team\n]\n", "code_toks_joined": "from team import Team <NEWLINE> __all__ = [ <NEWLINE> <INDENT> Team <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {}}], ["122df2ce1a58198f28ee32f382e6b896", {"code_string": "def read_transactions_from_csv(filename):\n    transactions = []\n    with open(filename, 'rb') as csvfile:\n        reader = csv.reader(csvfile, delimiter = ',', quotechar = '\"')\n        reader.next()\n        for row in reader:\n            transactions.append(csv_row_to_transaction(row))\n    return transactions\n", "code_toks_joined": "def read_transactions_from_csv ( filename ) : <NEWLINE> <INDENT> transactions = [ ] <NEWLINE> with open ( filename , <STRING> ) as csvfile : <NEWLINE> <INDENT> reader = csv . reader ( csvfile , delimiter = <STRING> , quotechar = <STRING> ) <NEWLINE> reader . next ( ) <NEWLINE> for row in reader : <NEWLINE> <INDENT> transactions . append ( csv_row_to_transaction ( row ) ) <NEWLINE> <DEDENT> <DEDENT> return transactions <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'rb'", "','", "'\"'"]}}], ["d4f2e4f29cbeb833d1a6ba460497eb43", {"code_string": "def requiredMemoryMB(self):\n    \"\"\" Require about 2GB free \"\"\"\n    return 2000\n", "code_toks_joined": "def requiredMemoryMB ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return 2000 <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Require about 2GB free \"\"\""]}}], ["76b6b13bacffd5e7dcf3f3e1e566810e", {"code_string": "class Tx(namedtuple(\"Tx\", \"version inputs outputs locktime\")):\n    '''Class representing a transaction.'''\n    @ cachedproperty\n    def is_coinbase(self):\n        return self.inputs[0].is_coinbase\n", "code_toks_joined": "class Tx ( namedtuple ( <STRING> , <STRING> ) ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> @ cachedproperty <NEWLINE> def is_coinbase ( self ) : <NEWLINE> <INDENT> return self . inputs [ 0 ] . is_coinbase <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Tx\"", "\"version inputs outputs locktime\"", "'''Class representing a transaction.'''"]}}], ["cd991ee2ab9becf905243868f11a8bfd", {"code_string": "def draw_square(size):\n    for side in range(0, 4):\n        turtle.forward(size)\n        turtle.right(90)\n", "code_toks_joined": "def draw_square ( size ) : <NEWLINE> <INDENT> for side in range ( 0 , 4 ) : <NEWLINE> <INDENT> turtle . forward ( size ) <NEWLINE> turtle . right ( 90 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["51c9b83ea37b01e3e01c96f1b65e2007", {"code_string": "from elixir import setup_all, create_all, metadata, Entity, session, drop_all\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.pool import StaticPool\nfrom astral.conf import settings\nfrom astral.models.node import Node\nfrom astral.models.stream import Stream\nfrom astral.models.ticket import Ticket\nfrom astral.models.event import Event\nmetadata.bind = create_engine(\"sqlite:///%s?check_same_thread=False\" %\n    settings.DATABASE_PATH, echo = False, poolclass = StaticPool)\nsetup_all()\ncreate_all()\n", "code_toks_joined": "from elixir import setup_all , create_all , metadata , Entity , session , drop_all <NEWLINE> from sqlalchemy import create_engine <NEWLINE> from sqlalchemy . pool import StaticPool <NEWLINE> from astral . conf import settings <NEWLINE> from astral . models . node import Node <NEWLINE> from astral . models . stream import Stream <NEWLINE> from astral . models . ticket import Ticket <NEWLINE> from astral . models . event import Event <NEWLINE> metadata . bind = create_engine ( <STRING> % <NEWLINE> <INDENT> settings . DATABASE_PATH , echo = False , poolclass = StaticPool ) <NEWLINE> <DEDENT> setup_all ( ) <NEWLINE> create_all ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"sqlite:///%s?check_same_thread=False\""]}}], ["aa9406c3d1c6226462fc0609f6810705", {"code_string": "def get_imdb_ijba(data_dir):\n    imdb = []\n    nfold = 10\n    for n in xrange(nfold):\n        file_name = '/home/hzjiang/Code/Faceness-HK-CNN/IJBA_detection/split%d/test_%d_imlist.txt' %((n + 1), (n + 1))\n        fid = open(file_name, 'r')\n        image_names = []\n        for im_name in fid:\n            image_names.append(im_name.strip('\\n'))\n        imdb.append(image_names)\n    return imdb\n", "code_toks_joined": "def get_imdb_ijba ( data_dir ) : <NEWLINE> <INDENT> imdb = [ ] <NEWLINE> nfold = 10 <NEWLINE> for n in xrange ( nfold ) : <NEWLINE> <INDENT> file_name = <STRING> % ( ( n + 1 ) , ( n + 1 ) ) <NEWLINE> fid = open ( file_name , <STRING> ) <NEWLINE> image_names = [ ] <NEWLINE> for im_name in fid : <NEWLINE> <INDENT> image_names . append ( im_name . strip ( <STRING> ) ) <NEWLINE> <DEDENT> imdb . append ( image_names ) <NEWLINE> <DEDENT> return imdb <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/home/hzjiang/Code/Faceness-HK-CNN/IJBA_detection/split%d/test_%d_imlist.txt'", "'r'", "'\\n'"]}}], ["571fa05bd9833bebb8389d5920e41dc0", {"code_string": "def fib_x(n):\n    if n == 0 or n == 1:\n        return 1\n    else:\n        return fib_x(n - 1) + fib_x(n - 2)\n", "code_toks_joined": "def fib_x ( n ) : <NEWLINE> <INDENT> if n == 0 or n == 1 : <NEWLINE> <INDENT> return 1 <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return fib_x ( n - 1 ) + fib_x ( n - 2 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["d568ebf96ddcf91dbdb8024cecc11d18", {"code_string": "import imp\nfrom django.core.management import execute_manager\nimport sys\nimport os\nsys.path.insert(0, os.path.abspath('../..'))\ntry:\n    imp.find_module('settings')\nexcept ImportError:\n    import sys\n    sys.stderr.write(\"Error: Can't find the file 'settings.py' in the directory containing %r. It appears you've customized things.\\nYou'll have to run django-admin.py, passing it your settings module.\\n\" % __file__)\n    sys.exit(1)\nimport settings\nif __name__ == \"__main__\":\n    execute_manager(settings)\n", "code_toks_joined": "import imp <NEWLINE> from django . core . management import execute_manager <NEWLINE> import sys <NEWLINE> import os <NEWLINE> sys . path . insert ( 0 , os . path . abspath ( <STRING> ) ) <NEWLINE> try : <NEWLINE> <INDENT> imp . find_module ( <STRING> ) <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> import sys <NEWLINE> sys . stderr . write ( <STRING> % __file__ ) <NEWLINE> sys . exit ( 1 ) <NEWLINE> <DEDENT> import settings <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> execute_manager ( settings ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'../..'", "'settings'", "\"Error: Can't find the file 'settings.py' in the directory containing %r. It appears you've customized things.\\nYou'll have to run django-admin.py, passing it your settings module.\\n\"", "\"__main__\""]}}], ["6cd37b878a009c9ab5dccf520694f0f2", {"code_string": "def get_run(firehose_dir, version = 'Latest'):\n    \"\"\"Helper to get a run from the file-system.\"\"\"\n    path = '{}/ucsd_analyses'.format(firehose_dir)\n    if version is 'Latest':\n        version = sorted(os.listdir(path))[- 1]\n    run = pickle.load(open('{}/{}/RunObject.p'.format(path, version), 'rb'))\n    return run\n", "code_toks_joined": "def get_run ( firehose_dir , version = <STRING> ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> path = <STRING> . format ( firehose_dir ) <NEWLINE> if version is <STRING> : <NEWLINE> <INDENT> version = sorted ( os . listdir ( path ) ) [ - 1 ] <NEWLINE> <DEDENT> run = pickle . load ( open ( <STRING> . format ( path , version ) , <STRING> ) ) <NEWLINE> return run <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Latest'", "\"\"\"Helper to get a run from the file-system.\"\"\"", "'{}/ucsd_analyses'", "'Latest'", "'{}/{}/RunObject.p'", "'rb'"]}}], ["4423c3b1fb19ae441d556d5b7c2b5a2b", {"code_string": "'''Generates SQL-script(enough to create database) by dbengine config.'''\n__author__ = \"Lesha Strashko\"\n__date__ = \"$Date: 2003/11/18 13:02:02 $\"\n__version__ = \"$Revision: 1.2 $\"\n__credits__ = \"No credits today\"\nconfigPath = 'sulib.config.db'\nsqlFilePath = None\nwithDBCreate = 1\nuId = 0\nimport dbengine\nfrom toolib.utility.timer import Timer\n", "code_toks_joined": "<STRING> <NEWLINE> __author__ = <STRING> <NEWLINE> __date__ = <STRING> <NEWLINE> __version__ = <STRING> <NEWLINE> __credits__ = <STRING> <NEWLINE> configPath = <STRING> <NEWLINE> sqlFilePath = None <NEWLINE> withDBCreate = 1 <NEWLINE> uId = 0 <NEWLINE> import dbengine <NEWLINE> from toolib . utility . timer import Timer <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Generates SQL-script(enough to create database) by dbengine config.'''", "\"Lesha Strashko\"", "\"$Date: 2003/11/18 13:02:02 $\"", "\"$Revision: 1.2 $\"", "\"No credits today\"", "'sulib.config.db'"]}}], ["281ceeb43cc5dfbb9eec3f12dd929d7e", {"code_string": "class CorpusDataSitemap(GenericSitemap):\n    priority = 0.9\n    def __init__(self):\n        super(CorpusDataSitemap, self).__init__(info_dict = {'queryset': Poem.objects.all()})\n", "code_toks_joined": "class CorpusDataSitemap ( GenericSitemap ) : <NEWLINE> <INDENT> priority = 0.9 <NEWLINE> def __init__ ( self ) : <NEWLINE> <INDENT> super ( CorpusDataSitemap , self ) . __init__ ( info_dict = { <STRING> : Poem . objects . all ( ) } ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'queryset'"]}}], ["f604b18f5a1b279031e9edcd13ff7e9a", {"code_string": "def test_template_for_url(self):\n    \"\"\"Test correct rendering template for url.\"\"\"\n    resp = self.client.get('/presence_weekday.html')\n    self.assertEqual(resp.status_code, 200)\n", "code_toks_joined": "def test_template_for_url ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> resp = self . client . get ( <STRING> ) <NEWLINE> self . assertEqual ( resp . status_code , 200 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test correct rendering template for url.\"\"\"", "'/presence_weekday.html'"]}}], ["c8933d6cb0e66d8f1e15f372c8fd2e6c", {"code_string": "import unittest\nimport numpy as np\nfrom numpy.testing import assert_array_almost_equal\nfrom param import resolve_path\nfrom topo.base.boundingregion import BoundingBox\nfrom topo.pattern.image import FileImage\nfrom topo.transferfn import IdentityTF\n", "code_toks_joined": "import unittest <NEWLINE> import numpy as np <NEWLINE> from numpy . testing import assert_array_almost_equal <NEWLINE> from param import resolve_path <NEWLINE> from topo . base . boundingregion import BoundingBox <NEWLINE> from topo . pattern . image import FileImage <NEWLINE> from topo . transferfn import IdentityTF <NEWLINE>", "anonymize_dict": {}}], ["b71ed782a397f0f2ac65a6269cede37f", {"code_string": "def test_tableheader():\n    tokens = tuple(lexer.tokenize('\\n\\t [[personal. information.details]] \\n'))\n    element = TableHeaderElement(tokens)\n    assert element.is_array_of_tables\n    assert('personal', 'information', 'details') == element.names\n    assert element.has_name_prefix(('personal', 'information'))\n", "code_toks_joined": "def test_tableheader ( ) : <NEWLINE> <INDENT> tokens = tuple ( lexer . tokenize ( <STRING> ) ) <NEWLINE> element = TableHeaderElement ( tokens ) <NEWLINE> assert element . is_array_of_tables <NEWLINE> assert ( <STRING> , <STRING> , <STRING> ) == element . names <NEWLINE> assert element . has_name_prefix ( ( <STRING> , <STRING> ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'\\n\\t [[personal. information.details]] \\n'", "'personal'", "'information'", "'details'", "'personal'", "'information'"]}}], ["e27219b9e4c637f91a8aa1999fabd953", {"code_string": "def initialization(levels):\n    nt = 0\n    for i, l in enumerate(levels):\n        if i == len(levels) - 1:\n            break\n        nt += levels[i + 1] * l\n        if i != len(levels) - 2:\n            nt += levels[i + 1]\n    return np.random.normal(0., 1., nt)\n", "code_toks_joined": "def initialization ( levels ) : <NEWLINE> <INDENT> nt = 0 <NEWLINE> for i , l in enumerate ( levels ) : <NEWLINE> <INDENT> if i == len ( levels ) - 1 : <NEWLINE> <INDENT> break <NEWLINE> <DEDENT> nt += levels [ i + 1 ] * l <NEWLINE> if i != len ( levels ) - 2 : <NEWLINE> <INDENT> nt += levels [ i + 1 ] <NEWLINE> <DEDENT> <DEDENT> return np . random . normal ( 0. , 1. , nt ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["00fe6e6ccc8d68080ee5bdeac5fbadbf", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('crdist', '0001_initial'),\n    ]\n    operations = [\n        migrations.RunPython(load_fixture),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . RunPython ( load_fixture ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'crdist'", "'0001_initial'"]}}], ["6f478bf01e3f61752689d4fba6b5fc07", {"code_string": "def play(item):\n    logger.info(\"pelisalacarta.channels.seriesadicto extract_url\")\n    itemlist = servertools.find_video_items(data = item.url)\n    for videoitem in itemlist:\n        videoitem.title = \"Enlace encontrado en \" + videoitem.server + \" (\" + scrapertools.get_filename_from_url(videoitem.url) + \")\"\n        videoitem.fulltitle = item.fulltitle\n        videoitem.thumbnail = item.thumbnail\n        videoitem.channel = item.channel\n    return itemlist\n", "code_toks_joined": "def play ( item ) : <NEWLINE> <INDENT> logger . info ( <STRING> ) <NEWLINE> itemlist = servertools . find_video_items ( data = item . url ) <NEWLINE> for videoitem in itemlist : <NEWLINE> <INDENT> videoitem . title = <STRING> + videoitem . server + <STRING> + scrapertools . get_filename_from_url ( videoitem . url ) + <STRING> <NEWLINE> videoitem . fulltitle = item . fulltitle <NEWLINE> videoitem . thumbnail = item . thumbnail <NEWLINE> videoitem . channel = item . channel <NEWLINE> <DEDENT> return itemlist <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"pelisalacarta.channels.seriesadicto extract_url\"", "\"Enlace encontrado en \"", "\" (\"", "\")\""]}}], ["ec8b97247430b33d25eaced1399890ad", {"code_string": "\"\"\"example creation of PNGs for use with this program:\"\"\"\nfrom pathlib import Path\nfrom wand.image import Image\nfrom tempfile import NamedTemporaryFile\nimport subprocess\nMINHEIGHT = 500\n", "code_toks_joined": "<STRING> <NEWLINE> from pathlib import Path <NEWLINE> from wand . image import Image <NEWLINE> from tempfile import NamedTemporaryFile <NEWLINE> import subprocess <NEWLINE> MINHEIGHT = 500 <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"example creation of PNGs for use with this program:\"\"\""]}}], ["d3e4e3a4e3164b668f16be3e9f502b71", {"code_string": "class FencedCodeExtension(markdown.Extension):\n    def extendMarkdown(self, md, md_globals):\n        \"\"\" Add FencedBlockPreprocessor to the Markdown instance. \"\"\"\n        md.preprocessors.add('fenced_code_block',\n            FencedBlockPreprocessor(md),\n            \"_begin\")\n", "code_toks_joined": "class FencedCodeExtension ( markdown . Extension ) : <NEWLINE> <INDENT> def extendMarkdown ( self , md , md_globals ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> md . preprocessors . add ( <STRING> , <NEWLINE> <INDENT> FencedBlockPreprocessor ( md ) , <NEWLINE> <STRING> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Add FencedBlockPreprocessor to the Markdown instance. \"\"\"", "'fenced_code_block'", "\"_begin\""]}}], ["467578df2ce72023ff32f5b216ea9c8b", {"code_string": "from datetime import datetime\nfrom django.shortcuts import resolve_url as r\nfrom django.test import TestCase\nfrom orcamentos.proposal.models import Entry\nfrom.test_base import BaseEntryTest\n", "code_toks_joined": "from datetime import datetime <NEWLINE> from django . shortcuts import resolve_url as r <NEWLINE> from django . test import TestCase <NEWLINE> from orcamentos . proposal . models import Entry <NEWLINE> from . test_base import BaseEntryTest <NEWLINE>", "anonymize_dict": {}}], ["069636b48b910161e0cc696fcae5737e", {"code_string": "import wx\nfrom multiplatform_widgets import widgets\nfrom base import basePanel\n", "code_toks_joined": "import wx <NEWLINE> from multiplatform_widgets import widgets <NEWLINE> from base import basePanel <NEWLINE>", "anonymize_dict": {}}], ["b1c070855f9d037cdb0713a14bd0d127", {"code_string": "from __future__ import absolute_import\nimport sys\nfrom salt.utils.winservice import Service, instart\nimport salt\nimport salt.defaults.exitcodes\nimport win32serviceutil\nimport win32service\nimport winerror\n", "code_toks_joined": "from __future__ import absolute_import <NEWLINE> import sys <NEWLINE> from salt . utils . winservice import Service , instart <NEWLINE> import salt <NEWLINE> import salt . defaults . exitcodes <NEWLINE> import win32serviceutil <NEWLINE> import win32service <NEWLINE> import winerror <NEWLINE>", "anonymize_dict": {}}], ["d2ef54ebaf598fa2cb5439efbc31fc2a", {"code_string": "import numpy as np\nimport matplotlib.pyplot as plt\nmarker_settings = {\n    'Hottest': 'ro-',\n    'SKBPR-BC': 'gs-',\n    'SKBPR-BCIPF': 'b^-',\n    'SKBPR-BCIPF-FB': 'mD-',\n    'SKBPR-BC-SEQ': 'k*-',\n}\n", "code_toks_joined": "import numpy as np <NEWLINE> import matplotlib . pyplot as plt <NEWLINE> marker_settings = { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <DEDENT> } <NEWLINE>", "anonymize_dict": {"<STRING>": ["'Hottest'", "'ro-'", "'SKBPR-BC'", "'gs-'", "'SKBPR-BCIPF'", "'b^-'", "'SKBPR-BCIPF-FB'", "'mD-'", "'SKBPR-BC-SEQ'", "'k*-'"]}}], ["ac5f1680a1d8566c21cee83bb3438cc8", {"code_string": "class DD(object):\n    \"\"\"Class for constructing dd tag.\"\"\"\n    def __init__(self, text = None):\n        self.tag = 'dd'\n        self.values = {'text': text}\n    def construct(self):\n        \"\"\"Returns the constructed dd tag <dd></dd>.\"\"\"\n        return dd.render(self.values)\n", "code_toks_joined": "class DD ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , text = None ) : <NEWLINE> <INDENT> self . tag = <STRING> <NEWLINE> self . values = { <STRING> : text } <NEWLINE> <DEDENT> def construct ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return dd . render ( self . values ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Class for constructing dd tag.\"\"\"", "'dd'", "'text'", "\"\"\"Returns the constructed dd tag <dd></dd>.\"\"\""]}}], ["2dcab6f1c07e49a00fe745f077f8005c", {"code_string": "class Contact():\n    def __init__(self):\n        self.n = N()\n        self.fn = n.formatted_name()\n", "code_toks_joined": "class Contact ( ) : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> self . n = N ( ) <NEWLINE> self . fn = n . formatted_name ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["ead1f31fc4797e2e9c8031156f764180", {"code_string": "def __init__(self, http_client = None, http_call_back = None):\n    \"\"\"Constructor which allows a different HTTP client for this controller.\"\"\"\n    BaseController.__init__(self, http_client, http_call_back)\n", "code_toks_joined": "def __init__ ( self , http_client = None , http_call_back = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> BaseController . __init__ ( self , http_client , http_call_back ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Constructor which allows a different HTTP client for this controller.\"\"\""]}}], ["7e8c0640ab70885c02dcc5d810082844", {"code_string": "class AutomationScenesView(SubView):\n    def __init__(self, evManager):\n        super().__init__(evManager)\n        self.name = \"AutomationView\"\n        self.title = \"Escenas\"\n", "code_toks_joined": "class AutomationScenesView ( SubView ) : <NEWLINE> <INDENT> def __init__ ( self , evManager ) : <NEWLINE> <INDENT> super ( ) . __init__ ( evManager ) <NEWLINE> self . name = <STRING> <NEWLINE> self . title = <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"AutomationView\"", "\"Escenas\""]}}], ["7bcb0486dd274731a9ecb752df8ac80c", {"code_string": "\"\"\"Using a Lock without blocking\"\"\"\nimport logging\nimport threading\nimport time\nlogging.basicConfig(level = logging.DEBUG,\n    format = '(%(threadName)-10s) %(message)s',\n    )\n", "code_toks_joined": "<STRING> <NEWLINE> import logging <NEWLINE> import threading <NEWLINE> import time <NEWLINE> logging . basicConfig ( level = logging . DEBUG , <NEWLINE> <INDENT> format = <STRING> , <NEWLINE> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Using a Lock without blocking\"\"\"", "'(%(threadName)-10s) %(message)s'"]}}], ["c995fd50c07a2de67bc4df3523210fad", {"code_string": "from sa_tools.parsers.search_result import SearchResultParser\nfrom sa_tools.base import SAObj\nfrom sa_tools.thread import Thread\nfrom sa_tools.forum import Forum\nfrom sa_tools.poster import Poster\nfrom sa_tools.post import Post\n", "code_toks_joined": "from sa_tools . parsers . search_result import SearchResultParser <NEWLINE> from sa_tools . base import SAObj <NEWLINE> from sa_tools . thread import Thread <NEWLINE> from sa_tools . forum import Forum <NEWLINE> from sa_tools . poster import Poster <NEWLINE> from sa_tools . post import Post <NEWLINE>", "anonymize_dict": {}}], ["ffd3169a81ed04939946a98dd68382f4", {"code_string": "from setuptools import setup\nsetup(\n    name = \"MeshToolkit\",\n    version = \"0.2\",\n    packages = ['MeshToolkit'],\n    scripts = ['meshtoolkit.py'],\n    author = \"Micha\u00ebl Roy\",\n    author_email = \"microygh@gmail.com\",\n    description = \"Python 3D Mesh Toolkit\",\n    license = \"MIT\",\n    url = \"https://github.com/microy/MeshToolkit\"\n)\n", "code_toks_joined": "from setuptools import setup <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> scripts = [ <STRING> ] , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> license = <STRING> , <NEWLINE> url = <STRING> <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"MeshToolkit\"", "\"0.2\"", "'MeshToolkit'", "'meshtoolkit.py'", "\"Micha\u00ebl Roy\"", "\"microygh@gmail.com\"", "\"Python 3D Mesh Toolkit\"", "\"MIT\"", "\"https://github.com/microy/MeshToolkit\""]}}], ["dd1ed7f1b6b64a38874a5a5cc09480d0", {"code_string": "def getedutext(self):\n    \"\"\" Get all EDU text here\"\"\"\n    edunodelist = getedunode(self.tree)\n    texts = []\n    for node in edunodelist:\n        texts.append(node.text)\n    return texts\n", "code_toks_joined": "def getedutext ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> edunodelist = getedunode ( self . tree ) <NEWLINE> texts = [ ] <NEWLINE> for node in edunodelist : <NEWLINE> <INDENT> texts . append ( node . text ) <NEWLINE> <DEDENT> return texts <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Get all EDU text here\"\"\""]}}], ["dcdb69774a0b2f0cedc5fef053d3dba2", {"code_string": "\"\"\"Add altitude_reports table\"\"\"\nrevision = 'f24937651f71'\ndown_revision = '457bbf802239'\nbranch_labels = None\ndepends_on = None\nfrom alembic import op\nfrom sqlalchemy import Column, ForeignKey, Numeric\nfrom sqlalchemy_utils import UUIDType\n", "code_toks_joined": "<STRING> <NEWLINE> revision = <STRING> <NEWLINE> down_revision = <STRING> <NEWLINE> branch_labels = None <NEWLINE> depends_on = None <NEWLINE> from alembic import op <NEWLINE> from sqlalchemy import Column , ForeignKey , Numeric <NEWLINE> from sqlalchemy_utils import UUIDType <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Add altitude_reports table\"\"\"", "'f24937651f71'", "'457bbf802239'"]}}], ["ba863b7f8d86801fdf462b8285e1bad9", {"code_string": "import re\nimport numpy as np\nimport sympy\nfrom sympy import collect\n", "code_toks_joined": "import re <NEWLINE> import numpy as np <NEWLINE> import sympy <NEWLINE> from sympy import collect <NEWLINE>", "anonymize_dict": {}}], ["0e35ec1a7dfc932d6e94c4a3935629c9", {"code_string": "def test_401_with_unsupported_authorization_header(client):\n    headers = Headers()\n    headers.set('Authorization', 'MAC 123456789')\n    response = client.get('/user', headers = headers)\n    assert response.status_code == 401\n    assert response.json.get('error') == 'invalid_token'\n", "code_toks_joined": "def test_401_with_unsupported_authorization_header ( client ) : <NEWLINE> <INDENT> headers = Headers ( ) <NEWLINE> headers . set ( <STRING> , <STRING> ) <NEWLINE> response = client . get ( <STRING> , headers = headers ) <NEWLINE> assert response . status_code == 401 <NEWLINE> assert response . json . get ( <STRING> ) == <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Authorization'", "'MAC 123456789'", "'/user'", "'error'", "'invalid_token'"]}}], ["e2a6d8c4a603040eb2bc924df911eb3b", {"code_string": "import testtools\nimport webob.exc\nfrom nova.api.openstack.compute import hosts as os_hosts_v21\nfrom nova.compute import power_state\nfrom nova.compute import vm_states\nfrom nova import context as context_maker\nfrom nova import db\nfrom nova import exception\nfrom nova import test\nfrom nova.tests.unit.api.openstack import fakes\nfrom nova.tests.unit import fake_hosts\nfrom nova.tests import uuidsentinel\n", "code_toks_joined": "import testtools <NEWLINE> import webob . exc <NEWLINE> from nova . api . openstack . compute import hosts as os_hosts_v21 <NEWLINE> from nova . compute import power_state <NEWLINE> from nova . compute import vm_states <NEWLINE> from nova import context as context_maker <NEWLINE> from nova import db <NEWLINE> from nova import exception <NEWLINE> from nova import test <NEWLINE> from nova . tests . unit . api . openstack import fakes <NEWLINE> from nova . tests . unit import fake_hosts <NEWLINE> from nova . tests import uuidsentinel <NEWLINE>", "anonymize_dict": {}}], ["afdfd745dae51db739d99e3adc87d58f", {"code_string": "import pypug\n\"\"\"Retrieve a compound along with specified properties using its CID\"\"\"\ncid = 2244\nproperties = [\"MolecularWeight\", \"MolecularFormula\", \"InChI\", \"CannicalSMILES\"]\ndata = pypug.getCompoundPropertiesFromCID(cid, properties)\nprint(data)\n", "code_toks_joined": "import pypug <NEWLINE> <STRING> <NEWLINE> cid = 2244 <NEWLINE> properties = [ <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE> data = pypug . getCompoundPropertiesFromCID ( cid , properties ) <NEWLINE> print ( data ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Retrieve a compound along with specified properties using its CID\"\"\"", "\"MolecularWeight\"", "\"MolecularFormula\"", "\"InChI\"", "\"CannicalSMILES\""]}}], ["be25c3c8dbbe3a8640536759c8f37b32", {"code_string": "\"\"\"bcn_tcards URL Configuration\"\"\"\nfrom django.conf.urls import url, include\nfrom django.contrib import admin\nurlpatterns = [\n    url(r'^api/admin/', include(admin.site.urls)),\n    url(r'^api/auth/', include('registration.urls')),\n    url(r'^api/data/', include('data.urls')),\n    url(r'^api/tourists/', include('tourists.urls')),\n    url(r'^api/docs/', include('rest_framework_docs.urls')),\n]\n", "code_toks_joined": "<STRING> <NEWLINE> from django . conf . urls import url , include <NEWLINE> from django . contrib import admin <NEWLINE> urlpatterns = [ <NEWLINE> <INDENT> url ( <STRING> , include ( admin . site . urls ) ) , <NEWLINE> url ( <STRING> , include ( <STRING> ) ) , <NEWLINE> url ( <STRING> , include ( <STRING> ) ) , <NEWLINE> url ( <STRING> , include ( <STRING> ) ) , <NEWLINE> url ( <STRING> , include ( <STRING> ) ) , <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"bcn_tcards URL Configuration\"\"\"", "r'^api/admin/'", "r'^api/auth/'", "'registration.urls'", "r'^api/data/'", "'data.urls'", "r'^api/tourists/'", "'tourists.urls'", "r'^api/docs/'", "'rest_framework_docs.urls'"]}}], ["fc8ad086065bd23986c9217d686a1d5b", {"code_string": "class MockedOSCrawlerFailure:\n    def crawl(self, container_id, ** kwargs):\n        if container_id == 'errorid':\n            raise OSError('some exception')\n        else:\n            return[('linux', {'os': 'some_os'}, 'os')]\n", "code_toks_joined": "class MockedOSCrawlerFailure : <NEWLINE> <INDENT> def crawl ( self , container_id , ** kwargs ) : <NEWLINE> <INDENT> if container_id == <STRING> : <NEWLINE> <INDENT> raise OSError ( <STRING> ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return [ ( <STRING> , { <STRING> : <STRING> } , <STRING> ) ] <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'errorid'", "'some exception'", "'linux'", "'os'", "'some_os'", "'os'"]}}], ["401116c5ceb4ac6f3dba22ca1982a275", {"code_string": "def GetConversations(limit, offset):\n    all_args = {k: len(v) == 0 or v[0] for k, v in request.args.lists()}\n    return dg.MakeFakeDataMgr(\"\").RecentConversations(limit, offset, all_args)\n", "code_toks_joined": "def GetConversations ( limit , offset ) : <NEWLINE> <INDENT> all_args = { k : len ( v ) == 0 or v [ 0 ] for k , v in request . args . lists ( ) } <NEWLINE> return dg . MakeFakeDataMgr ( <STRING> ) . RecentConversations ( limit , offset , all_args ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\""]}}], ["bf539034a994d15f711cc89da404db69", {"code_string": "def r34(tags):\n    link = 'http://rule34.xxx/index.php?page=dapi&s=post&q=index&limit=100&tags=' + tags\n    rget = requests.get(link.replace(' ', '_').replace('+', ' '))\n    root = xml.etree.ElementTree.fromstring(rget.text)\n    try:\n        return 'http:' + root[random.randint(0, len(root) - 1)].attrib['file_url']\n    except ValueError:\n        return 'No results found.'\n    except Exception as e:\n        return e\n", "code_toks_joined": "def r34 ( tags ) : <NEWLINE> <INDENT> link = <STRING> + tags <NEWLINE> rget = requests . get ( link . replace ( <STRING> , <STRING> ) . replace ( <STRING> , <STRING> ) ) <NEWLINE> root = xml . etree . ElementTree . fromstring ( rget . text ) <NEWLINE> try : <NEWLINE> <INDENT> return <STRING> + root [ random . randint ( 0 , len ( root ) - 1 ) ] . attrib [ <STRING> ] <NEWLINE> <DEDENT> except ValueError : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> except Exception as e : <NEWLINE> <INDENT> return e <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'http://rule34.xxx/index.php?page=dapi&s=post&q=index&limit=100&tags='", "' '", "'_'", "'+'", "' '", "'http:'", "'file_url'", "'No results found.'"]}}], ["77bb55d16ddadac3bc51c444b74a3e09", {"code_string": "\"\"\"Test cutplace performance.\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\nimport io\nimport logging\nimport os.path\nimport pstats\nimport random\nimport unittest\nimport six\nfrom cutplace import interface\nfrom cutplace import validio\nfrom cutplace import _compat\nfrom cutplace import applications\nfrom cutplace import _tools\nfrom tests import dev_test\n_log = logging.getLogger(\"cutplace.dev_reports\")\ntry:\n    import cProfile as profile\nexcept ImportError:\n    import profile\n    _log.warning('cProfile is not available, using profile')\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import absolute_import <NEWLINE> from __future__ import division <NEWLINE> from __future__ import print_function <NEWLINE> from __future__ import unicode_literals <NEWLINE> import io <NEWLINE> import logging <NEWLINE> import os . path <NEWLINE> import pstats <NEWLINE> import random <NEWLINE> import unittest <NEWLINE> import six <NEWLINE> from cutplace import interface <NEWLINE> from cutplace import validio <NEWLINE> from cutplace import _compat <NEWLINE> from cutplace import applications <NEWLINE> from cutplace import _tools <NEWLINE> from tests import dev_test <NEWLINE> _log = logging . getLogger ( <STRING> ) <NEWLINE> try : <NEWLINE> <INDENT> import cProfile as profile <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> import profile <NEWLINE> _log . warning ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test cutplace performance.\"\"\"", "\"cutplace.dev_reports\"", "'cProfile is not available, using profile'"]}}], ["8b719b47a8982e54676023e49dbd258e", {"code_string": "def contextMenuEvent(self, event):\n    pos = event.globalPos()\n    action = actionAtPos(pos)\n    if action:\n        G.item_context_menu.act(action, pos)\n    event.accept()\n", "code_toks_joined": "def contextMenuEvent ( self , event ) : <NEWLINE> <INDENT> pos = event . globalPos ( ) <NEWLINE> action = actionAtPos ( pos ) <NEWLINE> if action : <NEWLINE> <INDENT> G . item_context_menu . act ( action , pos ) <NEWLINE> <DEDENT> event . accept ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["06bfeff7424902ccbce2bb174f5fc3b4", {"code_string": "class ReconcileOrdersAndTransactionsDownstreamMixin(MapReduceJobTaskMixin):\n    \"\"\"Define parameters needed downstream for running ReconcileOrdersAndTransactionsTask.\"\"\"\n    import_date = luigi.DateParameter()\n", "code_toks_joined": "class ReconcileOrdersAndTransactionsDownstreamMixin ( MapReduceJobTaskMixin ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> import_date = luigi . DateParameter ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Define parameters needed downstream for running ReconcileOrdersAndTransactionsTask.\"\"\""]}}], ["244a69592b1b1403186863c3f944010a", {"code_string": "class SendingEligibility(object):\n    def __init__(self):\n        self.eligible = ''\n        self.reason_code = ''\n        self.account_number = ''\n        self.ica = ''\n        self.currency = ''\n        self.country = ''\n        self.brand = ''\n", "code_toks_joined": "class SendingEligibility ( object ) : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> self . eligible = <STRING> <NEWLINE> self . reason_code = <STRING> <NEWLINE> self . account_number = <STRING> <NEWLINE> self . ica = <STRING> <NEWLINE> self . currency = <STRING> <NEWLINE> self . country = <STRING> <NEWLINE> self . brand = <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["''", "''", "''", "''", "''", "''", "''"]}}], ["8663fcea39dea8d876ba072494468ca2", {"code_string": "import coverage\nfrom unittest import TextTestRunner, TestLoader\nfrom os.path import split, join, abspath\nfrom os import chdir\nif __name__ == \"__main__\":\n    project_dir = split(split(abspath(__file__))[0])[0]\n    chdir(project_dir)\n    cov = coverage.coverage(branch = True)\n    cov.start()\n    suite = TestLoader().discover(\".\", pattern = \"test_*.py\")\n    TextTestRunner(verbosity = 2).run(suite)\n    cov.stop()\n    cov.save()\n    cov.html_report()\n", "code_toks_joined": "import coverage <NEWLINE> from unittest import TextTestRunner , TestLoader <NEWLINE> from os . path import split , join , abspath <NEWLINE> from os import chdir <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> project_dir = split ( split ( abspath ( __file__ ) ) [ 0 ] ) [ 0 ] <NEWLINE> chdir ( project_dir ) <NEWLINE> cov = coverage . coverage ( branch = True ) <NEWLINE> cov . start ( ) <NEWLINE> suite = TestLoader ( ) . discover ( <STRING> , pattern = <STRING> ) <NEWLINE> TextTestRunner ( verbosity = 2 ) . run ( suite ) <NEWLINE> cov . stop ( ) <NEWLINE> cov . save ( ) <NEWLINE> cov . html_report ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"__main__\"", "\".\"", "\"test_*.py\""]}}], ["ef5080c23db746b85bfe3ec6b76c2270", {"code_string": "def course_description(request, pk):\n    course = get_object_or_404(models.Course, pk = pk)\n    return http.HttpResponse(course.long_description_html)\n", "code_toks_joined": "def course_description ( request , pk ) : <NEWLINE> <INDENT> course = get_object_or_404 ( models . Course , pk = pk ) <NEWLINE> return http . HttpResponse ( course . long_description_html ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["7886016fb3dc3d4f55a1a63bf4db374d", {"code_string": "def create_from_template(self, template_id, custom_fields = None, * args, ** kwargs):\n    auth = None\n    if 'auth' in kwargs:\n        auth = kwargs['auth']\n        del(kwargs['auth'])\n    self.validate_signers()\n    data = self.data()\n    data['reusable_form_id'] = template_id\n    if custom_fields:\n        for k, v in custom_fields.items():\n            data['custom_fields[%s]' % k] = v\n    return self.signature_request.send_with_reusable_form.post(auth = auth, data = data, ** kwargs)\n", "code_toks_joined": "def create_from_template ( self , template_id , custom_fields = None , * args , ** kwargs ) : <NEWLINE> <INDENT> auth = None <NEWLINE> if <STRING> in kwargs : <NEWLINE> <INDENT> auth = kwargs [ <STRING> ] <NEWLINE> del ( kwargs [ <STRING> ] ) <NEWLINE> <DEDENT> self . validate_signers ( ) <NEWLINE> data = self . data ( ) <NEWLINE> data [ <STRING> ] = template_id <NEWLINE> if custom_fields : <NEWLINE> <INDENT> for k , v in custom_fields . items ( ) : <NEWLINE> <INDENT> data [ <STRING> % k ] = v <NEWLINE> <DEDENT> <DEDENT> return self . signature_request . send_with_reusable_form . post ( auth = auth , data = data , ** kwargs ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'auth'", "'auth'", "'auth'", "'reusable_form_id'", "'custom_fields[%s]'"]}}], ["1771c94b0d5d31a98a3c5ac72fd9eb07", {"code_string": "\"\"\"Account Chart Update Wizard\"\"\"\n__authors__ = [\"Jordi Esteve <jesteve@zikzakmedia.com>\",\n    \"Borja L\u00f3pez Soil\u00e1n <borjals@pexego.es>\"]\nimport account\n", "code_toks_joined": "<STRING> <NEWLINE> __authors__ = [ <STRING> , <NEWLINE> <INDENT> <STRING> ] <NEWLINE> <DEDENT> import account <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Account Chart Update Wizard\"\"\"", "\"Jordi Esteve <jesteve@zikzakmedia.com>\"", "\"Borja L\u00f3pez Soil\u00e1n <borjals@pexego.es>\""]}}], ["09d9bc63156c8993bb730f8aee4fd5fd", {"code_string": "def __init__(self, seqno, type = None):\n    Base.__init__(self, type)\n    self.state['sequenceNumber'] = seqno\n    self.data = ''\n", "code_toks_joined": "def __init__ ( self , seqno , type = None ) : <NEWLINE> <INDENT> Base . __init__ ( self , type ) <NEWLINE> self . state [ <STRING> ] = seqno <NEWLINE> self . data = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'sequenceNumber'", "''"]}}], ["0a465f9e7b3d2af4b1701043feaf2e1e", {"code_string": "class User(object):\n    \"\"\"Simple user, date only for easy storing in database\"\"\"\n    def __init__(self):\n        self.user_id = None\n        self.first_name = None\n        self.last_name = None\n        self.email = None\n        self.pin = None\n    def load_from_tuple(self, user):\n        self.user_id = user[0]\n        self.first_name = user[1]\n        self.last_name = user[2]\n        self.email = user[3]\n        self.pin = user[4]\n        return self\n", "code_toks_joined": "class User ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self ) : <NEWLINE> <INDENT> self . user_id = None <NEWLINE> self . first_name = None <NEWLINE> self . last_name = None <NEWLINE> self . email = None <NEWLINE> self . pin = None <NEWLINE> <DEDENT> def load_from_tuple ( self , user ) : <NEWLINE> <INDENT> self . user_id = user [ 0 ] <NEWLINE> self . first_name = user [ 1 ] <NEWLINE> self . last_name = user [ 2 ] <NEWLINE> self . email = user [ 3 ] <NEWLINE> self . pin = user [ 4 ] <NEWLINE> return self <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Simple user, date only for easy storing in database\"\"\""]}}], ["4335c6e5e590ff090eef6aeba39cd560", {"code_string": "def print_usage():\n    print(\"Usage: \" + str(sys.argv[0]) + \" [size] [Red town] [Red hero] [Blue town] [Blue hero], ...\")\n    print(\"Default: XL map with random Red, Blue, Green and Tan\")\n    print(\"Examples: \")\n    print(\"\\t\" + str(sys.argv[0]) + \" L Necropolis Tamika\")\n    print(\"\\t\" + str(sys.argv[0]) + \" XL Necropolis Tamika Random Random Random Random Random Random\")\n    print(\"\\t\" + str(sys.argv[0]) + \" XLU Necropolis Tamika Castle Orrin Random Random Random Random Random Random Random Random\")\n", "code_toks_joined": "def print_usage ( ) : <NEWLINE> <INDENT> print ( <STRING> + str ( sys . argv [ 0 ] ) + <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> print ( <STRING> + str ( sys . argv [ 0 ] ) + <STRING> ) <NEWLINE> print ( <STRING> + str ( sys . argv [ 0 ] ) + <STRING> ) <NEWLINE> print ( <STRING> + str ( sys . argv [ 0 ] ) + <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Usage: \"", "\" [size] [Red town] [Red hero] [Blue town] [Blue hero], ...\"", "\"Default: XL map with random Red, Blue, Green and Tan\"", "\"Examples: \"", "\"\\t\"", "\" L Necropolis Tamika\"", "\"\\t\"", "\" XL Necropolis Tamika Random Random Random Random Random Random\"", "\"\\t\"", "\" XLU Necropolis Tamika Castle Orrin Random Random Random Random Random Random Random Random\""]}}], ["549740421487e01ec77ace3b9047329a", {"code_string": "import unittest\nfrom PySide2.QtWidgets import QMenu\nfrom PySide2.QtGui import QKeySequence, QIcon\nfrom PySide2.QtCore import SLOT\nfrom helper import UsesQApplication\n", "code_toks_joined": "import unittest <NEWLINE> from PySide2 . QtWidgets import QMenu <NEWLINE> from PySide2 . QtGui import QKeySequence , QIcon <NEWLINE> from PySide2 . QtCore import SLOT <NEWLINE> from helper import UsesQApplication <NEWLINE>", "anonymize_dict": {}}], ["1356b1ff0c7663236f93c3a056d7ec15", {"code_string": "from django.conf.urls import patterns, url\nfrom.views import IndexView, DetailView\nurlpatterns = [\n    url(r'^$', IndexView.as_view(), name = 'index'),\n    url(r'^announce/(?P<pk>[0-9]+)$', DetailView.as_view(), name = 'detail'),\n]\n", "code_toks_joined": "from django . conf . urls import patterns , url <NEWLINE> from . views import IndexView , DetailView <NEWLINE> urlpatterns = [ <NEWLINE> <INDENT> url ( <STRING> , IndexView . as_view ( ) , name = <STRING> ) , <NEWLINE> url ( <STRING> , DetailView . as_view ( ) , name = <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["r'^$'", "'index'", "r'^announce/(?P<pk>[0-9]+)$'", "'detail'"]}}], ["b4b125095e3266230e96f1fa87739908", {"code_string": "from django.utils.module_loading import autodiscover_modules\nfrom.decorators import register\nfrom.sites import AdminReportSite, site\nfrom.reports import Report\n__version__ = '0.10.8'\n__all__ = [\"register\", \"AdminReportSite\", \"site\", \"Report\"]\n", "code_toks_joined": "from django . utils . module_loading import autodiscover_modules <NEWLINE> from . decorators import register <NEWLINE> from . sites import AdminReportSite , site <NEWLINE> from . reports import Report <NEWLINE> __version__ = <STRING> <NEWLINE> __all__ = [ <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'0.10.8'", "\"register\"", "\"AdminReportSite\"", "\"site\"", "\"Report\""]}}], ["de7e3bb399df375299df042bde41e6b7", {"code_string": "def count(self):\n    if self.topContainer is None:\n        return 0\n    return 1\n", "code_toks_joined": "def count ( self ) : <NEWLINE> <INDENT> if self . topContainer is None : <NEWLINE> <INDENT> return 0 <NEWLINE> <DEDENT> return 1 <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["245e2e1e0e59515886f87db3a8d720be", {"code_string": "def get_song_json(self, song_id):\n    json_url = 'https://mspxy.joysound.com/Common/Lyric'\n    post_data = 'kind=naviGroupId&selSongNo=%s&interactionFlg=0&apiVer=1.0' %(song_id, )\n    headers = {\n        'X-JSP-APP-NAME': '0000800'\n    }\n    json_str = common.get_url_content(json_url, post_data, headers)\n    if not json_str:\n        logging.info('Failed to get json from url [%s]', url)\n        return False\n    obj = json.loads(json_str)\n    return obj\n", "code_toks_joined": "def get_song_json ( self , song_id ) : <NEWLINE> <INDENT> json_url = <STRING> <NEWLINE> post_data = <STRING> % ( song_id , ) <NEWLINE> headers = { <NEWLINE> <INDENT> <STRING> : <STRING> <NEWLINE> <DEDENT> } <NEWLINE> json_str = common . get_url_content ( json_url , post_data , headers ) <NEWLINE> if not json_str : <NEWLINE> <INDENT> logging . info ( <STRING> , url ) <NEWLINE> return False <NEWLINE> <DEDENT> obj = json . loads ( json_str ) <NEWLINE> return obj <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'https://mspxy.joysound.com/Common/Lyric'", "'kind=naviGroupId&selSongNo=%s&interactionFlg=0&apiVer=1.0'", "'X-JSP-APP-NAME'", "'0000800'", "'Failed to get json from url [%s]'"]}}], ["a57809085bd8674540d976a4997fdc06", {"code_string": "def test_ip_to_int_conversion(self):\n    for ip in ip_generator(50000):\n        num = convert_ip_to_int(ip)\n        self.failIf(num < 0)\n        self.assertEqual(ip, convert_int_to_ip(num))\n", "code_toks_joined": "def test_ip_to_int_conversion ( self ) : <NEWLINE> <INDENT> for ip in ip_generator ( 50000 ) : <NEWLINE> <INDENT> num = convert_ip_to_int ( ip ) <NEWLINE> self . failIf ( num < 0 ) <NEWLINE> self . assertEqual ( ip , convert_int_to_ip ( num ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["14a552e47b0170597ef4b1e70345ec5d", {"code_string": "class Permissions(models.Model):\n    '''This is a fake model that has nothing in it, because'''\n    class Meta:\n        permissions = (\n            (\"can_view\", \"Can view\"),\n        )\n", "code_toks_joined": "class Permissions ( models . Model ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> class Meta : <NEWLINE> <INDENT> permissions = ( <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''This is a fake model that has nothing in it, because'''", "\"can_view\"", "\"Can view\""]}}], ["975b84d409bbb67e79c17e0774492b31", {"code_string": "def test_disconnect(self):\n    self.robot.disconnect()\n    res = self.robot.is_connected()\n    self.assertEquals(bool(res), False)\n", "code_toks_joined": "def test_disconnect ( self ) : <NEWLINE> <INDENT> self . robot . disconnect ( ) <NEWLINE> res = self . robot . is_connected ( ) <NEWLINE> self . assertEquals ( bool ( res ) , False ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["15a2c9468656cb6f39d815cb139d8c55", {"code_string": "import keys as keys\nfrom readFromWhatPulseDb import readFromWhatPulseDb\nfrom mySqlHandler import mySqlHandler\ndata = readFromWhatPulseDb().returnData()\nsql = mySqlHandler(keys)\nfor entry in data:\n    sql.insertArrayIntoDb(entry)\n", "code_toks_joined": "import keys as keys <NEWLINE> from readFromWhatPulseDb import readFromWhatPulseDb <NEWLINE> from mySqlHandler import mySqlHandler <NEWLINE> data = readFromWhatPulseDb ( ) . returnData ( ) <NEWLINE> sql = mySqlHandler ( keys ) <NEWLINE> for entry in data : <NEWLINE> <INDENT> sql . insertArrayIntoDb ( entry ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["c84b8af5c368de21354ca697ee92e736", {"code_string": "from __future__ import division\nfrom optparse import OptionParser\nimport csv\nimport MySQLdb\nimport sys\n", "code_toks_joined": "from __future__ import division <NEWLINE> from optparse import OptionParser <NEWLINE> import csv <NEWLINE> import MySQLdb <NEWLINE> import sys <NEWLINE>", "anonymize_dict": {}}], ["14a150e41e1274c700f37bf0911f1776", {"code_string": "def test_is_created(self):\n    shell = unittest.mock.MagicMock()\n    container = robot.cloud.container.Container(shell, \"test\")\n    shell.run.return_value = robot.tests.future((1, \"\"))\n    self.assertFalse((yield container.is_created()))\n    shell.reset_mock()\n    shell.run.return_value = robot.tests.future((0, \"\"))\n    self.assertTrue((yield container.is_created()))\n", "code_toks_joined": "def test_is_created ( self ) : <NEWLINE> <INDENT> shell = unittest . mock . MagicMock ( ) <NEWLINE> container = robot . cloud . container . Container ( shell , <STRING> ) <NEWLINE> shell . run . return_value = robot . tests . future ( ( 1 , <STRING> ) ) <NEWLINE> self . assertFalse ( ( yield container . is_created ( ) ) ) <NEWLINE> shell . reset_mock ( ) <NEWLINE> shell . run . return_value = robot . tests . future ( ( 0 , <STRING> ) ) <NEWLINE> self . assertTrue ( ( yield container . is_created ( ) ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"test\"", "\"\"", "\"\""]}}], ["732bf7632103511c1120f09169ee0ce8", {"code_string": "def get(self, id):\n    self.check_admin()\n    user_dao = UserDao(self.db_session())\n    user = user_dao.retrieve(id = id)\n    result = [p.to_dict() for p in user.permissions]\n    return result, 200\n", "code_toks_joined": "def get ( self , id ) : <NEWLINE> <INDENT> self . check_admin ( ) <NEWLINE> user_dao = UserDao ( self . db_session ( ) ) <NEWLINE> user = user_dao . retrieve ( id = id ) <NEWLINE> result = [ p . to_dict ( ) for p in user . permissions ] <NEWLINE> return result , 200 <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["93cf1fa72f40a96bbae1f7389ad7ecd0", {"code_string": "class HtmlView(AbstractView):\n    def __init__(self, template_name, model):\n        self._template_name = template_name\n        self._model = model\n    def get_content_type(self):\n        return \"text/html;charset=utf-8\"\n    def render(self, out):\n        basedir = os.path.dirname(__file__)\n        t_file = os.path.join(basedir, \"..\", \"templates\",\n            self._template_name)\n        out.write(template.render(t_file, self._model))\n", "code_toks_joined": "class HtmlView ( AbstractView ) : <NEWLINE> <INDENT> def __init__ ( self , template_name , model ) : <NEWLINE> <INDENT> self . _template_name = template_name <NEWLINE> self . _model = model <NEWLINE> <DEDENT> def get_content_type ( self ) : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> def render ( self , out ) : <NEWLINE> <INDENT> basedir = os . path . dirname ( __file__ ) <NEWLINE> t_file = os . path . join ( basedir , <STRING> , <STRING> , <NEWLINE> <INDENT> self . _template_name ) <NEWLINE> <DEDENT> out . write ( template . render ( t_file , self . _model ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"text/html;charset=utf-8\"", "\"..\"", "\"templates\""]}}], ["2fb02850135ecb92dbf35240a70e6285", {"code_string": "import numpy as np\nimport scipy.io.wavfile\nimport os, re\n", "code_toks_joined": "import numpy as np <NEWLINE> import scipy . io . wavfile <NEWLINE> import os , re <NEWLINE>", "anonymize_dict": {}}], ["b6b225c473e40f32353ed77c2c6b92dc", {"code_string": "def __init__(self, data = None):\n    self.parent = None\n    self.data = data\n    self.forest = []\n", "code_toks_joined": "def __init__ ( self , data = None ) : <NEWLINE> <INDENT> self . parent = None <NEWLINE> self . data = data <NEWLINE> self . forest = [ ] <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["c725de8fafd5c88f252a4f1f3fb244a6", {"code_string": "class Overrides(Adapter):\n    def __init__(self, data = {}, * args, ** kwargs):\n        super(Overrides, self).__init__(* args, ** kwargs)\n        self.data = data\n        self.load()\n    def load(self, formatter = None):\n        self.data = dict((self.format(k, formatter), v) for k, v in self.data.items())\n", "code_toks_joined": "class Overrides ( Adapter ) : <NEWLINE> <INDENT> def __init__ ( self , data = { } , * args , ** kwargs ) : <NEWLINE> <INDENT> super ( Overrides , self ) . __init__ ( * args , ** kwargs ) <NEWLINE> self . data = data <NEWLINE> self . load ( ) <NEWLINE> <DEDENT> def load ( self , formatter = None ) : <NEWLINE> <INDENT> self . data = dict ( ( self . format ( k , formatter ) , v ) for k , v in self . data . items ( ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["16827371375980130eb94d197203284a", {"code_string": "\"\"\"@author: Chenglong Chen <c.chenglong@gmail.com>\"\"\"\nimport os\nimport sys\nimport numpy as np\nimport config\nfrom config import TRAIN_SIZE\nfrom utils import np_utils, pkl_utils\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> import sys <NEWLINE> import numpy as np <NEWLINE> import config <NEWLINE> from config import TRAIN_SIZE <NEWLINE> from utils import np_utils , pkl_utils <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"@author: Chenglong Chen <c.chenglong@gmail.com>\"\"\""]}}], ["bfd13228b3d55bc419683b5154cedcc6", {"code_string": "def test_get_index():\n    example = [1, 2]\n    assert get_index(example, 0) == 1\n    assert get_index(example, 3) is None\n", "code_toks_joined": "def test_get_index ( ) : <NEWLINE> <INDENT> example = [ 1 , 2 ] <NEWLINE> assert get_index ( example , 0 ) == 1 <NEWLINE> assert get_index ( example , 3 ) is None <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["44e58de506227e86bcded918184232c1", {"code_string": "def symlink(source, destination, use_bind = False):\n    worker.register_resource(\n        SymlinkResource(\n            source, destination, use_bind\n        )\n    )\n", "code_toks_joined": "def symlink ( source , destination , use_bind = False ) : <NEWLINE> <INDENT> worker . register_resource ( <NEWLINE> <INDENT> SymlinkResource ( <NEWLINE> <INDENT> source , destination , use_bind <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["0db4bafeaeb9db28e6b25fc3ca16c5ae", {"code_string": "def tab_response(self):\n    if self.flow.intercepted and self.flow.response:\n        return \"Response intercepted\"\n    else:\n        return \"Response\"\n", "code_toks_joined": "def tab_response ( self ) : <NEWLINE> <INDENT> if self . flow . intercepted and self . flow . response : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Response intercepted\"", "\"Response\""]}}], ["7b058dc8ce7c98ba01275f5f76aefdab", {"code_string": "\"\"\"Ops for building neural network seq2seq decoders and losses.\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow.contrib.seq2seq.python.ops.basic_decoder import *\nfrom tensorflow.contrib.seq2seq.python.ops.decoder import *\nfrom tensorflow.contrib.seq2seq.python.ops.dynamic_attention_wrapper import *\nfrom tensorflow.contrib.seq2seq.python.ops.helper import *\nfrom tensorflow.contrib.seq2seq.python.ops.loss import *\nfrom tensorflow.python.util.all_util import remove_undocumented\n_allowed_symbols = [\"sequence_loss\"]\nremove_undocumented(__name__, _allowed_symbols)\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import absolute_import <NEWLINE> from __future__ import division <NEWLINE> from __future__ import print_function <NEWLINE> from tensorflow . contrib . seq2seq . python . ops . basic_decoder import * <NEWLINE> from tensorflow . contrib . seq2seq . python . ops . decoder import * <NEWLINE> from tensorflow . contrib . seq2seq . python . ops . dynamic_attention_wrapper import * <NEWLINE> from tensorflow . contrib . seq2seq . python . ops . helper import * <NEWLINE> from tensorflow . contrib . seq2seq . python . ops . loss import * <NEWLINE> from tensorflow . python . util . all_util import remove_undocumented <NEWLINE> _allowed_symbols = [ <STRING> ] <NEWLINE> remove_undocumented ( __name__ , _allowed_symbols ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Ops for building neural network seq2seq decoders and losses.\"\"\"", "\"sequence_loss\""]}}], ["1834804c6e4370b5d60dd3a0a28e0dd6", {"code_string": "from setuptools import setup\nsetup(\n    name = \"lazypool\",\n    version = \"1.0.0\",\n    author = \"Nathaniel Williams\",\n    author_email = \"nat.williams@gmail.com\",\n    license = \"Apache 2.0\",\n    url = \"https://github.com/natw/lazypool\",\n    packages = ['lazypool'],\n)\n", "code_toks_joined": "from setuptools import setup <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> license = <STRING> , <NEWLINE> url = <STRING> , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"lazypool\"", "\"1.0.0\"", "\"Nathaniel Williams\"", "\"nat.williams@gmail.com\"", "\"Apache 2.0\"", "\"https://github.com/natw/lazypool\"", "'lazypool'"]}}], ["d104561f89c6e8d80ed24a66666d0b27", {"code_string": "def __init__(self, ** kwargs):\n    super(Proposal, self).__init__(** kwargs)\n    self.votes = VoteSpace(type = SPACETYPE.PROPOSAL)\n    self.comments = CommentSpace(type = SPACETYPE.PROPOSAL)\n", "code_toks_joined": "def __init__ ( self , ** kwargs ) : <NEWLINE> <INDENT> super ( Proposal , self ) . __init__ ( ** kwargs ) <NEWLINE> self . votes = VoteSpace ( type = SPACETYPE . PROPOSAL ) <NEWLINE> self . comments = CommentSpace ( type = SPACETYPE . PROPOSAL ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["300bbff77366bfee4246c0f1ebd9d969", {"code_string": "def testfindfit(data):\n    if verbose:\n        print('findfit')\n    if audioop.findfit(data[1], data[1]) !=(0, 1.0):\n        return 0\n    return 1\n", "code_toks_joined": "def testfindfit ( data ) : <NEWLINE> <INDENT> if verbose : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> if audioop . findfit ( data [ 1 ] , data [ 1 ] ) != ( 0 , 1.0 ) : <NEWLINE> <INDENT> return 0 <NEWLINE> <DEDENT> return 1 <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'findfit'"]}}], ["f0045720a310680e93bcecdf7a64893d", {"code_string": "from distutils.core import setup\nsetup(\n    name = 'python-percy',\n    version = '0.0.1',\n    description = 'python-percy',\n    author = 'Jonas Trappenberg',\n    author_email = 'jonas-github-python-percy@trappenberg.ch',\n    url = 'https://github.com/teeberg/python-percy',\n    packages = ['percy'],\n    install_requires = [\n        'bs4',\n        'GitPython<2',\n        'requests',\n        'six',\n        'tinycss2',\n    ],\n)\n", "code_toks_joined": "from distutils . core import setup <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> url = <STRING> , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> install_requires = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <DEDENT> ] , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'python-percy'", "'0.0.1'", "'python-percy'", "'Jonas Trappenberg'", "'jonas-github-python-percy@trappenberg.ch'", "'https://github.com/teeberg/python-percy'", "'percy'", "'bs4'", "'GitPython<2'", "'requests'", "'six'", "'tinycss2'"]}}], ["0135796e81e6fa9c56441e2316d28c61", {"code_string": "def getlocale(category = LC_CTYPE):\n    \"\"\" Returns the current setting for the given locale category as\"\"\"\n    return None, None\n", "code_toks_joined": "def getlocale ( category = LC_CTYPE ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return None , None <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Returns the current setting for the given locale category as\"\"\""]}}], ["87ff3b058b7feac73ac8970709a7266f", {"code_string": "def __call__(self, y):\n    res = self.interpolate(y)\n    return res\n", "code_toks_joined": "def __call__ ( self , y ) : <NEWLINE> <INDENT> res = self . interpolate ( y ) <NEWLINE> return res <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["4b0eaa47c1b491d394d0ab5d65bd67cd", {"code_string": "from selene.support import by\nfrom selene.support.jquery_style_selectors import s\nfrom selenium.webdriver.common.by import By\nfrom TestUserData.TestUserData import test_email, correct_test_password\nfrom roses.rosesPages.RemindpasswordPage import RemindpasswordPage\nfrom roses.rosesPages.TopBottomMenu import TopBottomMenu\nfrom roses.rosesPages.UsercabinetPage import UsercabinetPage\n", "code_toks_joined": "from selene . support import by <NEWLINE> from selene . support . jquery_style_selectors import s <NEWLINE> from selenium . webdriver . common . by import By <NEWLINE> from TestUserData . TestUserData import test_email , correct_test_password <NEWLINE> from roses . rosesPages . RemindpasswordPage import RemindpasswordPage <NEWLINE> from roses . rosesPages . TopBottomMenu import TopBottomMenu <NEWLINE> from roses . rosesPages . UsercabinetPage import UsercabinetPage <NEWLINE>", "anonymize_dict": {}}], ["aad543b601e8fb39417793ab416d00b3", {"code_string": "def test_goalf_toolchain(self):\n    \"\"\"Test for goalf toolchain.\"\"\"\n    self.get_toolchain(\"goalf\", version = \"1.1.0-no-OFED\")\n", "code_toks_joined": "def test_goalf_toolchain ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . get_toolchain ( <STRING> , version = <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test for goalf toolchain.\"\"\"", "\"goalf\"", "\"1.1.0-no-OFED\""]}}], ["851c4b0fc3587c6bf7149f1d697b3c3d", {"code_string": "from helpers import crop_image\nfrom lbp import LocalBinaryPatternsDescriptor\nfrom hist import HistDescriptor\n", "code_toks_joined": "from helpers import crop_image <NEWLINE> from lbp import LocalBinaryPatternsDescriptor <NEWLINE> from hist import HistDescriptor <NEWLINE>", "anonymize_dict": {}}], ["cf1ce1243b32c947b2b4e0c2ff59eff6", {"code_string": "from unittest import TestCase\nimport numpy as np\nfrom sklearn.svm.classes import SVC\nfrom tests.estimator.classifier.Classifier import Classifier\nfrom tests.language.Ruby import Ruby\n", "code_toks_joined": "from unittest import TestCase <NEWLINE> import numpy as np <NEWLINE> from sklearn . svm . classes import SVC <NEWLINE> from tests . estimator . classifier . Classifier import Classifier <NEWLINE> from tests . language . Ruby import Ruby <NEWLINE>", "anonymize_dict": {}}], ["d23006157bb0d58d6099af97d482d2ae", {"code_string": "def _parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--loglevel', choices = ('DEBUG', 'INFO', 'WARNING'),\n        default = 'DEBUG')\n    parser.add_argument('--folder', default = DEFAULT_FOLDER)\n    parser.add_argument('--pickle', default = None)\n    parser.add_argument('--seed', default = DEFAULT_SEED)\n    return parser.parse_args()\n", "code_toks_joined": "def _parse_args ( ) : <NEWLINE> <INDENT> parser = argparse . ArgumentParser ( ) <NEWLINE> parser . add_argument ( <STRING> , choices = ( <STRING> , <STRING> , <STRING> ) , <NEWLINE> <INDENT> default = <STRING> ) <NEWLINE> <DEDENT> parser . add_argument ( <STRING> , default = DEFAULT_FOLDER ) <NEWLINE> parser . add_argument ( <STRING> , default = None ) <NEWLINE> parser . add_argument ( <STRING> , default = DEFAULT_SEED ) <NEWLINE> return parser . parse_args ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'--loglevel'", "'DEBUG'", "'INFO'", "'WARNING'", "'DEBUG'", "'--folder'", "'--pickle'", "'--seed'"]}}], ["10540ceb286b7607b11dab4b8654c068", {"code_string": "def get_profile_page_html(self, uid = None, page = '1', domain = 'http://weibo.cn'):\n    if not uid:\n        uid = str(self.http_helper.get_uid())\n    profile_path = self.path_profile.replace('{domain}', domain)\n    profile_path = profile_path.replace('{uid}', str(uid))\n    profile_path = profile_path.replace('{page}', str(page))\n    return self.http_helper.get_html(profile_path)\n", "code_toks_joined": "def get_profile_page_html ( self , uid = None , page = <STRING> , domain = <STRING> ) : <NEWLINE> <INDENT> if not uid : <NEWLINE> <INDENT> uid = str ( self . http_helper . get_uid ( ) ) <NEWLINE> <DEDENT> profile_path = self . path_profile . replace ( <STRING> , domain ) <NEWLINE> profile_path = profile_path . replace ( <STRING> , str ( uid ) ) <NEWLINE> profile_path = profile_path . replace ( <STRING> , str ( page ) ) <NEWLINE> return self . http_helper . get_html ( profile_path ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'1'", "'http://weibo.cn'", "'{domain}'", "'{uid}'", "'{page}'"]}}], ["4e34751d6fdc90dc09ddb7c0c4dd0d5c", {"code_string": "from datetime import datetime\nfrom dateutil.relativedelta import relativedelta\nimport time\nimport pooler\nfrom report.render import render\n", "code_toks_joined": "from datetime import datetime <NEWLINE> from dateutil . relativedelta import relativedelta <NEWLINE> import time <NEWLINE> import pooler <NEWLINE> from report . render import render <NEWLINE>", "anonymize_dict": {}}], ["34597b9a752772fa8606fcf60a3b880d", {"code_string": "from gravity.tae.text import Text, TextBulk, TextFile, TokenizedText, GzipTextFile, XmlText\nfrom gravity.tae.text import fRegexpSearch, fMatch, fSearch, AnnotatedText\nfrom gravity.tae.text import fStandardSearch, fStandardMatch, fSearchAll, fTokensAligner\nfrom gravity.tae.tokenizer import WhiteSpaceTokenzier\nimport unittest, os, re\ntest_dir = os.path.dirname(__file__)\ntxt_file = os.path.join(test_dir, \"text.txt\")\nassert os.path.exists(txt_file)\n", "code_toks_joined": "from gravity . tae . text import Text , TextBulk , TextFile , TokenizedText , GzipTextFile , XmlText <NEWLINE> from gravity . tae . text import fRegexpSearch , fMatch , fSearch , AnnotatedText <NEWLINE> from gravity . tae . text import fStandardSearch , fStandardMatch , fSearchAll , fTokensAligner <NEWLINE> from gravity . tae . tokenizer import WhiteSpaceTokenzier <NEWLINE> import unittest , os , re <NEWLINE> test_dir = os . path . dirname ( __file__ ) <NEWLINE> txt_file = os . path . join ( test_dir , <STRING> ) <NEWLINE> assert os . path . exists ( txt_file ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"text.txt\""]}}], ["1b121afc0d2f3acf23c989c7d45c0090", {"code_string": "def update_paths(pipe_dict, ms_path = None, pipepath = None):\n    if ms_path is not None:\n        pipe_dict['ms_active'] = ms_path\n        pipe_dict['SDM_name'] = ms_path[: - 3]\n    if pipepath is not None:\n        pipe_dict['pipepath'] = pipepath\n    return pipe_dict\n", "code_toks_joined": "def update_paths ( pipe_dict , ms_path = None , pipepath = None ) : <NEWLINE> <INDENT> if ms_path is not None : <NEWLINE> <INDENT> pipe_dict [ <STRING> ] = ms_path <NEWLINE> pipe_dict [ <STRING> ] = ms_path [ : - 3 ] <NEWLINE> <DEDENT> if pipepath is not None : <NEWLINE> <INDENT> pipe_dict [ <STRING> ] = pipepath <NEWLINE> <DEDENT> return pipe_dict <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'ms_active'", "'SDM_name'", "'pipepath'"]}}], ["f2e9578ea2d225d91b7e8a6cce748cb3", {"code_string": "class Command(BaseCommand):\n    help = \"Completely rebuilds the search index by removing the old data and then updating.\"\n    option_list = list(BaseCommand.option_list) + list(ClearCommand.base_options) +[option for option in UpdateCommand.base_options if option.get_opt_string() == '-u']\n    def handle(self, ** options):\n        call_command('clear_index', ** options)\n        call_command('update_index', ** options)\n", "code_toks_joined": "class Command ( BaseCommand ) : <NEWLINE> <INDENT> help = <STRING> <NEWLINE> option_list = list ( BaseCommand . option_list ) + list ( ClearCommand . base_options ) + [ option for option in UpdateCommand . base_options if option . get_opt_string ( ) == <STRING> ] <NEWLINE> def handle ( self , ** options ) : <NEWLINE> <INDENT> call_command ( <STRING> , ** options ) <NEWLINE> call_command ( <STRING> , ** options ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Completely rebuilds the search index by removing the old data and then updating.\"", "'-u'", "'clear_index'", "'update_index'"]}}], ["d8eccefba9dd86dff052217a4f5d0d3d", {"code_string": "def _get_connection_list(self, hosts, port):\n    \"\"\"Create a connection object for `etcd.Client`.  Returns a tuple\"\"\"\n    return['{host}:{port}'.format(** locals())\n        for host in hosts]\n", "code_toks_joined": "def _get_connection_list ( self , hosts , port ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return [ <STRING> . format ( ** locals ( ) ) <NEWLINE> <INDENT> for host in hosts ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Create a connection object for `etcd.Client`.  Returns a tuple\"\"\"", "'{host}:{port}'"]}}], ["0592cd74aad0a79ec07d05914e262877", {"code_string": "def get_rater_ids(self, batch_id):\n    values = []\n    for rating_object in self.ratings:\n        if rating_object.batch_id == batch_id and rating_object.rater_id not in values:\n            values.append(rating_object.rater_id)\n    return values[0: 5]\n", "code_toks_joined": "def get_rater_ids ( self , batch_id ) : <NEWLINE> <INDENT> values = [ ] <NEWLINE> for rating_object in self . ratings : <NEWLINE> <INDENT> if rating_object . batch_id == batch_id and rating_object . rater_id not in values : <NEWLINE> <INDENT> values . append ( rating_object . rater_id ) <NEWLINE> <DEDENT> <DEDENT> return values [ 0 : 5 ] <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["d91f332467472fb2cc6c28323fe31825", {"code_string": "def _im_identify_type(fn):\n    out = check_output([\"identify\", \"-format\", \"%m\\n\", fn]).split('\\n')[0]\n    return out.strip().lower()\n", "code_toks_joined": "def _im_identify_type ( fn ) : <NEWLINE> <INDENT> out = check_output ( [ <STRING> , <STRING> , <STRING> , fn ] ) . split ( <STRING> ) [ 0 ] <NEWLINE> return out . strip ( ) . lower ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"identify\"", "\"-format\"", "\"%m\\n\"", "'\\n'"]}}], ["07aefc77abe94fba18c199f9773b533b", {"code_string": "import os\nfrom django.conf import settings\nfrom django.core.exceptions import ImproperlyConfigured\nfrom django.forms import ValidationError\nfrom.models import AjaxFileUploaded\nfrom.signals import pre_ajax_file_save\n", "code_toks_joined": "import os <NEWLINE> from django . conf import settings <NEWLINE> from django . core . exceptions import ImproperlyConfigured <NEWLINE> from django . forms import ValidationError <NEWLINE> from . models import AjaxFileUploaded <NEWLINE> from . signals import pre_ajax_file_save <NEWLINE>", "anonymize_dict": {}}], ["432b3168d63b0d34161825748b30e20c", {"code_string": "from __future__ import division\nimport logging\nimport os\nimport pkg_resources\nimport pandas\nfrom pandas import concat\nfrom openfisca_france_indirect_taxation.build_survey_data.utils import ident_men_dtype\nlog = logging.getLogger(__name__)\n", "code_toks_joined": "from __future__ import division <NEWLINE> import logging <NEWLINE> import os <NEWLINE> import pkg_resources <NEWLINE> import pandas <NEWLINE> from pandas import concat <NEWLINE> from openfisca_france_indirect_taxation . build_survey_data . utils import ident_men_dtype <NEWLINE> log = logging . getLogger ( __name__ ) <NEWLINE>", "anonymize_dict": {}}], ["9ba29a4658c3afd5573acf63254ea2aa", {"code_string": "def fin_current(self, t = None):\n    if(not t):\n        t = time.time()\n    if(self.cur_event):\n        self.cur_event.end = t\n        self.cur_event = None\n", "code_toks_joined": "def fin_current ( self , t = None ) : <NEWLINE> <INDENT> if ( not t ) : <NEWLINE> <INDENT> t = time . time ( ) <NEWLINE> <DEDENT> if ( self . cur_event ) : <NEWLINE> <INDENT> self . cur_event . end = t <NEWLINE> self . cur_event = None <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["603ec06acbc977135375eb28c3d3f2ac", {"code_string": "def F2level(J, B, D, H, lamb, lambdap, lambdapp, mu, mup, mupp, muppp):\n    x = J *(J + 1)\n    return B * x - D * x * x + H * x * x * x + 2 * lamb / 3 + 2 * lambdap * x / 3 + 2 * lambdapp * x * x / 3 - mu - mup * x - mupp * x * x + muppp\n", "code_toks_joined": "def F2level ( J , B , D , H , lamb , lambdap , lambdapp , mu , mup , mupp , muppp ) : <NEWLINE> <INDENT> x = J * ( J + 1 ) <NEWLINE> return B * x - D * x * x + H * x * x * x + 2 * lamb / 3 + 2 * lambdap * x / 3 + 2 * lambdapp * x * x / 3 - mu - mup * x - mupp * x * x + muppp <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["07bef1749b5422cb8dfdbc71e1a45a7e", {"code_string": "def setUp(self):\n    \"\"\"Sets up the needed objects used throughout the test.\"\"\"\n    pre_obj = event.PreprocessObject()\n    self._plugin = mac_document_versions.MacDocumentVersionsPlugin(pre_obj)\n", "code_toks_joined": "def setUp ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> pre_obj = event . PreprocessObject ( ) <NEWLINE> self . _plugin = mac_document_versions . MacDocumentVersionsPlugin ( pre_obj ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Sets up the needed objects used throughout the test.\"\"\""]}}], ["356a43578d349b9ec596d64e9a024b52", {"code_string": "def test_return_for():\n    \"\"\"else + return is not accetable.\"\"\"\n    for i in range(10):\n        if i % 2:\n            return i\n    else:\n        print('math is broken')\n", "code_toks_joined": "def test_return_for ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> for i in range ( 10 ) : <NEWLINE> <INDENT> if i % 2 : <NEWLINE> <INDENT> return i <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"else + return is not accetable.\"\"\"", "'math is broken'"]}}], ["abc4729a5989d1d43464af893dd532fa", {"code_string": "\"\"\"c_annotations.py\"\"\"\nfrom os import path\nfrom docutils import nodes\nfrom docutils.parsers.rst import directives\nfrom sphinx import addnodes\nfrom sphinx.domains.c import CObject\n", "code_toks_joined": "<STRING> <NEWLINE> from os import path <NEWLINE> from docutils import nodes <NEWLINE> from docutils . parsers . rst import directives <NEWLINE> from sphinx import addnodes <NEWLINE> from sphinx . domains . c import CObject <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"c_annotations.py\"\"\""]}}], ["823e4e94a7eb165d8988e1937d0cb432", {"code_string": "def str2int(s):\n    def fn2(x, y):\n        return x * 10 + y\n    def char2num2(s):\n        return{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9}[s]\n    return reduce(fn2, map(char2num2, s))\n", "code_toks_joined": "def str2int ( s ) : <NEWLINE> <INDENT> def fn2 ( x , y ) : <NEWLINE> <INDENT> return x * 10 + y <NEWLINE> <DEDENT> def char2num2 ( s ) : <NEWLINE> <INDENT> return { <STRING> : 0 , <STRING> : 1 , <STRING> : 2 , <STRING> : 3 , <STRING> : 4 , <STRING> : 5 , <STRING> : 6 , <STRING> : 7 , <STRING> : 8 , <STRING> : 9 } [ s ] <NEWLINE> <DEDENT> return reduce ( fn2 , map ( char2num2 , s ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'0'", "'1'", "'2'", "'3'", "'4'", "'5'", "'6'", "'7'", "'8'", "'9'"]}}], ["1093f343cd64dd1108d5fcbad722c210", {"code_string": "import hashlib\nsecret_key = \"yzbqklnj\"\nnumber = 0\n", "code_toks_joined": "import hashlib <NEWLINE> secret_key = <STRING> <NEWLINE> number = 0 <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"yzbqklnj\""]}}], ["6ae46e3931647659e881cf3e0a89400d", {"code_string": "from django import forms\nfrom django.forms.utils import flatatt\nfrom django.utils.html import escape\nfrom django.utils.safestring import mark_safe\nfrom django.utils.translation import ugettext as _\n", "code_toks_joined": "from django import forms <NEWLINE> from django . forms . utils import flatatt <NEWLINE> from django . utils . html import escape <NEWLINE> from django . utils . safestring import mark_safe <NEWLINE> from django . utils . translation import ugettext as _ <NEWLINE>", "anonymize_dict": {}}], ["19c7944664f7942de18304f465029ed1", {"code_string": "\"\"\"Tools for setting up printing in interactive sessions. \"\"\"\nfrom __future__ import print_function, division\nfrom io import BytesIO\ntry:\n    from sympy import latex as default_latex\n    from sympy import preview\n    from sympy.core.compatibility import integer_types\n    from sympy.utilities.misc import debug\nexcept ImportError:\n    print(\"Sympy could not be found, so LaTeX printing cannot be enabled.\")\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import print_function , division <NEWLINE> from io import BytesIO <NEWLINE> try : <NEWLINE> <INDENT> from sympy import latex as default_latex <NEWLINE> from sympy import preview <NEWLINE> from sympy . core . compatibility import integer_types <NEWLINE> from sympy . utilities . misc import debug <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Tools for setting up printing in interactive sessions. \"\"\"", "\"Sympy could not be found, so LaTeX printing cannot be enabled.\""]}}], ["4e98c2dff3abf0e0c9d254d58377cb00", {"code_string": "'''Created on Jun 11, 2015'''\nimport time\nimport logging\nimport numpy as np\nfrom robo.initial_design.init_random_uniform import init_random_uniform\nfrom robo.solver.bayesian_optimization import BayesianOptimization\nfrom robo.incumbent.best_observation import BestProjectedObservation\nfrom robo.initial_design.extrapolative_initial_design import extrapolative_initial_design\nlogger = logging.getLogger(__name__)\n", "code_toks_joined": "<STRING> <NEWLINE> import time <NEWLINE> import logging <NEWLINE> import numpy as np <NEWLINE> from robo . initial_design . init_random_uniform import init_random_uniform <NEWLINE> from robo . solver . bayesian_optimization import BayesianOptimization <NEWLINE> from robo . incumbent . best_observation import BestProjectedObservation <NEWLINE> from robo . initial_design . extrapolative_initial_design import extrapolative_initial_design <NEWLINE> logger = logging . getLogger ( __name__ ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Created on Jun 11, 2015'''"]}}], ["e39b7c53364e92cc02b9ca5a811dadf6", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('workout_programs', '0006_auto_20170220_2217'),\n    ]\n    operations = [\n        migrations.RemoveField(\n            model_name = 'set',\n            name = 'number',\n        ),\n        migrations.AlterField(\n            model_name = 'set',\n            name = 'exercise_block',\n            field = models.ForeignKey(on_delete = django.db.models.deletion.CASCADE, related_name = 'sets_to_be_completed', to = 'workout_programs.ExerciseBlock'),\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . RemoveField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> <DEDENT> ) , <NEWLINE> migrations . AlterField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . ForeignKey ( on_delete = django . db . models . deletion . CASCADE , related_name = <STRING> , to = <STRING> ) , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'workout_programs'", "'0006_auto_20170220_2217'", "'set'", "'number'", "'set'", "'exercise_block'", "'sets_to_be_completed'", "'workout_programs.ExerciseBlock'"]}}], ["14651d92339c235253ca2bb389269efa", {"code_string": "class Collections(enum.Enum):\n    \"\"\"Collections for all supported apis.\"\"\"\n    PROJECTS_TESTMATRICES = (\n        'projects.testMatrices',\n        'projects/{projectId}/testMatrices/{testMatrixId}',\n        {},\n        [u'projectId', u'testMatrixId']\n    )\n    TESTENVIRONMENTCATALOG = (\n        'testEnvironmentCatalog',\n        'testEnvironmentCatalog/{environmentType}',\n        {},\n        [u'environmentType']\n    )\n    def __init__(self, collection_name, path, flat_paths, params):\n        self.collection_name = collection_name\n        self.path = path\n        self.flat_paths = flat_paths\n        self.params = params\n", "code_toks_joined": "class Collections ( enum . Enum ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> PROJECTS_TESTMATRICES = ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> { } , <NEWLINE> [ <STRING> , <STRING> ] <NEWLINE> <DEDENT> ) <NEWLINE> TESTENVIRONMENTCATALOG = ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> { } , <NEWLINE> [ <STRING> ] <NEWLINE> <DEDENT> ) <NEWLINE> def __init__ ( self , collection_name , path , flat_paths , params ) : <NEWLINE> <INDENT> self . collection_name = collection_name <NEWLINE> self . path = path <NEWLINE> self . flat_paths = flat_paths <NEWLINE> self . params = params <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Collections for all supported apis.\"\"\"", "'projects.testMatrices'", "'projects/{projectId}/testMatrices/{testMatrixId}'", "u'projectId'", "u'testMatrixId'", "'testEnvironmentCatalog'", "'testEnvironmentCatalog/{environmentType}'", "u'environmentType'"]}}], ["33fae4f4b14b2cd4d2b4cbb358219448", {"code_string": "def render_prompt(self, prompt):\n    '''Parses the `prompt` string and returns the rendered version'''\n    prompt = prompt.strip(\"'\").replace(\"\\\\'\", \"'\")\n    for colour in ansi.COLOURS_NAMED:\n        if '[%s]' %(colour) in prompt:\n            prompt = prompt.replace(\n                '[%s]' %(colour), ansiFormatter.cmdColourNamed(colour))\n    prompt = prompt.replace('[R]', ansiFormatter.cmdReset())\n    return prompt\n", "code_toks_joined": "def render_prompt ( self , prompt ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> prompt = prompt . strip ( <STRING> ) . replace ( <STRING> , <STRING> ) <NEWLINE> for colour in ansi . COLOURS_NAMED : <NEWLINE> <INDENT> if <STRING> % ( colour ) in prompt : <NEWLINE> <INDENT> prompt = prompt . replace ( <NEWLINE> <INDENT> <STRING> % ( colour ) , ansiFormatter . cmdColourNamed ( colour ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> prompt = prompt . replace ( <STRING> , ansiFormatter . cmdReset ( ) ) <NEWLINE> return prompt <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Parses the `prompt` string and returns the rendered version'''", "\"'\"", "\"\\\\'\"", "\"'\"", "'[%s]'", "'[%s]'", "'[R]'"]}}], ["a77d74238f81650dab0c0546fbbd962c", {"code_string": "from abc_lexer import ABC_Lexer\nimport time\nimport sys\nlex = ABC_Lexer()\n", "code_toks_joined": "from abc_lexer import ABC_Lexer <NEWLINE> import time <NEWLINE> import sys <NEWLINE> lex = ABC_Lexer ( ) <NEWLINE>", "anonymize_dict": {}}], ["595869bc94f6c1d75cb948985ec676bd", {"code_string": "from model.group import Group\nimport random\nimport string\nimport os.path\nimport jsonpickle\nimport getopt\nimport sys\ntry:\n    opts, args = getopt.getopt(sys.argv[1: ], \"n:f:\", [\"number of groups\", \"file\"])\nexcept:\n    getopt.usage()\n    sys.exit(2)\nn = 5\nf = \"data/groups.json\"\nfor o, a in opts:\n    if o == '-n':\n        n = int(a)\n    elif o == '-f':\n        f = a\n", "code_toks_joined": "from model . group import Group <NEWLINE> import random <NEWLINE> import string <NEWLINE> import os . path <NEWLINE> import jsonpickle <NEWLINE> import getopt <NEWLINE> import sys <NEWLINE> try : <NEWLINE> <INDENT> opts , args = getopt . getopt ( sys . argv [ 1 : ] , <STRING> , [ <STRING> , <STRING> ] ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> getopt . usage ( ) <NEWLINE> sys . exit ( 2 ) <NEWLINE> <DEDENT> n = 5 <NEWLINE> f = <STRING> <NEWLINE> for o , a in opts : <NEWLINE> <INDENT> if o == <STRING> : <NEWLINE> <INDENT> n = int ( a ) <NEWLINE> <DEDENT> elif o == <STRING> : <NEWLINE> <INDENT> f = a <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"n:f:\"", "\"number of groups\"", "\"file\"", "\"data/groups.json\"", "'-n'", "'-f'"]}}], ["fc78517d6f4ad2ef7342aa985ceca658", {"code_string": "import os\nimport glob\nimport xml.etree.ElementTree as elementTree\nimport pymysql as mySQL\nimport argparse\nimport getpass\n", "code_toks_joined": "import os <NEWLINE> import glob <NEWLINE> import xml . etree . ElementTree as elementTree <NEWLINE> import pymysql as mySQL <NEWLINE> import argparse <NEWLINE> import getpass <NEWLINE>", "anonymize_dict": {}}], ["df49adb7dff4f8066e08b096492ad9b8", {"code_string": "\"\"\"The plunger file handler for writing information about the model to stdout.\"\"\"\nimport sys\ntry:\n    from plunger import toolbox\nexcept ImportError:\n    sys.path.append(\"..\")\n    import toolbox\n    sys.path.pop()\nformat = \"info\"\next = \"\"\nneeds_dir = False\ndoes_import = False\ndoes_export = True\nversion = \"0.1.0\"\n", "code_toks_joined": "<STRING> <NEWLINE> import sys <NEWLINE> try : <NEWLINE> <INDENT> from plunger import toolbox <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> sys . path . append ( <STRING> ) <NEWLINE> import toolbox <NEWLINE> sys . path . pop ( ) <NEWLINE> <DEDENT> format = <STRING> <NEWLINE> ext = <STRING> <NEWLINE> needs_dir = False <NEWLINE> does_import = False <NEWLINE> does_export = True <NEWLINE> version = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"The plunger file handler for writing information about the model to stdout.\"\"\"", "\"..\"", "\"info\"", "\"\"", "\"0.1.0\""]}}], ["cfac2c5e101ce6c39278a97b7b4ffb62", {"code_string": "import os\nimport re\nPS3AUTOTESTS_DIR = os.path.abspath(\"..\")\nPS3AUTOTESTS_BENCHMARKS = os.path.join(PS3AUTOTESTS_DIR, \"benchmarks\")\nPS3AUTOTESTS_COMMON = os.path.join(PS3AUTOTESTS_DIR, \"common\")\nPS3AUTOTESTS_TESTS = os.path.join(PS3AUTOTESTS_DIR, \"tests\")\n", "code_toks_joined": "import os <NEWLINE> import re <NEWLINE> PS3AUTOTESTS_DIR = os . path . abspath ( <STRING> ) <NEWLINE> PS3AUTOTESTS_BENCHMARKS = os . path . join ( PS3AUTOTESTS_DIR , <STRING> ) <NEWLINE> PS3AUTOTESTS_COMMON = os . path . join ( PS3AUTOTESTS_DIR , <STRING> ) <NEWLINE> PS3AUTOTESTS_TESTS = os . path . join ( PS3AUTOTESTS_DIR , <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"..\"", "\"benchmarks\"", "\"common\"", "\"tests\""]}}], ["96f2ffe2f01f2b688a7168f75776738b", {"code_string": "\"\"\"*************************************\"\"\"\nfrom espresso.esutil import cxxinit\nfrom espresso import pmi\nfrom _espresso import analysis_Autocorrelation\n", "code_toks_joined": "<STRING> <NEWLINE> from espresso . esutil import cxxinit <NEWLINE> from espresso import pmi <NEWLINE> from _espresso import analysis_Autocorrelation <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"*************************************\"\"\""]}}], ["47fbadaef3e1c88e59db0f93fc917966", {"code_string": "def nlogn_model(start, log_slope):\n    def __inner_model__(x):\n        return start + log_slope * x.name * math.log(x.name or 0.0001)\n    return __inner_model__\n", "code_toks_joined": "def nlogn_model ( start , log_slope ) : <NEWLINE> <INDENT> def __inner_model__ ( x ) : <NEWLINE> <INDENT> return start + log_slope * x . name * math . log ( x . name or 0.0001 ) <NEWLINE> <DEDENT> return __inner_model__ <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["4e994e34fdadbdac9a5e8abbda690a44", {"code_string": "def set_cache(rev):\n    from django.core.cache import cache\n    cache.set('current_revision', rev, timeout = None)\n", "code_toks_joined": "def set_cache ( rev ) : <NEWLINE> <INDENT> from django . core . cache import cache <NEWLINE> cache . set ( <STRING> , rev , timeout = None ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'current_revision'"]}}], ["66bd12d841d1b0573dd7fc311173a6bc", {"code_string": "def importDB():\n    selimagedb = filedialog.askopenfile(filetypes = ((\"Image Database\", \"*.pmdb\"), (\"All files\", \"*.*\")))\n    try:\n        IMDatabase = pickle.load(open(selimagedb, \"rb\"))\n    except:\n        invalidimagewindow(\"Error: Invalid Database\", \"Unable to import.\")\n", "code_toks_joined": "def importDB ( ) : <NEWLINE> <INDENT> selimagedb = filedialog . askopenfile ( filetypes = ( ( <STRING> , <STRING> ) , ( <STRING> , <STRING> ) ) ) <NEWLINE> try : <NEWLINE> <INDENT> IMDatabase = pickle . load ( open ( selimagedb , <STRING> ) ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> invalidimagewindow ( <STRING> , <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Image Database\"", "\"*.pmdb\"", "\"All files\"", "\"*.*\"", "\"rb\"", "\"Error: Invalid Database\"", "\"Unable to import.\""]}}], ["5c2b139bb2739c6edde8471eb67bde7c", {"code_string": "def forwards(self, orm):\n    \"Write your forwards methods here.\"\n    threads = orm['askbot.Thread'].objects.all()\n    count = threads.count()\n    message = 'Adding site to threads'\n    site_id = django_settings.SITE_ID\n    current_site = orm['sites.Site'].objects.get(id = site_id)\n    for thread in ProgressBar(threads.iterator(), count, message):\n        thread.site = current_site\n        thread.save()\n", "code_toks_joined": "def forwards ( self , orm ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> threads = orm [ <STRING> ] . objects . all ( ) <NEWLINE> count = threads . count ( ) <NEWLINE> message = <STRING> <NEWLINE> site_id = django_settings . SITE_ID <NEWLINE> current_site = orm [ <STRING> ] . objects . get ( id = site_id ) <NEWLINE> for thread in ProgressBar ( threads . iterator ( ) , count , message ) : <NEWLINE> <INDENT> thread . site = current_site <NEWLINE> thread . save ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Write your forwards methods here.\"", "'askbot.Thread'", "'Adding site to threads'", "'sites.Site'"]}}], ["0986783f0116ffc114f6dff60f2537be", {"code_string": "\"\"\"Schema module provides auto-generate relational database model as object based.\"\"\"\nimport inspect\nfrom..singleton import Singleton as dpSingleton\nfrom..engine import Engine as dpEngine\nfrom..loader import Loader as dpLoader\nfrom..model import Model as dpModel\nfrom..cache import dpInValueModelConfig\n", "code_toks_joined": "<STRING> <NEWLINE> import inspect <NEWLINE> from . . singleton import Singleton as dpSingleton <NEWLINE> from . . engine import Engine as dpEngine <NEWLINE> from . . loader import Loader as dpLoader <NEWLINE> from . . model import Model as dpModel <NEWLINE> from . . cache import dpInValueModelConfig <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Schema module provides auto-generate relational database model as object based.\"\"\""]}}], ["04c261db43b64258df77f344828891bf", {"code_string": "import wsme\nfrom wsme.rest import json\nfrom wsme import types\nfrom daisy.api.v2.model.metadef_object import MetadefObject\nfrom daisy.api.v2.model.metadef_property_type import PropertyType\nfrom daisy.api.v2.model.metadef_resource_type import ResourceTypeAssociation\nfrom daisy.api.v2.model.metadef_tag import MetadefTag\nfrom daisy.common.wsme_utils import WSMEModelTransformer\n", "code_toks_joined": "import wsme <NEWLINE> from wsme . rest import json <NEWLINE> from wsme import types <NEWLINE> from daisy . api . v2 . model . metadef_object import MetadefObject <NEWLINE> from daisy . api . v2 . model . metadef_property_type import PropertyType <NEWLINE> from daisy . api . v2 . model . metadef_resource_type import ResourceTypeAssociation <NEWLINE> from daisy . api . v2 . model . metadef_tag import MetadefTag <NEWLINE> from daisy . common . wsme_utils import WSMEModelTransformer <NEWLINE>", "anonymize_dict": {}}], ["86d14ff1d7a71d16d259effc9f497334", {"code_string": "import re\nfrom django import http\ntry:\n    from urlparse import urlparse\nexcept ImportError:\n    from urllib.parse import urlparse\nfrom corsheaders import defaults as settings\nfrom django.db.models.loading import get_model\nACCESS_CONTROL_ALLOW_ORIGIN = 'Access-Control-Allow-Origin'\nACCESS_CONTROL_EXPOSE_HEADERS = 'Access-Control-Expose-Headers'\nACCESS_CONTROL_ALLOW_CREDENTIALS = 'Access-Control-Allow-Credentials'\nACCESS_CONTROL_ALLOW_HEADERS = 'Access-Control-Allow-Headers'\nACCESS_CONTROL_ALLOW_METHODS = 'Access-Control-Allow-Methods'\nACCESS_CONTROL_MAX_AGE = 'Access-Control-Max-Age'\n", "code_toks_joined": "import re <NEWLINE> from django import http <NEWLINE> try : <NEWLINE> <INDENT> from urlparse import urlparse <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> from urllib . parse import urlparse <NEWLINE> <DEDENT> from corsheaders import defaults as settings <NEWLINE> from django . db . models . loading import get_model <NEWLINE> ACCESS_CONTROL_ALLOW_ORIGIN = <STRING> <NEWLINE> ACCESS_CONTROL_EXPOSE_HEADERS = <STRING> <NEWLINE> ACCESS_CONTROL_ALLOW_CREDENTIALS = <STRING> <NEWLINE> ACCESS_CONTROL_ALLOW_HEADERS = <STRING> <NEWLINE> ACCESS_CONTROL_ALLOW_METHODS = <STRING> <NEWLINE> ACCESS_CONTROL_MAX_AGE = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'Access-Control-Allow-Origin'", "'Access-Control-Expose-Headers'", "'Access-Control-Allow-Credentials'", "'Access-Control-Allow-Headers'", "'Access-Control-Allow-Methods'", "'Access-Control-Max-Age'"]}}], ["495ae5390c2fbdcc8d6db3aae86bd7f9", {"code_string": "from distutils.core import setup\nsetup(\n    name = 'PyCascade',\n    version = '1.0',\n    author = 'Peter Griess',\n    author_email = 'pgriess@gmail.com',\n    maintainer = 'Peter Griess',\n    maintainer_email = 'pgriess@gmail.com',\n    url = 'http://github.com/pgriess/PyCascade',\n    download_url = 'http://github.com/downloads/pgriess/PyCascade/PyCascade-1.0.tar.gz',\n    description = 'A Python client for Cascade, the Yahoo! Mail API',\n    long_description = 'A Python implementation of a `Cascade <http://developer.yahoo.com/mail/>`_ client; uses `OAuth <http://developer.yahoo.com/oauth/>`_ for authorization.',\n    classifiers = [\n        'Development Status :: 4 - Beta',\n        'Intended Audience :: Developers',\n        'License :: OSI Approved :: BSD License',\n        'Programming Language :: Python',\n        'Topic :: Communications :: Email',\n        'Topic :: Software Development :: Libraries',\n        'Topic :: Software Development :: Libraries :: Python Modules'\n    ],\n    py_modules = ['cascade'],\n    requires = ['oauth'],\n    provides = ['cascade']\n)\n", "code_toks_joined": "from distutils . core import setup <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> maintainer = <STRING> , <NEWLINE> maintainer_email = <STRING> , <NEWLINE> url = <STRING> , <NEWLINE> download_url = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> long_description = <STRING> , <NEWLINE> classifiers = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> <NEWLINE> <DEDENT> ] , <NEWLINE> py_modules = [ <STRING> ] , <NEWLINE> requires = [ <STRING> ] , <NEWLINE> provides = [ <STRING> ] <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'PyCascade'", "'1.0'", "'Peter Griess'", "'pgriess@gmail.com'", "'Peter Griess'", "'pgriess@gmail.com'", "'http://github.com/pgriess/PyCascade'", "'http://github.com/downloads/pgriess/PyCascade/PyCascade-1.0.tar.gz'", "'A Python client for Cascade, the Yahoo! Mail API'", "'A Python implementation of a `Cascade <http://developer.yahoo.com/mail/>`_ client; uses `OAuth <http://developer.yahoo.com/oauth/>`_ for authorization.'", "'Development Status :: 4 - Beta'", "'Intended Audience :: Developers'", "'License :: OSI Approved :: BSD License'", "'Programming Language :: Python'", "'Topic :: Communications :: Email'", "'Topic :: Software Development :: Libraries'", "'Topic :: Software Development :: Libraries :: Python Modules'", "'cascade'", "'oauth'", "'cascade'"]}}], ["62c404889776cf6305b4002a1b21b845", {"code_string": "\"\"\"Utilities for accessing LDAP databases.\"\"\"\nimport ldap\nimport os.path\nfrom django.utils.encoding import force_unicode\nDEBUG = False\nif DEBUG:\n    import sys\n    ldap.set_option(ldap.OPT_DEBUG_LEVEL, 255)\n    ldapmodule_trace_level = 1\n    ldapmodule_trace_file = sys.stderr\nif os.path.exists('/etc/gentoo-release'):\n    ldap.set_option(ldap.OPT_X_TLS_CERTFILE, '/etc/openldap/ssl/ldap.pem')\n    ldap.set_option(ldap.OPT_X_TLS_KEYFILE, '/etc/openldap/ssl/ldap.pem')\n    ldap.set_option(ldap.OPT_X_TLS_CACERTDIR, '/usr/share/ca-certificates')\n", "code_toks_joined": "<STRING> <NEWLINE> import ldap <NEWLINE> import os . path <NEWLINE> from django . utils . encoding import force_unicode <NEWLINE> DEBUG = False <NEWLINE> if DEBUG : <NEWLINE> <INDENT> import sys <NEWLINE> ldap . set_option ( ldap . OPT_DEBUG_LEVEL , 255 ) <NEWLINE> ldapmodule_trace_level = 1 <NEWLINE> ldapmodule_trace_file = sys . stderr <NEWLINE> <DEDENT> if os . path . exists ( <STRING> ) : <NEWLINE> <INDENT> ldap . set_option ( ldap . OPT_X_TLS_CERTFILE , <STRING> ) <NEWLINE> ldap . set_option ( ldap . OPT_X_TLS_KEYFILE , <STRING> ) <NEWLINE> ldap . set_option ( ldap . OPT_X_TLS_CACERTDIR , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Utilities for accessing LDAP databases.\"\"\"", "'/etc/gentoo-release'", "'/etc/openldap/ssl/ldap.pem'", "'/etc/openldap/ssl/ldap.pem'", "'/usr/share/ca-certificates'"]}}], ["e15497ebb35ef347bb5f0ffb5b7d454b", {"code_string": "def scrub_cell(cell):\n    if cell['cell_type'] != 'code':\n        return\n    if 'outputs' in cell:\n        cell['outputs'] = []\n    for field in(\"prompt_number\", \"execution_number\"):\n        if field in cell:\n            del cell[field]\n    for field in(\"execution_count\", ):\n        if field in cell:\n            cell[field] = None\n", "code_toks_joined": "def scrub_cell ( cell ) : <NEWLINE> <INDENT> if cell [ <STRING> ] != <STRING> : <NEWLINE> <INDENT> return <NEWLINE> <DEDENT> if <STRING> in cell : <NEWLINE> <INDENT> cell [ <STRING> ] = [ ] <NEWLINE> <DEDENT> for field in ( <STRING> , <STRING> ) : <NEWLINE> <INDENT> if field in cell : <NEWLINE> <INDENT> del cell [ field ] <NEWLINE> <DEDENT> <DEDENT> for field in ( <STRING> , ) : <NEWLINE> <INDENT> if field in cell : <NEWLINE> <INDENT> cell [ field ] = None <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'cell_type'", "'code'", "'outputs'", "'outputs'", "\"prompt_number\"", "\"execution_number\"", "\"execution_count\""]}}], ["4d4b1fc6aed78035a8a359a44b3e32e6", {"code_string": "def getMelinderFluids():\n    \"\"\"Returns a list of CoefficientData objects, which\"\"\"\n    classes = []\n    ignList = getIgnoreNames()\n    for name, obj in inspect.getmembers(MelinderFluids):\n        if inspect.isclass(obj):\n            if not name in ignList:\n                classes.append(obj())\n    return classes\n", "code_toks_joined": "def getMelinderFluids ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> classes = [ ] <NEWLINE> ignList = getIgnoreNames ( ) <NEWLINE> for name , obj in inspect . getmembers ( MelinderFluids ) : <NEWLINE> <INDENT> if inspect . isclass ( obj ) : <NEWLINE> <INDENT> if not name in ignList : <NEWLINE> <INDENT> classes . append ( obj ( ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> return classes <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Returns a list of CoefficientData objects, which\"\"\""]}}], ["40535335d3e90cbdaa846f223dc18f7a", {"code_string": "\"\"\"Unit tests for the :data:`iris.analysis.VARIANCE` aggregator.\"\"\"\nfrom __future__ import(absolute_import, division, print_function)\nfrom six.moves import(filter, input, map, range, zip)\nimport iris.tests as tests\nimport biggus\nimport numpy as np\nimport numpy.ma as ma\nfrom iris.analysis import VARIANCE\nimport iris.cube\nfrom iris.coords import DimCoord\nfrom iris.tests import mock\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import ( absolute_import , division , print_function ) <NEWLINE> from six . moves import ( filter , input , map , range , zip ) <NEWLINE> import iris . tests as tests <NEWLINE> import biggus <NEWLINE> import numpy as np <NEWLINE> import numpy . ma as ma <NEWLINE> from iris . analysis import VARIANCE <NEWLINE> import iris . cube <NEWLINE> from iris . coords import DimCoord <NEWLINE> from iris . tests import mock <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Unit tests for the :data:`iris.analysis.VARIANCE` aggregator.\"\"\""]}}], ["c44f7f2799a1cf530a8f7c694802fb5b", {"code_string": "def expand_2d_path(self, path):\n    expanded_paths = {\n        self.HH: 'hh',\n        self.HL: 'hl',\n        self.LH: 'lh',\n        self.LL: 'll'\n    }\n    return(''.join([expanded_paths[p][0] for p in path]),\n        ''.join([expanded_paths[p][1] for p in path]))\n", "code_toks_joined": "def expand_2d_path ( self , path ) : <NEWLINE> <INDENT> expanded_paths = { <NEWLINE> <INDENT> self . HH : <STRING> , <NEWLINE> self . HL : <STRING> , <NEWLINE> self . LH : <STRING> , <NEWLINE> self . LL : <STRING> <NEWLINE> <DEDENT> } <NEWLINE> return ( <STRING> . join ( [ expanded_paths [ p ] [ 0 ] for p in path ] ) , <NEWLINE> <INDENT> <STRING> . join ( [ expanded_paths [ p ] [ 1 ] for p in path ] ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'hh'", "'hl'", "'lh'", "'ll'", "''", "''"]}}], ["e8e836e31f1b50406137ac39fce24c9e", {"code_string": "def test_norm_spherical(self):\n    norm_s = self.spherical.norm()\n    assert isinstance(norm_s, u.Quantity)\n    assert norm_s.dtype.kind == 'f'\n    assert np.all(norm_s == self.distance)\n", "code_toks_joined": "def test_norm_spherical ( self ) : <NEWLINE> <INDENT> norm_s = self . spherical . norm ( ) <NEWLINE> assert isinstance ( norm_s , u . Quantity ) <NEWLINE> assert norm_s . dtype . kind == <STRING> <NEWLINE> assert np . all ( norm_s == self . distance ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'f'"]}}], ["d1830d88f6be15487ce9e7ffc061a855", {"code_string": "from django.conf.urls import include, url\nfrom django.views.generic import RedirectView\nfrom dashboard.views.account import SignupView\nurlpatterns = [\n    url(r\"^account/signup/$\", SignupView.as_view(), name = \"account_signup\"),\n    url(r'^$', RedirectView.as_view(url = '/dashboard/', permanent = False), name = 'home'),\n    url(r\"^account/\", include(\"account.urls\")),\n    url(r\"^dashboard/\", include(\"dashboard.urls\", namespace = \"dashboard\"))\n]\n", "code_toks_joined": "from django . conf . urls import include , url <NEWLINE> from django . views . generic import RedirectView <NEWLINE> from dashboard . views . account import SignupView <NEWLINE> urlpatterns = [ <NEWLINE> <INDENT> url ( <STRING> , SignupView . as_view ( ) , name = <STRING> ) , <NEWLINE> url ( <STRING> , RedirectView . as_view ( url = <STRING> , permanent = False ) , name = <STRING> ) , <NEWLINE> url ( <STRING> , include ( <STRING> ) ) , <NEWLINE> url ( <STRING> , include ( <STRING> , namespace = <STRING> ) ) <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["r\"^account/signup/$\"", "\"account_signup\"", "r'^$'", "'/dashboard/'", "'home'", "r\"^account/\"", "\"account.urls\"", "r\"^dashboard/\"", "\"dashboard.urls\"", "\"dashboard\""]}}], ["7d7d3974051a012130f93e0189b5bcf3", {"code_string": "def test_cf_errand_manifest_has_cf_cli_package(self):\n    for manifest in glob.glob('release/jobs/*/job.MF'):\n        if not manifest.startswith('release/jobs/docker-bosh-'):\n            self.assertTrue('cf_cli' in read_yaml(manifest).get('packages', []), manifest)\n", "code_toks_joined": "def test_cf_errand_manifest_has_cf_cli_package ( self ) : <NEWLINE> <INDENT> for manifest in glob . glob ( <STRING> ) : <NEWLINE> <INDENT> if not manifest . startswith ( <STRING> ) : <NEWLINE> <INDENT> self . assertTrue ( <STRING> in read_yaml ( manifest ) . get ( <STRING> , [ ] ) , manifest ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'release/jobs/*/job.MF'", "'release/jobs/docker-bosh-'", "'cf_cli'", "'packages'"]}}], ["05142b558ba6fbbd90d38d7e7fd38b13", {"code_string": "n = int(input())\narr = list(map(int, input().split()))\nst = []\nres = [- 1] * n\nfor i, a in enumerate(arr):\n    while st and st[- 1][1] < a:\n        res[st.pop()[0]] = i\n    st.append((i, a))\nprint(* res)\n", "code_toks_joined": "n = int ( input ( ) ) <NEWLINE> arr = list ( map ( int , input ( ) . split ( ) ) ) <NEWLINE> st = [ ] <NEWLINE> res = [ - 1 ] * n <NEWLINE> for i , a in enumerate ( arr ) : <NEWLINE> <INDENT> while st and st [ - 1 ] [ 1 ] < a : <NEWLINE> <INDENT> res [ st . pop ( ) [ 0 ] ] = i <NEWLINE> <DEDENT> st . append ( ( i , a ) ) <NEWLINE> <DEDENT> print ( * res ) <NEWLINE>", "anonymize_dict": {}}], ["c8a8ffe64c1603aafa7e69f49776230e", {"code_string": "def __init__(self, _self = cmd):\n    Wizard.__init__(self, _self)\n    for a in self.get_prompt():\n        print(a)\n", "code_toks_joined": "def __init__ ( self , _self = cmd ) : <NEWLINE> <INDENT> Wizard . __init__ ( self , _self ) <NEWLINE> for a in self . get_prompt ( ) : <NEWLINE> <INDENT> print ( a ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["72063807db98e0890e5cd453a35847c9", {"code_string": "class ContactForm(AbstractContactForm):\n    sender = forms.CharField(\n        help_text = _('An email address where the recipient may reach you.'),\n        validators = [EmailValidator]\n    )\n", "code_toks_joined": "class ContactForm ( AbstractContactForm ) : <NEWLINE> <INDENT> sender = forms . CharField ( <NEWLINE> <INDENT> help_text = _ ( <STRING> ) , <NEWLINE> validators = [ EmailValidator ] <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'An email address where the recipient may reach you.'"]}}], ["d117f72a149c3c512959ce124a83a6df", {"code_string": "def fetchResourceData(dataset_id):\n    '''Fetch resource information from datasets.'''\n    d = Dataset(dataset_id)\n    d.info()\n    resources = d.resources()\n    resource_data = []\n    for resource in resources:\n        data = {k: Resource(resource).info()[k] for k in _fields(config, 'resources')}\n        resource_data.append(data)\n    return resource_data\n", "code_toks_joined": "def fetchResourceData ( dataset_id ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> d = Dataset ( dataset_id ) <NEWLINE> d . info ( ) <NEWLINE> resources = d . resources ( ) <NEWLINE> resource_data = [ ] <NEWLINE> for resource in resources : <NEWLINE> <INDENT> data = { k : Resource ( resource ) . info ( ) [ k ] for k in _fields ( config , <STRING> ) } <NEWLINE> resource_data . append ( data ) <NEWLINE> <DEDENT> return resource_data <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Fetch resource information from datasets.'''", "'resources'"]}}], ["9ed3a289c30fc1f15c3eef5451f36aea", {"code_string": "def test_callpairorbetter_fold_preflop():\n    table = Table()\n    num_players = 3\n    for i in xrange(num_players):\n        player = Player(10, 'CallPairOrBetter')\n        player.sit(table, i)\n    table.initialize_hand()\n    table.players[0].hole_cards.append(Card('H', 10))\n    table.players[0].hole_cards.append(Card('H', 9))\n    assert table.players[0].decide() == Decision.FOLD\n", "code_toks_joined": "def test_callpairorbetter_fold_preflop ( ) : <NEWLINE> <INDENT> table = Table ( ) <NEWLINE> num_players = 3 <NEWLINE> for i in xrange ( num_players ) : <NEWLINE> <INDENT> player = Player ( 10 , <STRING> ) <NEWLINE> player . sit ( table , i ) <NEWLINE> <DEDENT> table . initialize_hand ( ) <NEWLINE> table . players [ 0 ] . hole_cards . append ( Card ( <STRING> , 10 ) ) <NEWLINE> table . players [ 0 ] . hole_cards . append ( Card ( <STRING> , 9 ) ) <NEWLINE> assert table . players [ 0 ] . decide ( ) == Decision . FOLD <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'CallPairOrBetter'", "'H'", "'H'"]}}], ["1d8252d5cce39c5c214e62b673b5ef43", {"code_string": "def create_client(self):\n    c = super(CinderV2TestCase, self).create_client()\n    self.assertIsInstance(c, cinder_client_v2.Client)\n    return c\n", "code_toks_joined": "def create_client ( self ) : <NEWLINE> <INDENT> c = super ( CinderV2TestCase , self ) . create_client ( ) <NEWLINE> self . assertIsInstance ( c , cinder_client_v2 . Client ) <NEWLINE> return c <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["8cbbcc3dd65fe9e7ddc93b3285046ceb", {"code_string": "import settings\nimport pika\nimport tweepy\nimport json\nimport jinja2\n", "code_toks_joined": "import settings <NEWLINE> import pika <NEWLINE> import tweepy <NEWLINE> import json <NEWLINE> import jinja2 <NEWLINE>", "anonymize_dict": {}}], ["baf488d4aa5559c802accd19c63863ab", {"code_string": "def test_search_top(self):\n    results = self.db.search(\"127.0.0.3\", top = True)\n    self.assertEqual(len(results), 1)\n", "code_toks_joined": "def test_search_top ( self ) : <NEWLINE> <INDENT> results = self . db . search ( <STRING> , top = True ) <NEWLINE> self . assertEqual ( len ( results ) , 1 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"127.0.0.3\""]}}], ["fd151a23d21e86ef123a15a558a1355d", {"code_string": "def install(self):\n    lg.info(\"Install.\")\n    self._hwdb = self.resolve(pyhwdb)\n    self._hwdb.incall(\"pytest\")\n    self.post_callback(1, self.insert)\n    pass\n", "code_toks_joined": "def install ( self ) : <NEWLINE> <INDENT> lg . info ( <STRING> ) <NEWLINE> self . _hwdb = self . resolve ( pyhwdb ) <NEWLINE> self . _hwdb . incall ( <STRING> ) <NEWLINE> self . post_callback ( 1 , self . insert ) <NEWLINE> pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Install.\"", "\"pytest\""]}}], ["38d0c44911fcae30eec7bde1a1b763b0", {"code_string": "def dummy_loss(gan_model, add_summaries = True):\n    return math_ops.reduce_sum(gan_model.discriminator_real_outputs -\n        gan_model.discriminator_gen_outputs)\n", "code_toks_joined": "def dummy_loss ( gan_model , add_summaries = True ) : <NEWLINE> <INDENT> return math_ops . reduce_sum ( gan_model . discriminator_real_outputs - <NEWLINE> <INDENT> gan_model . discriminator_gen_outputs ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["f0716d0fd9c21495665f0dcc65e08e3a", {"code_string": "class Local(Common):\n    DEBUG = values.BooleanValue(True)\n    TEMPLATE_DEBUG = DEBUG\n    INSTALLED_APPS = Common.INSTALLED_APPS\n    EMAIL_HOST = \"localhost\"\n    EMAIL_PORT = 1025\n    EMAIL_BACKEND = values.Value('django.core.mail.backends.console.EmailBackend')\n    MIDDLEWARE_CLASSES = Common.MIDDLEWARE_CLASSES +('debug_toolbar.middleware.DebugToolbarMiddleware', )\n    INSTALLED_APPS +=('debug_toolbar', )\n    DEBUG_TOOLBAR_PATCH_SETTINGS = False\n    INTERNAL_IPS = ('127.0.0.1', )\n    DEBUG_TOOLBAR_CONFIG = {\n        'DISABLE_PANELS': [\n            'debug_toolbar.panels.redirects.RedirectsPanel',\n        ],\n        'SHOW_TEMPLATE_CONTEXT': True,\n    }\n", "code_toks_joined": "class Local ( Common ) : <NEWLINE> <INDENT> DEBUG = values . BooleanValue ( True ) <NEWLINE> TEMPLATE_DEBUG = DEBUG <NEWLINE> INSTALLED_APPS = Common . INSTALLED_APPS <NEWLINE> EMAIL_HOST = <STRING> <NEWLINE> EMAIL_PORT = 1025 <NEWLINE> EMAIL_BACKEND = values . Value ( <STRING> ) <NEWLINE> MIDDLEWARE_CLASSES = Common . MIDDLEWARE_CLASSES + ( <STRING> , ) <NEWLINE> INSTALLED_APPS += ( <STRING> , ) <NEWLINE> DEBUG_TOOLBAR_PATCH_SETTINGS = False <NEWLINE> INTERNAL_IPS = ( <STRING> , ) <NEWLINE> DEBUG_TOOLBAR_CONFIG = { <NEWLINE> <INDENT> <STRING> : [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <DEDENT> ] , <NEWLINE> <STRING> : True , <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"localhost\"", "'django.core.mail.backends.console.EmailBackend'", "'debug_toolbar.middleware.DebugToolbarMiddleware'", "'debug_toolbar'", "'127.0.0.1'", "'DISABLE_PANELS'", "'debug_toolbar.panels.redirects.RedirectsPanel'", "'SHOW_TEMPLATE_CONTEXT'"]}}], ["38aae18080ad9f76411eec41be19311e", {"code_string": "from ipp_macro_series_parser.demographie.parser import(\n    create_demographie_data_frame\n    )\n", "code_toks_joined": "from ipp_macro_series_parser . demographie . parser import ( <NEWLINE> <INDENT> create_demographie_data_frame <NEWLINE> ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["1f704eb736f413c9971576d00068f569", {"code_string": "class ISession(zope.interface.Interface):\n    \"\"\"Integrates ICMSAPI with the ``transaction`` module.\"\"\"\n    def update_video(bcvideo):\n        \"\"\"Updates the video metadata (on transaction commit).\"\"\"\n", "code_toks_joined": "class ISession ( zope . interface . Interface ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def update_video ( bcvideo ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Integrates ICMSAPI with the ``transaction`` module.\"\"\"", "\"\"\"Updates the video metadata (on transaction commit).\"\"\""]}}], ["6073912d735717efe85c7e5ab06e6eb9", {"code_string": "def flush(self, obj):\n    \"\"\"Flush all permissions for an existing object.\"\"\"\n    object_uuid = LENSE.OBJECTS.getattr(obj, 'uuid')\n    if not object_uuid:\n        self.log('Object has no UUID, skipping permissions...', level = 'debug', method = 'flush')\n        return\n    self.model.objects.filter(object_uuid = object_uuid).delete()\n    self.log('Flushing permissions for {0}'.format(repr(obj)), level = 'debug', method = 'flush')\n", "code_toks_joined": "def flush ( self , obj ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> object_uuid = LENSE . OBJECTS . getattr ( obj , <STRING> ) <NEWLINE> if not object_uuid : <NEWLINE> <INDENT> self . log ( <STRING> , level = <STRING> , method = <STRING> ) <NEWLINE> return <NEWLINE> <DEDENT> self . model . objects . filter ( object_uuid = object_uuid ) . delete ( ) <NEWLINE> self . log ( <STRING> . format ( repr ( obj ) ) , level = <STRING> , method = <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Flush all permissions for an existing object.\"\"\"", "'uuid'", "'Object has no UUID, skipping permissions...'", "'debug'", "'flush'", "'Flushing permissions for {0}'", "'debug'", "'flush'"]}}], ["2061c47b7733b1d429a2d192c25ff3dd", {"code_string": "class DNSException(Exception):\n    \"\"\"Abstract base class shared by all dnspython exceptions.\"\"\"\n    pass\n", "code_toks_joined": "class DNSException ( Exception ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Abstract base class shared by all dnspython exceptions.\"\"\""]}}], ["21fbedf00083abb3e076f1fa26b052a2", {"code_string": "def _wait_for_port(self):\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    while sock.connect_ex((self.listen_ip, self.port)) != 0:\n        sleep(.1)\n    sleep(.5)\n    del sock\n", "code_toks_joined": "def _wait_for_port ( self ) : <NEWLINE> <INDENT> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <NEWLINE> while sock . connect_ex ( ( self . listen_ip , self . port ) ) != 0 : <NEWLINE> <INDENT> sleep ( .1 ) <NEWLINE> <DEDENT> sleep ( .5 ) <NEWLINE> del sock <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["8448b487d01e38fbd1ef81062f33445b", {"code_string": "def evolve(context):\n    if getattr(context, 'events', None) is None:\n        print(\"Adding 'events' to root\")\n        context.events = SiteEvents()\n    for tag_id, tag_obj in context.tags._tagid_to_obj.items():\n        tag_obj._id = tag_id\n    for gen, index, mapping in context.events:\n        if 'profile_url' not in mapping:\n            profile_url = '/'.join(mapping['thumbnail'].split('/')[: - 1])\n            mapping['profile_url'] = profile_url\n", "code_toks_joined": "def evolve ( context ) : <NEWLINE> <INDENT> if getattr ( context , <STRING> , None ) is None : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> context . events = SiteEvents ( ) <NEWLINE> <DEDENT> for tag_id , tag_obj in context . tags . _tagid_to_obj . items ( ) : <NEWLINE> <INDENT> tag_obj . _id = tag_id <NEWLINE> <DEDENT> for gen , index , mapping in context . events : <NEWLINE> <INDENT> if <STRING> not in mapping : <NEWLINE> <INDENT> profile_url = <STRING> . join ( mapping [ <STRING> ] . split ( <STRING> ) [ : - 1 ] ) <NEWLINE> mapping [ <STRING> ] = profile_url <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'events'", "\"Adding 'events' to root\"", "'profile_url'", "'/'", "'thumbnail'", "'/'", "'profile_url'"]}}], ["b1b736bb764c0c91e0fc4709637014ed", {"code_string": "class String(FieldType):\n    def coerce(self, obj, attr, value):\n        if isinstance(value, (basestring, int, long, float,\n            datetime.datetime)):\n            return unicode(value)\n        else:\n            raise ValueError(_('A string is required here, not %s'),\n                value.__class__.__name__)\n", "code_toks_joined": "class String ( FieldType ) : <NEWLINE> <INDENT> def coerce ( self , obj , attr , value ) : <NEWLINE> <INDENT> if isinstance ( value , ( basestring , int , long , float , <NEWLINE> <INDENT> datetime . datetime ) ) : <NEWLINE> return unicode ( value ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> raise ValueError ( _ ( <STRING> ) , <NEWLINE> <INDENT> value . __class__ . __name__ ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'A string is required here, not %s'"]}}], ["fb30f3a8afce563e097495f08074d275", {"code_string": "def purpose():\n    \"\"\" The purpose of this test is to verify the right sections splitting \"\"\"\n    and_ = \"\"\" different features related specifically to\"\"\"\n    @ one_of_the_brightest(features, of, Python)\n    def are_decorators(syntax):\n        pass\n", "code_toks_joined": "def purpose ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> and_ = <STRING> <NEWLINE> @ one_of_the_brightest ( features , of , Python ) <NEWLINE> def are_decorators ( syntax ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" The purpose of this test is to verify the right sections splitting \"\"\"", "\"\"\" different features related specifically to\"\"\""]}}], ["4f5b11e70d9bec3c25eb27d1cbe61e4d", {"code_string": "'''Created on 2017-3-28'''\nimport wx\nfrom pyResMan.Dialogs.pyResManDialog import pyResManDialog\n", "code_toks_joined": "<STRING> <NEWLINE> import wx <NEWLINE> from pyResMan . Dialogs . pyResManDialog import pyResManDialog <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Created on 2017-3-28'''"]}}], ["7028285c8e99cab3d26566caea86349d", {"code_string": "import decimal\nimport re\nimport csv\n", "code_toks_joined": "import decimal <NEWLINE> import re <NEWLINE> import csv <NEWLINE>", "anonymize_dict": {}}], ["faa079e02ef581faa500674513683610", {"code_string": "def moveBatUp(bat_x, bat_y, bat_z):\n    if(bat_y - 1 < bottom):\n        bat_y = bottom + 1\n    if(bat_y + 1 > top):\n        bat_y = top - 1\n    mc.setBlocks(bat_x, bat_y - 1, bat_z, bat_x, bat_y + 1, bat_z, block.WOOL.id, 2)\n    mc.setBlock(bat_x, bat_y - 2, bat_z, block.WOOL.id, 15)\n", "code_toks_joined": "def moveBatUp ( bat_x , bat_y , bat_z ) : <NEWLINE> <INDENT> if ( bat_y - 1 < bottom ) : <NEWLINE> <INDENT> bat_y = bottom + 1 <NEWLINE> <DEDENT> if ( bat_y + 1 > top ) : <NEWLINE> <INDENT> bat_y = top - 1 <NEWLINE> <DEDENT> mc . setBlocks ( bat_x , bat_y - 1 , bat_z , bat_x , bat_y + 1 , bat_z , block . WOOL . id , 2 ) <NEWLINE> mc . setBlock ( bat_x , bat_y - 2 , bat_z , block . WOOL . id , 15 ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["f02074f0a0dd415a646ecbd5f4983f30", {"code_string": "def performOauthDance(auth):\n    print('Please visit:', auth.get_authorization_url())\n    verifier = input('Verification token:')\n    try:\n        auth.get_access_token(verifier)\n        print('\\n'.join([\n            'Authentication data is:',\n            'ACCESS_TOKEN=%s' % auth.access_token,\n            'ACCESS_TOKEN_SECRET=%s' % auth.access_token_secret]))\n    except tweepy.TweepError:\n        print('Failed to authenticate correctly.')\n", "code_toks_joined": "def performOauthDance ( auth ) : <NEWLINE> <INDENT> print ( <STRING> , auth . get_authorization_url ( ) ) <NEWLINE> verifier = input ( <STRING> ) <NEWLINE> try : <NEWLINE> <INDENT> auth . get_access_token ( verifier ) <NEWLINE> print ( <STRING> . join ( [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> % auth . access_token , <NEWLINE> <STRING> % auth . access_token_secret ] ) ) <NEWLINE> <DEDENT> <DEDENT> except tweepy . TweepError : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Please visit:'", "'Verification token:'", "'\\n'", "'Authentication data is:'", "'ACCESS_TOKEN=%s'", "'ACCESS_TOKEN_SECRET=%s'", "'Failed to authenticate correctly.'"]}}], ["f16424e142a43883a47777eaa43d7ea4", {"code_string": "def testSubsampleFourByFour(self):\n    x = array_ops.reshape(math_ops.to_float(math_ops.range(16)), [1, 4, 4, 1])\n    x = resnet_utils.subsample(x, 2)\n    expected = array_ops.reshape(\n        constant_op.constant([0, 2, 8, 10]), [1, 2, 2, 1])\n    with self.test_session():\n        self.assertAllClose(x.eval(), expected.eval())\n", "code_toks_joined": "def testSubsampleFourByFour ( self ) : <NEWLINE> <INDENT> x = array_ops . reshape ( math_ops . to_float ( math_ops . range ( 16 ) ) , [ 1 , 4 , 4 , 1 ] ) <NEWLINE> x = resnet_utils . subsample ( x , 2 ) <NEWLINE> expected = array_ops . reshape ( <NEWLINE> <INDENT> constant_op . constant ( [ 0 , 2 , 8 , 10 ] ) , [ 1 , 2 , 2 , 1 ] ) <NEWLINE> <DEDENT> with self . test_session ( ) : <NEWLINE> <INDENT> self . assertAllClose ( x . eval ( ) , expected . eval ( ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["4efa1e46882ef6a5263165679781280a", {"code_string": "\"\"\"Converts a .env file to Elastic Beanstalk environment variables\"\"\"\nimport os\nfrom sys import exit\nfrom subprocess import check_call\ntry:\n    import dotenv\nexcept ImportError:\n    print(\"Please install the 'dotenv' library: 'pip install dotenv'\")\n    exit()\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> from sys import exit <NEWLINE> from subprocess import check_call <NEWLINE> try : <NEWLINE> <INDENT> import dotenv <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> exit ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Converts a .env file to Elastic Beanstalk environment variables\"\"\"", "\"Please install the 'dotenv' library: 'pip install dotenv'\""]}}], ["2445f00ab8fca7a62ab0b52aa34dbc5c", {"code_string": "def test_deferred_class_factory(self):\n    from django.db.models.query_utils import deferred_class_factory\n    new_class = deferred_class_factory(Item,\n        ('this_is_some_very_long_attribute_name_so_modelname_truncation_is_triggered', ))\n    self.assertEqual(new_class.__name__,\n        'Item_Deferred_this_is_some_very_long_attribute_nac34b1f495507dad6b02e2cb235c875e')\n", "code_toks_joined": "def test_deferred_class_factory ( self ) : <NEWLINE> <INDENT> from django . db . models . query_utils import deferred_class_factory <NEWLINE> new_class = deferred_class_factory ( Item , <NEWLINE> <INDENT> ( <STRING> , ) ) <NEWLINE> <DEDENT> self . assertEqual ( new_class . __name__ , <NEWLINE> <INDENT> <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'this_is_some_very_long_attribute_name_so_modelname_truncation_is_triggered'", "'Item_Deferred_this_is_some_very_long_attribute_nac34b1f495507dad6b02e2cb235c875e'"]}}], ["22b437033208a096050e1b3a3a3b8883", {"code_string": "import datetime\nfrom helpers import unittest\nimport luigi\nfrom luigi.parameter import DateIntervalParameter as DI\n", "code_toks_joined": "import datetime <NEWLINE> from helpers import unittest <NEWLINE> import luigi <NEWLINE> from luigi . parameter import DateIntervalParameter as DI <NEWLINE>", "anonymize_dict": {}}], ["0cc76428fdefe9180138e3b7d32ed719", {"code_string": "def get_filter6(self, dir):\n    \"\"\"Generate filter rules for this host by generating a list of\"\"\"\n    result = []\n    for i in self.ip:\n        if Util.verify_ip6net(i):\n            if i == \"::/0\":\n                result.append(\"\")\n            elif i != \"\":\n                result.append(\"-%s %s\" %(dir, i))\n    return result\n", "code_toks_joined": "def get_filter6 ( self , dir ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> result = [ ] <NEWLINE> for i in self . ip : <NEWLINE> <INDENT> if Util . verify_ip6net ( i ) : <NEWLINE> <INDENT> if i == <STRING> : <NEWLINE> <INDENT> result . append ( <STRING> ) <NEWLINE> <DEDENT> elif i != <STRING> : <NEWLINE> <INDENT> result . append ( <STRING> % ( dir , i ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> return result <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Generate filter rules for this host by generating a list of\"\"\"", "\"::/0\"", "\"\"", "\"\"", "\"-%s %s\""]}}], ["b0385ddae2af522ac02eeb1d3eb4013b", {"code_string": "class DetailsModel(models.Model):\n    details = models.CharField(verbose_name = _('details'), max_length = 64, blank = True, null = True)\n    class Meta:\n        abstract = True\n", "code_toks_joined": "class DetailsModel ( models . Model ) : <NEWLINE> <INDENT> details = models . CharField ( verbose_name = _ ( <STRING> ) , max_length = 64 , blank = True , null = True ) <NEWLINE> class Meta : <NEWLINE> <INDENT> abstract = True <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'details'"]}}], ["b29935018aff3bc36109046bee4c9173", {"code_string": "def getOrganism():\n    baseUrl = 'http://rest.kegg.jp/list/organism'\n    req = urllib2.Request(baseUrl)\n    response = urllib2.urlopen(req)\n    organism_infos = response.read().split('\\n')\n    for organism_info in organism_infos:\n        info_list = organism_info.split('\\t')\n        print(info_list)\n        print('organism %s' % info_list[1])\n        save_organism_info_to_db(info_list)\n", "code_toks_joined": "def getOrganism ( ) : <NEWLINE> <INDENT> baseUrl = <STRING> <NEWLINE> req = urllib2 . Request ( baseUrl ) <NEWLINE> response = urllib2 . urlopen ( req ) <NEWLINE> organism_infos = response . read ( ) . split ( <STRING> ) <NEWLINE> for organism_info in organism_infos : <NEWLINE> <INDENT> info_list = organism_info . split ( <STRING> ) <NEWLINE> print ( info_list ) <NEWLINE> print ( <STRING> % info_list [ 1 ] ) <NEWLINE> save_organism_info_to_db ( info_list ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'http://rest.kegg.jp/list/organism'", "'\\n'", "'\\t'", "'organism %s'"]}}], ["fd59d1a7d48cccccc4914913bd6517e6", {"code_string": "def _collapse(self):\n    self.resize(self.startwidth, self.parent().height())\n    self.move(self.parent().width() - self.startwidth, 0)\n    self.expaned = False\n", "code_toks_joined": "def _collapse ( self ) : <NEWLINE> <INDENT> self . resize ( self . startwidth , self . parent ( ) . height ( ) ) <NEWLINE> self . move ( self . parent ( ) . width ( ) - self . startwidth , 0 ) <NEWLINE> self . expaned = False <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["609000906db8b971f074630d17e1acee", {"code_string": "import factory\nfrom models import Classgroup, Message, Resource\nfrom django.contrib.auth.models import User\nfrom django.contrib.auth.hashers import make_password\n", "code_toks_joined": "import factory <NEWLINE> from models import Classgroup , Message , Resource <NEWLINE> from django . contrib . auth . models import User <NEWLINE> from django . contrib . auth . hashers import make_password <NEWLINE>", "anonymize_dict": {}}], ["8011773549f25153509752211eff8e30", {"code_string": "def CIlevel(redshiftGrid, PDF, fraction, numlevels = 200):\n    \"\"\"Computes confidence interval from PDF.\"\"\"\n    evidence = np.trapz(PDF, redshiftGrid)\n    for level in np.linspace(0, PDF.max(), num = numlevels):\n        ind = np.where(PDF <= level)\n        resint = np.trapz(PDF[ind], redshiftGrid[ind])\n        if resint >= fraction * evidence:\n            return level\n", "code_toks_joined": "def CIlevel ( redshiftGrid , PDF , fraction , numlevels = 200 ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> evidence = np . trapz ( PDF , redshiftGrid ) <NEWLINE> for level in np . linspace ( 0 , PDF . max ( ) , num = numlevels ) : <NEWLINE> <INDENT> ind = np . where ( PDF <= level ) <NEWLINE> resint = np . trapz ( PDF [ ind ] , redshiftGrid [ ind ] ) <NEWLINE> if resint >= fraction * evidence : <NEWLINE> <INDENT> return level <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Computes confidence interval from PDF.\"\"\""]}}], ["315a5e378a5c6c16d65a0bcb1de661bb", {"code_string": "class Degree(models.Model):\n    name = models.CharField(max_length = 255)\n    def __str__(self):\n        return self.name\n", "code_toks_joined": "class Degree ( models . Model ) : <NEWLINE> <INDENT> name = models . CharField ( max_length = 255 ) <NEWLINE> def __str__ ( self ) : <NEWLINE> <INDENT> return self . name <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["3c86d0719c3975cf895f988e43c36371", {"code_string": "class userProfile(models.Model):\n    user = models.OneToOneField(settings.AUTH_USER_MODEL)\n    bio = models.CharField(max_length = 200)\n", "code_toks_joined": "class userProfile ( models . Model ) : <NEWLINE> <INDENT> user = models . OneToOneField ( settings . AUTH_USER_MODEL ) <NEWLINE> bio = models . CharField ( max_length = 200 ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["eafe4928ccc5a1a8f8c79f4ecdbb0c74", {"code_string": "def __init__(self, conc_level, n_req):\n    self.conc_level = conc_level\n    self.n_req = n_req\n", "code_toks_joined": "def __init__ ( self , conc_level , n_req ) : <NEWLINE> <INDENT> self . conc_level = conc_level <NEWLINE> self . n_req = n_req <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["aa197c673cdbe470e7a4a923c1af7a61", {"code_string": "def passes(out, err):\n    return all(\n        [th.reads(err, '/tests/symlinks.sh'),\n            th.writes(err, '/tmp/subdir1/bar'),\n            th.count_writes(err, 1),\n            th.reads(err, '/tmp/root_symlink'),\n            th.reads(err, '/tmp/subdir2/symlink'),\n            th.reads(err, '/tmp/subdir1/foo_symlink'),\n            ])\n", "code_toks_joined": "def passes ( out , err ) : <NEWLINE> <INDENT> return all ( <NEWLINE> <INDENT> [ th . reads ( err , <STRING> ) , <NEWLINE> <INDENT> th . writes ( err , <STRING> ) , <NEWLINE> th . count_writes ( err , 1 ) , <NEWLINE> th . reads ( err , <STRING> ) , <NEWLINE> th . reads ( err , <STRING> ) , <NEWLINE> th . reads ( err , <STRING> ) , <NEWLINE> ] ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/tests/symlinks.sh'", "'/tmp/subdir1/bar'", "'/tmp/root_symlink'", "'/tmp/subdir2/symlink'", "'/tmp/subdir1/foo_symlink'"]}}], ["9d97ae235b427a2e87df53748cf4c7ed", {"code_string": "def __init__(self):\n    super(PowerOn, self).__init__()\n    self.name = \"power-on\"\n    self.summary = \"send power_on command\"\n    self.description = \"supply power to device\"\n", "code_toks_joined": "def __init__ ( self ) : <NEWLINE> <INDENT> super ( PowerOn , self ) . __init__ ( ) <NEWLINE> self . name = <STRING> <NEWLINE> self . summary = <STRING> <NEWLINE> self . description = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"power-on\"", "\"send power_on command\"", "\"supply power to device\""]}}], ["f8101db0ab6046deff258b275f5368b3", {"code_string": "\"\"\"\"\"\"\nfrom __future__ import print_function\nfrom builtins import range\nfrom untwisted.network import core, Spin, xmap\nfrom untwisted.iostd import Client, lose, CONNECT, CONNECT_ERR\nfrom untwisted.task import Task, DONE\nfrom untwisted.network import die\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import print_function <NEWLINE> from builtins import range <NEWLINE> from untwisted . network import core , Spin , xmap <NEWLINE> from untwisted . iostd import Client , lose , CONNECT , CONNECT_ERR <NEWLINE> from untwisted . task import Task , DONE <NEWLINE> from untwisted . network import die <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"\"\"\""]}}], ["ce354be25661ce2bf49d8a8bbb39b56d", {"code_string": "def getCharPositionInLine(self):\n    \"\"\"Using setter/getter methods is deprecated. Use o.charPositionInLine\"\"\"\n    return self.charPositionInLine\n", "code_toks_joined": "def getCharPositionInLine ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . charPositionInLine <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Using setter/getter methods is deprecated. Use o.charPositionInLine\"\"\""]}}], ["60c19e8af0b161d57eb4eb21f7ac26fd", {"code_string": "class Upgrader(upgrade.Upgrader):\n    def upgrade_2_0_to_3_0(self, tools, address):\n        root = tools.root(address)\n        root.get_node(2).erase()\n        root.ensure_node(1, 1, 255, 7).set_data(piw.makelong(1, 0))\n        tools.substitute_connection(paths.makeid_list(address, 2), paths.makeid_list(address, 2, 1))\n        return True\n", "code_toks_joined": "class Upgrader ( upgrade . Upgrader ) : <NEWLINE> <INDENT> def upgrade_2_0_to_3_0 ( self , tools , address ) : <NEWLINE> <INDENT> root = tools . root ( address ) <NEWLINE> root . get_node ( 2 ) . erase ( ) <NEWLINE> root . ensure_node ( 1 , 1 , 255 , 7 ) . set_data ( piw . makelong ( 1 , 0 ) ) <NEWLINE> tools . substitute_connection ( paths . makeid_list ( address , 2 ) , paths . makeid_list ( address , 2 , 1 ) ) <NEWLINE> return True <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["4437375bcedc4a52dcd93a21c6e201ff", {"code_string": "\"\"\"WSGI config for alumni project.\"\"\"\nimport os\nos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"alumni.settings\")\nimport alumni.startup as startup\nstartup.run()\nfrom django.core.wsgi import get_wsgi_application\napplication = get_wsgi_application()\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> os . environ . setdefault ( <STRING> , <STRING> ) <NEWLINE> import alumni . startup as startup <NEWLINE> startup . run ( ) <NEWLINE> from django . core . wsgi import get_wsgi_application <NEWLINE> application = get_wsgi_application ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"WSGI config for alumni project.\"\"\"", "\"DJANGO_SETTINGS_MODULE\"", "\"alumni.settings\""]}}], ["a983627b9828d8f6b370f1c592a66616", {"code_string": "\"\"\"Utility functions for authorization.\"\"\"\nimport md5\nimport random\nfrom twisted.cred.error import Unauthorized\n", "code_toks_joined": "<STRING> <NEWLINE> import md5 <NEWLINE> import random <NEWLINE> from twisted . cred . error import Unauthorized <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Utility functions for authorization.\"\"\""]}}], ["bb42add5af7ec80a731e02b074ea6a4d", {"code_string": "from pygccxml import declarations\ng_value_type_cache = {}\ng_top_parent = None\n", "code_toks_joined": "from pygccxml import declarations <NEWLINE> g_value_type_cache = { } <NEWLINE> g_top_parent = None <NEWLINE>", "anonymize_dict": {}}], ["20c1e2774ce95e8ad497c827b3ea0920", {"code_string": "class PhotosView(GalleryUtils):\n    def __init__(self, app):\n        self.app = app\n    def get_first_photo_in_photos_view(self):\n        \"\"\"Returns the very first photo in the photos view.\"\"\"\n        return self.select_many_retry(\n            \"QQuickItem\",\n            objectName = \"allPotosGridPhoto\")[0]\n    def number_of_photos(self):\n        \"\"\"Returns the number of events\"\"\"\n        photo_delegates = self.app.select_many(\"QQuickItem\",\n            objectName = \"allPotosGridPhoto\")\n        return len(photo_delegates)\n", "code_toks_joined": "class PhotosView ( GalleryUtils ) : <NEWLINE> <INDENT> def __init__ ( self , app ) : <NEWLINE> <INDENT> self . app = app <NEWLINE> <DEDENT> def get_first_photo_in_photos_view ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . select_many_retry ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> objectName = <STRING> ) [ 0 ] <NEWLINE> <DEDENT> <DEDENT> def number_of_photos ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> photo_delegates = self . app . select_many ( <STRING> , <NEWLINE> <INDENT> objectName = <STRING> ) <NEWLINE> <DEDENT> return len ( photo_delegates ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Returns the very first photo in the photos view.\"\"\"", "\"QQuickItem\"", "\"allPotosGridPhoto\"", "\"\"\"Returns the number of events\"\"\"", "\"QQuickItem\"", "\"allPotosGridPhoto\""]}}], ["ed8621b927ef1d3117186c82df2dfffd", {"code_string": "def _send_data(self, exit_code, data):\n    message = {\n        'success': exit_code == 0,\n        'output': str(data) if data else ''\n    }\n    pickled_message = pickle.dumps(message)\n    self.request.sendall(pickled_message)\n", "code_toks_joined": "def _send_data ( self , exit_code , data ) : <NEWLINE> <INDENT> message = { <NEWLINE> <INDENT> <STRING> : exit_code == 0 , <NEWLINE> <STRING> : str ( data ) if data else <STRING> <NEWLINE> <DEDENT> } <NEWLINE> pickled_message = pickle . dumps ( message ) <NEWLINE> self . request . sendall ( pickled_message ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'success'", "'output'", "''"]}}], ["d6a8d1dc2186e524efc4f28507225f09", {"code_string": "from django.conf.urls import url, include\nfrom.views import *\nurlpatterns = [\n    url(r'^$', DateListView.as_view(), name = 'list'),\n    url(r'^(?P<year>\\d+)/(?P<month>\\d+)/(?P<day>\\d+)/$', DateDetailView.as_view(), name = 'detail'),\n    url(r'^(?P<year>\\d+)/(?P<month>\\d+)/(?P<day>\\d+)/meal/', include('meal.urls', namespace = 'meal')),\n]\n", "code_toks_joined": "from django . conf . urls import url , include <NEWLINE> from . views import * <NEWLINE> urlpatterns = [ <NEWLINE> <INDENT> url ( <STRING> , DateListView . as_view ( ) , name = <STRING> ) , <NEWLINE> url ( <STRING> , DateDetailView . as_view ( ) , name = <STRING> ) , <NEWLINE> url ( <STRING> , include ( <STRING> , namespace = <STRING> ) ) , <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["r'^$'", "'list'", "r'^(?P<year>\\d+)/(?P<month>\\d+)/(?P<day>\\d+)/$'", "'detail'", "r'^(?P<year>\\d+)/(?P<month>\\d+)/(?P<day>\\d+)/meal/'", "'meal.urls'", "'meal'"]}}], ["14e4ad432eeee406f123edac741e21be", {"code_string": "class clv_document_question_answer(osv.osv):\n    _name = 'clv_document.question_answer'\n    _columns = {\n        'name': fields.char(size = 256,\n            string = 'Document Question Answer', required = True,\n            help = 'Question Answer in an Document'),\n        'description': fields.text(string = 'Description'),\n        'notes': fields.text(string = 'Notes'),\n        'active': fields.boolean('Active',\n            help = \"If unchecked, it will allow you to hide the answer without removing it.\"),\n        }\n    _defaults = {\n        'active': 1,\n        }\n", "code_toks_joined": "class clv_document_question_answer ( osv . osv ) : <NEWLINE> <INDENT> _name = <STRING> <NEWLINE> _columns = { <NEWLINE> <INDENT> <STRING> : fields . char ( size = 256 , <NEWLINE> <INDENT> string = <STRING> , required = True , <NEWLINE> help = <STRING> ) , <NEWLINE> <DEDENT> <STRING> : fields . text ( string = <STRING> ) , <NEWLINE> <STRING> : fields . text ( string = <STRING> ) , <NEWLINE> <STRING> : fields . boolean ( <STRING> , <NEWLINE> <INDENT> help = <STRING> ) , <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT> _defaults = { <NEWLINE> <INDENT> <STRING> : 1 , <NEWLINE> } <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'clv_document.question_answer'", "'name'", "'Document Question Answer'", "'Question Answer in an Document'", "'description'", "'Description'", "'notes'", "'Notes'", "'active'", "'Active'", "\"If unchecked, it will allow you to hide the answer without removing it.\"", "'active'"]}}], ["b21fef1ad4c044860ebad20ce63dae69", {"code_string": "def create(cls, schema, name):\n    \"\"\"Create an object based on the root tag name.\"\"\"\n    fn = cls.tags.get(name)\n    if fn is not None:\n        return fn(schema, name)\n    else:\n        return XBuiltin(schema, name)\n", "code_toks_joined": "def create ( cls , schema , name ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> fn = cls . tags . get ( name ) <NEWLINE> if fn is not None : <NEWLINE> <INDENT> return fn ( schema , name ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return XBuiltin ( schema , name ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Create an object based on the root tag name.\"\"\""]}}], ["d1b0d3428e3528ffd2050ea28c2dd176", {"code_string": "from __future__ import unicode_literals\nimport autoslug.fields\nfrom django.db import migrations, models\nimport dartcms.utils.fields\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> import autoslug . fields <NEWLINE> from django . db import migrations , models <NEWLINE> import dartcms . utils . fields <NEWLINE>", "anonymize_dict": {}}], ["5109519af53db3ee3fae96e2d5071ec2", {"code_string": "class TestLoadState(unittest.TestCase):\n    def setUp(self):\n        self.dojo = Dojo()\n    def test_data_loaded_successfully(self):\n        self.dojo.load_state('models/dojo_test_database')\n        self.assertEqual(path.exists('models/dojo_test_database.db'), True)\n", "code_toks_joined": "class TestLoadState ( unittest . TestCase ) : <NEWLINE> <INDENT> def setUp ( self ) : <NEWLINE> <INDENT> self . dojo = Dojo ( ) <NEWLINE> <DEDENT> def test_data_loaded_successfully ( self ) : <NEWLINE> <INDENT> self . dojo . load_state ( <STRING> ) <NEWLINE> self . assertEqual ( path . exists ( <STRING> ) , True ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'models/dojo_test_database'", "'models/dojo_test_database.db'"]}}], ["c02faa54b8aca4bf73378ff9994bc62b", {"code_string": "from marionette_driver import expected, By, Wait\nfrom marionette_driver.errors import NoSuchElementException\nfrom firefox_ui_harness.decorators import skip_under_xvfb\nfrom firefox_ui_harness import FirefoxTestCase\n", "code_toks_joined": "from marionette_driver import expected , By , Wait <NEWLINE> from marionette_driver . errors import NoSuchElementException <NEWLINE> from firefox_ui_harness . decorators import skip_under_xvfb <NEWLINE> from firefox_ui_harness import FirefoxTestCase <NEWLINE>", "anonymize_dict": {}}], ["f06c27f07cb13f6191e7ff443b0996dc", {"code_string": "import urllib\nfrom bs4 import BeautifulSoup\nurl = \"http://192.168.16.128/WackoPicko/\"\npage = urllib.request.urlopen(url)\ns_p = page.read()\ns = BeautifulSoup(s_p, \"html.parser\")\na = []\nfor form in s.findAll(\"title\"):\n    a = form\n    print(a)\n", "code_toks_joined": "import urllib <NEWLINE> from bs4 import BeautifulSoup <NEWLINE> url = <STRING> <NEWLINE> page = urllib . request . urlopen ( url ) <NEWLINE> s_p = page . read ( ) <NEWLINE> s = BeautifulSoup ( s_p , <STRING> ) <NEWLINE> a = [ ] <NEWLINE> for form in s . findAll ( <STRING> ) : <NEWLINE> <INDENT> a = form <NEWLINE> print ( a ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"http://192.168.16.128/WackoPicko/\"", "\"html.parser\"", "\"title\""]}}], ["d873f092f3a3efac4a47bb21e3abe462", {"code_string": "def interactive_console(self):\n    \"\"\"Run an interactive console\"\"\"\n    return self.vm.interactive_ssh()\n", "code_toks_joined": "def interactive_console ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . vm . interactive_ssh ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Run an interactive console\"\"\""]}}], ["3f659a4f5f5a899fc5598ff0a09a8c76", {"code_string": "def _create_buttons(self):\n    frame = Frame(self)\n    self._create_button(frame, self._left_button,\n        self._left_button_clicked)\n    self._create_button(frame, self._right_button,\n        self._right_button_clicked)\n    frame.pack()\n", "code_toks_joined": "def _create_buttons ( self ) : <NEWLINE> <INDENT> frame = Frame ( self ) <NEWLINE> self . _create_button ( frame , self . _left_button , <NEWLINE> <INDENT> self . _left_button_clicked ) <NEWLINE> <DEDENT> self . _create_button ( frame , self . _right_button , <NEWLINE> <INDENT> self . _right_button_clicked ) <NEWLINE> <DEDENT> frame . pack ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["66b40b6bd4aa9b61fef1e97ae560cfa9", {"code_string": "from django.conf.urls.defaults import *\nfrom events.views import *\nfrom events.models import Event, EventTime\nurlpatterns = patterns('',\n    url(r'^(?P<event_id>\\d+)-(?P<event_slug>[\\w\\-]+)/$', event_detail,\n        name = \"event\"),\n    url(r'^time/(?P<event_time_id>\\d+)-(?P<event_slug>[\\w\\-]+)/$',\n        event_time_detail, name = \"event_time\"),\n    url(r'^time/(?P<event_time_id>\\d+)-(?P<event_slug>[\\w\\-]+)/register/$',\n        register_for_event,\n        name = 'event_time_register'),\n)\n", "code_toks_joined": "from django . conf . urls . defaults import * <NEWLINE> from events . views import * <NEWLINE> from events . models import Event , EventTime <NEWLINE> urlpatterns = patterns ( <STRING> , <NEWLINE> <INDENT> url ( <STRING> , event_detail , <NEWLINE> <INDENT> name = <STRING> ) , <NEWLINE> <DEDENT> url ( <STRING> , <NEWLINE> <INDENT> event_time_detail , name = <STRING> ) , <NEWLINE> <DEDENT> url ( <STRING> , <NEWLINE> <INDENT> register_for_event , <NEWLINE> name = <STRING> ) , <NEWLINE> <DEDENT> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["''", "r'^(?P<event_id>\\d+)-(?P<event_slug>[\\w\\-]+)/$'", "\"event\"", "r'^time/(?P<event_time_id>\\d+)-(?P<event_slug>[\\w\\-]+)/$'", "\"event_time\"", "r'^time/(?P<event_time_id>\\d+)-(?P<event_slug>[\\w\\-]+)/register/$'", "'event_time_register'"]}}], ["40d34693bbf98946138b47ce9c9d35e4", {"code_string": "from __future__ import absolute_import\nfrom diggerplus.settings import DB_SETTINGS\nfrom diggerplus.db import db_manager\n", "code_toks_joined": "from __future__ import absolute_import <NEWLINE> from diggerplus . settings import DB_SETTINGS <NEWLINE> from diggerplus . db import db_manager <NEWLINE>", "anonymize_dict": {}}], ["db4146817987fe1c1032fef9d7f7a4e7", {"code_string": "def forwards(self, orm):\n    db.add_column(u'register_player', 'phone_number',\n        self.gf('django.db.models.fields.CharField')(default = '', max_length = 100, blank = True),\n        keep_default = False)\n", "code_toks_joined": "def forwards ( self , orm ) : <NEWLINE> <INDENT> db . add_column ( <STRING> , <STRING> , <NEWLINE> <INDENT> self . gf ( <STRING> ) ( default = <STRING> , max_length = 100 , blank = True ) , <NEWLINE> keep_default = False ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["u'register_player'", "'phone_number'", "'django.db.models.fields.CharField'", "''"]}}], ["cb9f21245e6d23097fb30c4691ca1129", {"code_string": "from mezzanine.pages.admin import PageAdmin\nfrom django.contrib import admin\nfrom hs_modelinstance.models import ModelInstanceResource\nadmin.site.register(ModelInstanceResource, PageAdmin)\n", "code_toks_joined": "from mezzanine . pages . admin import PageAdmin <NEWLINE> from django . contrib import admin <NEWLINE> from hs_modelinstance . models import ModelInstanceResource <NEWLINE> admin . site . register ( ModelInstanceResource , PageAdmin ) <NEWLINE>", "anonymize_dict": {}}], ["e8fa719bb3fd91d80f7261e88d94744f", {"code_string": "from django.contrib import admin\nfrom main.models import(Student,\n    Professor,\n    Admin,\n    Course,\n    Feedback,\n    CourseStudent,\n    CourseProfessor,\n    RequestFeedback)\nadmin.site.register(Student)\nadmin.site.register(Professor)\nadmin.site.register(Course)\nadmin.site.register(Feedback)\nadmin.site.register(Admin)\nadmin.site.register(CourseStudent)\nadmin.site.register(CourseProfessor)\nadmin.site.register(RequestFeedback)\n", "code_toks_joined": "from django . contrib import admin <NEWLINE> from main . models import ( Student , <NEWLINE> <INDENT> Professor , <NEWLINE> Admin , <NEWLINE> Course , <NEWLINE> Feedback , <NEWLINE> CourseStudent , <NEWLINE> CourseProfessor , <NEWLINE> RequestFeedback ) <NEWLINE> <DEDENT> admin . site . register ( Student ) <NEWLINE> admin . site . register ( Professor ) <NEWLINE> admin . site . register ( Course ) <NEWLINE> admin . site . register ( Feedback ) <NEWLINE> admin . site . register ( Admin ) <NEWLINE> admin . site . register ( CourseStudent ) <NEWLINE> admin . site . register ( CourseProfessor ) <NEWLINE> admin . site . register ( RequestFeedback ) <NEWLINE>", "anonymize_dict": {}}], ["5f5e56d3b204eb7732ed14ddf160c1d3", {"code_string": "from muralifpb.models import UserStudent\nfrom muralifpb.models import Category\nfrom muralifpb.models import Post\nfrom muralifpb.models import NewsPortals\n", "code_toks_joined": "from muralifpb . models import UserStudent <NEWLINE> from muralifpb . models import Category <NEWLINE> from muralifpb . models import Post <NEWLINE> from muralifpb . models import NewsPortals <NEWLINE>", "anonymize_dict": {}}], ["118a0770a36ef7e89e6807f7c492aedb", {"code_string": "def migrate():\n    with cd(PROJECT_DIRNAME):\n        run(\"python manage.py syncdb\")\n        run(\"python manage.py migrate\")\n", "code_toks_joined": "def migrate ( ) : <NEWLINE> <INDENT> with cd ( PROJECT_DIRNAME ) : <NEWLINE> <INDENT> run ( <STRING> ) <NEWLINE> run ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"python manage.py syncdb\"", "\"python manage.py migrate\""]}}], ["8196ddc9938e9a8f0ef751a8fb6d0939", {"code_string": "def clean(filename):\n    try:\n        garbage = re.findall('\\[\\d+\\]\\s*$', filename)[0]\n        cleanname = filename[: - len(garbage)]\n    except IndexError:\n        cleanname = filename\n    return cleanname\n", "code_toks_joined": "def clean ( filename ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> garbage = re . findall ( <STRING> , filename ) [ 0 ] <NEWLINE> cleanname = filename [ : - len ( garbage ) ] <NEWLINE> <DEDENT> except IndexError : <NEWLINE> <INDENT> cleanname = filename <NEWLINE> <DEDENT> return cleanname <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'\\[\\d+\\]\\s*$'"]}}], ["3578d4df350f731510f6c8c35788f1a7", {"code_string": "class Node(models.Model):\n    address = models.CharField(unique = True, primary_key = True, max_length = 256)\n    hostname = models.CharField(blank = True, max_length = 256)\n    sshkeys = models.ManyToManyField('SshKey')\n    userdata = models.ForeignKey('UserData')\n    def __str__(self):\n        return self.address\n    __unicode__ = __str__\n", "code_toks_joined": "class Node ( models . Model ) : <NEWLINE> <INDENT> address = models . CharField ( unique = True , primary_key = True , max_length = 256 ) <NEWLINE> hostname = models . CharField ( blank = True , max_length = 256 ) <NEWLINE> sshkeys = models . ManyToManyField ( <STRING> ) <NEWLINE> userdata = models . ForeignKey ( <STRING> ) <NEWLINE> def __str__ ( self ) : <NEWLINE> <INDENT> return self . address <NEWLINE> <DEDENT> __unicode__ = __str__ <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'SshKey'", "'UserData'"]}}], ["d35db182722b61bb7aecbc0b2753c3b0", {"code_string": "def reset_defaults(self):\n    \"\"\"Resets all settings to their deafult values\"\"\"\n    for name, widget in self.form.widgets.items():\n        value = get_default_setting(name)\n        self.form.set_widget_value(widget, value)\n", "code_toks_joined": "def reset_defaults ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> for name , widget in self . form . widgets . items ( ) : <NEWLINE> <INDENT> value = get_default_setting ( name ) <NEWLINE> self . form . set_widget_value ( widget , value ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Resets all settings to their deafult values\"\"\""]}}], ["77aba5ac523d27cb8d4d5b06207c9ad4", {"code_string": "def _convert_savegame(self, savegame):\n    \"\"\"Converts ourself to a savegame or global object.  This could be\"\"\"\n    for item in self.items:\n        item._convert_savegame(savegame)\n    self.savegame = savegame\n", "code_toks_joined": "def _convert_savegame ( self , savegame ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> for item in self . items : <NEWLINE> <INDENT> item . _convert_savegame ( savegame ) <NEWLINE> <DEDENT> self . savegame = savegame <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Converts ourself to a savegame or global object.  This could be\"\"\""]}}], ["a65124a3a7f2437078dcd88341080d84", {"code_string": "def test_array_to_byte_string_stereo_bytedepthE4(self):\n    self.assertEqual(util.array_to_byte_string(self.stereo, 4),\n        self.stereo_str4)\n", "code_toks_joined": "def test_array_to_byte_string_stereo_bytedepthE4 ( self ) : <NEWLINE> <INDENT> self . assertEqual ( util . array_to_byte_string ( self . stereo , 4 ) , <NEWLINE> <INDENT> self . stereo_str4 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["cdca1a2e49a0a60f748d2e53670c236a", {"code_string": "from libs.common import requestVPNCycle\nfrom libs.utility import debugTrace, errorTrace, infoTrace\ndebugTrace(\"-- Entered cycle.py --\")\nrequestVPNCycle(False)\ndebugTrace(\"-- Exit cycle.py --\")\n", "code_toks_joined": "from libs . common import requestVPNCycle <NEWLINE> from libs . utility import debugTrace , errorTrace , infoTrace <NEWLINE> debugTrace ( <STRING> ) <NEWLINE> requestVPNCycle ( False ) <NEWLINE> debugTrace ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"-- Entered cycle.py --\"", "\"-- Exit cycle.py --\""]}}], ["f55f8b8d64130f976676a815f59d5b53", {"code_string": "def get_requirements():\n    with open('requirements/prod.txt') as f:\n        rv = f.read().splitlines()\n    return rv\n", "code_toks_joined": "def get_requirements ( ) : <NEWLINE> <INDENT> with open ( <STRING> ) as f : <NEWLINE> <INDENT> rv = f . read ( ) . splitlines ( ) <NEWLINE> <DEDENT> return rv <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'requirements/prod.txt'"]}}], ["af46514e5e6535565ee798110c5107c5", {"code_string": "from django.conf import settings\nfrom django.conf.urls.defaults import patterns, include, url\nfrom django.contrib import admin\nadmin.autodiscover()\nurlpatterns = patterns('',\n    url(r'^admin/', include(admin.site.urls)),\n)\nif settings.DEBUG:\n    urlpatterns += patterns('',\n        (r'^media/(?P<path>.*)$', 'django.views.static.serve', {'document_root': settings.MEDIA_ROOT}),\n    )\n", "code_toks_joined": "from django . conf import settings <NEWLINE> from django . conf . urls . defaults import patterns , include , url <NEWLINE> from django . contrib import admin <NEWLINE> admin . autodiscover ( ) <NEWLINE> urlpatterns = patterns ( <STRING> , <NEWLINE> <INDENT> url ( <STRING> , include ( admin . site . urls ) ) , <NEWLINE> <DEDENT> ) <NEWLINE> if settings . DEBUG : <NEWLINE> <INDENT> urlpatterns += patterns ( <STRING> , <NEWLINE> <INDENT> ( <STRING> , <STRING> , { <STRING> : settings . MEDIA_ROOT } ) , <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["''", "r'^admin/'", "''", "r'^media/(?P<path>.*)$'", "'django.views.static.serve'", "'document_root'"]}}], ["ceb4465fa376a9f888c87340d4296d13", {"code_string": "def test_http_error(self):\n    url = 'http://example.com/template'\n    requests.get(url, stream = True).AndRaise(exceptions.HTTPError())\n    self.m.ReplayAll()\n    self.assertRaises(urlfetch.URLFetchError, urlfetch.get, url)\n    self.m.VerifyAll()\n", "code_toks_joined": "def test_http_error ( self ) : <NEWLINE> <INDENT> url = <STRING> <NEWLINE> requests . get ( url , stream = True ) . AndRaise ( exceptions . HTTPError ( ) ) <NEWLINE> self . m . ReplayAll ( ) <NEWLINE> self . assertRaises ( urlfetch . URLFetchError , urlfetch . get , url ) <NEWLINE> self . m . VerifyAll ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'http://example.com/template'"]}}], ["7490a99f5bfee4886e4a09f3753d275d", {"code_string": "class Submit(object):\n    def __init__(self, jsubrc, task_id, dry_run):\n        self.__jsubrc = jsubrc\n        self.__task_id = task_id\n        self.__dry_run = dry_run\n    def execute(self):\n        click.echo('Submitting')\n        j = Jsub(self.__jsubrc)\n        j.submit(self.__task_id, dry_run = self.__dry_run)\n", "code_toks_joined": "class Submit ( object ) : <NEWLINE> <INDENT> def __init__ ( self , jsubrc , task_id , dry_run ) : <NEWLINE> <INDENT> self . __jsubrc = jsubrc <NEWLINE> self . __task_id = task_id <NEWLINE> self . __dry_run = dry_run <NEWLINE> <DEDENT> def execute ( self ) : <NEWLINE> <INDENT> click . echo ( <STRING> ) <NEWLINE> j = Jsub ( self . __jsubrc ) <NEWLINE> j . submit ( self . __task_id , dry_run = self . __dry_run ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Submitting'"]}}], ["f675ddeb9ae78a5002c9c83853ea538f", {"code_string": "class TestStream:\n    def test_repeat_each(self):\n        nsamples = 10\n        nrepeats = 5\n        stream = Stream(range(nsamples))\n        repeated_stream = repeat_each(stream, nrepeats)\n        assert type(repeated_stream) is type(stream)\n        repeated_stream = list(repeated_stream)\n        assert np.allclose(repeated_stream[0: : 5], repeated_stream[3: : 5])\n", "code_toks_joined": "class TestStream : <NEWLINE> <INDENT> def test_repeat_each ( self ) : <NEWLINE> <INDENT> nsamples = 10 <NEWLINE> nrepeats = 5 <NEWLINE> stream = Stream ( range ( nsamples ) ) <NEWLINE> repeated_stream = repeat_each ( stream , nrepeats ) <NEWLINE> assert type ( repeated_stream ) is type ( stream ) <NEWLINE> repeated_stream = list ( repeated_stream ) <NEWLINE> assert np . allclose ( repeated_stream [ 0 : : 5 ] , repeated_stream [ 3 : : 5 ] ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["4da8b2fa2009a76da8938d7be4050aad", {"code_string": "import argparse\nfrom alerta.app import app\nfrom alerta.app import db\nfrom alerta.version import __version__\nLOG = app.logger\n", "code_toks_joined": "import argparse <NEWLINE> from alerta . app import app <NEWLINE> from alerta . app import db <NEWLINE> from alerta . version import __version__ <NEWLINE> LOG = app . logger <NEWLINE>", "anonymize_dict": {}}], ["a1c50df14b9d887708c2ba09db5dd73e", {"code_string": "import smach_ros\nimport smach\nfrom smach import state\nimport rospy\nimport yaml\nimport os.path\nimport numpy as np\nfrom std_msgs.msg import Float64, String\nfrom dynamixel_msgs.msg import JointState\nfrom dynamixel_controllers.srv import TorqueEnable, SetSpeed\nfrom dynamixel_driver.dynamixel_io import DynamixelIO\nfrom approach_control_srv.srv import Gesture\n", "code_toks_joined": "import smach_ros <NEWLINE> import smach <NEWLINE> from smach import state <NEWLINE> import rospy <NEWLINE> import yaml <NEWLINE> import os . path <NEWLINE> import numpy as np <NEWLINE> from std_msgs . msg import Float64 , String <NEWLINE> from dynamixel_msgs . msg import JointState <NEWLINE> from dynamixel_controllers . srv import TorqueEnable , SetSpeed <NEWLINE> from dynamixel_driver . dynamixel_io import DynamixelIO <NEWLINE> from approach_control_srv . srv import Gesture <NEWLINE>", "anonymize_dict": {}}], ["7cf7113c50ae46567c8decf6d65102da", {"code_string": "def tearDownClass(cls):\n    cls.io_loop.add_callback(cls.http_server.stop)\n    cls.io_loop.add_callback(cls.https_server.stop)\n    cls.io_loop.add_callback(cls.proxy_server.stop)\n    cls.io_loop.add_callback(cls.io_loop.stop)\n    cls.server_thread.join()\n", "code_toks_joined": "def tearDownClass ( cls ) : <NEWLINE> <INDENT> cls . io_loop . add_callback ( cls . http_server . stop ) <NEWLINE> cls . io_loop . add_callback ( cls . https_server . stop ) <NEWLINE> cls . io_loop . add_callback ( cls . proxy_server . stop ) <NEWLINE> cls . io_loop . add_callback ( cls . io_loop . stop ) <NEWLINE> cls . server_thread . join ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["74ea1621704a46888886453a62e54d1d", {"code_string": "import django\nimport os\nimport sys\nif django.VERSION <(1, 8):\n    from django.db.backends import BaseDatabaseClient\nelse:\n    from django.db.backends.base.client import BaseDatabaseClient\n", "code_toks_joined": "import django <NEWLINE> import os <NEWLINE> import sys <NEWLINE> if django . VERSION < ( 1 , 8 ) : <NEWLINE> <INDENT> from django . db . backends import BaseDatabaseClient <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> from django . db . backends . base . client import BaseDatabaseClient <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["7ea5de84641060fc61f5ba9f4fd07f49", {"code_string": "import logging\nimport state\nimport network\nimport worker\nimport project\nimport user\nimport tracking\nimport cpc.network.server_response\nimport cpc.util\nfrom cpc.server.state.user_handler import UserLevel\nlog = logging.getLogger(__name__)\n", "code_toks_joined": "import logging <NEWLINE> import state <NEWLINE> import network <NEWLINE> import worker <NEWLINE> import project <NEWLINE> import user <NEWLINE> import tracking <NEWLINE> import cpc . network . server_response <NEWLINE> import cpc . util <NEWLINE> from cpc . server . state . user_handler import UserLevel <NEWLINE> log = logging . getLogger ( __name__ ) <NEWLINE>", "anonymize_dict": {}}], ["2dd306e92cdc8b91a5f79f6ee04a1de2", {"code_string": "import sys\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport csv\n", "code_toks_joined": "import sys <NEWLINE> import matplotlib . pyplot as plt <NEWLINE> import numpy as np <NEWLINE> import csv <NEWLINE>", "anonymize_dict": {}}], ["ca3425bdca1cbbd8a952923d507abd34", {"code_string": "class CloseableNestedSetup(logbook.NestedSetup):\n    def close(self):\n        for obj in self.objects:\n            if hasattr(obj, \"close\"):\n                obj.close()\n", "code_toks_joined": "class CloseableNestedSetup ( logbook . NestedSetup ) : <NEWLINE> <INDENT> def close ( self ) : <NEWLINE> <INDENT> for obj in self . objects : <NEWLINE> <INDENT> if hasattr ( obj , <STRING> ) : <NEWLINE> <INDENT> obj . close ( ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"close\""]}}], ["8301379225b5fe2ebd8a8416e6cbef5d", {"code_string": "from __future__ import unicode_literals\nfrom django import forms\nfrom django.utils.translation import ugettext_lazy as _\nfrom.models import Grid, GRID_CONFIG, DJANGOCMS_GRID_CHOICES\nNUM_COLUMNS = [\n    (i, '%s' % i) for i in range(0, GRID_CONFIG['COLUMNS'])\n]\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> from django import forms <NEWLINE> from django . utils . translation import ugettext_lazy as _ <NEWLINE> from . models import Grid , GRID_CONFIG , DJANGOCMS_GRID_CHOICES <NEWLINE> NUM_COLUMNS = [ <NEWLINE> <INDENT> ( i , <STRING> % i ) for i in range ( 0 , GRID_CONFIG [ <STRING> ] ) <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'%s'", "'COLUMNS'"]}}], ["92b5e7f866a8e1f197b24c15dca2275b", {"code_string": "def unshorten(url, quality = None):\n    import js2py\n    html = requests.get(url).text\n    javascript = '{}.split(\\'|\\')[1]'.format(\n        re.search(r'\\[\"fmt_stream_map\"\\,(\".+?\")\\]', html).group(1)\n    )\n    logger.debug('Executing: {}'.format(javascript))\n    src = js2py.eval_js(javascript)\n    logger.debug('[google drive] found source {}'.format(src))\n    if quality is None:\n        logger.warning('[google drive] quality was not passed')\n        quality = get_quality(src)\n    return[Source(src, quality)]\n", "code_toks_joined": "def unshorten ( url , quality = None ) : <NEWLINE> <INDENT> import js2py <NEWLINE> html = requests . get ( url ) . text <NEWLINE> javascript = <STRING> . format ( <NEWLINE> <INDENT> re . search ( <STRING> , html ) . group ( 1 ) <NEWLINE> <DEDENT> ) <NEWLINE> logger . debug ( <STRING> . format ( javascript ) ) <NEWLINE> src = js2py . eval_js ( javascript ) <NEWLINE> logger . debug ( <STRING> . format ( src ) ) <NEWLINE> if quality is None : <NEWLINE> <INDENT> logger . warning ( <STRING> ) <NEWLINE> quality = get_quality ( src ) <NEWLINE> <DEDENT> return [ Source ( src , quality ) ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'{}.split(\\'|\\')[1]'", "r'\\[\"fmt_stream_map\"\\,(\".+?\")\\]'", "'Executing: {}'", "'[google drive] found source {}'", "'[google drive] quality was not passed'"]}}], ["263f36d84654ca2fdbeeb5c16f4a37c2", {"code_string": "def testToNumberFloat(self):\n    obj = QLocale(QLocale.C)\n    self.assertEqual((ctypes.c_float(37.109).value, True),\n        obj.toFloat('37.109'))\n", "code_toks_joined": "def testToNumberFloat ( self ) : <NEWLINE> <INDENT> obj = QLocale ( QLocale . C ) <NEWLINE> self . assertEqual ( ( ctypes . c_float ( 37.109 ) . value , True ) , <NEWLINE> <INDENT> obj . toFloat ( <STRING> ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'37.109'"]}}], ["7750b7cfdecb2ad640093ecffab5d9e5", {"code_string": "import logging\nimport os\nbasedir = os.path.abspath(os.path.dirname(__file__))\n", "code_toks_joined": "import logging <NEWLINE> import os <NEWLINE> basedir = os . path . abspath ( os . path . dirname ( __file__ ) ) <NEWLINE>", "anonymize_dict": {}}], ["12d7858fe4f80df0d02b18e6c308d273", {"code_string": "from __future__ import absolute_import, division, print_function\nfrom.base import Base, Defaults, DBase, Datasheet, Thread\nfrom.events import Event, Actions, Action\nfrom.ecs import EntityCatalogue, Entity, Component\nfrom.settings import Settings\n", "code_toks_joined": "from __future__ import absolute_import , division , print_function <NEWLINE> from . base import Base , Defaults , DBase , Datasheet , Thread <NEWLINE> from . events import Event , Actions , Action <NEWLINE> from . ecs import EntityCatalogue , Entity , Component <NEWLINE> from . settings import Settings <NEWLINE>", "anonymize_dict": {}}], ["493189e01202d744cb8d132d25481551", {"code_string": "\"\"\"virtualenv installs a wrapper for the real distutils into the\"\"\"\nimport sys, os, imp\nfrom modulegraph.modulegraph import MissingModule, Package, SourceModule, CompiledModule, find_module\n", "code_toks_joined": "<STRING> <NEWLINE> import sys , os , imp <NEWLINE> from modulegraph . modulegraph import MissingModule , Package , SourceModule , CompiledModule , find_module <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"virtualenv installs a wrapper for the real distutils into the\"\"\""]}}], ["0f189c8c5bc9e8fc21a65722d4fa1484", {"code_string": "def test_tokenize(self):\n    gw = fatzebra.gateway.Gateway()\n    result = gw.tokenize(\"Jim Murphy\", VALID_CARD, VALID_EXPIRY, \"123\")\n    self.assertIsNotNone(result.token)\n", "code_toks_joined": "def test_tokenize ( self ) : <NEWLINE> <INDENT> gw = fatzebra . gateway . Gateway ( ) <NEWLINE> result = gw . tokenize ( <STRING> , VALID_CARD , VALID_EXPIRY , <STRING> ) <NEWLINE> self . assertIsNotNone ( result . token ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Jim Murphy\"", "\"123\""]}}], ["41cc0da589f5ea716f8dd3cbfdd48789", {"code_string": "from mercurial.dicthelpers import diff, join\nimport unittest\nimport silenttestrunner\n", "code_toks_joined": "from mercurial . dicthelpers import diff , join <NEWLINE> import unittest <NEWLINE> import silenttestrunner <NEWLINE>", "anonymize_dict": {}}], ["199821866a48ced6081916e891f54f14", {"code_string": "import sys, os\nfrom xml.etree import ElementTree as ET\nimport xml\n'''fromstring() parses XML from a string directly into an Element, which is the root element of the parsed tree.'''\ndumpfile = open(sys.argv[1])\ntest = ET.fromstringlist(dumpfile)\nfor address in test.iter('*'):\n    print(address.tag, address.text)\n", "code_toks_joined": "import sys , os <NEWLINE> from xml . etree import ElementTree as ET <NEWLINE> import xml <NEWLINE> <STRING> <NEWLINE> dumpfile = open ( sys . argv [ 1 ] ) <NEWLINE> test = ET . fromstringlist ( dumpfile ) <NEWLINE> for address in test . iter ( <STRING> ) : <NEWLINE> <INDENT> print ( address . tag , address . text ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''fromstring() parses XML from a string directly into an Element, which is the root element of the parsed tree.'''", "'*'"]}}], ["f6731867af1058b36e4998f78966edb4", {"code_string": "class UJsonTestCase(BackendBase):\n    def setUp(self):\n        self.set_preferred_backend('ujson')\n    def test_backend(self):\n        expected_pickled = (\n            '{\"things\":[{'\n            '\"py\\/object\":\"backend_test.Thing\",'\n            '\"name\":\"data\",\"child\":null}'\n            ']}')\n        self.assertEncodeDecode(expected_pickled)\n", "code_toks_joined": "class UJsonTestCase ( BackendBase ) : <NEWLINE> <INDENT> def setUp ( self ) : <NEWLINE> <INDENT> self . set_preferred_backend ( <STRING> ) <NEWLINE> <DEDENT> def test_backend ( self ) : <NEWLINE> <INDENT> expected_pickled = ( <NEWLINE> <INDENT> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <DEDENT> self . assertEncodeDecode ( expected_pickled ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'ujson'", "'{\"things\":[{'", "'\"py\\/object\":\"backend_test.Thing\",'", "'\"name\":\"data\",\"child\":null}'", "']}'"]}}], ["832c308e8e03ec348a777c58fe3497f9", {"code_string": "def init_hashing(depth, width, alg):\n    \"\"\"Initialize the static variables of the hashing module.\"\"\"\n    hashIO.set_depth(depth)\n    hashIO.set_width(width)\n    hashIO.set_hashalg(alg)\n", "code_toks_joined": "def init_hashing ( depth , width , alg ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> hashIO . set_depth ( depth ) <NEWLINE> hashIO . set_width ( width ) <NEWLINE> hashIO . set_hashalg ( alg ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Initialize the static variables of the hashing module.\"\"\""]}}], ["86f35292db2ca61d4d85196a42dd1d1f", {"code_string": "def _load_entry_point(self):\n    \"\"\"attempt to load this url's dialect from entry points, or return None\"\"\"\n    try:\n        import pkg_resources\n    except ImportError:\n        return None\n    for res in pkg_resources.iter_entry_points('sqlalchemy.dialects'):\n        if res.name == self.drivername.replace(\"+\", \".\"):\n            return res.load()\n    else:\n        return None\n", "code_toks_joined": "def _load_entry_point ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> try : <NEWLINE> <INDENT> import pkg_resources <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> for res in pkg_resources . iter_entry_points ( <STRING> ) : <NEWLINE> <INDENT> if res . name == self . drivername . replace ( <STRING> , <STRING> ) : <NEWLINE> <INDENT> return res . load ( ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"attempt to load this url's dialect from entry points, or return None\"\"\"", "'sqlalchemy.dialects'", "\"+\"", "\".\""]}}], ["dce0e9c64732d018d7ce8ed492765d61", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('task', '0012_auto_20160228_1100'),\n    ]\n    operations = [\n        migrations.AddField(\n            model_name = 'failedfaxtask',\n            name = 'reason',\n            field = models.CharField(default = b'', max_length = 255, blank = True),\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . AddField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . CharField ( default = <STRING> , max_length = 255 , blank = True ) , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'task'", "'0012_auto_20160228_1100'", "'failedfaxtask'", "'reason'", "b''"]}}], ["e532c777fe5c0a98da8cd722fb950f40", {"code_string": "def main():\n    director.init(resizable = True)\n    scene1 = cocos.scene.Scene()\n    scene2 = cocos.scene.Scene()\n    colorl = ColorLayer(32, 32, 255, 255)\n    sprite = Sprite('grossini.png', (320, 240))\n    colorl.add(sprite)\n    scene1.add(BackgroundLayer(), z = 0)\n    scene2.add(colorl, z = 0)\n    director.run(CornerMoveTransition(scene1, 2, scene2))\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> director . init ( resizable = True ) <NEWLINE> scene1 = cocos . scene . Scene ( ) <NEWLINE> scene2 = cocos . scene . Scene ( ) <NEWLINE> colorl = ColorLayer ( 32 , 32 , 255 , 255 ) <NEWLINE> sprite = Sprite ( <STRING> , ( 320 , 240 ) ) <NEWLINE> colorl . add ( sprite ) <NEWLINE> scene1 . add ( BackgroundLayer ( ) , z = 0 ) <NEWLINE> scene2 . add ( colorl , z = 0 ) <NEWLINE> director . run ( CornerMoveTransition ( scene1 , 2 , scene2 ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'grossini.png'"]}}], ["7f076d3832875734b3f436a6ea8f20ea", {"code_string": "def ticker(cur1, cur2):\n    s = __name__.split(\".\")[1]\n    r = sys._getframe().f_code.co_name\n    symbol = cur1.capitalize() + cur2.capitalize()\n    cr = core.request(s, r).replace(constants.SYMBOL_PATTERN, symbol)\n    return core.get(core.hostname(s), cr, core.header(s), core.compression(s), core.timeout(s))\n", "code_toks_joined": "def ticker ( cur1 , cur2 ) : <NEWLINE> <INDENT> s = __name__ . split ( <STRING> ) [ 1 ] <NEWLINE> r = sys . _getframe ( ) . f_code . co_name <NEWLINE> symbol = cur1 . capitalize ( ) + cur2 . capitalize ( ) <NEWLINE> cr = core . request ( s , r ) . replace ( constants . SYMBOL_PATTERN , symbol ) <NEWLINE> return core . get ( core . hostname ( s ) , cr , core . header ( s ) , core . compression ( s ) , core . timeout ( s ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\".\""]}}], ["6f155182fef2474cfda14a1c637ba680", {"code_string": "def test_time_domain_default(self):\n    \"\"\" Test a TimeDomain with default start time. \"\"\"\n    domain = Domain.TimeDomain()\n    actual = domain.draw(3)\n    expected = [time(0, 0), time(0, 1), time(0, 2)]\n    self.assertItemsEqual(actual, expected)\n    self.assertEquals(domain.max_size, 60 * 24)\n", "code_toks_joined": "def test_time_domain_default ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> domain = Domain . TimeDomain ( ) <NEWLINE> actual = domain . draw ( 3 ) <NEWLINE> expected = [ time ( 0 , 0 ) , time ( 0 , 1 ) , time ( 0 , 2 ) ] <NEWLINE> self . assertItemsEqual ( actual , expected ) <NEWLINE> self . assertEquals ( domain . max_size , 60 * 24 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Test a TimeDomain with default start time. \"\"\""]}}], ["e8c8e915ba2a5a80da4c9afaeceac63d", {"code_string": "class Item(pg.sprite.Sprite):\n    def __init__(self, game, pos, type):\n        self._layer = ITEMS_LAYER\n        self.groups = game.all_sprites, game.items\n        pg.sprite.Sprite.__init__(self, self.groups)\n        self.game = game\n        self.image = game.item_images[type]\n        self.rect = self.image.get_rect()\n        self.type = type\n        self.rect.center = pos\n        self.pos = pos\n", "code_toks_joined": "class Item ( pg . sprite . Sprite ) : <NEWLINE> <INDENT> def __init__ ( self , game , pos , type ) : <NEWLINE> <INDENT> self . _layer = ITEMS_LAYER <NEWLINE> self . groups = game . all_sprites , game . items <NEWLINE> pg . sprite . Sprite . __init__ ( self , self . groups ) <NEWLINE> self . game = game <NEWLINE> self . image = game . item_images [ type ] <NEWLINE> self . rect = self . image . get_rect ( ) <NEWLINE> self . type = type <NEWLINE> self . rect . center = pos <NEWLINE> self . pos = pos <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["a9c4c7bedfea08fe637fd5850b4f3c4a", {"code_string": "def test_get_compound_annotated_section_data_set(self):\n    expected = \"http://api.brain-map.org/api/v2/annotated_section_data_sets.json?structures=112763676&intensity_values='High','Low','Medium'&density_values='High','Low'&pattern_values='Full'&age_names='E11.5','13.5'\"\n    self.asdsa.json_msg_query = MagicMock(name = 'json_msg_query')\n    self.asdsa.get_annotated_section_data_sets(\n        structures = [112763676],\n        intensity_values = [\"High\", \"Low\", \"Medium\"],\n        density_values = [\"High\", \"Low\"],\n        pattern_values = [\"Full\"],\n        age_names = [\"E11.5\", \"13.5\"])\n    self.asdsa.json_msg_query.assert_called_once_with(expected)\n", "code_toks_joined": "def test_get_compound_annotated_section_data_set ( self ) : <NEWLINE> <INDENT> expected = <STRING> <NEWLINE> self . asdsa . json_msg_query = MagicMock ( name = <STRING> ) <NEWLINE> self . asdsa . get_annotated_section_data_sets ( <NEWLINE> <INDENT> structures = [ 112763676 ] , <NEWLINE> intensity_values = [ <STRING> , <STRING> , <STRING> ] , <NEWLINE> density_values = [ <STRING> , <STRING> ] , <NEWLINE> pattern_values = [ <STRING> ] , <NEWLINE> age_names = [ <STRING> , <STRING> ] ) <NEWLINE> <DEDENT> self . asdsa . json_msg_query . assert_called_once_with ( expected ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"http://api.brain-map.org/api/v2/annotated_section_data_sets.json?structures=112763676&intensity_values='High','Low','Medium'&density_values='High','Low'&pattern_values='Full'&age_names='E11.5','13.5'\"", "'json_msg_query'", "\"High\"", "\"Low\"", "\"Medium\"", "\"High\"", "\"Low\"", "\"Full\"", "\"E11.5\"", "\"13.5\""]}}], ["219d3c0e7f350ecc6f0836e45776833d", {"code_string": "\"\"\"Search interface customizations.\"\"\"\nfrom __future__ import absolute_import, print_function\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import absolute_import , print_function <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Search interface customizations.\"\"\""]}}], ["8427b7596e70e69eac218ede596e7f69", {"code_string": "class ClearCalendarForm(i18nforms.Form):\n    \"\"\" Form used to delete a calendar. \"\"\"\n    confirm_delete = wtforms.BooleanField(\n        _('Yes I want to clear this calendar')\n    )\n", "code_toks_joined": "class ClearCalendarForm ( i18nforms . Form ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> confirm_delete = wtforms . BooleanField ( <NEWLINE> <INDENT> _ ( <STRING> ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Form used to delete a calendar. \"\"\"", "'Yes I want to clear this calendar'"]}}], ["f4916cc59624e67052a9c869313d2b5b", {"code_string": "def run_app():\n    root = Tk()\n    controller = Controller(root)\n    controller.start()\n    root.mainloop()\n", "code_toks_joined": "def run_app ( ) : <NEWLINE> <INDENT> root = Tk ( ) <NEWLINE> controller = Controller ( root ) <NEWLINE> controller . start ( ) <NEWLINE> root . mainloop ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["fdbf0bad1fa2e956247666eaf58051f4", {"code_string": "def __init__(self, model, data, parameters = None):\n    self.model = copy.copy(model)\n    self.num_layers = model.num_layers\n    self.data = data\n    if parameters is None:\n        parameters = OptimizerParameters()\n    self.parameters = parameters\n    self.cost = 0.0\n    self.n_iter = 0\n    self.hits = 0.0\n    self.step_w = None\n    self.step_b = None\n", "code_toks_joined": "def __init__ ( self , model , data , parameters = None ) : <NEWLINE> <INDENT> self . model = copy . copy ( model ) <NEWLINE> self . num_layers = model . num_layers <NEWLINE> self . data = data <NEWLINE> if parameters is None : <NEWLINE> <INDENT> parameters = OptimizerParameters ( ) <NEWLINE> <DEDENT> self . parameters = parameters <NEWLINE> self . cost = 0.0 <NEWLINE> self . n_iter = 0 <NEWLINE> self . hits = 0.0 <NEWLINE> self . step_w = None <NEWLINE> self . step_b = None <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["a8a5d6623ef068c82555a3c5b2b1bbae", {"code_string": "def medman_genre(med, args):\n    if len(args) == 0:\n        print(\"ARGSSSS\")\n        return False\n    if args[0] == \"help\":\n        print('''Usage: medman genre <command> [args...]''')\n        return True\n    elif args[0] == \"name\":\n        return handle_name(med, args[1], args[2: ])\n    elif args[0] == \"entry\":\n        return handle_entry(med, args[1], args[2], args[3: ])\n", "code_toks_joined": "def medman_genre ( med , args ) : <NEWLINE> <INDENT> if len ( args ) == 0 : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> return False <NEWLINE> <DEDENT> if args [ 0 ] == <STRING> : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> return True <NEWLINE> <DEDENT> elif args [ 0 ] == <STRING> : <NEWLINE> <INDENT> return handle_name ( med , args [ 1 ] , args [ 2 : ] ) <NEWLINE> <DEDENT> elif args [ 0 ] == <STRING> : <NEWLINE> <INDENT> return handle_entry ( med , args [ 1 ] , args [ 2 ] , args [ 3 : ] ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"ARGSSSS\"", "\"help\"", "'''Usage: medman genre <command> [args...]'''", "\"name\"", "\"entry\""]}}], ["888921be71369fd4fca9d1855f0bdf13", {"code_string": "try:\n    from unittest import mock\nexcept ImportError:\n    import mock\ntry:\n    import unittest2 as unittest\nexcept ImportError:\n    import unittest\n", "code_toks_joined": "try : <NEWLINE> <INDENT> from unittest import mock <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> import mock <NEWLINE> <DEDENT> try : <NEWLINE> <INDENT> import unittest2 as unittest <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> import unittest <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["bdc9223a080aac5a06f40c917e906dc1", {"code_string": "def js_ex(string):\n    print(\"js_ex \")\n    result = browser.js_ex(string)\n    print(result)\n    return result\n", "code_toks_joined": "def js_ex ( string ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> result = browser . js_ex ( string ) <NEWLINE> print ( result ) <NEWLINE> return result <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"js_ex \""]}}], ["c4421b8726ee5da61fff969f27ee983c", {"code_string": "def delete_first(self):\n    wd = self.app.wd\n    wd.find_element_by_css_selector(\"input[type='checkbox']\").click()\n    wd.find_element_by_name(\"delete\").click()\n", "code_toks_joined": "def delete_first ( self ) : <NEWLINE> <INDENT> wd = self . app . wd <NEWLINE> wd . find_element_by_css_selector ( <STRING> ) . click ( ) <NEWLINE> wd . find_element_by_name ( <STRING> ) . click ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"input[type='checkbox']\"", "\"delete\""]}}], ["0a90aee94f4fff46ea59cb9e2194eb96", {"code_string": "class tester_t(parser_test_case.parser_test_case_t):\n    COMPILATION_MODE = parser.COMPILATION_MODE.ALL_AT_ONCE\n    def __init__(self, * args):\n        parser_test_case.parser_test_case_t.__init__(self, * args)\n        self.header = 'complex_types.hpp'\n        self.declarations = None\n    def setUp(self):\n        if not self.declarations:\n            self.declarations = parser.parse([self.header], self.config)\n    def test(self):\n        \"\"\"This test tests presence of complex long double, float within\"\"\"\n        pass\n", "code_toks_joined": "class tester_t ( parser_test_case . parser_test_case_t ) : <NEWLINE> <INDENT> COMPILATION_MODE = parser . COMPILATION_MODE . ALL_AT_ONCE <NEWLINE> def __init__ ( self , * args ) : <NEWLINE> <INDENT> parser_test_case . parser_test_case_t . __init__ ( self , * args ) <NEWLINE> self . header = <STRING> <NEWLINE> self . declarations = None <NEWLINE> <DEDENT> def setUp ( self ) : <NEWLINE> <INDENT> if not self . declarations : <NEWLINE> <INDENT> self . declarations = parser . parse ( [ self . header ] , self . config ) <NEWLINE> <DEDENT> <DEDENT> def test ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> pass <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'complex_types.hpp'", "\"\"\"This test tests presence of complex long double, float within\"\"\""]}}], ["72e46319ae583c5ecdd51024b8d1d4da", {"code_string": "def backwards(self, orm):\n    db.add_column('lizard_workspace_layercollageitem', 'restrict_to_month', self.gf('django.db.models.fields.IntegerField')(null = True, blank = True), keep_default = False)\n    db.add_column('lizard_workspace_layercollageitem', 'summer_or_winter', self.gf('django.db.models.fields.IntegerField')(default = 1), keep_default = False)\n    db.add_column('lizard_workspace_layercollageitem', 'day_or_night', self.gf('django.db.models.fields.IntegerField')(default = 1), keep_default = False)\n    db.add_column('lizard_workspace_layercollageitem', 'day_of_week', self.gf('django.db.models.fields.IntegerField')(null = True, blank = True), keep_default = False)\n", "code_toks_joined": "def backwards ( self , orm ) : <NEWLINE> <INDENT> db . add_column ( <STRING> , <STRING> , self . gf ( <STRING> ) ( null = True , blank = True ) , keep_default = False ) <NEWLINE> db . add_column ( <STRING> , <STRING> , self . gf ( <STRING> ) ( default = 1 ) , keep_default = False ) <NEWLINE> db . add_column ( <STRING> , <STRING> , self . gf ( <STRING> ) ( default = 1 ) , keep_default = False ) <NEWLINE> db . add_column ( <STRING> , <STRING> , self . gf ( <STRING> ) ( null = True , blank = True ) , keep_default = False ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'lizard_workspace_layercollageitem'", "'restrict_to_month'", "'django.db.models.fields.IntegerField'", "'lizard_workspace_layercollageitem'", "'summer_or_winter'", "'django.db.models.fields.IntegerField'", "'lizard_workspace_layercollageitem'", "'day_or_night'", "'django.db.models.fields.IntegerField'", "'lizard_workspace_layercollageitem'", "'day_of_week'", "'django.db.models.fields.IntegerField'"]}}], ["62c967be2b52e1af3a4f3329069d244c", {"code_string": "def load_url(url, mapper = TupleMapper, options = {}):\n    mimetype = guess_type(url)\n    if mimetype not in PARSERS:\n        raise ParseFailed(\"Could not determine parser for %s\" % mimetype)\n    parser = PARSERS[mimetype]\n    loader = NetLoader\n    IO = make_io(loader, parser, mapper)\n    return IO(url = url, ** options)\n", "code_toks_joined": "def load_url ( url , mapper = TupleMapper , options = { } ) : <NEWLINE> <INDENT> mimetype = guess_type ( url ) <NEWLINE> if mimetype not in PARSERS : <NEWLINE> <INDENT> raise ParseFailed ( <STRING> % mimetype ) <NEWLINE> <DEDENT> parser = PARSERS [ mimetype ] <NEWLINE> loader = NetLoader <NEWLINE> IO = make_io ( loader , parser , mapper ) <NEWLINE> return IO ( url = url , ** options ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Could not determine parser for %s\""]}}], ["cd6977bb0d13b1f0fb9911a24ed50280", {"code_string": "def set(self, key, value):\n    \"\"\"Creates dictionary for the self.__data\"\"\"\n    self.__data = ({key, value})\n", "code_toks_joined": "def set ( self , key , value ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . __data = ( { key , value } ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Creates dictionary for the self.__data\"\"\""]}}], ["8bccbd72e5fa19eaaf2d7ec9c1744f14", {"code_string": "def build_from_web_request(cls, params, default_chunk_size):\n    chunk_size = params.get('chunk_size')\n    filters = params.get_all('filters')\n    orderings = params.get_all('ordering')\n    if not chunk_size and not filters and not orderings:\n        return None\n    chunk_size = int(chunk_size or default_chunk_size)\n    secret = cls._build_secret(params)\n    return cls._TableContext1(1, chunk_size, filters, orderings, {}, secret)\n", "code_toks_joined": "def build_from_web_request ( cls , params , default_chunk_size ) : <NEWLINE> <INDENT> chunk_size = params . get ( <STRING> ) <NEWLINE> filters = params . get_all ( <STRING> ) <NEWLINE> orderings = params . get_all ( <STRING> ) <NEWLINE> if not chunk_size and not filters and not orderings : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> chunk_size = int ( chunk_size or default_chunk_size ) <NEWLINE> secret = cls . _build_secret ( params ) <NEWLINE> return cls . _TableContext1 ( 1 , chunk_size , filters , orderings , { } , secret ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'chunk_size'", "'filters'", "'ordering'"]}}], ["3d75d61e96d8acaacf80f25dd184f2b9", {"code_string": "\"\"\"SQL schema for ouchdb.\"\"\"\nSCHEMA = \"\"\"create table databases (\"\"\"\nDATABASE_TABLE = \"\"\"create table %s (\"\"\"\nVIEW_TABLE = \"\"\"create table %s (\"\"\"\n", "code_toks_joined": "<STRING> <NEWLINE> SCHEMA = <STRING> <NEWLINE> DATABASE_TABLE = <STRING> <NEWLINE> VIEW_TABLE = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"SQL schema for ouchdb.\"\"\"", "\"\"\"create table databases (\"\"\"", "\"\"\"create table %s (\"\"\"", "\"\"\"create table %s (\"\"\""]}}], ["c81f60711274739bbb6a422664c7497c", {"code_string": "def test_create_security_group_rule_with_remote_group_id(self):\n    sg1_body, _ = self._create_security_group()\n    sg2_body, _ = self._create_security_group()\n    sg_id = sg1_body['security_group']['id']\n    direction = 'ingress'\n    protocol = 'udp'\n    port_range_min = 50\n    port_range_max = 55\n    remote_id = sg2_body['security_group']['id']\n    self._create_verify_security_group_rule(sg_id, direction,\n        self.ethertype, protocol,\n        port_range_min,\n        port_range_max,\n        remote_group_id = remote_id)\n", "code_toks_joined": "def test_create_security_group_rule_with_remote_group_id ( self ) : <NEWLINE> <INDENT> sg1_body , _ = self . _create_security_group ( ) <NEWLINE> sg2_body , _ = self . _create_security_group ( ) <NEWLINE> sg_id = sg1_body [ <STRING> ] [ <STRING> ] <NEWLINE> direction = <STRING> <NEWLINE> protocol = <STRING> <NEWLINE> port_range_min = 50 <NEWLINE> port_range_max = 55 <NEWLINE> remote_id = sg2_body [ <STRING> ] [ <STRING> ] <NEWLINE> self . _create_verify_security_group_rule ( sg_id , direction , <NEWLINE> <INDENT> self . ethertype , protocol , <NEWLINE> port_range_min , <NEWLINE> port_range_max , <NEWLINE> remote_group_id = remote_id ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'security_group'", "'id'", "'ingress'", "'udp'", "'security_group'", "'id'"]}}], ["e050769fb889d152f06d5f602ae9a8fe", {"code_string": "def get_group(self, group_name):\n    internal = self.__group.get_group(group_name)\n    if internal is None:\n        return None\n    return Group(internal)\n", "code_toks_joined": "def get_group ( self , group_name ) : <NEWLINE> <INDENT> internal = self . __group . get_group ( group_name ) <NEWLINE> if internal is None : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> return Group ( internal ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["105d966b371630c5e7196da04e6ca4aa", {"code_string": "from __future__ import absolute_import\nfrom unipath import Path\nfrom.local import *\nDATABASES = {\n    'default': {\n        'NAME': 'fc3',\n        'ENGINE': 'django.db.backends.postgresql_psycopg2',\n        'USER': 'graham',\n        'PASSWORD': '',\n        'HOST': 'localhost',\n    }\n}\nLOCAL_ROOT = Path(\"/Users/graham/Documents/fc3/testing/web/media\")\nWEATHER_ROOT = LOCAL_ROOT + '/weather/'\nEMAIL_BACKEND = 'django.core.mail.backends.console.EmailBackend'\nNOTIFICATIONS_QUEUE_MINS = 0\n", "code_toks_joined": "from __future__ import absolute_import <NEWLINE> from unipath import Path <NEWLINE> from . local import * <NEWLINE> DATABASES = { <NEWLINE> <INDENT> <STRING> : { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT> } <NEWLINE> LOCAL_ROOT = Path ( <STRING> ) <NEWLINE> WEATHER_ROOT = LOCAL_ROOT + <STRING> <NEWLINE> EMAIL_BACKEND = <STRING> <NEWLINE> NOTIFICATIONS_QUEUE_MINS = 0 <NEWLINE>", "anonymize_dict": {"<STRING>": ["'default'", "'NAME'", "'fc3'", "'ENGINE'", "'django.db.backends.postgresql_psycopg2'", "'USER'", "'graham'", "'PASSWORD'", "''", "'HOST'", "'localhost'", "\"/Users/graham/Documents/fc3/testing/web/media\"", "'/weather/'", "'django.core.mail.backends.console.EmailBackend'"]}}], ["c7e49cc9c5728ea60b1ea138390c8be4", {"code_string": "from datetime import datetime\nfrom sqlalchemy.orm import aliased\nfrom flask import Blueprint, request, url_for, redirect, render_template, session\nfrom flask.ext.wtf import Form, TextField, Required, PasswordField, HiddenField, DateField, IntegerField\nfrom pager.libs.flask_ import blueprint_templated, error, success\nfrom pager.models import db, User, Message, MessageLog\nfrom pager.tasks import absence_email, send_notify_mail\nadmin = Blueprint('admin', __name__)\ntemplated = blueprint_templated(admin.name)\n", "code_toks_joined": "from datetime import datetime <NEWLINE> from sqlalchemy . orm import aliased <NEWLINE> from flask import Blueprint , request , url_for , redirect , render_template , session <NEWLINE> from flask . ext . wtf import Form , TextField , Required , PasswordField , HiddenField , DateField , IntegerField <NEWLINE> from pager . libs . flask_ import blueprint_templated , error , success <NEWLINE> from pager . models import db , User , Message , MessageLog <NEWLINE> from pager . tasks import absence_email , send_notify_mail <NEWLINE> admin = Blueprint ( <STRING> , __name__ ) <NEWLINE> templated = blueprint_templated ( admin . name ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'admin'"]}}], ["97c28463567ef8b2ad56f8092fa32375", {"code_string": "from setuptools import setup, find_packages\nsetup(\n    name = \"grader\",\n    version = \"0.0.1\",\n    packages = find_packages(),\n    install_requires = [\"docker>=2\", \"rarfile>=3\", \"sh>=1\"],\n    tests_require = [\"pytest\"]\n)\n", "code_toks_joined": "from setuptools import setup , find_packages <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> packages = find_packages ( ) , <NEWLINE> install_requires = [ <STRING> , <STRING> , <STRING> ] , <NEWLINE> tests_require = [ <STRING> ] <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"grader\"", "\"0.0.1\"", "\"docker>=2\"", "\"rarfile>=3\"", "\"sh>=1\"", "\"pytest\""]}}], ["a16bd3b18877dbb2e38f88aec8340711", {"code_string": "class MessageQuerySet(QuerySet):\n    \"\"\"Message query set\"\"\"\n    def undelivered(self, to = None):\n        \"\"\"Fetch only undelivered messages\"\"\"\n        if to is not None:\n            return self.filter(deliveries__receiver = to,\n                deliveries__delivered_at__isnull = True)\n        else:\n            return self.filter(deliveries__delivered_at__isnull = True)\n", "code_toks_joined": "class MessageQuerySet ( QuerySet ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def undelivered ( self , to = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if to is not None : <NEWLINE> <INDENT> return self . filter ( deliveries__receiver = to , <NEWLINE> <INDENT> deliveries__delivered_at__isnull = True ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> return self . filter ( deliveries__delivered_at__isnull = True ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Message query set\"\"\"", "\"\"\"Fetch only undelivered messages\"\"\""]}}], ["97f922c951dea9cb7b0163b24e340931", {"code_string": "import dbus\nimport sys\nimport getopt\n", "code_toks_joined": "import dbus <NEWLINE> import sys <NEWLINE> import getopt <NEWLINE>", "anonymize_dict": {}}], ["1d2dc141c35b329b448ef2336190e966", {"code_string": "import os\nimport sys\nimport ConfigParser\nfrom SimpleXMLRPCServer import SimpleXMLRPCServer, SimpleXMLRPCRequestHandler\nconfig = ConfigParser.ConfigParser()\nconfig.read(['./openerp.cfg'])\nxmlrpc_host = config.get('XMLRPC', 'host')\nxmlrpc_port = eval(config.get('XMLRPC', 'port'))\nroot_folder = config.get('Folder', 'root')\n", "code_toks_joined": "import os <NEWLINE> import sys <NEWLINE> import ConfigParser <NEWLINE> from SimpleXMLRPCServer import SimpleXMLRPCServer , SimpleXMLRPCRequestHandler <NEWLINE> config = ConfigParser . ConfigParser ( ) <NEWLINE> config . read ( [ <STRING> ] ) <NEWLINE> xmlrpc_host = config . get ( <STRING> , <STRING> ) <NEWLINE> xmlrpc_port = eval ( config . get ( <STRING> , <STRING> ) ) <NEWLINE> root_folder = config . get ( <STRING> , <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'./openerp.cfg'", "'XMLRPC'", "'host'", "'XMLRPC'", "'port'", "'Folder'", "'root'"]}}], ["949c8e048b210d44b69df0c927959106", {"code_string": "class DummyParser:\n    anchorlist = []\n    def feed(self, s):\n        pass\n", "code_toks_joined": "class DummyParser : <NEWLINE> <INDENT> anchorlist = [ ] <NEWLINE> def feed ( self , s ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["0ac60fe89003a288a97915f76ffed184", {"code_string": "import requests\nfrom bs4 import BeautifulSoup\nimport getpass\n", "code_toks_joined": "import requests <NEWLINE> from bs4 import BeautifulSoup <NEWLINE> import getpass <NEWLINE>", "anonymize_dict": {}}], ["91136c3e255020119083dd6c4619ad9a", {"code_string": "\"\"\"Test the iris.analysis.interpolate module.\"\"\"\nfrom __future__ import(absolute_import, division, print_function)\nimport iris.tests as tests\nimport numpy as np\nimport iris.analysis.interpolate as interpolate\nfrom iris.coords import DimCoord\nfrom iris.cube import Cube\nfrom iris.tests.test_interpolation import normalise_order\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import ( absolute_import , division , print_function ) <NEWLINE> import iris . tests as tests <NEWLINE> import numpy as np <NEWLINE> import iris . analysis . interpolate as interpolate <NEWLINE> from iris . coords import DimCoord <NEWLINE> from iris . cube import Cube <NEWLINE> from iris . tests . test_interpolation import normalise_order <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Test the iris.analysis.interpolate module.\"\"\""]}}], ["d50045184d2fa8141a8c94e04baec702", {"code_string": "\"\"\"Misc CLI functions.\"\"\"\nimport distutils.sysconfig\nimport sys\nplib = distutils.sysconfig.get_python_lib()\nmod_path = \"%s/cobbler\" % plib\nsys.path.insert(0, mod_path)\nfrom utils import _\nimport commands\nfrom cexceptions import *\nHELP_FORMAT = commands.HELP_FORMAT\n", "code_toks_joined": "<STRING> <NEWLINE> import distutils . sysconfig <NEWLINE> import sys <NEWLINE> plib = distutils . sysconfig . get_python_lib ( ) <NEWLINE> mod_path = <STRING> % plib <NEWLINE> sys . path . insert ( 0 , mod_path ) <NEWLINE> from utils import _ <NEWLINE> import commands <NEWLINE> from cexceptions import * <NEWLINE> HELP_FORMAT = commands . HELP_FORMAT <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Misc CLI functions.\"\"\"", "\"%s/cobbler\""]}}], ["d2b5a964955ed5ae47f0d2b8064694fa", {"code_string": "from nose.tools import assert_equal\nimport clinvoc\nfrom clinvoc.hcpcs import HCPCS\n", "code_toks_joined": "from nose . tools import assert_equal <NEWLINE> import clinvoc <NEWLINE> from clinvoc . hcpcs import HCPCS <NEWLINE>", "anonymize_dict": {}}], ["4d622cca75bfe2ab3b773d53b3aa2de6", {"code_string": "class Fortaleza(DstTzInfo):\n    '''America/Fortaleza timezone definition. See datetime.tzinfo for details'''\n    zone = 'America/Fortaleza'\n", "code_toks_joined": "class Fortaleza ( DstTzInfo ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> zone = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''America/Fortaleza timezone definition. See datetime.tzinfo for details'''", "'America/Fortaleza'"]}}], ["bb04b586f366746fa0c8418186b50307", {"code_string": "def initialize(self, ctx):\n    self.path = self.url\n    super(HttpReader, self).initialize(ctx)\n    if(self.url == None):\n        raise Exception(\"Missing url attribute for %s\" % self)\n", "code_toks_joined": "def initialize ( self , ctx ) : <NEWLINE> <INDENT> self . path = self . url <NEWLINE> super ( HttpReader , self ) . initialize ( ctx ) <NEWLINE> if ( self . url == None ) : <NEWLINE> <INDENT> raise Exception ( <STRING> % self ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Missing url attribute for %s\""]}}], ["9a0be31da4f73d5b0dc6d87281575db1", {"code_string": "def get_column_names(cursor):\n    '''Get all column names from a cursor object'''\n    return[col[0] for col in cursor.description]\n", "code_toks_joined": "def get_column_names ( cursor ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return [ col [ 0 ] for col in cursor . description ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Get all column names from a cursor object'''"]}}], ["c6abdc2221155056c95581d0a917b73d", {"code_string": "class Evaluator(template.EvaluatorInterface):\n    evalList = ['pid', 'parentpid', 'UserSID', 'Username', 'name', 'path', 'moduleList']\n    def __init__(self, iocTree, remoteCommand, wd, keepFiles, confidential, dirname):\n        template.EvaluatorInterface.__init__(self, iocTree, remoteCommand, wd, keepFiles, confidential, dirname)\n        self.setEvaluatorParams(evalList = Evaluator.evalList, name = 'process', ext = 'sh')\n", "code_toks_joined": "class Evaluator ( template . EvaluatorInterface ) : <NEWLINE> <INDENT> evalList = [ <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE> def __init__ ( self , iocTree , remoteCommand , wd , keepFiles , confidential , dirname ) : <NEWLINE> <INDENT> template . EvaluatorInterface . __init__ ( self , iocTree , remoteCommand , wd , keepFiles , confidential , dirname ) <NEWLINE> self . setEvaluatorParams ( evalList = Evaluator . evalList , name = <STRING> , ext = <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'pid'", "'parentpid'", "'UserSID'", "'Username'", "'name'", "'path'", "'moduleList'", "'process'", "'sh'"]}}], ["43d1ea065a702007119229e829aecb71", {"code_string": "import numpy as np\nimport argparse\nfrom vasppy.poscar import Poscar\nfrom vasppy.cell import Cell\n", "code_toks_joined": "import numpy as np <NEWLINE> import argparse <NEWLINE> from vasppy . poscar import Poscar <NEWLINE> from vasppy . cell import Cell <NEWLINE>", "anonymize_dict": {}}], ["95a3c22c520e58a8d760f139f5835155", {"code_string": "def upgrade():\n    op.create_table('comments',\n    sa.Column('id', sa.Integer(), nullable = False),\n    sa.Column('comment', sa.String(length = 260), nullable = True),\n    sa.Column('page', sa.String(length = 80), nullable = True),\n    sa.Column('chapter', sa.String(length = 80), nullable = True),\n    sa.PrimaryKeyConstraint('id')\n    )\n", "code_toks_joined": "def upgrade ( ) : <NEWLINE> <INDENT> op . create_table ( <STRING> , <NEWLINE> sa . Column ( <STRING> , sa . Integer ( ) , nullable = False ) , <NEWLINE> sa . Column ( <STRING> , sa . String ( length = 260 ) , nullable = True ) , <NEWLINE> sa . Column ( <STRING> , sa . String ( length = 80 ) , nullable = True ) , <NEWLINE> sa . Column ( <STRING> , sa . String ( length = 80 ) , nullable = True ) , <NEWLINE> sa . PrimaryKeyConstraint ( <STRING> ) <NEWLINE> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'comments'", "'id'", "'comment'", "'page'", "'chapter'", "'id'"]}}], ["5fd024c059bfc6c14ae8ea3352d10acc", {"code_string": "def post_bookmark(bmk, auth_token):\n    params = bmk2params(bmk, auth_token)\n    reply = requests.post(add_url, params = params)\n    return parse_reply(reply)\n", "code_toks_joined": "def post_bookmark ( bmk , auth_token ) : <NEWLINE> <INDENT> params = bmk2params ( bmk , auth_token ) <NEWLINE> reply = requests . post ( add_url , params = params ) <NEWLINE> return parse_reply ( reply ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["17c3af91d497de2a4838ac6ff8cfadce", {"code_string": "def tunnel_port_handler(self, ev):\n    self.logger.debug('tunnel_port ev %s', ev)\n    if ev.add_del:\n        self._tunnel_port_add(ev)\n    else:\n        self._tunnel_port_del(ev)\n", "code_toks_joined": "def tunnel_port_handler ( self , ev ) : <NEWLINE> <INDENT> self . logger . debug ( <STRING> , ev ) <NEWLINE> if ev . add_del : <NEWLINE> <INDENT> self . _tunnel_port_add ( ev ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . _tunnel_port_del ( ev ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'tunnel_port ev %s'"]}}], ["0b6870ba884af2904c6b58c1cdd46744", {"code_string": "from django.conf import settings\nfrom django.core.mail import EmailMultiAlternatives\nfrom django.template.loader import render_to_string\n", "code_toks_joined": "from django . conf import settings <NEWLINE> from django . core . mail import EmailMultiAlternatives <NEWLINE> from django . template . loader import render_to_string <NEWLINE>", "anonymize_dict": {}}], ["ab0e35b326f588f8c5d16e0f98bf9469", {"code_string": "\"\"\"PRE-PROCESSORS\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import unicode_literals\nfrom.import util\nfrom.import odict\nimport re\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import absolute_import <NEWLINE> from __future__ import unicode_literals <NEWLINE> from . import util <NEWLINE> from . import odict <NEWLINE> import re <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"PRE-PROCESSORS\"\"\""]}}], ["2c4b88d40230fede59fc29faf5f70675", {"code_string": "import numpy as np\nfrom zvsgld import ZVSGLD\nfrom sklearn.metrics import log_loss\n", "code_toks_joined": "import numpy as np <NEWLINE> from zvsgld import ZVSGLD <NEWLINE> from sklearn . metrics import log_loss <NEWLINE>", "anonymize_dict": {}}], ["6bc83bd013c6c23e3130acbf6133ab5e", {"code_string": "\"\"\"Unit Tests for IronPython engine\"\"\"\n__context__ = 'zerodoc'\nimport pyrevit.unittests as prtests\nprtests.perform_engine_tests()\n", "code_toks_joined": "<STRING> <NEWLINE> __context__ = <STRING> <NEWLINE> import pyrevit . unittests as prtests <NEWLINE> prtests . perform_engine_tests ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Unit Tests for IronPython engine\"\"\"", "'zerodoc'"]}}], ["0af4151f82c58f84e88592a4a4442561", {"code_string": "def get_pubkey_from_x(self, xpub, for_change, n):\n    _, _, _, c, cK = deserialize_xkey(xpub)\n    for i in[for_change, n]:\n        cK, c = CKD_pub(cK, c, i)\n    return cK.encode('hex')\n", "code_toks_joined": "def get_pubkey_from_x ( self , xpub , for_change , n ) : <NEWLINE> <INDENT> _ , _ , _ , c , cK = deserialize_xkey ( xpub ) <NEWLINE> for i in [ for_change , n ] : <NEWLINE> <INDENT> cK , c = CKD_pub ( cK , c , i ) <NEWLINE> <DEDENT> return cK . encode ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'hex'"]}}], ["e1dddac2213b54296c75d36d38490b35", {"code_string": "def _connect(self):\n    \"\"\"Connect to the host we've been initialized with\"\"\"\n    if self._play_context.become:\n        self.__become_method_supported()\n", "code_toks_joined": "def _connect ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if self . _play_context . become : <NEWLINE> <INDENT> self . __become_method_supported ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Connect to the host we've been initialized with\"\"\""]}}], ["19e838bf62a7d746e565c03e419c7f2c", {"code_string": "def calcRabbits(n, k):\n    pairs = [1, 1]\n    for i in range(2, n):\n        f1 = pairs[i - 1]\n        f2 = pairs[i - 2] * 3\n        pairs.append((f1 + f2))\n    return pairs\n", "code_toks_joined": "def calcRabbits ( n , k ) : <NEWLINE> <INDENT> pairs = [ 1 , 1 ] <NEWLINE> for i in range ( 2 , n ) : <NEWLINE> <INDENT> f1 = pairs [ i - 1 ] <NEWLINE> f2 = pairs [ i - 2 ] * 3 <NEWLINE> pairs . append ( ( f1 + f2 ) ) <NEWLINE> <DEDENT> return pairs <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["371ac69504eb053cbd9c41d1b166316d", {"code_string": "def classifySPoutput(targetOutputColumns, outputColumns):\n    \"\"\"Classify the SP output\"\"\"\n    numTargets, numDims = targetOutputColumns.shape\n    overlap = np.zeros((numTargets, ))\n    for i in range(numTargets):\n        overlap[i] = percentOverlap(outputColumns, targetOutputColumns[i, : ])\n    classLabel = np.argmax(overlap)\n    return classLabel\n", "code_toks_joined": "def classifySPoutput ( targetOutputColumns , outputColumns ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> numTargets , numDims = targetOutputColumns . shape <NEWLINE> overlap = np . zeros ( ( numTargets , ) ) <NEWLINE> for i in range ( numTargets ) : <NEWLINE> <INDENT> overlap [ i ] = percentOverlap ( outputColumns , targetOutputColumns [ i , : ] ) <NEWLINE> <DEDENT> classLabel = np . argmax ( overlap ) <NEWLINE> return classLabel <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Classify the SP output\"\"\""]}}], ["cd8921ac4142fea5d6c35de8067eb853", {"code_string": "def getNotes(self):\n    return[\"Username is case sensitive\",\n    \"Automatically imports 2 years of transactions\",\n    \"Older transactions may be imported from the\\nAmeritrade website.  See documentation for more details.\",\n    \"Imported stock split transactions may have incorrect data\"]\n", "code_toks_joined": "def getNotes ( self ) : <NEWLINE> <INDENT> return [ <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Username is case sensitive\"", "\"Automatically imports 2 years of transactions\"", "\"Older transactions may be imported from the\\nAmeritrade website.  See documentation for more details.\"", "\"Imported stock split transactions may have incorrect data\""]}}], ["0f3708daa618cad0243bc9d0edb71b19", {"code_string": "def test_xml_to_json():\n    res = serialize.xml_to_json(ex.C_XML_1)\n    assert res == ex.C_XML_1_AS_JSON\n", "code_toks_joined": "def test_xml_to_json ( ) : <NEWLINE> <INDENT> res = serialize . xml_to_json ( ex . C_XML_1 ) <NEWLINE> assert res == ex . C_XML_1_AS_JSON <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["5ed12003556b80354ea3cb36ce200d9a", {"code_string": "def release_floatingip(self, floatingip):\n    row = self._get_row_with_floatingip(floatingip)\n    row.mark()\n    self.floatingips_table.release.click()\n    self.floatingip_form.submit.click()\n    self.wait_till_popups_disappear()\n", "code_toks_joined": "def release_floatingip ( self , floatingip ) : <NEWLINE> <INDENT> row = self . _get_row_with_floatingip ( floatingip ) <NEWLINE> row . mark ( ) <NEWLINE> self . floatingips_table . release . click ( ) <NEWLINE> self . floatingip_form . submit . click ( ) <NEWLINE> self . wait_till_popups_disappear ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["eb4f2c82e774423c6345632f8bcb920d", {"code_string": "class AnityaException(Exception):\n    ''' Generic class covering all the exceptions generated by anitya. '''\n    pass\n", "code_toks_joined": "class AnityaException ( Exception ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["''' Generic class covering all the exceptions generated by anitya. '''"]}}], ["a4d707daff6a444089f3228714ef9c57", {"code_string": "import asyncio\nimport argparse\nfrom timer import timer\nimport settings\n", "code_toks_joined": "import asyncio <NEWLINE> import argparse <NEWLINE> from timer import timer <NEWLINE> import settings <NEWLINE>", "anonymize_dict": {}}], ["53d3215e00da686e45fce23fdf8e8618", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('booth', '0005_auto_20161124_2044'),\n    ]\n    operations = [\n        migrations.AlterField(\n            model_name = 'schedule',\n            name = 'time',\n            field = models.TimeField(default = datetime.time(1, 50, 31, 856605), verbose_name = 'Time to record'),\n            preserve_default = False,\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . AlterField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . TimeField ( default = datetime . time ( 1 , 50 , 31 , 856605 ) , verbose_name = <STRING> ) , <NEWLINE> preserve_default = False , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'booth'", "'0005_auto_20161124_2044'", "'schedule'", "'time'", "'Time to record'"]}}], ["72cfb8f3282c0f8237ec44fa215120fa", {"code_string": "def run():\n    '''Returns status code'''\n    print(getDatastorePath('cloud/cloudcfg.json'))\n    return 0\n", "code_toks_joined": "def run ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> print ( getDatastorePath ( <STRING> ) ) <NEWLINE> return 0 <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Returns status code'''", "'cloud/cloudcfg.json'"]}}], ["1fbb7d958fd8777ddcd11aef81cdc596", {"code_string": "def nice_times(seconds):\n    if seconds < 60 * 60:\n        hours = None\n        if seconds < 60:\n            minutes = None\n        else:\n            minutes = seconds / 60\n    else:\n        minutes = seconds / 60\n        hours = seconds / 60 / 60\n    return hours, minutes\n", "code_toks_joined": "def nice_times ( seconds ) : <NEWLINE> <INDENT> if seconds < 60 * 60 : <NEWLINE> <INDENT> hours = None <NEWLINE> if seconds < 60 : <NEWLINE> <INDENT> minutes = None <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> minutes = seconds / 60 <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> minutes = seconds / 60 <NEWLINE> hours = seconds / 60 / 60 <NEWLINE> <DEDENT> return hours , minutes <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["b97e577106f28a7eefd80ccf4f73106c", {"code_string": "def main(args):\n    server.start(main_loop)\n    adapter = Application(server, 'app')\n    plugin.plugin_main(adapter)\n    try:\n        server.main_loop()\n    except KeyboardInterrupt:\n        pass\n    return 0\n", "code_toks_joined": "def main ( args ) : <NEWLINE> <INDENT> server . start ( main_loop ) <NEWLINE> adapter = Application ( server , <STRING> ) <NEWLINE> plugin . plugin_main ( adapter ) <NEWLINE> try : <NEWLINE> <INDENT> server . main_loop ( ) <NEWLINE> <DEDENT> except KeyboardInterrupt : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> return 0 <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'app'"]}}], ["225900ed500413b2f8a8f3322a1d8af0", {"code_string": "def test_csv2nlj(tmpdir, compare_iter, dicts_csv_path, dicts_path):\n    outfile = str(tmpdir.mkdir('test').join('out.json'))\n    result = CliRunner().invoke(main, [\n        'csv2nlj', dicts_csv_path, outfile\n    ])\n    assert result.exit_code == 0\n    with nlj.open(dicts_path) as expected:\n        with nlj.open(outfile) as actual:\n            compare_iter(expected, actual)\n", "code_toks_joined": "def test_csv2nlj ( tmpdir , compare_iter , dicts_csv_path , dicts_path ) : <NEWLINE> <INDENT> outfile = str ( tmpdir . mkdir ( <STRING> ) . join ( <STRING> ) ) <NEWLINE> result = CliRunner ( ) . invoke ( main , [ <NEWLINE> <INDENT> <STRING> , dicts_csv_path , outfile <NEWLINE> <DEDENT> ] ) <NEWLINE> assert result . exit_code == 0 <NEWLINE> with nlj . open ( dicts_path ) as expected : <NEWLINE> <INDENT> with nlj . open ( outfile ) as actual : <NEWLINE> <INDENT> compare_iter ( expected , actual ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'test'", "'out.json'", "'csv2nlj'"]}}], ["c27e743b3eda09885279a9eb4586e825", {"code_string": "def tearDown(self):\n    \"\"\"Tear down test fixture for each model test method.\"\"\"\n    DBSession.rollback()\n", "code_toks_joined": "def tearDown ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> DBSession . rollback ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Tear down test fixture for each model test method.\"\"\""]}}], ["68c4210af81d57a65080d89b835ba158", {"code_string": "class Scraper(object):\n    \"\"\"Scrape a milestones page to find a school's important dates.\"\"\"\n    def scrape(self):\n        \"\"\"Scape a page for milestone dates.\"\"\"\n        raise NotImplementedError()\n", "code_toks_joined": "class Scraper ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def scrape ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> raise NotImplementedError ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Scrape a milestones page to find a school's important dates.\"\"\"", "\"\"\"Scape a page for milestone dates.\"\"\""]}}], ["9d2973625571df2981f8f84e34ab3667", {"code_string": "def euclidean_distance(data, p1, p2):\n    si = {}\n    for item in data[person1]:\n        if item in data[person2]:\n            si[item] = 1\n    if len(si) == 0:\n        return 0\n    sum_of_squares = 0\n    for item in data[person1]:\n        if item in data[person2]:\n            sum_of_squares += pow(data[person1][item] - data[person2][item], 2)\n    return 1 /(1 + sum_of_squares)\n", "code_toks_joined": "def euclidean_distance ( data , p1 , p2 ) : <NEWLINE> <INDENT> si = { } <NEWLINE> for item in data [ person1 ] : <NEWLINE> <INDENT> if item in data [ person2 ] : <NEWLINE> <INDENT> si [ item ] = 1 <NEWLINE> <DEDENT> <DEDENT> if len ( si ) == 0 : <NEWLINE> <INDENT> return 0 <NEWLINE> <DEDENT> sum_of_squares = 0 <NEWLINE> for item in data [ person1 ] : <NEWLINE> <INDENT> if item in data [ person2 ] : <NEWLINE> <INDENT> sum_of_squares += pow ( data [ person1 ] [ item ] - data [ person2 ] [ item ] , 2 ) <NEWLINE> <DEDENT> <DEDENT> return 1 / ( 1 + sum_of_squares ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ac8ccddd00886182c224211a23665ec5", {"code_string": "def _get_user_input() -> dict:\n    return docopt(\n        doc = _read_interface(),\n        version = const.VERSION\n    )\n", "code_toks_joined": "def _get_user_input ( ) -> dict : <NEWLINE> <INDENT> return docopt ( <NEWLINE> <INDENT> doc = _read_interface ( ) , <NEWLINE> version = const . VERSION <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["1c846527965ad8ee696cc384930023e8", {"code_string": "def ms_to_sec(ms):\n    \"\"\"Returns an Integer approximated value\"\"\"\n    return int(ms / 1000)\n", "code_toks_joined": "def ms_to_sec ( ms ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return int ( ms / 1000 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Returns an Integer approximated value\"\"\""]}}], ["9cfa55c3a2d437a810d1c1300e39bf37", {"code_string": "class PipelineLogger:\n    logFunctions = {'info': logging.info,\n        'debug': logging.debug,\n        'warning': logging.warning,\n        'error': logging.error,\n        'critical': logging.critical,\n            'exception': logging.exception}\n    @ staticmethod\n    def log(moduleName, level, message):\n        level = level.lower()\n        logging.getLogger(moduleName)\n        PipelineLogger.logFunctions[level](message)\n", "code_toks_joined": "class PipelineLogger : <NEWLINE> <INDENT> logFunctions = { <STRING> : logging . info , <NEWLINE> <INDENT> <STRING> : logging . debug , <NEWLINE> <STRING> : logging . warning , <NEWLINE> <STRING> : logging . error , <NEWLINE> <STRING> : logging . critical , <NEWLINE> <INDENT> <STRING> : logging . exception } <NEWLINE> <DEDENT> <DEDENT> @ staticmethod <NEWLINE> def log ( moduleName , level , message ) : <NEWLINE> <INDENT> level = level . lower ( ) <NEWLINE> logging . getLogger ( moduleName ) <NEWLINE> PipelineLogger . logFunctions [ level ] ( message ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'info'", "'debug'", "'warning'", "'error'", "'critical'", "'exception'"]}}], ["e96cb32314bca9dccbedf356d0615d2b", {"code_string": "class SimpleExample(BaseWidget):\n    def __init__(self):\n        super(SimpleExample, self).__init__('Simple example')\n        self._control = ControlFile('Select a file')\n        self._formset = [' ', (' ', '_control', ' '), ' ']\n", "code_toks_joined": "class SimpleExample ( BaseWidget ) : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> super ( SimpleExample , self ) . __init__ ( <STRING> ) <NEWLINE> self . _control = ControlFile ( <STRING> ) <NEWLINE> self . _formset = [ <STRING> , ( <STRING> , <STRING> , <STRING> ) , <STRING> ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Simple example'", "'Select a file'", "' '", "' '", "'_control'", "' '", "' '"]}}], ["54a5435003c9c60e3befa8ee18ebe848", {"code_string": "def test_make_and_send_dns_message_missing_AA_flags(self, * mocks):\n    self.agent._make_dns_message = Mock(return_value = '')\n    response = RoObject(\n        rcode = Mock(return_value = dns.rcode.NOERROR),\n        flags = 0,\n    )\n    self.agent._send_dns_message = Mock(return_value = response)\n    out = self.agent._make_and_send_dns_message('h', 123, 1, 2, 3, 4, 5)\n    self.assertEqual((None, 0), out)\n", "code_toks_joined": "def test_make_and_send_dns_message_missing_AA_flags ( self , * mocks ) : <NEWLINE> <INDENT> self . agent . _make_dns_message = Mock ( return_value = <STRING> ) <NEWLINE> response = RoObject ( <NEWLINE> <INDENT> rcode = Mock ( return_value = dns . rcode . NOERROR ) , <NEWLINE> flags = 0 , <NEWLINE> <DEDENT> ) <NEWLINE> self . agent . _send_dns_message = Mock ( return_value = response ) <NEWLINE> out = self . agent . _make_and_send_dns_message ( <STRING> , 123 , 1 , 2 , 3 , 4 , 5 ) <NEWLINE> self . assertEqual ( ( None , 0 ) , out ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["''", "'h'"]}}], ["a13ed851e94aa7fb1c32f31107429f41", {"code_string": "def __init__(self):\n    self.__varName = ''\n    self.__current = ''\n    self.__curList = []\n", "code_toks_joined": "def __init__ ( self ) : <NEWLINE> <INDENT> self . __varName = <STRING> <NEWLINE> self . __current = <STRING> <NEWLINE> self . __curList = [ ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["''", "''"]}}], ["7d4a5f8a9a57c4b99ae05a15ad0b7500", {"code_string": "import sys, socket\nfrom collect_client import *\nfrom client_psutil_plugin import psutil_stat\nhostname = socket.gethostname()\nserver_address = ['%s:40000' % hostname]\nif True:\n    c = collectd(hostname, server_address)\nelse:\n    c = collectd(hostname, server_address, stack = 10)\n\"\"\"arcus = arcus_stat()\"\"\"\nps = psutil_stat()\nc.plugins.append(ps)\nc.daemon()\n", "code_toks_joined": "import sys , socket <NEWLINE> from collect_client import * <NEWLINE> from client_psutil_plugin import psutil_stat <NEWLINE> hostname = socket . gethostname ( ) <NEWLINE> server_address = [ <STRING> % hostname ] <NEWLINE> if True : <NEWLINE> <INDENT> c = collectd ( hostname , server_address ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> c = collectd ( hostname , server_address , stack = 10 ) <NEWLINE> <DEDENT> <STRING> <NEWLINE> ps = psutil_stat ( ) <NEWLINE> c . plugins . append ( ps ) <NEWLINE> c . daemon ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'%s:40000'", "\"\"\"arcus = arcus_stat()\"\"\""]}}], ["c4bf3cd99f133cfe7f4e05de8a78da4d", {"code_string": "from realacct_list import RealAcctListMixin\nfrom realtxn_list import RealTxnListForRealAcctMixin\n", "code_toks_joined": "from realacct_list import RealAcctListMixin <NEWLINE> from realtxn_list import RealTxnListForRealAcctMixin <NEWLINE>", "anonymize_dict": {}}], ["6f5f7703f7ef9319dff90157bb8a3170", {"code_string": "from django.conf.urls import patterns, url\nfrom django.contrib.auth.decorators import login_required\nfrom.views import ActivityStream, ActivityStreamSettings\nurlpatterns = patterns('activity_stream.views',\n    url(r'^$', ActivityStream.as_view(), name = 'activity_stream'),\n    url(r'^settings/$', login_required(ActivityStreamSettings.as_view()),\n        name = 'activity_stream_settings'),\n)\n", "code_toks_joined": "from django . conf . urls import patterns , url <NEWLINE> from django . contrib . auth . decorators import login_required <NEWLINE> from . views import ActivityStream , ActivityStreamSettings <NEWLINE> urlpatterns = patterns ( <STRING> , <NEWLINE> <INDENT> url ( <STRING> , ActivityStream . as_view ( ) , name = <STRING> ) , <NEWLINE> url ( <STRING> , login_required ( ActivityStreamSettings . as_view ( ) ) , <NEWLINE> <INDENT> name = <STRING> ) , <NEWLINE> <DEDENT> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'activity_stream.views'", "r'^$'", "'activity_stream'", "r'^settings/$'", "'activity_stream_settings'"]}}], ["d2034db8fa959b2dac1334ef254bca6b", {"code_string": "from django.conf.urls import patterns, url\nfrom home import views\nurlpatterns = patterns('',\n    url(r'^$', views.index, name = 'index'),\n    url(r'^gadget/(?P<gadget_id>\\d+)$', views.gadget_details, name = 'details'),\n    url(r'^gadget/(?P<gadget_id>\\d+)/do$', views.gadget_do, name = 'do'),\n)\n", "code_toks_joined": "from django . conf . urls import patterns , url <NEWLINE> from home import views <NEWLINE> urlpatterns = patterns ( <STRING> , <NEWLINE> <INDENT> url ( <STRING> , views . index , name = <STRING> ) , <NEWLINE> url ( <STRING> , views . gadget_details , name = <STRING> ) , <NEWLINE> url ( <STRING> , views . gadget_do , name = <STRING> ) , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["''", "r'^$'", "'index'", "r'^gadget/(?P<gadget_id>\\d+)$'", "'details'", "r'^gadget/(?P<gadget_id>\\d+)/do$'", "'do'"]}}], ["d6c16adbc2246739c568fff920408f4b", {"code_string": "def setUp(self):\n    self.dataUnit = HomeoDataUnit()\n    self.unit = HomeoUnit()\n", "code_toks_joined": "def setUp ( self ) : <NEWLINE> <INDENT> self . dataUnit = HomeoDataUnit ( ) <NEWLINE> self . unit = HomeoUnit ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["50837281c42cd2217ee6b1b0e87cfb5b", {"code_string": "import logging\nfrom django.core.management.base import BaseCommand\nfrom feedzilla.models import Post\n", "code_toks_joined": "import logging <NEWLINE> from django . core . management . base import BaseCommand <NEWLINE> from feedzilla . models import Post <NEWLINE>", "anonymize_dict": {}}], ["58189b629d476de5af2e015f2502549c", {"code_string": "def set_voice():\n    global voice\n    import pyvona\n    voice = pyvona.create_voice()\n", "code_toks_joined": "def set_voice ( ) : <NEWLINE> <INDENT> global voice <NEWLINE> import pyvona <NEWLINE> voice = pyvona . create_voice ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["0d60e33fded2874c2f2d0022125150cf", {"code_string": "def delete_group_rows(self, session, group):\n    \"\"\"Delete rows from a given group and return them\"\"\"\n    rows = [r for r in self.rows if r[2] == group]\n    ids = [r[0] for r in rows]\n    session.execute('DELETE FROM test WHERE id in (%s)' % ', '.join(ids))\n    return list(rows)\n", "code_toks_joined": "def delete_group_rows ( self , session , group ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> rows = [ r for r in self . rows if r [ 2 ] == group ] <NEWLINE> ids = [ r [ 0 ] for r in rows ] <NEWLINE> session . execute ( <STRING> % <STRING> . join ( ids ) ) <NEWLINE> return list ( rows ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Delete rows from a given group and return them\"\"\"", "'DELETE FROM test WHERE id in (%s)'", "', '"]}}], ["bd408dcced642957179b968ab2694440", {"code_string": "class Whisk:\n    def __init__(self):\n        start_time = time.time()\n        mdbundle = FileLoader(MARKDOWN_EXT, ROOT_DIR, MarkdownFile)\n        templates = set(f.metadata['template'] for f in mdbundle.files)\n        tt = Templater(TEMPLATE_DIR)\n        tt.load_templates(templates)\n        for mdfile in mdbundle.files:\n            tt.render_and_write(mdfile)\n        print('Rendered %i markdown files in %f seconds.' %(len(mdbundle.files), time.time() - start_time))\n", "code_toks_joined": "class Whisk : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> start_time = time . time ( ) <NEWLINE> mdbundle = FileLoader ( MARKDOWN_EXT , ROOT_DIR , MarkdownFile ) <NEWLINE> templates = set ( f . metadata [ <STRING> ] for f in mdbundle . files ) <NEWLINE> tt = Templater ( TEMPLATE_DIR ) <NEWLINE> tt . load_templates ( templates ) <NEWLINE> for mdfile in mdbundle . files : <NEWLINE> <INDENT> tt . render_and_write ( mdfile ) <NEWLINE> <DEDENT> print ( <STRING> % ( len ( mdbundle . files ) , time . time ( ) - start_time ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'template'", "'Rendered %i markdown files in %f seconds.'"]}}], ["9b83bb8fb363d0e8c2e63a40abfeffaf", {"code_string": "def test_substitution(self):\n    \"\"\"Verify that the special substitutions are replaced by the correct,\"\"\"\n    testcases = [(\"@yearly\", \"0 0 1 1 *\"),\n        (\"@annually\", \"0 0 1 1 *\"),\n        (\"@monthly\", \"0 0 1 * *\"),\n        (\"@weekly\", \"0 0 * * 0\"),\n        (\"@daily\", \"0 0 * * *\"),\n        (\"@midnight\", \"0 0 * * *\"),\n        (\"@hourly\", \"0 * * * *\")]\n    for a, b in testcases:\n        obj = cronex.CronExpression(a)\n        self.assertTrue(b in repr(obj))\n", "code_toks_joined": "def test_substitution ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> testcases = [ ( <STRING> , <STRING> ) , <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) ] <NEWLINE> <DEDENT> for a , b in testcases : <NEWLINE> <INDENT> obj = cronex . CronExpression ( a ) <NEWLINE> self . assertTrue ( b in repr ( obj ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Verify that the special substitutions are replaced by the correct,\"\"\"", "\"@yearly\"", "\"0 0 1 1 *\"", "\"@annually\"", "\"0 0 1 1 *\"", "\"@monthly\"", "\"0 0 1 * *\"", "\"@weekly\"", "\"0 0 * * 0\"", "\"@daily\"", "\"0 0 * * *\"", "\"@midnight\"", "\"0 0 * * *\"", "\"@hourly\"", "\"0 * * * *\""]}}], ["cedf163fd10379a20ecee226b5154384", {"code_string": "def deploy_ssh_pubkeys(self, ovfenv):\n    for pubkey in ovfenv.ssh_pubkeys:\n        logger.info(\"Deploy ssh public key.\")\n        self.distro.osutil.deploy_ssh_pubkey(ovfenv.username, pubkey)\n", "code_toks_joined": "def deploy_ssh_pubkeys ( self , ovfenv ) : <NEWLINE> <INDENT> for pubkey in ovfenv . ssh_pubkeys : <NEWLINE> <INDENT> logger . info ( <STRING> ) <NEWLINE> self . distro . osutil . deploy_ssh_pubkey ( ovfenv . username , pubkey ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Deploy ssh public key.\""]}}], ["d06d7efc413287d21cb3ae5c31282838", {"code_string": "import demowlcutils\nfrom demowlcutils import ppxml, WLC_login\nfrom pprint import pprint as pp\nfrom jnpr.wlc import WirelessLanController as WLC\nwlc = WLC(host = 'a', user = 'b', password = 'c')\n", "code_toks_joined": "import demowlcutils <NEWLINE> from demowlcutils import ppxml , WLC_login <NEWLINE> from pprint import pprint as pp <NEWLINE> from jnpr . wlc import WirelessLanController as WLC <NEWLINE> wlc = WLC ( host = <STRING> , user = <STRING> , password = <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'a'", "'b'", "'c'"]}}], ["0744db4aa821ff844e81875f7747ee8f", {"code_string": "from app import db, app\nfrom models import File\nfrom datetime import date, datetime, time, timedelta\nimport os\nimport shutil\n", "code_toks_joined": "from app import db , app <NEWLINE> from models import File <NEWLINE> from datetime import date , datetime , time , timedelta <NEWLINE> import os <NEWLINE> import shutil <NEWLINE>", "anonymize_dict": {}}], ["9b34579d89974613d640d6c8180e0479", {"code_string": "from flask.ext.script import Manager, Server\nfrom flaskcms import creat_app\nserver = Server(port = 8000)\nmanager = Manager(creat_app('config.py'))\nmanager.add_command(\"runserver\", server)\nif __name__ == \"__main__\":\n    manager.run()\n", "code_toks_joined": "from flask . ext . script import Manager , Server <NEWLINE> from flaskcms import creat_app <NEWLINE> server = Server ( port = 8000 ) <NEWLINE> manager = Manager ( creat_app ( <STRING> ) ) <NEWLINE> manager . add_command ( <STRING> , server ) <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> manager . run ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'config.py'", "\"runserver\"", "\"__main__\""]}}], ["915c5ca6dd1b980d35000bb087a239ba", {"code_string": "from functools import wraps\nfrom django.http import HttpResponse\nfrom django.core.urlresolvers import reverse\nfrom django.core.handlers.wsgi import WSGIRequest\nfrom fandjango.utils import get_post_authorization_redirect_url\nfrom fandjango.views import authorize_application\nfrom fandjango.settings import FACEBOOK_APPLICATION_DOMAIN\nfrom fandjango.settings import FACEBOOK_APPLICATION_NAMESPACE\nfrom fandjango.settings import FACEBOOK_APPLICATION_INITIAL_PERMISSIONS\nfrom fandjango.settings import FACEBOOK_AUTHORIZATION_REDIRECT_URL\n", "code_toks_joined": "from functools import wraps <NEWLINE> from django . http import HttpResponse <NEWLINE> from django . core . urlresolvers import reverse <NEWLINE> from django . core . handlers . wsgi import WSGIRequest <NEWLINE> from fandjango . utils import get_post_authorization_redirect_url <NEWLINE> from fandjango . views import authorize_application <NEWLINE> from fandjango . settings import FACEBOOK_APPLICATION_DOMAIN <NEWLINE> from fandjango . settings import FACEBOOK_APPLICATION_NAMESPACE <NEWLINE> from fandjango . settings import FACEBOOK_APPLICATION_INITIAL_PERMISSIONS <NEWLINE> from fandjango . settings import FACEBOOK_AUTHORIZATION_REDIRECT_URL <NEWLINE>", "anonymize_dict": {}}], ["9fdc9e2084522b8d59d95b439d9509cc", {"code_string": "def __init__(self, size):\n    \"\"\"__init__(io::NullInputStream self, sys::SSize_T size) -> NullInputStream\"\"\"\n    this = _coda_io.new_NullInputStream(size)\n    try:\n        self.this.append(this)\n    except __builtin__.Exception:\n        self.this = this\n", "code_toks_joined": "def __init__ ( self , size ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> this = _coda_io . new_NullInputStream ( size ) <NEWLINE> try : <NEWLINE> <INDENT> self . this . append ( this ) <NEWLINE> <DEDENT> except __builtin__ . Exception : <NEWLINE> <INDENT> self . this = this <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"__init__(io::NullInputStream self, sys::SSize_T size) -> NullInputStream\"\"\""]}}], ["203b24e62721cfaf42cf272826e2bf7f", {"code_string": "def testContentTypeTokenGeneratorCreatesEquivalentGlobalTokens(self):\n    self.assertEqual(\n        len(self.token_generator.generate(scope.access_all())),\n        len(basic_token_generator.generate(scope.access_all())),\n    )\n", "code_toks_joined": "def testContentTypeTokenGeneratorCreatesEquivalentGlobalTokens ( self ) : <NEWLINE> <INDENT> self . assertEqual ( <NEWLINE> <INDENT> len ( self . token_generator . generate ( scope . access_all ( ) ) ) , <NEWLINE> len ( basic_token_generator . generate ( scope . access_all ( ) ) ) , <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ed47a24ff63c8393be48073bc1eba335", {"code_string": "def test_startup_file(self):\n    \"\"\" mlaunch: create .mlaunch_startup file in data path \"\"\"\n    self.run_tool(\"init --single -v\")\n    startup_file = os.path.join(self.data_dir, '.mlaunch_startup')\n    assert os.path.isfile(startup_file)\n    file_contents = self.tool._convert_u2b(json.load(open(startup_file, 'r')))\n    assert file_contents['parsed_args'] == self.tool.args\n    assert file_contents['unknown_args'] == self.tool.unknown_args\n", "code_toks_joined": "def test_startup_file ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . run_tool ( <STRING> ) <NEWLINE> startup_file = os . path . join ( self . data_dir , <STRING> ) <NEWLINE> assert os . path . isfile ( startup_file ) <NEWLINE> file_contents = self . tool . _convert_u2b ( json . load ( open ( startup_file , <STRING> ) ) ) <NEWLINE> assert file_contents [ <STRING> ] == self . tool . args <NEWLINE> assert file_contents [ <STRING> ] == self . tool . unknown_args <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" mlaunch: create .mlaunch_startup file in data path \"\"\"", "\"init --single -v\"", "'.mlaunch_startup'", "'r'", "'parsed_args'", "'unknown_args'"]}}], ["d16036d5f18d03c0554e110603e378da", {"code_string": "def test_DWI2Tensor_outputs():\n    output_map = dict(tensor = dict(),\n    )\n    outputs = DWI2Tensor.output_spec()\n    for key, metadata in output_map.items():\n        for metakey, value in metadata.items():\n            yield assert_equal, getattr(outputs.traits()[key], metakey), value\n", "code_toks_joined": "def test_DWI2Tensor_outputs ( ) : <NEWLINE> <INDENT> output_map = dict ( tensor = dict ( ) , <NEWLINE> ) <NEWLINE> outputs = DWI2Tensor . output_spec ( ) <NEWLINE> for key , metadata in output_map . items ( ) : <NEWLINE> <INDENT> for metakey , value in metadata . items ( ) : <NEWLINE> <INDENT> yield assert_equal , getattr ( outputs . traits ( ) [ key ] , metakey ) , value <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["569ad470358ad65bdfd25f9c5aca38a7", {"code_string": "\"\"\"Public interface exports.\"\"\"\nfrom.jobs import Jobs\nfrom.job import Job\n", "code_toks_joined": "<STRING> <NEWLINE> from . jobs import Jobs <NEWLINE> from . job import Job <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Public interface exports.\"\"\""]}}], ["20916bbb66891e402c7dd58081334326", {"code_string": "def forwards(self, orm):\n    db.create_table(u'cmsplugin_newsplus_topic', (\n        (u'id', self.gf('django.db.models.fields.AutoField')(primary_key = True)),\n        ('title', self.gf('django.db.models.fields.CharField')(max_length = 255)),\n    ))\n    db.send_create_signal(u'cmsplugin_newsplus', ['Topic'])\n    db.add_column(u'cmsplugin_newsplus_news', 'topic',\n        self.gf('django.db.models.fields.related.ForeignKey')(to = orm['cmsplugin_newsplus.Topic'], null = True, blank = True),\n        keep_default = False)\n", "code_toks_joined": "def forwards ( self , orm ) : <NEWLINE> <INDENT> db . create_table ( <STRING> , ( <NEWLINE> <INDENT> ( <STRING> , self . gf ( <STRING> ) ( primary_key = True ) ) , <NEWLINE> ( <STRING> , self . gf ( <STRING> ) ( max_length = 255 ) ) , <NEWLINE> <DEDENT> ) ) <NEWLINE> db . send_create_signal ( <STRING> , [ <STRING> ] ) <NEWLINE> db . add_column ( <STRING> , <STRING> , <NEWLINE> <INDENT> self . gf ( <STRING> ) ( to = orm [ <STRING> ] , null = True , blank = True ) , <NEWLINE> keep_default = False ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["u'cmsplugin_newsplus_topic'", "u'id'", "'django.db.models.fields.AutoField'", "'title'", "'django.db.models.fields.CharField'", "u'cmsplugin_newsplus'", "'Topic'", "u'cmsplugin_newsplus_news'", "'topic'", "'django.db.models.fields.related.ForeignKey'", "'cmsplugin_newsplus.Topic'"]}}], ["a8e690633b499769012eb8a9c40478f6", {"code_string": "def main():\n    HOST = ''\n    PORT = 50001\n    message_list = ['alpha', 'bravo', 'charlie', 'delta']\n    for i in message_list:\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.bind((HOST, PORT))\n        s.listen(1)\n        conn, addr = s.accept()\n        conn.send(i)\n        conn.close()\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> HOST = <STRING> <NEWLINE> PORT = 50001 <NEWLINE> message_list = [ <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE> for i in message_list : <NEWLINE> <INDENT> s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <NEWLINE> s . bind ( ( HOST , PORT ) ) <NEWLINE> s . listen ( 1 ) <NEWLINE> conn , addr = s . accept ( ) <NEWLINE> conn . send ( i ) <NEWLINE> conn . close ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["''", "'alpha'", "'bravo'", "'charlie'", "'delta'"]}}], ["177c63b15f8470a919d03bb078221a78", {"code_string": "from __future__ import print_function\nimport sys\nimport os.path\nimport json\nimport argparse\nimport numpy as np\nimport datetime\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nimport s2p\nfrom s2plib.config import cfg\nfrom s2plib import common\nfrom s2plib import initialization\n", "code_toks_joined": "from __future__ import print_function <NEWLINE> import sys <NEWLINE> import os . path <NEWLINE> import json <NEWLINE> import argparse <NEWLINE> import numpy as np <NEWLINE> import datetime <NEWLINE> sys . path . append ( os . path . dirname ( os . path . dirname ( os . path . abspath ( __file__ ) ) ) ) <NEWLINE> import s2p <NEWLINE> from s2plib . config import cfg <NEWLINE> from s2plib import common <NEWLINE> from s2plib import initialization <NEWLINE>", "anonymize_dict": {}}], ["c5480b5d1bcc452156db4206ea3ea032", {"code_string": "def get(self):\n    \"\"\"This function is a wrapper for the get function.\"\"\"\n    bit_value = DAISY20.get(self.identifier) & 0x3f8\n    self.buffer.append(bit_value)\n    bfr = tuple(buf for buf in self.buffer if buf is not None)\n    mask = 0x03ff\n    for buffer_value in bfr:\n        mask = mask & buffer_value\n    if DAISY20.convert(mask ^ bit_value) < 0.2:\n        value = bit_value\n        DAISY20.last_value_set = value\n    else:\n        value = DAISY20.last_value_set\n    return DAISY20.convert(value)\n", "code_toks_joined": "def get ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> bit_value = DAISY20 . get ( self . identifier ) & 0x3f8 <NEWLINE> self . buffer . append ( bit_value ) <NEWLINE> bfr = tuple ( buf for buf in self . buffer if buf is not None ) <NEWLINE> mask = 0x03ff <NEWLINE> for buffer_value in bfr : <NEWLINE> <INDENT> mask = mask & buffer_value <NEWLINE> <DEDENT> if DAISY20 . convert ( mask ^ bit_value ) < 0.2 : <NEWLINE> <INDENT> value = bit_value <NEWLINE> DAISY20 . last_value_set = value <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> value = DAISY20 . last_value_set <NEWLINE> <DEDENT> return DAISY20 . convert ( value ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"This function is a wrapper for the get function.\"\"\""]}}], ["f7ecf8b75d85488273de70d1b6198090", {"code_string": "def inactivate(self):\n    assert self.is_active, ('This person facet is already inactive')\n    self.is_active = False\n", "code_toks_joined": "def inactivate ( self ) : <NEWLINE> <INDENT> assert self . is_active , ( <STRING> ) <NEWLINE> self . is_active = False <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'This person facet is already inactive'"]}}], ["1e60caa088e551f7ce10c314a9fad119", {"code_string": "class TrafficCardClass(object):\n    def __init__(self):\n        self.balance = 0\n    def charge(self, amount):\n        self.balance += amount\n    def pay(self, amount):\n        self.balance -= amount\n    def check(self):\n        return self.balance\n", "code_toks_joined": "class TrafficCardClass ( object ) : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> self . balance = 0 <NEWLINE> <DEDENT> def charge ( self , amount ) : <NEWLINE> <INDENT> self . balance += amount <NEWLINE> <DEDENT> def pay ( self , amount ) : <NEWLINE> <INDENT> self . balance -= amount <NEWLINE> <DEDENT> def check ( self ) : <NEWLINE> <INDENT> return self . balance <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["82ce8ae51be8a1f03c3712ef18560c52", {"code_string": "def setupDB():\n    \"\"\"\tInitialize the database if it does not exist yet\"\"\"\n    if not os.path.isfile(globalVars.dbPath):\n        logging.error(\"Database Missing\")\n        dbConn, dbcursor = dbConnection.dbConnect()\n        dbcursor.execute('CREATE TABLE \"messages\" ( \"message\"  , \"timestamp\"  , \"index\"  INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL );')\n        dbConnection.dbClose(dbConn)\n        logging.info(\"Database generated\")\n", "code_toks_joined": "def setupDB ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if not os . path . isfile ( globalVars . dbPath ) : <NEWLINE> <INDENT> logging . error ( <STRING> ) <NEWLINE> dbConn , dbcursor = dbConnection . dbConnect ( ) <NEWLINE> dbcursor . execute ( <STRING> ) <NEWLINE> dbConnection . dbClose ( dbConn ) <NEWLINE> logging . info ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"\tInitialize the database if it does not exist yet\"\"\"", "\"Database Missing\"", "'CREATE TABLE \"messages\" ( \"message\"  , \"timestamp\"  , \"index\"  INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL );'", "\"Database generated\""]}}], ["a88db6d80d1fd353ac70e94f15fe077f", {"code_string": "from reactnativebackend.settings.staging import *\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.postgresql_psycopg2',\n        'NAME': '',\n        'USER': '',\n        'PASSWORD': '',\n        'HOST': '',\n        'PORT': '',\n    }\n}\n", "code_toks_joined": "from reactnativebackend . settings . staging import * <NEWLINE> DATABASES = { <NEWLINE> <INDENT> <STRING> : { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT> } <NEWLINE>", "anonymize_dict": {"<STRING>": ["'default'", "'ENGINE'", "'django.db.backends.postgresql_psycopg2'", "'NAME'", "''", "'USER'", "''", "'PASSWORD'", "''", "'HOST'", "''", "'PORT'", "''"]}}], ["8c0f10fffc7600e544e6a8173a0f6582", {"code_string": "import boto3\ncloudwatch = boto3.client('cloudwatch')\ncloudwatch.put_metric_data(\n    MetricData = [\n        {\n            'MetricName': 'PAGES_VISITED',\n            'Dimensions': [\n                {\n                    'Name': 'UNIQUE_PAGES',\n                    'Value': 'URLS'\n                },\n            ],\n            'Unit': 'None',\n            'Value': 1.0\n        },\n    ],\n    Namespace = 'SITE/TRAFFIC'\n)\n", "code_toks_joined": "import boto3 <NEWLINE> cloudwatch = boto3 . client ( <STRING> ) <NEWLINE> cloudwatch . put_metric_data ( <NEWLINE> <INDENT> MetricData = [ <NEWLINE> <INDENT> { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : [ <NEWLINE> <INDENT> { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> <NEWLINE> <DEDENT> } , <NEWLINE> <DEDENT> ] , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : 1.0 <NEWLINE> <DEDENT> } , <NEWLINE> <DEDENT> ] , <NEWLINE> Namespace = <STRING> <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'cloudwatch'", "'MetricName'", "'PAGES_VISITED'", "'Dimensions'", "'Name'", "'UNIQUE_PAGES'", "'Value'", "'URLS'", "'Unit'", "'None'", "'Value'", "'SITE/TRAFFIC'"]}}], ["7f8e936edfd70248749dee4c800017a5", {"code_string": "import arcade\nif __name__ == '__main__':\n    arcade.open_window('Coin Game', 600, 600)\n    arcade.set_background_color(arcade.color.WHEAT)\n    arcade.run()\n", "code_toks_joined": "import arcade <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> arcade . open_window ( <STRING> , 600 , 600 ) <NEWLINE> arcade . set_background_color ( arcade . color . WHEAT ) <NEWLINE> arcade . run ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'__main__'", "'Coin Game'"]}}], ["1b2297b3b2ced6cf72fc42346466cc4e", {"code_string": "\"\"\"Symbolic primitives + unicode/ASCII abstraction for pretty.py\"\"\"\nimport sys\nwarnings = ''\ntry:\n    import unicodedata\n    def U(name):\n        \"\"\"unicode character by name or None if not found\"\"\"\n        try:\n            u = unicodedata.lookup(name)\n        except KeyError:\n            u = None\n            global warnings\n            warnings += 'W: no \\'%s\\' in unocodedata\\n' % name\n        return u\nexcept ImportError:\n    warnings += 'W: no unicodedata available\\n'\n    U = lambda name: None\nfrom sympy.printing.conventions import split_super_sub\n__all__ = ['greek', 'sub', 'sup', 'xsym', 'vobj', 'hobj', 'pretty_symbol',\n    'annotated']\n_use_unicode = False\n", "code_toks_joined": "<STRING> <NEWLINE> import sys <NEWLINE> warnings = <STRING> <NEWLINE> try : <NEWLINE> <INDENT> import unicodedata <NEWLINE> def U ( name ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> try : <NEWLINE> <INDENT> u = unicodedata . lookup ( name ) <NEWLINE> <DEDENT> except KeyError : <NEWLINE> <INDENT> u = None <NEWLINE> global warnings <NEWLINE> warnings += <STRING> % name <NEWLINE> <DEDENT> return u <NEWLINE> <DEDENT> <DEDENT> except ImportError : <NEWLINE> <INDENT> warnings += <STRING> <NEWLINE> U = lambda name : None <NEWLINE> <DEDENT> from sympy . printing . conventions import split_super_sub <NEWLINE> __all__ = [ <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <NEWLINE> <INDENT> <STRING> ] <NEWLINE> <DEDENT> _use_unicode = False <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Symbolic primitives + unicode/ASCII abstraction for pretty.py\"\"\"", "''", "\"\"\"unicode character by name or None if not found\"\"\"", "'W: no \\'%s\\' in unocodedata\\n'", "'W: no unicodedata available\\n'", "'greek'", "'sub'", "'sup'", "'xsym'", "'vobj'", "'hobj'", "'pretty_symbol'", "'annotated'"]}}], ["a379493f56920a77a23cb34162cf9846", {"code_string": "def polygonSelection(self):\n    if self.tool:\n        self.tool.reset()\n    self.request = 'intersects'\n    self.tool = selectPolygon(self.iface, self.themeColor, 1)\n    self.tool.setAction(self.actions[4])\n    self.iface.connect(self.tool, SIGNAL(\"selectionDone()\"), self.returnedBounds)\n    self.iface.mapCanvas().setMapTool(self.tool)\n    self.sb.showMessage(self.tr('Left click to place points. Right click to confirm.'))\n", "code_toks_joined": "def polygonSelection ( self ) : <NEWLINE> <INDENT> if self . tool : <NEWLINE> <INDENT> self . tool . reset ( ) <NEWLINE> <DEDENT> self . request = <STRING> <NEWLINE> self . tool = selectPolygon ( self . iface , self . themeColor , 1 ) <NEWLINE> self . tool . setAction ( self . actions [ 4 ] ) <NEWLINE> self . iface . connect ( self . tool , SIGNAL ( <STRING> ) , self . returnedBounds ) <NEWLINE> self . iface . mapCanvas ( ) . setMapTool ( self . tool ) <NEWLINE> self . sb . showMessage ( self . tr ( <STRING> ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'intersects'", "\"selectionDone()\"", "'Left click to place points. Right click to confirm.'"]}}], ["34d29ab155dd097f52340697dca94bf3", {"code_string": "def event_to_num_steps(self, event):\n    if self._num_steps is not None:\n        return self._num_steps[event]\n    else:\n        return 1\n", "code_toks_joined": "def event_to_num_steps ( self , event ) : <NEWLINE> <INDENT> if self . _num_steps is not None : <NEWLINE> <INDENT> return self . _num_steps [ event ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return 1 <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["3ecae37b330173de4ac3ac21462114a1", {"code_string": "def test_field_table(self):\n    w = Writer()\n    expect(w.write_table).args({'foo': 'bar'}).side_effect(\n        lambda * args: w._output_buffer.extend('tdata'))\n    w._field_table({'foo': 'bar'})\n    assert_equals('Ftdata', w._output_buffer)\n", "code_toks_joined": "def test_field_table ( self ) : <NEWLINE> <INDENT> w = Writer ( ) <NEWLINE> expect ( w . write_table ) . args ( { <STRING> : <STRING> } ) . side_effect ( <NEWLINE> <INDENT> lambda * args : w . _output_buffer . extend ( <STRING> ) ) <NEWLINE> <DEDENT> w . _field_table ( { <STRING> : <STRING> } ) <NEWLINE> assert_equals ( <STRING> , w . _output_buffer ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'foo'", "'bar'", "'tdata'", "'foo'", "'bar'", "'Ftdata'"]}}], ["603360eda1af2a981816ab62dda575af", {"code_string": "def myAccumulate(iterable, func = operator.add):\n    'Return running totals'\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total\n", "code_toks_joined": "def myAccumulate ( iterable , func = operator . add ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> it = iter ( iterable ) <NEWLINE> try : <NEWLINE> <INDENT> total = next ( it ) <NEWLINE> <DEDENT> except StopIteration : <NEWLINE> <INDENT> return <NEWLINE> <DEDENT> yield total <NEWLINE> for element in it : <NEWLINE> <INDENT> total = func ( total , element ) <NEWLINE> yield total <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Return running totals'"]}}], ["15ffca949ce657988110c6b37c423a44", {"code_string": "__author__ = 'swabyears'\nimport paramiko\nimport argparse\nimport time\nimport re\n'''Script to grab the port a particular MAC address is showing up on.'''\nswitches_this_script_works_on = ['C3560', 'C2960', 'C2950', 'C3750']\n", "code_toks_joined": "__author__ = <STRING> <NEWLINE> import paramiko <NEWLINE> import argparse <NEWLINE> import time <NEWLINE> import re <NEWLINE> <STRING> <NEWLINE> switches_this_script_works_on = [ <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'swabyears'", "'''Script to grab the port a particular MAC address is showing up on.'''", "'C3560'", "'C2960'", "'C2950'", "'C3750'"]}}], ["1d290945c1be431236e71dd5633761e1", {"code_string": "class OIDTemplate(object):\n    __slots__ = (\"_initializer\", \"_oid_cls\")\n    def __init__(self, initializer = b\"\", oid_cls = OID):\n        self._initializer = initializer\n        self._oid_cls = oid_cls\n    def new(self, data = b\"\"):\n        obj = self._oid_cls()\n        obj.open(self._initializer + data)\n        return obj\n", "code_toks_joined": "class OIDTemplate ( object ) : <NEWLINE> <INDENT> __slots__ = ( <STRING> , <STRING> ) <NEWLINE> def __init__ ( self , initializer = <STRING> , oid_cls = OID ) : <NEWLINE> <INDENT> self . _initializer = initializer <NEWLINE> self . _oid_cls = oid_cls <NEWLINE> <DEDENT> def new ( self , data = <STRING> ) : <NEWLINE> <INDENT> obj = self . _oid_cls ( ) <NEWLINE> obj . open ( self . _initializer + data ) <NEWLINE> return obj <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"_initializer\"", "\"_oid_cls\"", "b\"\"", "b\"\""]}}], ["a9e2dd98134d94c51af98405068e2878", {"code_string": "def handler_all(f):\n    \"\"\"Decorator which registers a function as a webhook handler for ALL webhook\"\"\"\n    registrations_global.append(f)\n    return f\n", "code_toks_joined": "def handler_all ( f ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> registrations_global . append ( f ) <NEWLINE> return f <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Decorator which registers a function as a webhook handler for ALL webhook\"\"\""]}}], ["341526d17e3c744753c64935225a41c2", {"code_string": "def stderr(self):\n    if self._stderr is None:\n        self._read_stderr()\n    return self._stderr\n", "code_toks_joined": "def stderr ( self ) : <NEWLINE> <INDENT> if self . _stderr is None : <NEWLINE> <INDENT> self . _read_stderr ( ) <NEWLINE> <DEDENT> return self . _stderr <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["78dcdff3f25145ef41fd735d33fef53a", {"code_string": "def raw_exec(command, arguments):\n    return subprocess.Popen((command, ) + arguments,\n        stdin = subprocess.PIPE,\n        stdout = subprocess.PIPE,\n        stderr = subprocess.STDOUT)\n", "code_toks_joined": "def raw_exec ( command , arguments ) : <NEWLINE> <INDENT> return subprocess . Popen ( ( command , ) + arguments , <NEWLINE> <INDENT> stdin = subprocess . PIPE , <NEWLINE> stdout = subprocess . PIPE , <NEWLINE> stderr = subprocess . STDOUT ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["49117cf6cda44553f84b9c0959b7b926", {"code_string": "from django.contrib import admin\nfrom django.conf.urls import patterns\nfrom django.contrib import admin, messages\nfrom django.core.paginator import Paginator, EmptyPage, PageNotAnInteger\nfrom django.http import HttpResponseRedirect, HttpResponse\nfrom django.shortcuts import render\nfrom django.template import RequestContext, loader\nfrom website.models import *\nfrom event_counter.admin import *\nfrom website.forms import *\nimport logging\nlogger = logging.getLogger('django.request')\n", "code_toks_joined": "from django . contrib import admin <NEWLINE> from django . conf . urls import patterns <NEWLINE> from django . contrib import admin , messages <NEWLINE> from django . core . paginator import Paginator , EmptyPage , PageNotAnInteger <NEWLINE> from django . http import HttpResponseRedirect , HttpResponse <NEWLINE> from django . shortcuts import render <NEWLINE> from django . template import RequestContext , loader <NEWLINE> from website . models import * <NEWLINE> from event_counter . admin import * <NEWLINE> from website . forms import * <NEWLINE> import logging <NEWLINE> logger = logging . getLogger ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'django.request'"]}}], ["9cabb97258105ddb7dd1399ddcfebcbc", {"code_string": "def init(context):\n    context.s1 = 'AG1612'\n    context.s2 = 'AU1612'\n    context.counter = 0\n    context.window = 60\n    context.ratio = 15\n    context.up_cross_up_limit = False\n    context.down_cross_down_limit = False\n    context.entry_score = 2\n    subscribe([context.s1, context.s2])\n", "code_toks_joined": "def init ( context ) : <NEWLINE> <INDENT> context . s1 = <STRING> <NEWLINE> context . s2 = <STRING> <NEWLINE> context . counter = 0 <NEWLINE> context . window = 60 <NEWLINE> context . ratio = 15 <NEWLINE> context . up_cross_up_limit = False <NEWLINE> context . down_cross_down_limit = False <NEWLINE> context . entry_score = 2 <NEWLINE> subscribe ( [ context . s1 , context . s2 ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'AG1612'", "'AU1612'"]}}], ["d4bc688d73bbb3db388bf9954c0a0eae", {"code_string": "def test_build_query_in_with_set(self):\n    self.sq.add_filter(SQ(content = 'why'))\n    self.sq.add_filter(SQ(title__in = set([\"A Famous Paper\", \"An Infamous Article\"])))\n    self.assertEqual(self.sq.build_query(), u'((why) AND title:(\"A Famous Paper\" OR \"An Infamous Article\"))')\n", "code_toks_joined": "def test_build_query_in_with_set ( self ) : <NEWLINE> <INDENT> self . sq . add_filter ( SQ ( content = <STRING> ) ) <NEWLINE> self . sq . add_filter ( SQ ( title__in = set ( [ <STRING> , <STRING> ] ) ) ) <NEWLINE> self . assertEqual ( self . sq . build_query ( ) , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'why'", "\"A Famous Paper\"", "\"An Infamous Article\"", "u'((why) AND title:(\"A Famous Paper\" OR \"An Infamous Article\"))'"]}}], ["14c6b9daab3d04f254b847138010cb89", {"code_string": "def __init__(self, id, name, descr):\n    JQuest.__init__(self, id, name, descr)\n    self.questItemIds = [ROUGH_JEWEL]\n", "code_toks_joined": "def __init__ ( self , id , name , descr ) : <NEWLINE> <INDENT> JQuest . __init__ ( self , id , name , descr ) <NEWLINE> self . questItemIds = [ ROUGH_JEWEL ] <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["f40640f8e60b175160616ca9f7476693", {"code_string": "def plotVideoAvg(feat):\n    feat = feat.sum(axis = 0) / feat.shape[0]\n    fig = plt.figure()\n    plt.bar(list(range(feat.shape[0])), feat)\n    plt.show()\n", "code_toks_joined": "def plotVideoAvg ( feat ) : <NEWLINE> <INDENT> feat = feat . sum ( axis = 0 ) / feat . shape [ 0 ] <NEWLINE> fig = plt . figure ( ) <NEWLINE> plt . bar ( list ( range ( feat . shape [ 0 ] ) ) , feat ) <NEWLINE> plt . show ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["593b32d45e48beee19c79c0cc61b3ebe", {"code_string": "def test_invalid_key(self):\n    try:\n        session = self.backend('1')\n        try:\n            session.save()\n        except AttributeError:\n            self.fail(\"The session object did not save properly.  Middleware may be saving cache items without namespaces.\")\n        self.assertNotEqual(session.session_key, '1')\n        self.assertEqual(session.get('cat'), None)\n        session.delete()\n    finally:\n        session.delete('1')\n", "code_toks_joined": "def test_invalid_key ( self ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> session = self . backend ( <STRING> ) <NEWLINE> try : <NEWLINE> <INDENT> session . save ( ) <NEWLINE> <DEDENT> except AttributeError : <NEWLINE> <INDENT> self . fail ( <STRING> ) <NEWLINE> <DEDENT> self . assertNotEqual ( session . session_key , <STRING> ) <NEWLINE> self . assertEqual ( session . get ( <STRING> ) , None ) <NEWLINE> session . delete ( ) <NEWLINE> <DEDENT> finally : <NEWLINE> <INDENT> session . delete ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'1'", "\"The session object did not save properly.  Middleware may be saving cache items without namespaces.\"", "'1'", "'cat'", "'1'"]}}], ["ac04acab884393240c97577a2174006f", {"code_string": "def backwards(self, orm):\n    db.delete_unique(u'core_device', ['site_id', 'name', 'building', 'floor', 'room'])\n    db.delete_table(u'core_site')\n    db.delete_table(u'core_person')\n    db.delete_table(u'core_device')\n    db.delete_table(u'core_unit')\n    db.delete_table(u'core_metric')\n    db.delete_table(u'core_sensor')\n    db.delete_table(u'core_scalardata')\n    db.delete_table(u'core_presencedata')\n    db.delete_table(u'core_statusupdate')\n", "code_toks_joined": "def backwards ( self , orm ) : <NEWLINE> <INDENT> db . delete_unique ( <STRING> , [ <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ] ) <NEWLINE> db . delete_table ( <STRING> ) <NEWLINE> db . delete_table ( <STRING> ) <NEWLINE> db . delete_table ( <STRING> ) <NEWLINE> db . delete_table ( <STRING> ) <NEWLINE> db . delete_table ( <STRING> ) <NEWLINE> db . delete_table ( <STRING> ) <NEWLINE> db . delete_table ( <STRING> ) <NEWLINE> db . delete_table ( <STRING> ) <NEWLINE> db . delete_table ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["u'core_device'", "'site_id'", "'name'", "'building'", "'floor'", "'room'", "u'core_site'", "u'core_person'", "u'core_device'", "u'core_unit'", "u'core_metric'", "u'core_sensor'", "u'core_scalardata'", "u'core_presencedata'", "u'core_statusupdate'"]}}], ["138775c9752b01f32765f89946bd3dd1", {"code_string": "def add_arguments(self, parser):\n    parser.add_argument('email', metavar = '<email>', type = str,\n        help = \"email of user to export\")\n    parser.add_argument('--output',\n        dest = 'output_dir',\n        action = \"store\",\n        default = None,\n        help = 'Directory to write exported data to.')\n    self.add_realm_args(parser)\n", "code_toks_joined": "def add_arguments ( self , parser ) : <NEWLINE> <INDENT> parser . add_argument ( <STRING> , metavar = <STRING> , type = str , <NEWLINE> <INDENT> help = <STRING> ) <NEWLINE> <DEDENT> parser . add_argument ( <STRING> , <NEWLINE> <INDENT> dest = <STRING> , <NEWLINE> action = <STRING> , <NEWLINE> default = None , <NEWLINE> help = <STRING> ) <NEWLINE> <DEDENT> self . add_realm_args ( parser ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'email'", "'<email>'", "\"email of user to export\"", "'--output'", "'output_dir'", "\"store\"", "'Directory to write exported data to.'"]}}], ["06d3e1b2630bdee10c29d5418dfc0ccd", {"code_string": "'''Braubuddy Thermostat.'''\nfrom braubuddy.thermostat.base import IThermostat\nfrom braubuddy.thermostat.simpleranged import SimpleRangedThermostat\n", "code_toks_joined": "<STRING> <NEWLINE> from braubuddy . thermostat . base import IThermostat <NEWLINE> from braubuddy . thermostat . simpleranged import SimpleRangedThermostat <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Braubuddy Thermostat.'''"]}}], ["70ea623ff39387d2fdc776e08fbb912f", {"code_string": "from nose.tools import *\nfrom mock import patch\nimport mock\nfrom.import nose_helper\nfrom kiwi.exceptions import *\nfrom kiwi.storage.loop_device import LoopDevice\n", "code_toks_joined": "from nose . tools import * <NEWLINE> from mock import patch <NEWLINE> import mock <NEWLINE> from . import nose_helper <NEWLINE> from kiwi . exceptions import * <NEWLINE> from kiwi . storage . loop_device import LoopDevice <NEWLINE>", "anonymize_dict": {}}], ["93d589695cc579d1af309fcda83ada86", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('ballot_box', '0001_initial'),\n    ]\n    operations = [\n        migrations.AddField(\n            model_name = 'candidate',\n            name = 'candidate_image',\n            field = models.BooleanField(default = False, verbose_name = 'Do We Have a Candidate Image?'),\n        ),\n        migrations.AddField(\n            model_name = 'candidate',\n            name = 'candidate_image_url',\n            field = models.URLField(blank = True, max_length = 1024, null = True, verbose_name = 'URL To Image'),\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . AddField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . BooleanField ( default = False , verbose_name = <STRING> ) , <NEWLINE> <DEDENT> ) , <NEWLINE> migrations . AddField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . URLField ( blank = True , max_length = 1024 , null = True , verbose_name = <STRING> ) , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'ballot_box'", "'0001_initial'", "'candidate'", "'candidate_image'", "'Do We Have a Candidate Image?'", "'candidate'", "'candidate_image_url'", "'URL To Image'"]}}], ["688690213e8c40c959111dcee01feb5b", {"code_string": "from __future__ import print_function, division\nimport os, re\nimport logging\nimport subprocess as sp\nfrom astropy.coordinates import SkyCoord\n", "code_toks_joined": "from __future__ import print_function , division <NEWLINE> import os , re <NEWLINE> import logging <NEWLINE> import subprocess as sp <NEWLINE> from astropy . coordinates import SkyCoord <NEWLINE>", "anonymize_dict": {}}], ["57f5a3598f824b331e286b51b8cfc1c0", {"code_string": "def got_key(client):\n    infile = open('README.md', 'r')\n    data = infile.read()\n    infile.close()\n    stream = andrena.FileTransfer(None, client)\n    stream.meta = \"newreadme\"\n    stream.buffer = data\n    client.send(stream)\n", "code_toks_joined": "def got_key ( client ) : <NEWLINE> <INDENT> infile = open ( <STRING> , <STRING> ) <NEWLINE> data = infile . read ( ) <NEWLINE> infile . close ( ) <NEWLINE> stream = andrena . FileTransfer ( None , client ) <NEWLINE> stream . meta = <STRING> <NEWLINE> stream . buffer = data <NEWLINE> client . send ( stream ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'README.md'", "'r'", "\"newreadme\""]}}], ["c9a7470d327f2226c31a9154eea8c3fc", {"code_string": "def search_equality(text):\n    \"\"\" Return the letter if that matches the pattern, else return None\"\"\"\n    pattern = \"[a-z][A-Z][A-Z][A-Z][a-z][A-Z][A-Z][A-Z][a-z]\"\n    equality = re.search(pattern, text)\n    if equality:\n        return equality.group()[4]\n    else:\n        return None\n", "code_toks_joined": "def search_equality ( text ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> pattern = <STRING> <NEWLINE> equality = re . search ( pattern , text ) <NEWLINE> if equality : <NEWLINE> <INDENT> return equality . group ( ) [ 4 ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Return the letter if that matches the pattern, else return None\"\"\"", "\"[a-z][A-Z][A-Z][A-Z][a-z][A-Z][A-Z][A-Z][a-z]\""]}}], ["e5abf8a025d5dd23626d709d14125213", {"code_string": "class UnaryOperator(object):\n    NAME = ''\n    def __init__(self, argument):\n        self.argument = argument\n    def __repr__(self):\n        return \"(%s %s)\" %(\n            self.NAME,\n            isinstance(self.argument, ListRedirect) and self.argument.reduce() or self.argument)\n", "code_toks_joined": "class UnaryOperator ( object ) : <NEWLINE> <INDENT> NAME = <STRING> <NEWLINE> def __init__ ( self , argument ) : <NEWLINE> <INDENT> self . argument = argument <NEWLINE> <DEDENT> def __repr__ ( self ) : <NEWLINE> <INDENT> return <STRING> % ( <NEWLINE> <INDENT> self . NAME , <NEWLINE> isinstance ( self . argument , ListRedirect ) and self . argument . reduce ( ) or self . argument ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["''", "\"(%s %s)\""]}}], ["034a57b9b751fdfba01f7eafb40bb190", {"code_string": "def AppendDictionary(d1, d2):\n    for tag, value in d2.iteritems():\n        if tag in d1:\n            d1[tag] = d1[tag] + ' ' + value\n        else:\n            d1[tag] = value\n", "code_toks_joined": "def AppendDictionary ( d1 , d2 ) : <NEWLINE> <INDENT> for tag , value in d2 . iteritems ( ) : <NEWLINE> <INDENT> if tag in d1 : <NEWLINE> <INDENT> d1 [ tag ] = d1 [ tag ] + <STRING> + value <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> d1 [ tag ] = value <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["' '"]}}], ["480e9ce3d0d075cc45e7bcc4c9f33404", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('product', '0016_auto_20170324_1716'),\n    ]\n    operations = [\n        migrations.AlterField(\n            model_name = 'product',\n            name = 'product_price',\n            field = models.DecimalField(decimal_places = 2, default = 0, max_digits = 5),\n        ),\n        migrations.AlterField(\n            model_name = 'product',\n            name = 'product_qtd',\n            field = models.IntegerField(default = 0),\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . AlterField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . DecimalField ( decimal_places = 2 , default = 0 , max_digits = 5 ) , <NEWLINE> <DEDENT> ) , <NEWLINE> migrations . AlterField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . IntegerField ( default = 0 ) , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'product'", "'0016_auto_20170324_1716'", "'product'", "'product_price'", "'product'", "'product_qtd'"]}}], ["6048b4cf90d53c47498399f2fb9d16c8", {"code_string": "\"\"\"A Django command that dumps the structure of a course as a JSON object.\"\"\"\nimport json\nfrom optparse import make_option\nfrom textwrap import dedent\nfrom django.core.management.base import BaseCommand, CommandError\nfrom xmodule.modulestore.django import modulestore\nfrom xmodule.modulestore.inheritance import own_metadata, compute_inherited_metadata\nfrom xblock_discussion import DiscussionXBlock\nfrom xblock.fields import Scope\nfrom opaque_keys import InvalidKeyError\nfrom opaque_keys.edx.keys import CourseKey\nFILTER_LIST = ['xml_attributes']\nINHERITED_FILTER_LIST = ['children', 'xml_attributes']\n", "code_toks_joined": "<STRING> <NEWLINE> import json <NEWLINE> from optparse import make_option <NEWLINE> from textwrap import dedent <NEWLINE> from django . core . management . base import BaseCommand , CommandError <NEWLINE> from xmodule . modulestore . django import modulestore <NEWLINE> from xmodule . modulestore . inheritance import own_metadata , compute_inherited_metadata <NEWLINE> from xblock_discussion import DiscussionXBlock <NEWLINE> from xblock . fields import Scope <NEWLINE> from opaque_keys import InvalidKeyError <NEWLINE> from opaque_keys . edx . keys import CourseKey <NEWLINE> FILTER_LIST = [ <STRING> ] <NEWLINE> INHERITED_FILTER_LIST = [ <STRING> , <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"A Django command that dumps the structure of a course as a JSON object.\"\"\"", "'xml_attributes'", "'children'", "'xml_attributes'"]}}], ["0c1f2b663e6644f16eb38fbf1fa62552", {"code_string": "def _table_stub(self):\n    \"\"\"Getter for the gRPC stub used for the Table Admin API.\"\"\"\n    if not self._admin:\n        raise ValueError('Client is not an admin client.')\n    return self._table_stub_internal\n", "code_toks_joined": "def _table_stub ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if not self . _admin : <NEWLINE> <INDENT> raise ValueError ( <STRING> ) <NEWLINE> <DEDENT> return self . _table_stub_internal <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Getter for the gRPC stub used for the Table Admin API.\"\"\"", "'Client is not an admin client.'"]}}], ["92d6fc5e381a342ffc08a374052830b0", {"code_string": "import os\nimport urllib\nimport json\nimport sys\nimport ast\nimport argparse\nimport utils\n", "code_toks_joined": "import os <NEWLINE> import urllib <NEWLINE> import json <NEWLINE> import sys <NEWLINE> import ast <NEWLINE> import argparse <NEWLINE> import utils <NEWLINE>", "anonymize_dict": {}}], ["1e9c4fc225d90b903691b43b29e0a35c", {"code_string": "from django.template import Library, Node, Variable, loader\nfrom django.template.context import Context\nregister = Library()\n", "code_toks_joined": "from django . template import Library , Node , Variable , loader <NEWLINE> from django . template . context import Context <NEWLINE> register = Library ( ) <NEWLINE>", "anonymize_dict": {}}], ["f236aa127726550e514a8dbb0c3f13a6", {"code_string": "class ScalarFunction(Function):\n    def _get_class_name(self, name):\n        if name is None:\n            name = util.guid()\n        return 'UDF_{0}'.format(name)\n    def _type_signature(self, inputs, output):\n        input_type = _to_input_sig(inputs)\n        output = validate_type(output)\n        output_type = rules.shape_like_flatargs(output)\n        return input_type, output_type\n", "code_toks_joined": "class ScalarFunction ( Function ) : <NEWLINE> <INDENT> def _get_class_name ( self , name ) : <NEWLINE> <INDENT> if name is None : <NEWLINE> <INDENT> name = util . guid ( ) <NEWLINE> <DEDENT> return <STRING> . format ( name ) <NEWLINE> <DEDENT> def _type_signature ( self , inputs , output ) : <NEWLINE> <INDENT> input_type = _to_input_sig ( inputs ) <NEWLINE> output = validate_type ( output ) <NEWLINE> output_type = rules . shape_like_flatargs ( output ) <NEWLINE> return input_type , output_type <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'UDF_{0}'"]}}], ["be0c15d45816f084ff5b7bc121aaead6", {"code_string": "def format_account(service_name, data):\n    \"\"\"Given profile data and the name of a\"\"\"\n    if \"username\" not in data:\n        raise KeyError(\"Account is missing a username\")\n    account = {\n        \"@type\": \"Account\",\n        \"service\": service_name,\n        \"identifier\": data[\"username\"],\n        \"proofType\": \"http\"\n    }\n    if(data.has_key(service_name)\n        and data[service_name].has_key(\"proof\")\n        and data[service_name][\"proof\"].has_key(\"url\")):\n        account[\"proofUrl\"] = data[service_name][\"proof\"][\"url\"]\n    return account\n", "code_toks_joined": "def format_account ( service_name , data ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if <STRING> not in data : <NEWLINE> <INDENT> raise KeyError ( <STRING> ) <NEWLINE> <DEDENT> account = { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : service_name , <NEWLINE> <STRING> : data [ <STRING> ] , <NEWLINE> <STRING> : <STRING> <NEWLINE> <DEDENT> } <NEWLINE> if ( data . has_key ( service_name ) <NEWLINE> <INDENT> and data [ service_name ] . has_key ( <STRING> ) <NEWLINE> and data [ service_name ] [ <STRING> ] . has_key ( <STRING> ) ) : <NEWLINE> account [ <STRING> ] = data [ service_name ] [ <STRING> ] [ <STRING> ] <NEWLINE> <DEDENT> return account <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Given profile data and the name of a\"\"\"", "\"username\"", "\"Account is missing a username\"", "\"@type\"", "\"Account\"", "\"service\"", "\"identifier\"", "\"username\"", "\"proofType\"", "\"http\"", "\"proof\"", "\"proof\"", "\"url\"", "\"proofUrl\"", "\"proof\"", "\"url\""]}}], ["fc7b50fb4ca444f350fd4628b63b1f1b", {"code_string": "from.signals import model_activations_changed, model_activations_updated\nfrom.version import __version__\ndefault_app_config = 'activatable_model.apps.ActivatableModelConfig'\n", "code_toks_joined": "from . signals import model_activations_changed , model_activations_updated <NEWLINE> from . version import __version__ <NEWLINE> default_app_config = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'activatable_model.apps.ActivatableModelConfig'"]}}], ["316c1d464b2e815b7c362d3635435121", {"code_string": "\"\"\"Render ASCII boxes and arrows as images.\"\"\"\nfrom __future__ import absolute_import\nfrom._error import Error\nfrom._error import OutputFormatError\nfrom._renderer import OUTPUT_FORMATS\nfrom._renderer import render\nfrom._rst import register_rst_directive\nVERSION = \"0.4.0\"\n__all__ = [\n    \"Error\",\n    \"OutputFormatError\",\n    \"OUTPUT_FORMATS\",\n    \"render\",\n    \"register_rst_directive\",\n]\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import absolute_import <NEWLINE> from . _error import Error <NEWLINE> from . _error import OutputFormatError <NEWLINE> from . _renderer import OUTPUT_FORMATS <NEWLINE> from . _renderer import render <NEWLINE> from . _rst import register_rst_directive <NEWLINE> VERSION = <STRING> <NEWLINE> __all__ = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Render ASCII boxes and arrows as images.\"\"\"", "\"0.4.0\"", "\"Error\"", "\"OutputFormatError\"", "\"OUTPUT_FORMATS\"", "\"render\"", "\"register_rst_directive\""]}}], ["b60caf49cdbe61297b07c51e831b22c0", {"code_string": "import json\nimport csv\nPATH = \"airports.dat\"\nOUT = \"airports.json\"\n", "code_toks_joined": "import json <NEWLINE> import csv <NEWLINE> PATH = <STRING> <NEWLINE> OUT = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"airports.dat\"", "\"airports.json\""]}}], ["1c24661401eeff4b15c8a7a1dfa7ef15", {"code_string": "def convert(reset, clean):\n    conv = EumssiConverter('DW-news-may-release', dw_a_map)\n    if reset:\n        conv.reset()\n    if clean:\n        conv.clean()\n    conv.run()\n", "code_toks_joined": "def convert ( reset , clean ) : <NEWLINE> <INDENT> conv = EumssiConverter ( <STRING> , dw_a_map ) <NEWLINE> if reset : <NEWLINE> <INDENT> conv . reset ( ) <NEWLINE> <DEDENT> if clean : <NEWLINE> <INDENT> conv . clean ( ) <NEWLINE> <DEDENT> conv . run ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'DW-news-may-release'"]}}], ["998398f886b612b161882930984064bf", {"code_string": "class _SingleArgumentFunctionWithCudnn(_SingleArgumentFunction):\n    def __init__(self, use_cudnn, func, * args, ** kwargs):\n        super(_SingleArgumentFunctionWithCudnn, self).__init__(\n            func, * args, ** kwargs)\n        self.use_cudnn = use_cudnn\n    def __call__(self, x):\n        with configuration.using_config('use_cudnn', self.use_cudnn):\n            return super(_SingleArgumentFunctionWithCudnn, self).__call__(x)\n", "code_toks_joined": "class _SingleArgumentFunctionWithCudnn ( _SingleArgumentFunction ) : <NEWLINE> <INDENT> def __init__ ( self , use_cudnn , func , * args , ** kwargs ) : <NEWLINE> <INDENT> super ( _SingleArgumentFunctionWithCudnn , self ) . __init__ ( <NEWLINE> <INDENT> func , * args , ** kwargs ) <NEWLINE> <DEDENT> self . use_cudnn = use_cudnn <NEWLINE> <DEDENT> def __call__ ( self , x ) : <NEWLINE> <INDENT> with configuration . using_config ( <STRING> , self . use_cudnn ) : <NEWLINE> <INDENT> return super ( _SingleArgumentFunctionWithCudnn , self ) . __call__ ( x ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'use_cudnn'"]}}], ["557641eb7d62208ccf217645d80d92c6", {"code_string": "class Waypoint:\n    def __init__(self, agent, x, y, z, arrival, duration):\n        self.agent = agent\n        self.x = x\n        self.y = y\n        self.z = z\n        self.arrival = arrival\n        self.duration = duration\n    def __lt__(self, other):\n        return self.arrival < other.arrival\n    def __repr__(self):\n        return \"Ag {} at {} s. [{}, {}, {}]\".format(self.agent, self.arrival, self.x, self.y, self.z)\n", "code_toks_joined": "class Waypoint : <NEWLINE> <INDENT> def __init__ ( self , agent , x , y , z , arrival , duration ) : <NEWLINE> <INDENT> self . agent = agent <NEWLINE> self . x = x <NEWLINE> self . y = y <NEWLINE> self . z = z <NEWLINE> self . arrival = arrival <NEWLINE> self . duration = duration <NEWLINE> <DEDENT> def __lt__ ( self , other ) : <NEWLINE> <INDENT> return self . arrival < other . arrival <NEWLINE> <DEDENT> def __repr__ ( self ) : <NEWLINE> <INDENT> return <STRING> . format ( self . agent , self . arrival , self . x , self . y , self . z ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Ag {} at {} s. [{}, {}, {}]\""]}}], ["e066b95b382df9486f21eb25add25e73", {"code_string": "\"\"\"This test checks for correct wait3() behavior.\"\"\"\nimport os\nimport time\nimport unittest\nfrom test.fork_wait import ForkWait\nfrom test.support import run_unittest, reap_children\nif not hasattr(os, 'fork'):\n    raise unittest.SkipTest(\"os.fork not defined\")\nif not hasattr(os, 'wait3'):\n    raise unittest.SkipTest(\"os.wait3 not defined\")\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> import time <NEWLINE> import unittest <NEWLINE> from test . fork_wait import ForkWait <NEWLINE> from test . support import run_unittest , reap_children <NEWLINE> if not hasattr ( os , <STRING> ) : <NEWLINE> <INDENT> raise unittest . SkipTest ( <STRING> ) <NEWLINE> <DEDENT> if not hasattr ( os , <STRING> ) : <NEWLINE> <INDENT> raise unittest . SkipTest ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"This test checks for correct wait3() behavior.\"\"\"", "'fork'", "\"os.fork not defined\"", "'wait3'", "\"os.wait3 not defined\""]}}], ["4ec218bb2403773f040145c51601c758", {"code_string": "\"\"\"\"\"\"\n__version__ = \"$Id$\"\nimport anydbm\nimport whichdb\ndb = anydbm.open('/tmp/example.db', 'n')\ndb['key'] = 'value'\ndb.close()\nprint(whichdb.whichdb('/tmp/example.db'))\n", "code_toks_joined": "<STRING> <NEWLINE> __version__ = <STRING> <NEWLINE> import anydbm <NEWLINE> import whichdb <NEWLINE> db = anydbm . open ( <STRING> , <STRING> ) <NEWLINE> db [ <STRING> ] = <STRING> <NEWLINE> db . close ( ) <NEWLINE> print ( whichdb . whichdb ( <STRING> ) ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"\"\"\"", "\"$Id$\"", "'/tmp/example.db'", "'n'", "'key'", "'value'", "'/tmp/example.db'"]}}], ["c6413f2630591b7a65c0e5908b49951f", {"code_string": "\"\"\"Serializer for user API\"\"\"\nfrom rest_framework import serializers\nfrom rest_framework.reverse import reverse\nfrom student.models import CourseEnrollment, User\nfrom certificates.models import certificate_status_for_student, CertificateStatuses\n", "code_toks_joined": "<STRING> <NEWLINE> from rest_framework import serializers <NEWLINE> from rest_framework . reverse import reverse <NEWLINE> from student . models import CourseEnrollment , User <NEWLINE> from certificates . models import certificate_status_for_student , CertificateStatuses <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Serializer for user API\"\"\""]}}], ["c7b6ee813dc59d68a146494ed637886c", {"code_string": "def test_is_not_instance(self, instance):\n    \"\"\"Tests whether it is correctly detected that these are not real numbers.\"\"\"\n    self.assertFalse(real.real_number.is_instance(instance))\n", "code_toks_joined": "def test_is_not_instance ( self , instance ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . assertFalse ( real . real_number . is_instance ( instance ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Tests whether it is correctly detected that these are not real numbers.\"\"\""]}}], ["fa0edbb536889c174b5375b6a54f6d19", {"code_string": "'''Created on 11 jan. 2017'''\nimport smtplib\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\n", "code_toks_joined": "<STRING> <NEWLINE> import smtplib <NEWLINE> from email . mime . multipart import MIMEMultipart <NEWLINE> from email . mime . text import MIMEText <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Created on 11 jan. 2017'''"]}}], ["8b703489ad238c43ca7049c791dbdc1c", {"code_string": "\"\"\"views.py: Django simple_history\"\"\"\nfrom __future__ import unicode_literals\nimport logging\n__author__ = 'Tim Valenta'\n__date__ = '10/10/14 05:50 PM'\n__copyright__ = 'Copyright 2014 Pivotal Energy Solutions. All rights reserved.'\n__credits__ = ['Steven Klass', ]\nlog = logging.getLogger(__name__)\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import unicode_literals <NEWLINE> import logging <NEWLINE> __author__ = <STRING> <NEWLINE> __date__ = <STRING> <NEWLINE> __copyright__ = <STRING> <NEWLINE> __credits__ = [ <STRING> , ] <NEWLINE> log = logging . getLogger ( __name__ ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"views.py: Django simple_history\"\"\"", "'Tim Valenta'", "'10/10/14 05:50 PM'", "'Copyright 2014 Pivotal Energy Solutions. All rights reserved.'", "'Steven Klass'"]}}], ["03d69c5ee5e8b91ed4e8d1cfdbc75e0a", {"code_string": "import random\nfor x in range(1, 11):\n    throw_1 = random.randint(1, 6)\n    throw_2 = random.randint(1, 6)\n    total = throw_1 + throw_2\n    print(total)\n    if(total == 7):\n        print('Seven thrown!')\n    if(total == 11):\n        print('Eleven thrown!')\n    if throw_1 == throw_2:\n        print('Double thrown!')\n", "code_toks_joined": "import random <NEWLINE> for x in range ( 1 , 11 ) : <NEWLINE> <INDENT> throw_1 = random . randint ( 1 , 6 ) <NEWLINE> throw_2 = random . randint ( 1 , 6 ) <NEWLINE> total = throw_1 + throw_2 <NEWLINE> print ( total ) <NEWLINE> if ( total == 7 ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> if ( total == 11 ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> if throw_1 == throw_2 : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Seven thrown!'", "'Eleven thrown!'", "'Double thrown!'"]}}], ["5442578ef9a4f86b611295b95dceb9f9", {"code_string": "import unittest\nfrom puzz import *\nimport os\n", "code_toks_joined": "import unittest <NEWLINE> from puzz import * <NEWLINE> import os <NEWLINE>", "anonymize_dict": {}}], ["352bc2f6e9308855d12e4c78958a1e56", {"code_string": "def fake_marathon_response():\n    current_dir = os.path.join(os.path.dirname(__file__))\n    config_file = os.path.abspath(\n        os.path.join(current_dir, 'configs', 'test_marathon_response.json')\n    )\n    with open(config_file, 'r') as f:\n        return json.loads(f.read())\n", "code_toks_joined": "def fake_marathon_response ( ) : <NEWLINE> <INDENT> current_dir = os . path . join ( os . path . dirname ( __file__ ) ) <NEWLINE> config_file = os . path . abspath ( <NEWLINE> <INDENT> os . path . join ( current_dir , <STRING> , <STRING> ) <NEWLINE> <DEDENT> ) <NEWLINE> with open ( config_file , <STRING> ) as f : <NEWLINE> <INDENT> return json . loads ( f . read ( ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'configs'", "'test_marathon_response.json'", "'r'"]}}], ["3df48bd451df693f3fae29e953f82802", {"code_string": "class Randomizer(object):\n    @ staticmethod\n    def bool_on_percentage(percentage = 0):\n        return random.randint(0, 100) < percentage\n", "code_toks_joined": "class Randomizer ( object ) : <NEWLINE> <INDENT> @ staticmethod <NEWLINE> def bool_on_percentage ( percentage = 0 ) : <NEWLINE> <INDENT> return random . randint ( 0 , 100 ) < percentage <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["bd77398a0cf397d6e9b20fdd1aa091f9", {"code_string": "def compile_jsmin(instr, outfile):\n    with open(outfile, 'wb') as fw:\n        compiler = sp.Popen([JSMIN], stdin = sp.PIPE, stdout = sp.PIPE)\n        stout, sterr = compiler.communicate(instr)\n        fw.write(stout)\n        print(\"compressed to %s bytes.\" % fw.tell())\n        print(\"that's %d%% less\" %(100 - fw.tell() / len(instr) * 100))\n", "code_toks_joined": "def compile_jsmin ( instr , outfile ) : <NEWLINE> <INDENT> with open ( outfile , <STRING> ) as fw : <NEWLINE> <INDENT> compiler = sp . Popen ( [ JSMIN ] , stdin = sp . PIPE , stdout = sp . PIPE ) <NEWLINE> stout , sterr = compiler . communicate ( instr ) <NEWLINE> fw . write ( stout ) <NEWLINE> print ( <STRING> % fw . tell ( ) ) <NEWLINE> print ( <STRING> % ( 100 - fw . tell ( ) / len ( instr ) * 100 ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'wb'", "\"compressed to %s bytes.\"", "\"that's %d%% less\""]}}], ["e6270ae77d570e50c702cb437c28bba9", {"code_string": "class DBNode(db.Model):\n    id = db.Column(db.Integer, primary_key = True, autoincrement = True)\n    hostname = db.Column(db.String(128))\n    ip = db.Column(db.String(128))\n    port = db.Column(db.Integer, default = 0)\n    def __init__(self, hostname, ip, port):\n        self.hostname = hostname\n        self.ip = ip\n        self.port = port\n", "code_toks_joined": "class DBNode ( db . Model ) : <NEWLINE> <INDENT> id = db . Column ( db . Integer , primary_key = True , autoincrement = True ) <NEWLINE> hostname = db . Column ( db . String ( 128 ) ) <NEWLINE> ip = db . Column ( db . String ( 128 ) ) <NEWLINE> port = db . Column ( db . Integer , default = 0 ) <NEWLINE> def __init__ ( self , hostname , ip , port ) : <NEWLINE> <INDENT> self . hostname = hostname <NEWLINE> self . ip = ip <NEWLINE> self . port = port <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["48872888fb3105ca8626a3a0f8d6cf27", {"code_string": "def retranslateUi(self, MainWindow):\n    MainWindow.setWindowTitle(_translate(\"MainWindow\", \"Mendeley Reopen\", None))\n    self.defaultViewText.setText(_translate(\"MainWindow\", \"No Sessions found\", None))\n    self.menuMen.setTitle(_translate(\"MainWindow\", \"&File\", None))\n    self.actionClose.setText(_translate(\"MainWindow\", \"&Close\", None))\n    self.actionClose.setShortcut(_translate(\"MainWindow\", \"Ctrl+Q\", None))\n", "code_toks_joined": "def retranslateUi ( self , MainWindow ) : <NEWLINE> <INDENT> MainWindow . setWindowTitle ( _translate ( <STRING> , <STRING> , None ) ) <NEWLINE> self . defaultViewText . setText ( _translate ( <STRING> , <STRING> , None ) ) <NEWLINE> self . menuMen . setTitle ( _translate ( <STRING> , <STRING> , None ) ) <NEWLINE> self . actionClose . setText ( _translate ( <STRING> , <STRING> , None ) ) <NEWLINE> self . actionClose . setShortcut ( _translate ( <STRING> , <STRING> , None ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"MainWindow\"", "\"Mendeley Reopen\"", "\"MainWindow\"", "\"No Sessions found\"", "\"MainWindow\"", "\"&File\"", "\"MainWindow\"", "\"&Close\"", "\"MainWindow\"", "\"Ctrl+Q\""]}}], ["d7bf2cc52de0eb4d922b91ffa450a6b5", {"code_string": "class agilentMSOX3012A(agilent3000A):\n    \"Agilent InfiniiVision MSOX3012A IVI oscilloscope driver\"\n    def __init__(self, * args, ** kwargs):\n        self.__dict__.setdefault('_instrument_id', 'MSO-X 3012A')\n        super(agilentMSOX3012A, self).__init__(* args, ** kwargs)\n        self._analog_channel_count = 2\n        self._digital_channel_count = 16\n        self._channel_count = self._analog_channel_count + self._digital_channel_count\n        self._bandwidth = 100e6\n        self._init_channels()\n", "code_toks_joined": "class agilentMSOX3012A ( agilent3000A ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , * args , ** kwargs ) : <NEWLINE> <INDENT> self . __dict__ . setdefault ( <STRING> , <STRING> ) <NEWLINE> super ( agilentMSOX3012A , self ) . __init__ ( * args , ** kwargs ) <NEWLINE> self . _analog_channel_count = 2 <NEWLINE> self . _digital_channel_count = 16 <NEWLINE> self . _channel_count = self . _analog_channel_count + self . _digital_channel_count <NEWLINE> self . _bandwidth = 100e6 <NEWLINE> self . _init_channels ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Agilent InfiniiVision MSOX3012A IVI oscilloscope driver\"", "'_instrument_id'", "'MSO-X 3012A'"]}}], ["c4c4ff17097bd554c04ccb9bb6be14fb", {"code_string": "class FilterAction(Enum):\n    discard = 0\n    bounce = 1\n    forward = 2\n    preserve = 3\n", "code_toks_joined": "class FilterAction ( Enum ) : <NEWLINE> <INDENT> discard = 0 <NEWLINE> bounce = 1 <NEWLINE> forward = 2 <NEWLINE> preserve = 3 <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["51e962d009be69b96db90c4e6d4530ad", {"code_string": "def start_guesstotal(self, db_session):\n    \"\"\"Enables guessing for the total number of deaths for the run.\"\"\"\n    mv_obj = db_session.query(models.MiscValue).filter(models.MiscValue.mv_key == 'guess-total-enabled').one()\n    mv_obj.mv_value = \"True\"\n    utils.add_to_public_chat_queue(self, \"Guessing for the total amount of deaths is now enabled.\")\n", "code_toks_joined": "def start_guesstotal ( self , db_session ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> mv_obj = db_session . query ( models . MiscValue ) . filter ( models . MiscValue . mv_key == <STRING> ) . one ( ) <NEWLINE> mv_obj . mv_value = <STRING> <NEWLINE> utils . add_to_public_chat_queue ( self , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Enables guessing for the total number of deaths for the run.\"\"\"", "'guess-total-enabled'", "\"True\"", "\"Guessing for the total amount of deaths is now enabled.\""]}}], ["92f198f2ff203f8fc474894f3fa0dc95", {"code_string": "def uniform_displace(stepsize, coords, indices = None):\n    '''uniform random displacement'''\n    if(indices):\n        for i in indices:\n            coords[i] += stepsize * rotations.vector_random_uniform_hypersphere(3)\n        return\n    for x in coords:\n        x += stepsize * rotations.vector_random_uniform_hypersphere(3)\n", "code_toks_joined": "def uniform_displace ( stepsize , coords , indices = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if ( indices ) : <NEWLINE> <INDENT> for i in indices : <NEWLINE> <INDENT> coords [ i ] += stepsize * rotations . vector_random_uniform_hypersphere ( 3 ) <NEWLINE> <DEDENT> return <NEWLINE> <DEDENT> for x in coords : <NEWLINE> <INDENT> x += stepsize * rotations . vector_random_uniform_hypersphere ( 3 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''uniform random displacement'''"]}}], ["41365536e18d9622e88634cdaf99fbc6", {"code_string": "def _combine_attributes(* attributes):\n    \"\"\"Returns multiple attributes concatenated and separated by DELIMITER.\"\"\"\n    return reduce(lambda a, b: str(a) + code.DELIMITER + str(b), attributes)\n", "code_toks_joined": "def _combine_attributes ( * attributes ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return reduce ( lambda a , b : str ( a ) + code . DELIMITER + str ( b ) , attributes ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Returns multiple attributes concatenated and separated by DELIMITER.\"\"\""]}}], ["1e5d8807528915ff9f2102ef1ee6c55c", {"code_string": "def test_load_model_workaround():\n    if os.getenv('CIRCLECI', None) is not None:\n        model_filename = '/home/ubuntu/pelops/testci/small.json'\n        weight_filename = '/home/ubuntu/pelops/testci/small.hdf5'\n    if os.getenv('INDOCKERCONTAINER', None) is not None:\n        model_filename = '/pelops_root/testci/small.json'\n        weight_filename = '/pelops_root/testci/small.hdf5'\n    model = KerasModelFeatureProducer.load_model_workaround(\n        model_filename, weight_filename)\n    assert model.layers[0].name == 'dense_8'\n", "code_toks_joined": "def test_load_model_workaround ( ) : <NEWLINE> <INDENT> if os . getenv ( <STRING> , None ) is not None : <NEWLINE> <INDENT> model_filename = <STRING> <NEWLINE> weight_filename = <STRING> <NEWLINE> <DEDENT> if os . getenv ( <STRING> , None ) is not None : <NEWLINE> <INDENT> model_filename = <STRING> <NEWLINE> weight_filename = <STRING> <NEWLINE> <DEDENT> model = KerasModelFeatureProducer . load_model_workaround ( <NEWLINE> <INDENT> model_filename , weight_filename ) <NEWLINE> <DEDENT> assert model . layers [ 0 ] . name == <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'CIRCLECI'", "'/home/ubuntu/pelops/testci/small.json'", "'/home/ubuntu/pelops/testci/small.hdf5'", "'INDOCKERCONTAINER'", "'/pelops_root/testci/small.json'", "'/pelops_root/testci/small.hdf5'", "'dense_8'"]}}], ["23b7da828c4740c8995e26b394da73f6", {"code_string": "def get_ip(self):\n    try: return self.info.get('MACHINE')\n    except: pass\n", "code_toks_joined": "def get_ip ( self ) : <NEWLINE> <INDENT> try : return self . info . get ( <STRING> ) <NEWLINE> except : pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'MACHINE'"]}}], ["575607b2cd003f4327c5b96fd39740c8", {"code_string": "class BlinkyRequestHandler(http.server.BaseHTTPRequestHandler):\n    def do_HEAD(self):\n        self.send_response(200)\n        self.send_header(\"Content-type\", \"text/plain\")\n        self.end_headers()\n    def do_GET(self):\n        global led_status\n        if led_status == gpio.LOW:\n            self.wfile.write(b\"Setting pin to HIGH\")\n            print('Setting pin to HIGH')\n            led_status = gpio.HIGH\n        else:\n            self.wfile.write(b\"Setting pin to LOW\")\n            print('Setting pin to LOW')\n            led_status = gpio.LOW\n        gpio.output(led_pin, led_status)\n", "code_toks_joined": "class BlinkyRequestHandler ( http . server . BaseHTTPRequestHandler ) : <NEWLINE> <INDENT> def do_HEAD ( self ) : <NEWLINE> <INDENT> self . send_response ( 200 ) <NEWLINE> self . send_header ( <STRING> , <STRING> ) <NEWLINE> self . end_headers ( ) <NEWLINE> <DEDENT> def do_GET ( self ) : <NEWLINE> <INDENT> global led_status <NEWLINE> if led_status == gpio . LOW : <NEWLINE> <INDENT> self . wfile . write ( <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> led_status = gpio . HIGH <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . wfile . write ( <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> led_status = gpio . LOW <NEWLINE> <DEDENT> gpio . output ( led_pin , led_status ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Content-type\"", "\"text/plain\"", "b\"Setting pin to HIGH\"", "'Setting pin to HIGH'", "b\"Setting pin to LOW\"", "'Setting pin to LOW'"]}}], ["146345e3032e9587e2b89b2ea861c149", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('taskEdition', '0004_auto_20150120_2122'),\n    ]\n    operations = [\n        migrations.AddField(\n            model_name = 'state',\n            name = 'position',\n            field = models.IntegerField(null = True, unique = True),\n            preserve_default = True,\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . AddField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . IntegerField ( null = True , unique = True ) , <NEWLINE> preserve_default = True , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'taskEdition'", "'0004_auto_20150120_2122'", "'state'", "'position'"]}}], ["89035371e771ff3a36ef74aa3585c766", {"code_string": "def baskara(a, b, c):\n    d = delta(a, b, c)\n    if d < 0:\n        print(\"Esta equa\u00e7\u00e3o n\u00e3o possui ra\u00edzes reais\")\n    elif d == 0:\n        raiz = - b /(2 * a)\n        print(\"A raiz desta equa\u00e7\u00e3o \u00e9 %5.2f\" % raiz)\n    else:\n        raiz1 = (- b + math.sqrt(delta)) /(2 * a)\n        raiz2 = (- b - math.sqrt(delta)) /(2 * a)\n        print(\"As ra\u00edzes da equa\u00e7\u00e3o s\u00e3o x1=%5.2f e x2=%6.2f\" %(raiz1, raiz2))\n", "code_toks_joined": "def baskara ( a , b , c ) : <NEWLINE> <INDENT> d = delta ( a , b , c ) <NEWLINE> if d < 0 : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> elif d == 0 : <NEWLINE> <INDENT> raiz = - b / ( 2 * a ) <NEWLINE> print ( <STRING> % raiz ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> raiz1 = ( - b + math . sqrt ( delta ) ) / ( 2 * a ) <NEWLINE> raiz2 = ( - b - math . sqrt ( delta ) ) / ( 2 * a ) <NEWLINE> print ( <STRING> % ( raiz1 , raiz2 ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Esta equa\u00e7\u00e3o n\u00e3o possui ra\u00edzes reais\"", "\"A raiz desta equa\u00e7\u00e3o \u00e9 %5.2f\"", "\"As ra\u00edzes da equa\u00e7\u00e3o s\u00e3o x1=%5.2f e x2=%6.2f\""]}}], ["f16b81d82e574900978eb9b721d66a5f", {"code_string": "import json\nimport urllib2\nimport re\nfrom bs4 import BeautifulSoup\nfrom order import Order\nfrom goods import Goods\nimport sys\nreload(sys)\nsys.setdefaultencoding('utf-8')\n", "code_toks_joined": "import json <NEWLINE> import urllib2 <NEWLINE> import re <NEWLINE> from bs4 import BeautifulSoup <NEWLINE> from order import Order <NEWLINE> from goods import Goods <NEWLINE> import sys <NEWLINE> reload ( sys ) <NEWLINE> sys . setdefaultencoding ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'utf-8'"]}}], ["38476473a3a796c2357d8f5953a22746", {"code_string": "import six\nfrom ... errors.saklientexception import SaklientException\nfrom..client import Client\nfrom.resource import Resource\nfrom ... util import Util\nimport saklient\nstr = six.text_type\n", "code_toks_joined": "import six <NEWLINE> from ... errors . saklientexception import SaklientException <NEWLINE> from . . client import Client <NEWLINE> from . resource import Resource <NEWLINE> from ... util import Util <NEWLINE> import saklient <NEWLINE> str = six . text_type <NEWLINE>", "anonymize_dict": {}}], ["9a821edd953d35746628baf5a5589ee3", {"code_string": "from kivy.app import App\nfrom kivy.uix.widget import Widget\nfrom kivy.graphics import Color, Ellipse, Rectangle, RoundedRectangle\nfrom kivy.lang import Builder\nTEXTURE = 'kiwi.jpg'\nYELLOW = (1, .7, 0)\nORANGE = (1, .45, 0)\nRED = (1, 0, 0)\nWHITE = (1, 1, 1)\n", "code_toks_joined": "from kivy . app import App <NEWLINE> from kivy . uix . widget import Widget <NEWLINE> from kivy . graphics import Color , Ellipse , Rectangle , RoundedRectangle <NEWLINE> from kivy . lang import Builder <NEWLINE> TEXTURE = <STRING> <NEWLINE> YELLOW = ( 1 , .7 , 0 ) <NEWLINE> ORANGE = ( 1 , .45 , 0 ) <NEWLINE> RED = ( 1 , 0 , 0 ) <NEWLINE> WHITE = ( 1 , 1 , 1 ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'kiwi.jpg'"]}}], ["b8b590519c2ddc297af37b34074fcdfc", {"code_string": "def RVKFooDxrqYXAX():\n    pspict, fig = SinglePicture(\"RVKFooDxrqYXAX\")\n    pspict.dilatation(1)\n    tableau = \"\"\".,2,.,.,.,5,8,.,3\"\"\"\n    solution = \"\"\"9,2,6,7,4,5,8,1,3\"\"\"\n    solution_substitution = \"\"\"4,-3,1    ,2,-1,0,    3,-4,-2\"\"\"\n    sudoku = SudokuGrid(tableau, length = 0.7)\n    pspict.DrawGraphs(sudoku)\n    pspict.comment = \"One sudoku grid with numbers from $-4$ to $4$.\"\n    fig.no_figure()\n    fig.conclude()\n    fig.write_the_file()\n", "code_toks_joined": "def RVKFooDxrqYXAX ( ) : <NEWLINE> <INDENT> pspict , fig = SinglePicture ( <STRING> ) <NEWLINE> pspict . dilatation ( 1 ) <NEWLINE> tableau = <STRING> <NEWLINE> solution = <STRING> <NEWLINE> solution_substitution = <STRING> <NEWLINE> sudoku = SudokuGrid ( tableau , length = 0.7 ) <NEWLINE> pspict . DrawGraphs ( sudoku ) <NEWLINE> pspict . comment = <STRING> <NEWLINE> fig . no_figure ( ) <NEWLINE> fig . conclude ( ) <NEWLINE> fig . write_the_file ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"RVKFooDxrqYXAX\"", "\"\"\".,2,.,.,.,5,8,.,3\"\"\"", "\"\"\"9,2,6,7,4,5,8,1,3\"\"\"", "\"\"\"4,-3,1    ,2,-1,0,    3,-4,-2\"\"\"", "\"One sudoku grid with numbers from $-4$ to $4$.\""]}}], ["5c9cb6a89a52141f8056cbb2acf850ed", {"code_string": "def mount(node_path):\n    u = get_udisks1()\n    u.mount(node_path)\n", "code_toks_joined": "def mount ( node_path ) : <NEWLINE> <INDENT> u = get_udisks1 ( ) <NEWLINE> u . mount ( node_path ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["77ec4a911531f7b5718551d3f2cd782e", {"code_string": "def test_parse_search(self):\n    ''' testing the options parswer when the action 'search' is given '''\n    gc = GalaxyCLI(args = [\"search\"])\n    self.run_parse_common(gc, \"search\")\n    self.assertEqual(gc.options.platforms, None)\n    self.assertEqual(gc.options.galaxy_tags, None)\n    self.assertEqual(gc.options.author, None)\n", "code_toks_joined": "def test_parse_search ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> gc = GalaxyCLI ( args = [ <STRING> ] ) <NEWLINE> self . run_parse_common ( gc , <STRING> ) <NEWLINE> self . assertEqual ( gc . options . platforms , None ) <NEWLINE> self . assertEqual ( gc . options . galaxy_tags , None ) <NEWLINE> self . assertEqual ( gc . options . author , None ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["''' testing the options parswer when the action 'search' is given '''", "\"search\"", "\"search\""]}}], ["d5e6e6a7cfdb8df737e7c82460322b4e", {"code_string": "def fwrap(fn, value):\n    iv = (value, )\n    return lambda: fn(iv[0])\n", "code_toks_joined": "def fwrap ( fn , value ) : <NEWLINE> <INDENT> iv = ( value , ) <NEWLINE> return lambda : fn ( iv [ 0 ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["c09f425ea33c5e0cef1ba3506c25c158", {"code_string": "def _get_method(method):\n    \"\"\"Return an imported object.\"\"\"\n    module = method.split(':')\n    _module_import = module[0]\n    class_name = module[- 1]\n    module_import = __import__(_module_import, fromlist = [class_name])\n    return getattr(module_import, class_name)\n", "code_toks_joined": "def _get_method ( method ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> module = method . split ( <STRING> ) <NEWLINE> _module_import = module [ 0 ] <NEWLINE> class_name = module [ - 1 ] <NEWLINE> module_import = __import__ ( _module_import , fromlist = [ class_name ] ) <NEWLINE> return getattr ( module_import , class_name ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Return an imported object.\"\"\"", "':'"]}}], ["0ee1b0af82f68dde73dc80b13436f980", {"code_string": "\"\"\"Provides DropoutLayer class for using in CNNs.\"\"\"\nimport numpy\nimport theano\nimport theano.tensor as T\nfrom net.layerparams import LayerParams\n__author__ = \"Markus Oberweger <oberweger@icg.tugraz.at>\"\n__copyright__ = \"Copyright 2015, ICG, Graz University of Technology, Austria\"\n__credits__ = [\"Paul Wohlhart\", \"Markus Oberweger\"]\n__license__ = \"GPL\"\n__version__ = \"1.0\"\n__maintainer__ = \"Markus Oberweger\"\n__email__ = \"oberweger@icg.tugraz.at\"\n__status__ = \"Development\"\n", "code_toks_joined": "<STRING> <NEWLINE> import numpy <NEWLINE> import theano <NEWLINE> import theano . tensor as T <NEWLINE> from net . layerparams import LayerParams <NEWLINE> __author__ = <STRING> <NEWLINE> __copyright__ = <STRING> <NEWLINE> __credits__ = [ <STRING> , <STRING> ] <NEWLINE> __license__ = <STRING> <NEWLINE> __version__ = <STRING> <NEWLINE> __maintainer__ = <STRING> <NEWLINE> __email__ = <STRING> <NEWLINE> __status__ = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Provides DropoutLayer class for using in CNNs.\"\"\"", "\"Markus Oberweger <oberweger@icg.tugraz.at>\"", "\"Copyright 2015, ICG, Graz University of Technology, Austria\"", "\"Paul Wohlhart\"", "\"Markus Oberweger\"", "\"GPL\"", "\"1.0\"", "\"Markus Oberweger\"", "\"oberweger@icg.tugraz.at\"", "\"Development\""]}}], ["bcff6ec7398d95ce713cad3fe3cf4146", {"code_string": "def copy(self):\n    ret = super(Chain, self).copy()\n    ret._children = set(ret._children)\n    d = ret.__dict__\n    for name in ret._children:\n        copied = d[name].copy()\n        copied.name = name\n        d[name] = copied\n    return ret\n", "code_toks_joined": "def copy ( self ) : <NEWLINE> <INDENT> ret = super ( Chain , self ) . copy ( ) <NEWLINE> ret . _children = set ( ret . _children ) <NEWLINE> d = ret . __dict__ <NEWLINE> for name in ret . _children : <NEWLINE> <INDENT> copied = d [ name ] . copy ( ) <NEWLINE> copied . name = name <NEWLINE> d [ name ] = copied <NEWLINE> <DEDENT> return ret <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["e90fe1adce347b0994557adc6f18bd42", {"code_string": "def html_footer(nome):\n    if nome == None:\n        footer = (\n            \"</div><div class='clear'></div>\"\n            \"<div id='footer'>\"\n            \"<div class='grid flex'>\"\n            \"<div class='col_10'>&copy; Copyright 2012\u20132013 All Rights Reserved.</div>\"\n            \"<div class='col_2'>Utente: Anonimo</div>\"\n            \"</div></div></body></html>\")\n    else:\n        footer = (\n            \"</div><div class='clear'></div>\"\n            \"<div id='footer'>\"\n            \"<div class='grid flex'>\"\n            \"<div class='col_10'>&copy; Copyright 2012\u20132013 All Rights Reserved.</div>\"\n            \"<div class='col_2'>Utente: \" + nome + \"</div>\"\n            \"</div></div></body></html>\")\n    return footer\n", "code_toks_joined": "def html_footer ( nome ) : <NEWLINE> <INDENT> if nome == None : <NEWLINE> <INDENT> footer = ( <NEWLINE> <INDENT> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> footer = ( <NEWLINE> <INDENT> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> + nome + <STRING> <NEWLINE> <STRING> ) <NEWLINE> <DEDENT> <DEDENT> return footer <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"</div><div class='clear'></div>\"", "\"<div id='footer'>\"", "\"<div class='grid flex'>\"", "\"<div class='col_10'>&copy; Copyright 2012\u20132013 All Rights Reserved.</div>\"", "\"<div class='col_2'>Utente: Anonimo</div>\"", "\"</div></div></body></html>\"", "\"</div><div class='clear'></div>\"", "\"<div id='footer'>\"", "\"<div class='grid flex'>\"", "\"<div class='col_10'>&copy; Copyright 2012\u20132013 All Rights Reserved.</div>\"", "\"<div class='col_2'>Utente: \"", "\"</div>\"", "\"</div></div></body></html>\""]}}], ["8768af699c13aee80f0c2aa4912bde7d", {"code_string": "\"\"\" Base class for the modules \"\"\"\nfrom __future__ import print_function\nfrom __future__ import absolute_import\nimport os\nimport re\nfrom argparse import ArgumentParser\nfrom gnuradio import gr\nfrom.util_functions import get_modname\nfrom.scm import SCMRepoFactory\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import print_function <NEWLINE> from __future__ import absolute_import <NEWLINE> import os <NEWLINE> import re <NEWLINE> from argparse import ArgumentParser <NEWLINE> from gnuradio import gr <NEWLINE> from . util_functions import get_modname <NEWLINE> from . scm import SCMRepoFactory <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\" Base class for the modules \"\"\""]}}], ["ecafe6aceb06a7d18eee266fe99075ae", {"code_string": "\"\"\"\"\"\"\nAWS_SECRET_KEY = 'secret_key'\nAWS_ACCESS_KEY = 'access_key'\nAWS_BUCKET = 'bucket'\nAWS_BASE_URL = 'https://*.cloudfront.net'\nAWS_EXPIRY_TIME = 60 * 30\nAWS_FORCE_HTTP = True\nUPLOAD_TO_S3 = False\nMEDIA_URL = \"\"\n\"\"\"A Wrapper around boto to upload to s3\"\"\"\nimport os\nfrom boto.s3.connection import S3Connection\nfrom boto.s3.key import Key\nfrom django.conf import settings\nif settings.UPLOAD_TO_S3:\n    conn = S3Connection(settings.AWS_ACCESS_KEY, settings.AWS_SECRET_KEY)\n    bucket = conn.get_bucket(settings.AWS_BUCKET)\n", "code_toks_joined": "<STRING> <NEWLINE> AWS_SECRET_KEY = <STRING> <NEWLINE> AWS_ACCESS_KEY = <STRING> <NEWLINE> AWS_BUCKET = <STRING> <NEWLINE> AWS_BASE_URL = <STRING> <NEWLINE> AWS_EXPIRY_TIME = 60 * 30 <NEWLINE> AWS_FORCE_HTTP = True <NEWLINE> UPLOAD_TO_S3 = False <NEWLINE> MEDIA_URL = <STRING> <NEWLINE> <STRING> <NEWLINE> import os <NEWLINE> from boto . s3 . connection import S3Connection <NEWLINE> from boto . s3 . key import Key <NEWLINE> from django . conf import settings <NEWLINE> if settings . UPLOAD_TO_S3 : <NEWLINE> <INDENT> conn = S3Connection ( settings . AWS_ACCESS_KEY , settings . AWS_SECRET_KEY ) <NEWLINE> bucket = conn . get_bucket ( settings . AWS_BUCKET ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"\"\"\"", "'secret_key'", "'access_key'", "'bucket'", "'https://*.cloudfront.net'", "\"\"", "\"\"\"A Wrapper around boto to upload to s3\"\"\""]}}], ["258b1ade52a1e7070e06b962d41356ce", {"code_string": "def toCSV(fname, data, labels = None):\n    \"\"\"Store data (a directory of equaly long lists) to the CSV file.\"\"\"\n    if len(data) == 0:\n        return\n    if labels is None:\n        labels = data.keys()\n    data = [data[l] for l in labels]\n    writer = csv.writer(fname, delimiter = '\\t')\n    writer.writerow(labels)\n    writer.writerows(zip(* data))\n", "code_toks_joined": "def toCSV ( fname , data , labels = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if len ( data ) == 0 : <NEWLINE> <INDENT> return <NEWLINE> <DEDENT> if labels is None : <NEWLINE> <INDENT> labels = data . keys ( ) <NEWLINE> <DEDENT> data = [ data [ l ] for l in labels ] <NEWLINE> writer = csv . writer ( fname , delimiter = <STRING> ) <NEWLINE> writer . writerow ( labels ) <NEWLINE> writer . writerows ( zip ( * data ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Store data (a directory of equaly long lists) to the CSV file.\"\"\"", "'\\t'"]}}], ["3c7cade3753d7f1edc65f536a296ab70", {"code_string": "def title(self):\n    title = _('Stock On Hand {0}'.format(self.title_month))\n    if self.location and self.location.location_type.name.upper() == 'FACILITY':\n        return \"{0} ({1}) Group {2}\".format(self.location.name,\n            self.location.site_code,\n            self.location.metadata.get('group', '---'))\n    return title\n", "code_toks_joined": "def title ( self ) : <NEWLINE> <INDENT> title = _ ( <STRING> . format ( self . title_month ) ) <NEWLINE> if self . location and self . location . location_type . name . upper ( ) == <STRING> : <NEWLINE> <INDENT> return <STRING> . format ( self . location . name , <NEWLINE> <INDENT> self . location . site_code , <NEWLINE> self . location . metadata . get ( <STRING> , <STRING> ) ) <NEWLINE> <DEDENT> <DEDENT> return title <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Stock On Hand {0}'", "'FACILITY'", "\"{0} ({1}) Group {2}\"", "'group'", "'---'"]}}], ["adc8cf6bdd435bfab23e553091cb7a20", {"code_string": "\"\"\"Orthography model\"\"\"\nfrom sqlalchemy import Column, Sequence\nfrom sqlalchemy.types import Integer, Unicode, UnicodeText, DateTime, Boolean\nfrom onlinelinguisticdatabase.model.meta import Base, now\n", "code_toks_joined": "<STRING> <NEWLINE> from sqlalchemy import Column , Sequence <NEWLINE> from sqlalchemy . types import Integer , Unicode , UnicodeText , DateTime , Boolean <NEWLINE> from onlinelinguisticdatabase . model . meta import Base , now <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Orthography model\"\"\""]}}], ["b3ea2ac70a588f42f38ba75401cb33a5", {"code_string": "def test_hmm_validation():\n    assert_raises(ValueError, MultinomialHMM(alpha = 0).fit, X, y, lengths)\n    assert_raises(ValueError, MultinomialHMM(alpha = - 1).fit, X, y, lengths)\n", "code_toks_joined": "def test_hmm_validation ( ) : <NEWLINE> <INDENT> assert_raises ( ValueError , MultinomialHMM ( alpha = 0 ) . fit , X , y , lengths ) <NEWLINE> assert_raises ( ValueError , MultinomialHMM ( alpha = - 1 ) . fit , X , y , lengths ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["1c295a4101a8b1b2201e5b2686614a42", {"code_string": "from setuptools import setup\nfrom os.path import join, dirname\nexecfile(join(dirname(__file__), 'OracleLibrary', 'version.py'))\nsetup(\n    name = 'robotframework-OracleLibrary',\n    version = VERSION,\n    author = 'Jules Barnes',\n    author_email = 'jules@julesbarnes.com',\n    packages = ['OracleLibrary'],\n    url = 'https://code.google.com/p/robotframework-OracleLibrary/',\n    license = 'LICENSE.txt',\n    description = 'Robot Framework Library to run sql queries against and Oracle DB',\n    long_description = open('README.txt').read(),\n    install_requires = [\n        'robotframework >= 2.8.3',\n        'cx_Oracle >= 5.1.2',\n        ],\n)\n", "code_toks_joined": "from setuptools import setup <NEWLINE> from os . path import join , dirname <NEWLINE> execfile ( join ( dirname ( __file__ ) , <STRING> , <STRING> ) ) <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = VERSION , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> url = <STRING> , <NEWLINE> license = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> long_description = open ( <STRING> ) . read ( ) , <NEWLINE> install_requires = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> ] , <NEWLINE> <DEDENT> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'OracleLibrary'", "'version.py'", "'robotframework-OracleLibrary'", "'Jules Barnes'", "'jules@julesbarnes.com'", "'OracleLibrary'", "'https://code.google.com/p/robotframework-OracleLibrary/'", "'LICENSE.txt'", "'Robot Framework Library to run sql queries against and Oracle DB'", "'README.txt'", "'robotframework >= 2.8.3'", "'cx_Oracle >= 5.1.2'"]}}], ["0dd33e89aa3bcb95d238e6d2aa1834d0", {"code_string": "import heapq as hq\nimport math\nimport sys\ninf = math.inf\n", "code_toks_joined": "import heapq as hq <NEWLINE> import math <NEWLINE> import sys <NEWLINE> inf = math . inf <NEWLINE>", "anonymize_dict": {}}], ["4e2d759e8b45da72c8b6caba0eaeb4ad", {"code_string": "def get(entity_id):\n    try:\n        return Entity.get(Entity.id == entity_id)\n    except DoesNotExist:\n        return None\n", "code_toks_joined": "def get ( entity_id ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> return Entity . get ( Entity . id == entity_id ) <NEWLINE> <DEDENT> except DoesNotExist : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["17c591c7d9c3aecbf8899fdff3259a34", {"code_string": "def single_search_processor(request):\n    context = {}\n    single_search_on = False\n    try:\n        if settings.SINGLE_SEARCH_ENABLED:\n            single_search_on = True\n    except AttributeError:\n        pass\n    context = {\n        'search_form': single_search_on,\n    }\n    return context\n", "code_toks_joined": "def single_search_processor ( request ) : <NEWLINE> <INDENT> context = { } <NEWLINE> single_search_on = False <NEWLINE> try : <NEWLINE> <INDENT> if settings . SINGLE_SEARCH_ENABLED : <NEWLINE> <INDENT> single_search_on = True <NEWLINE> <DEDENT> <DEDENT> except AttributeError : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> context = { <NEWLINE> <INDENT> <STRING> : single_search_on , <NEWLINE> <DEDENT> } <NEWLINE> return context <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'search_form'"]}}], ["d9471451d92ab9f01407be2543095349", {"code_string": "class DummyPublisher(BasePublisher):\n    def __init__(self):\n        pass\n    def open(self):\n        return True\n    def close(self):\n        return True\n    def send(self, msg):\n        print('[SENT] {}'.format(msg))\n        return True\n", "code_toks_joined": "class DummyPublisher ( BasePublisher ) : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def open ( self ) : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> def close ( self ) : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> def send ( self , msg ) : <NEWLINE> <INDENT> print ( <STRING> . format ( msg ) ) <NEWLINE> return True <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'[SENT] {}'"]}}], ["3956a200d430b2ed2d4b88457820bb5a", {"code_string": "def test_authorize_user_trailing_slash(self):\n    req = webob.Request.blank('/v2/')\n    req.headers['X-Auth-User'] = 'user1'\n    req.headers['X-Auth-Key'] = 'user1_key'\n    req.headers['X-Auth-Project-Id'] = 'user1_project'\n    result = req.get_response(fakes.wsgi_app(use_no_auth = True))\n    self.assertEqual(result.status, '204 No Content')\n    self.assertEqual(result.headers['X-Server-Management-Url'],\n        \"http://localhost/v2/user1_project\")\n", "code_toks_joined": "def test_authorize_user_trailing_slash ( self ) : <NEWLINE> <INDENT> req = webob . Request . blank ( <STRING> ) <NEWLINE> req . headers [ <STRING> ] = <STRING> <NEWLINE> req . headers [ <STRING> ] = <STRING> <NEWLINE> req . headers [ <STRING> ] = <STRING> <NEWLINE> result = req . get_response ( fakes . wsgi_app ( use_no_auth = True ) ) <NEWLINE> self . assertEqual ( result . status , <STRING> ) <NEWLINE> self . assertEqual ( result . headers [ <STRING> ] , <NEWLINE> <INDENT> <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/v2/'", "'X-Auth-User'", "'user1'", "'X-Auth-Key'", "'user1_key'", "'X-Auth-Project-Id'", "'user1_project'", "'204 No Content'", "'X-Server-Management-Url'", "\"http://localhost/v2/user1_project\""]}}], ["691995b6bcc125061993826c11ee146f", {"code_string": "class MasterConfig(Config):\n    api = CommonApiConfig(common_logger = 'dedalus.master.api.common',\n        access_logger = 'dedalus.master.api.access',\n        port = 8080)\n    backend = ConfigField(type = str, required = True, default = 'leveldb')\n    backend_config = ConfigField(type = dict, required = True, default = dict())\n    plugins = PluginsConfig()\n", "code_toks_joined": "class MasterConfig ( Config ) : <NEWLINE> <INDENT> api = CommonApiConfig ( common_logger = <STRING> , <NEWLINE> <INDENT> access_logger = <STRING> , <NEWLINE> port = 8080 ) <NEWLINE> <DEDENT> backend = ConfigField ( type = str , required = True , default = <STRING> ) <NEWLINE> backend_config = ConfigField ( type = dict , required = True , default = dict ( ) ) <NEWLINE> plugins = PluginsConfig ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'dedalus.master.api.common'", "'dedalus.master.api.access'", "'leveldb'"]}}], ["11fffdb2fa0be094e590280094a0d159", {"code_string": "import json\nimport logging\nimport logging.handlers\nimport os\nimport shutil\nimport sys\nimport traceback\nfrom argparse import ArgumentParser\nfrom pyani import anib, anim, tetra, pyani_config, pyani_files, pyani_graphics\nfrom pyani.run_multiprocessing import multiprocessing_run\nfrom pyani.pyani_config import params_mpl, params_r\n", "code_toks_joined": "import json <NEWLINE> import logging <NEWLINE> import logging . handlers <NEWLINE> import os <NEWLINE> import shutil <NEWLINE> import sys <NEWLINE> import traceback <NEWLINE> from argparse import ArgumentParser <NEWLINE> from pyani import anib , anim , tetra , pyani_config , pyani_files , pyani_graphics <NEWLINE> from pyani . run_multiprocessing import multiprocessing_run <NEWLINE> from pyani . pyani_config import params_mpl , params_r <NEWLINE>", "anonymize_dict": {}}], ["3d124fafcc89c33ea0ec814bcf9db044", {"code_string": "def getMonthEndDates(timestamps):\n    newTS = []\n    temp = timestamps[0].month\n    for x in range(0, len(timestamps) - 1):\n        if(temp != timestamps[x].month):\n            newTS.append(timestamps[x - 1])\n            temp = timestamps[x].month\n    newTS.append(timestamps[len(timestamps) - 1])\n    return newTS\n", "code_toks_joined": "def getMonthEndDates ( timestamps ) : <NEWLINE> <INDENT> newTS = [ ] <NEWLINE> temp = timestamps [ 0 ] . month <NEWLINE> for x in range ( 0 , len ( timestamps ) - 1 ) : <NEWLINE> <INDENT> if ( temp != timestamps [ x ] . month ) : <NEWLINE> <INDENT> newTS . append ( timestamps [ x - 1 ] ) <NEWLINE> temp = timestamps [ x ] . month <NEWLINE> <DEDENT> <DEDENT> newTS . append ( timestamps [ len ( timestamps ) - 1 ] ) <NEWLINE> return newTS <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["608331c9e437799516dc5351aa64d711", {"code_string": "def JSONrepr(self):\n    for k, (_, required) in self.props.items():\n        if required and k not in self.properties:\n            rtype = getattr(self, 'resource_type', \"<unknown type>\")\n            raise ValueError(\n                \"Resource %s required in type %s\" %(k, rtype))\n    self.validate()\n    if self.properties:\n        return self.resource\n    elif hasattr(self, 'resource_type'):\n        return{'Type': self.resource_type}\n    else:\n        return{}\n", "code_toks_joined": "def JSONrepr ( self ) : <NEWLINE> <INDENT> for k , ( _ , required ) in self . props . items ( ) : <NEWLINE> <INDENT> if required and k not in self . properties : <NEWLINE> <INDENT> rtype = getattr ( self , <STRING> , <STRING> ) <NEWLINE> raise ValueError ( <NEWLINE> <INDENT> <STRING> % ( k , rtype ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> self . validate ( ) <NEWLINE> if self . properties : <NEWLINE> <INDENT> return self . resource <NEWLINE> <DEDENT> elif hasattr ( self , <STRING> ) : <NEWLINE> <INDENT> return { <STRING> : self . resource_type } <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return { } <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'resource_type'", "\"<unknown type>\"", "\"Resource %s required in type %s\"", "'resource_type'", "'Type'"]}}], ["9910deb5ad4f6178aa1369fcf74366a7", {"code_string": "from distutils.core import setup, Extension\nsetup(name = 'shim', version = '0.1', ext_modules = [Extension('shim', ['shim.cpp'])])\n", "code_toks_joined": "from distutils . core import setup , Extension <NEWLINE> setup ( name = <STRING> , version = <STRING> , ext_modules = [ Extension ( <STRING> , [ <STRING> ] ) ] ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'shim'", "'0.1'", "'shim'", "'shim.cpp'"]}}], ["c82eefcb227941eaef73f8acae63693d", {"code_string": "def init(self):\n    \"\"\"M\u00e9thode d'initialisation.\"\"\"\n    self.ajouter_filtre(\"n\", \"nom\", \"nom_singulier\", \"regex\")\n    self.ajouter_filtre(\"l\", \"cle\", \"cle\", \"chaine\")\n", "code_toks_joined": "def init ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . ajouter_filtre ( <STRING> , <STRING> , <STRING> , <STRING> ) <NEWLINE> self . ajouter_filtre ( <STRING> , <STRING> , <STRING> , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"M\u00e9thode d'initialisation.\"\"\"", "\"n\"", "\"nom\"", "\"nom_singulier\"", "\"regex\"", "\"l\"", "\"cle\"", "\"cle\"", "\"chaine\""]}}], ["aff6d9960e751cfe9ca729c297f0b594", {"code_string": "def n(self):\n    \"\"\" Count and return the total number of samples. \"\"\"\n    return np.sum(self.h.values())\n", "code_toks_joined": "def n ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return np . sum ( self . h . values ( ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Count and return the total number of samples. \"\"\""]}}], ["40b6eca430478e0a59bb6424277d461a", {"code_string": "def __unicode__(self):\n    return u\"SendSMS: %s - %s: %s\" %(self.identifier, self.msisdn,\n        self.smstext)\n", "code_toks_joined": "def __unicode__ ( self ) : <NEWLINE> <INDENT> return <STRING> % ( self . identifier , self . msisdn , <NEWLINE> <INDENT> self . smstext ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["u\"SendSMS: %s - %s: %s\""]}}], ["d86735d346dd909569a982b7ad023067", {"code_string": "\"\"\"Creates autoscaled, network LB IGM running specified docker image.\"\"\"\nimport yaml\nsize = 0\nMIN_SIZE_KEY = 'minSize'\nDEFAULT_MIN_SIZE = 1\nMAX_SIZE_KEY = 'maxSize'\nDEFAULT_MAX_SIZE = 1\nCONTAINER_IMAGE_KEY = 'containerImage'\nDEFAULT_CONTAINER_IMAGE = 'centos-7'\nDOCKER_ENV_KEY = 'dockerEnv'\nDEFAULT_DOCKER_ENV = {}\n", "code_toks_joined": "<STRING> <NEWLINE> import yaml <NEWLINE> size = 0 <NEWLINE> MIN_SIZE_KEY = <STRING> <NEWLINE> DEFAULT_MIN_SIZE = 1 <NEWLINE> MAX_SIZE_KEY = <STRING> <NEWLINE> DEFAULT_MAX_SIZE = 1 <NEWLINE> CONTAINER_IMAGE_KEY = <STRING> <NEWLINE> DEFAULT_CONTAINER_IMAGE = <STRING> <NEWLINE> DOCKER_ENV_KEY = <STRING> <NEWLINE> DEFAULT_DOCKER_ENV = { } <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Creates autoscaled, network LB IGM running specified docker image.\"\"\"", "'minSize'", "'maxSize'", "'containerImage'", "'centos-7'", "'dockerEnv'"]}}], ["fa8e21cbf33af6e16c82644d8caa8550", {"code_string": "def process_connect(self):\n    if self.http_data.has_keepalive():\n        self.keep_alive = True\n    self.current_destination = self.get_destination_from_data()\n    if TestController.match_monitored_domains(self.current_destination.host):\n        self.redirect_destination()\n    self.send_data(socket_to = self.request, data = \"HTTP/1.0 200 Connection established\\r\\n\\r\\n\")\n    self.forward_https_channel()\n", "code_toks_joined": "def process_connect ( self ) : <NEWLINE> <INDENT> if self . http_data . has_keepalive ( ) : <NEWLINE> <INDENT> self . keep_alive = True <NEWLINE> <DEDENT> self . current_destination = self . get_destination_from_data ( ) <NEWLINE> if TestController . match_monitored_domains ( self . current_destination . host ) : <NEWLINE> <INDENT> self . redirect_destination ( ) <NEWLINE> <DEDENT> self . send_data ( socket_to = self . request , data = <STRING> ) <NEWLINE> self . forward_https_channel ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"HTTP/1.0 200 Connection established\\r\\n\\r\\n\""]}}], ["fbf654580bdd27de7d2412e631a2f638", {"code_string": "\"\"\"Convert an image to a .dat file using patterns from img2dat.pat\"\"\"\nimport os\nfrom PIL import Image, ImageEnhance\nfrom sys import argv, exit, stderr\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> from PIL import Image , ImageEnhance <NEWLINE> from sys import argv , exit , stderr <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Convert an image to a .dat file using patterns from img2dat.pat\"\"\""]}}], ["e0a8fef5d2daa2f110810cf3bf4d7138", {"code_string": "class LoggingStatsd(DogStatsd):\n    \"\"\"Adding logging to emitted metrics.\"\"\"\n    def _report(self, metric, metric_type, value, tags, sample_rate):\n        logger.debug('[statsd] %s %s: %s', metric, metric_type, value)\n        return super()._report(metric, metric_type, value, tags, sample_rate)\n", "code_toks_joined": "class LoggingStatsd ( DogStatsd ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def _report ( self , metric , metric_type , value , tags , sample_rate ) : <NEWLINE> <INDENT> logger . debug ( <STRING> , metric , metric_type , value ) <NEWLINE> return super ( ) . _report ( metric , metric_type , value , tags , sample_rate ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Adding logging to emitted metrics.\"\"\"", "'[statsd] %s %s: %s'"]}}], ["3944f3479c9927e1445ff898c6bcc78b", {"code_string": "def reset(self):\n    \"\"\" re-initializes the environment, setting the ship to rest at a random orientation.\"\"\"\n    self.sensors = [random.uniform(- 30., 30.), 0.0, 0.0]\n    if self.render:\n        if self.server.clients > 0:\n            self.server.send([\"r\", \"r\", \"r\"])\n", "code_toks_joined": "def reset ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . sensors = [ random . uniform ( - 30. , 30. ) , 0.0 , 0.0 ] <NEWLINE> if self . render : <NEWLINE> <INDENT> if self . server . clients > 0 : <NEWLINE> <INDENT> self . server . send ( [ <STRING> , <STRING> , <STRING> ] ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" re-initializes the environment, setting the ship to rest at a random orientation.\"\"\"", "\"r\"", "\"r\"", "\"r\""]}}], ["a20968294de0dc2f2b2aacb75ce486d9", {"code_string": "def dotset(obj, keys, value):\n    attrs = keys.split('.')\n    target = obj\n    if '.' in keys:\n        target = dotget(obj, '.'.join(attrs[: - 1]))\n    setattr(target, attrs[- 1], value)\n", "code_toks_joined": "def dotset ( obj , keys , value ) : <NEWLINE> <INDENT> attrs = keys . split ( <STRING> ) <NEWLINE> target = obj <NEWLINE> if <STRING> in keys : <NEWLINE> <INDENT> target = dotget ( obj , <STRING> . join ( attrs [ : - 1 ] ) ) <NEWLINE> <DEDENT> setattr ( target , attrs [ - 1 ] , value ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'.'", "'.'", "'.'"]}}], ["59311c088172be7dac5981fa0d985e9f", {"code_string": "class OfferAdmin(admin.ModelAdmin):\n    fields = ('name', 'offer')\n    if django.VERSION[: 2] <=(1, 5):\n        class Media:\n            js = ('//code.jquery.com/jquery-1.11.0.min.js', )\n", "code_toks_joined": "class OfferAdmin ( admin . ModelAdmin ) : <NEWLINE> <INDENT> fields = ( <STRING> , <STRING> ) <NEWLINE> if django . VERSION [ : 2 ] <= ( 1 , 5 ) : <NEWLINE> <INDENT> class Media : <NEWLINE> <INDENT> js = ( <STRING> , ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'name'", "'offer'", "'//code.jquery.com/jquery-1.11.0.min.js'"]}}], ["c5797fc9b7c2b1a34e34d09810c4dfe8", {"code_string": "class Serializer(django.core.serializers.json.Serializer):\n    \"\"\"A copy of Django's serializer for JSON, but using our own encoder.\"\"\"\n    def end_serialization(self):\n        if json.__version__.split('.') >=['2', '1', '3']:\n            self.options.update({'use_decimal': False})\n        json.dump(\n            self.objects, self.stream, cls = MAASJSONEncoder, ** self.options)\n", "code_toks_joined": "class Serializer ( django . core . serializers . json . Serializer ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def end_serialization ( self ) : <NEWLINE> <INDENT> if json . __version__ . split ( <STRING> ) >= [ <STRING> , <STRING> , <STRING> ] : <NEWLINE> <INDENT> self . options . update ( { <STRING> : False } ) <NEWLINE> <DEDENT> json . dump ( <NEWLINE> <INDENT> self . objects , self . stream , cls = MAASJSONEncoder , ** self . options ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"A copy of Django's serializer for JSON, but using our own encoder.\"\"\"", "'.'", "'2'", "'1'", "'3'", "'use_decimal'"]}}], ["a6a46e6c0d4ef63adc059dbad2c833e1", {"code_string": "class GumballMachineProxy(object):\n    \"\"\"hold a GumballMachine, and call pass on attribute calls\"\"\"\n    def __init__(self, gumball_machine):\n        self.machine = gumball_machine\n    def __getattr__(self, attr):\n        \"\"\"call the attribute on our gumball machine\"\"\"\n        check_attr = getattr(self.machine, attr)\n        if callable(check_attr):\n            def wrap_remote_call(* args, ** kargs):\n                return check_attr(* args, ** kargs)\n            return wrap_remote_call\n        else:\n            return check_attr\n", "code_toks_joined": "class GumballMachineProxy ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , gumball_machine ) : <NEWLINE> <INDENT> self . machine = gumball_machine <NEWLINE> <DEDENT> def __getattr__ ( self , attr ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> check_attr = getattr ( self . machine , attr ) <NEWLINE> if callable ( check_attr ) : <NEWLINE> <INDENT> def wrap_remote_call ( * args , ** kargs ) : <NEWLINE> <INDENT> return check_attr ( * args , ** kargs ) <NEWLINE> <DEDENT> return wrap_remote_call <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return check_attr <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"hold a GumballMachine, and call pass on attribute calls\"\"\"", "\"\"\"call the attribute on our gumball machine\"\"\""]}}], ["28bc32d316850618e56fd03d90c2fdec", {"code_string": "class Arith():\n    def __init__(self, a):\n        self.a = a\n    def add(self, b):\n        return NUMBERS[\n            NUMBERS.index(self.a) +\n            NUMBERS.index(b)\n            ]\n", "code_toks_joined": "class Arith ( ) : <NEWLINE> <INDENT> def __init__ ( self , a ) : <NEWLINE> <INDENT> self . a = a <NEWLINE> <DEDENT> def add ( self , b ) : <NEWLINE> <INDENT> return NUMBERS [ <NEWLINE> <INDENT> NUMBERS . index ( self . a ) + <NEWLINE> NUMBERS . index ( b ) <NEWLINE> ] <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["2f8a08140f15f61e4e69f3019ff5e9b0", {"code_string": "def test_set_decimal_objective(self):\n    \"\"\"Test that Decimal can be used in objective.\"\"\"\n    prob = self.solver.create_problem()\n    prob.define('x', lower = 3, upper = 100)\n    prob.set_objective(Decimal('3.4') * prob.var('x'))\n", "code_toks_joined": "def test_set_decimal_objective ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> prob = self . solver . create_problem ( ) <NEWLINE> prob . define ( <STRING> , lower = 3 , upper = 100 ) <NEWLINE> prob . set_objective ( Decimal ( <STRING> ) * prob . var ( <STRING> ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test that Decimal can be used in objective.\"\"\"", "'x'", "'3.4'", "'x'"]}}], ["90e0d7bd5f62e6f3dba1120858296e74", {"code_string": "def warn_and_error(a, b):\n    print(a)\n    1[2]\n", "code_toks_joined": "def warn_and_error ( a , b ) : <NEWLINE> <INDENT> print ( a ) <NEWLINE> 1 [ 2 ] <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["53adbf7c46b437b89b30e5054f51aa8b", {"code_string": "def on_close(self):\n    new_controller_type = self.controller_type_combo.currentText()\n    new_controller_name = self.controller_name_text.text()\n    if new_controller_type == 'Modbus':\n        new_controller_address = self.ip_address_text.text()\n    elif new_controller_type == 'Dummy':\n        new_controller_address = ''\n    else:\n        new_controller_address = ''\n    self.new_controller_data = (new_controller_type, new_controller_name,\n        new_controller_address)\n", "code_toks_joined": "def on_close ( self ) : <NEWLINE> <INDENT> new_controller_type = self . controller_type_combo . currentText ( ) <NEWLINE> new_controller_name = self . controller_name_text . text ( ) <NEWLINE> if new_controller_type == <STRING> : <NEWLINE> <INDENT> new_controller_address = self . ip_address_text . text ( ) <NEWLINE> <DEDENT> elif new_controller_type == <STRING> : <NEWLINE> <INDENT> new_controller_address = <STRING> <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> new_controller_address = <STRING> <NEWLINE> <DEDENT> self . new_controller_data = ( new_controller_type , new_controller_name , <NEWLINE> <INDENT> new_controller_address ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Modbus'", "'Dummy'", "''", "''"]}}], ["80d7b5cb61e6baf23faf70bd543d0544", {"code_string": "def get_urls():\n    '''Recursively builds a list of all the urls in the current project and the name of their associated view'''\n    from operator import itemgetter\n    nice_urls = []\n    app = get_app('Openworm')\n    for model in get_models(app):\n        nice_urls.append({\"pattern\": model().get_subclass_name()})\n    nice_urls = sorted(nice_urls, key = itemgetter('pattern'))\n    return nice_urls\n", "code_toks_joined": "def get_urls ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> from operator import itemgetter <NEWLINE> nice_urls = [ ] <NEWLINE> app = get_app ( <STRING> ) <NEWLINE> for model in get_models ( app ) : <NEWLINE> <INDENT> nice_urls . append ( { <STRING> : model ( ) . get_subclass_name ( ) } ) <NEWLINE> <DEDENT> nice_urls = sorted ( nice_urls , key = itemgetter ( <STRING> ) ) <NEWLINE> return nice_urls <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Recursively builds a list of all the urls in the current project and the name of their associated view'''", "'Openworm'", "\"pattern\"", "'pattern'"]}}], ["4733c5f09f7647b9df02964b5ddddf81", {"code_string": "def dataIterator():\n    ''' A simple data iterator '''\n    batch_idx = 0\n    while True:\n        idxs = np.arange(0, len(X_train))\n        np.random.shuffle(idxs)\n        shuf_features = X_train[idxs]\n        shuf_labels = y_train[idxs]\n        for batch_idx in range(0, len(X_train), batch_size):\n            features_batch = shuf_features[batch_idx: batch_idx + batch_size]\n            features_batch = features_batch.astype(\"float32\")\n            labels_batch = shuf_labels[batch_idx: batch_idx + batch_size]\n            yield features_batch, labels_batch\n", "code_toks_joined": "def dataIterator ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> batch_idx = 0 <NEWLINE> while True : <NEWLINE> <INDENT> idxs = np . arange ( 0 , len ( X_train ) ) <NEWLINE> np . random . shuffle ( idxs ) <NEWLINE> shuf_features = X_train [ idxs ] <NEWLINE> shuf_labels = y_train [ idxs ] <NEWLINE> for batch_idx in range ( 0 , len ( X_train ) , batch_size ) : <NEWLINE> <INDENT> features_batch = shuf_features [ batch_idx : batch_idx + batch_size ] <NEWLINE> features_batch = features_batch . astype ( <STRING> ) <NEWLINE> labels_batch = shuf_labels [ batch_idx : batch_idx + batch_size ] <NEWLINE> yield features_batch , labels_batch <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["''' A simple data iterator '''", "\"float32\""]}}], ["c0a4972c094faeacb2919f45da08a42c", {"code_string": "def test_installation():\n    assert sys.version_info.major == 3\n    assert sys.version_info.minor >= 5\n", "code_toks_joined": "def test_installation ( ) : <NEWLINE> <INDENT> assert sys . version_info . major == 3 <NEWLINE> assert sys . version_info . minor >= 5 <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["b33eead0ac25cb044f03f01c416e1e98", {"code_string": "from appmain import appmain\nif __name__ == '__main__':\n    appmain.show()\n    appmain.run()\n", "code_toks_joined": "from appmain import appmain <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> appmain . show ( ) <NEWLINE> appmain . run ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'__main__'"]}}], ["21b9e58f6dfd0243725e4ad25d3674f1", {"code_string": "import os\nimport argparse\nfrom dtoolcore import DataSet\n", "code_toks_joined": "import os <NEWLINE> import argparse <NEWLINE> from dtoolcore import DataSet <NEWLINE>", "anonymize_dict": {}}], ["d022a804c20e955deefc7f28e3402699", {"code_string": "'''Created on 8. juli 2014'''\nfrom PyQt4.QtGui import QFormLayout, QToolButton\nfrom ert_gui.ide.keywords.definitions import RangeStringArgument, ProperNameFormatStringArgument\nfrom ert_gui.models.connectors import EnsembleSizeModel\nfrom ert_gui.models.connectors.init import CaseSelectorModel\nfrom ert_gui.models.connectors.run import SensitivityStudy, ActiveRealizationsModel, RunPathModel, SensitivityTargetCaseFormatModel\nfrom ert_gui.simulation import SensitivityStudyParametersPanel\nfrom ert_gui.simulation.simulation_config_panel import SimulationConfigPanel\nfrom ert_gui.widgets import util\nfrom ert_gui.widgets.active_label import ActiveLabel\nfrom ert_gui.widgets.closable_dialog import ClosableDialog\nfrom ert_gui.widgets.combo_choice import ComboChoice\nfrom ert_gui.widgets.string_box import StringBox\n", "code_toks_joined": "<STRING> <NEWLINE> from PyQt4 . QtGui import QFormLayout , QToolButton <NEWLINE> from ert_gui . ide . keywords . definitions import RangeStringArgument , ProperNameFormatStringArgument <NEWLINE> from ert_gui . models . connectors import EnsembleSizeModel <NEWLINE> from ert_gui . models . connectors . init import CaseSelectorModel <NEWLINE> from ert_gui . models . connectors . run import SensitivityStudy , ActiveRealizationsModel , RunPathModel , SensitivityTargetCaseFormatModel <NEWLINE> from ert_gui . simulation import SensitivityStudyParametersPanel <NEWLINE> from ert_gui . simulation . simulation_config_panel import SimulationConfigPanel <NEWLINE> from ert_gui . widgets import util <NEWLINE> from ert_gui . widgets . active_label import ActiveLabel <NEWLINE> from ert_gui . widgets . closable_dialog import ClosableDialog <NEWLINE> from ert_gui . widgets . combo_choice import ComboChoice <NEWLINE> from ert_gui . widgets . string_box import StringBox <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Created on 8. juli 2014'''"]}}], ["f35afc3e136a100a127815097dc7ed43", {"code_string": "def _validate_user_data(self, user_data):\n    \"\"\"Check if the user_data is encoded properly.\"\"\"\n    if not user_data:\n        return\n    try:\n        base64.b64decode(user_data)\n    except:\n        expl = _('Userdata content cannot be decoded')\n        raise exc.HTTPBadRequest(explanation = expl)\n", "code_toks_joined": "def _validate_user_data ( self , user_data ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if not user_data : <NEWLINE> <INDENT> return <NEWLINE> <DEDENT> try : <NEWLINE> <INDENT> base64 . b64decode ( user_data ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> expl = _ ( <STRING> ) <NEWLINE> raise exc . HTTPBadRequest ( explanation = expl ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Check if the user_data is encoded properly.\"\"\"", "'Userdata content cannot be decoded'"]}}], ["03ded9de1f014a886948e1c59c1cea0d", {"code_string": "def commits_months(period, authors):\n    M = Matrix_empty(13, len(period))\n    M[0] = period\n    for author in authors:\n        for aux in author:\n            M[int(aux[2].month)][int(aux[2].year - date_min)] += 1\n    return M\n", "code_toks_joined": "def commits_months ( period , authors ) : <NEWLINE> <INDENT> M = Matrix_empty ( 13 , len ( period ) ) <NEWLINE> M [ 0 ] = period <NEWLINE> for author in authors : <NEWLINE> <INDENT> for aux in author : <NEWLINE> <INDENT> M [ int ( aux [ 2 ] . month ) ] [ int ( aux [ 2 ] . year - date_min ) ] += 1 <NEWLINE> <DEDENT> <DEDENT> return M <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["54ae2ffc0da4646d94ff96b454e294b6", {"code_string": "\"\"\"Contains the logic for `aq update machine --hostname`.\"\"\"\nfrom aquilon.worker.broker import BrokerCommand\nfrom aquilon.worker.commands.update_machine import CommandUpdateMachine\nfrom aquilon.worker.dbwrappers.host import hostname_to_host\n", "code_toks_joined": "<STRING> <NEWLINE> from aquilon . worker . broker import BrokerCommand <NEWLINE> from aquilon . worker . commands . update_machine import CommandUpdateMachine <NEWLINE> from aquilon . worker . dbwrappers . host import hostname_to_host <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Contains the logic for `aq update machine --hostname`.\"\"\""]}}], ["e07e7b6542101151ed5e56e2d11a7900", {"code_string": "from bluffinmuffin.protocol.enums import BluffinMessageIdEnum\nfrom bluffinmuffin.protocol.interfaces import AbstractResponse\nfrom.check_display_exist_command import CheckDisplayExistCommand\n", "code_toks_joined": "from bluffinmuffin . protocol . enums import BluffinMessageIdEnum <NEWLINE> from bluffinmuffin . protocol . interfaces import AbstractResponse <NEWLINE> from . check_display_exist_command import CheckDisplayExistCommand <NEWLINE>", "anonymize_dict": {}}], ["0f314ee0e18dce55ef20755609d74a7e", {"code_string": "def find_best_stations(needed, states):\n    all_names = set()\n    while needed:\n        joint = set()\n        saved = set()\n        names = None\n        for name, serial in states.items():\n            joint = serial & needed\n            if len(joint) > len(saved):\n                saved = joint\n                names = name\n        if names != None:\n            all_names.add(names)\n            needed -= saved\n    return all_names\n", "code_toks_joined": "def find_best_stations ( needed , states ) : <NEWLINE> <INDENT> all_names = set ( ) <NEWLINE> while needed : <NEWLINE> <INDENT> joint = set ( ) <NEWLINE> saved = set ( ) <NEWLINE> names = None <NEWLINE> for name , serial in states . items ( ) : <NEWLINE> <INDENT> joint = serial & needed <NEWLINE> if len ( joint ) > len ( saved ) : <NEWLINE> <INDENT> saved = joint <NEWLINE> names = name <NEWLINE> <DEDENT> <DEDENT> if names != None : <NEWLINE> <INDENT> all_names . add ( names ) <NEWLINE> needed -= saved <NEWLINE> <DEDENT> <DEDENT> return all_names <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["35d825cdd48204241765218cad48f23a", {"code_string": "def get_content_field(self):\n    \"\"\"Returns the field that supplies the primary document to be indexed.\"\"\"\n    for field_name, field in self.fields.items():\n        if field.document is True:\n            return field.index_fieldname\n", "code_toks_joined": "def get_content_field ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> for field_name , field in self . fields . items ( ) : <NEWLINE> <INDENT> if field . document is True : <NEWLINE> <INDENT> return field . index_fieldname <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Returns the field that supplies the primary document to be indexed.\"\"\""]}}], ["9f19956909177814366f1407a1a17495", {"code_string": "def backwards(self, orm):\n    db.delete_table(u'dragon_portal_course')\n    db.delete_table(u'dragon_portal_dragonuser')\n    db.delete_table(db.shorten_name(u'dragon_portal_dragonuser_groups'))\n    db.delete_table(db.shorten_name(u'dragon_portal_dragonuser_user_permissions'))\n    db.delete_table(u'dragon_portal_parentprofile')\n    db.delete_table(u'dragon_portal_studentprofile')\n    db.delete_table(u'dragon_portal_progress')\n", "code_toks_joined": "def backwards ( self , orm ) : <NEWLINE> <INDENT> db . delete_table ( <STRING> ) <NEWLINE> db . delete_table ( <STRING> ) <NEWLINE> db . delete_table ( db . shorten_name ( <STRING> ) ) <NEWLINE> db . delete_table ( db . shorten_name ( <STRING> ) ) <NEWLINE> db . delete_table ( <STRING> ) <NEWLINE> db . delete_table ( <STRING> ) <NEWLINE> db . delete_table ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["u'dragon_portal_course'", "u'dragon_portal_dragonuser'", "u'dragon_portal_dragonuser_groups'", "u'dragon_portal_dragonuser_user_permissions'", "u'dragon_portal_parentprofile'", "u'dragon_portal_studentprofile'", "u'dragon_portal_progress'"]}}], ["e4b98762fb7b7ac9c51ed531009ca8a6", {"code_string": "import argparse\nimport numpy as np\nimport pylab as plt\nfrom flowtools.datamaps import Spread\nfrom flowtools.draw import plot_line\nfrom flowtools.utils import calc_radius, combine_spread, get_colours, get_labels, get_linestyles, get_shift\n", "code_toks_joined": "import argparse <NEWLINE> import numpy as np <NEWLINE> import pylab as plt <NEWLINE> from flowtools . datamaps import Spread <NEWLINE> from flowtools . draw import plot_line <NEWLINE> from flowtools . utils import calc_radius , combine_spread , get_colours , get_labels , get_linestyles , get_shift <NEWLINE>", "anonymize_dict": {}}], ["6b7dc48ed8d316582a752ed0ed12cb24", {"code_string": "\"\"\"pygments.lexers.capnproto\"\"\"\nimport re\nfrom pygments.lexer import RegexLexer, default\nfrom pygments.token import Text, Comment, Keyword, Name, Literal\n__all__ = ['CapnProtoLexer']\n", "code_toks_joined": "<STRING> <NEWLINE> import re <NEWLINE> from pygments . lexer import RegexLexer , default <NEWLINE> from pygments . token import Text , Comment , Keyword , Name , Literal <NEWLINE> __all__ = [ <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"pygments.lexers.capnproto\"\"\"", "'CapnProtoLexer'"]}}], ["0f37c07d4feb1a225b7fe676fc6dfb03", {"code_string": "\"\"\" produce iqtree-pomo 'counts' formatted input file from ipyrad .loci file \"\"\"\nimport os\nimport itertools\nimport numpy as np\nfrom ipyrad.assemble.util import IPyradWarningExit, AMBIGS\nBASE2IDX = {\n    \"A\": 0,\n    \"C\": 1,\n    \"G\": 2,\n    \"T\": 3,\n}\nHEADER = \"\"\" COUNTSFILE   NPOP  {NPOP}   NSITES {NSITES}\"\"\"\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> import itertools <NEWLINE> import numpy as np <NEWLINE> from ipyrad . assemble . util import IPyradWarningExit , AMBIGS <NEWLINE> BASE2IDX = { <NEWLINE> <INDENT> <STRING> : 0 , <NEWLINE> <STRING> : 1 , <NEWLINE> <STRING> : 2 , <NEWLINE> <STRING> : 3 , <NEWLINE> <DEDENT> } <NEWLINE> HEADER = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\" produce iqtree-pomo 'counts' formatted input file from ipyrad .loci file \"\"\"", "\"A\"", "\"C\"", "\"G\"", "\"T\"", "\"\"\" COUNTSFILE   NPOP  {NPOP}   NSITES {NSITES}\"\"\""]}}], ["4a031b44d20664896e86b7413797d64a", {"code_string": "from __future__ import unicode_literals\nimport binascii\nimport base64\nimport hashlib\nimport re\nimport json\nfrom.common import InfoExtractor\nfrom..compat import(\n    compat_ord,\n    compat_urllib_parse,\n    compat_urllib_parse_unquote,\n)\nfrom..utils import(\n    ExtractorError,\n    sanitized_Request,\n)\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> import binascii <NEWLINE> import base64 <NEWLINE> import hashlib <NEWLINE> import re <NEWLINE> import json <NEWLINE> from . common import InfoExtractor <NEWLINE> from . . compat import ( <NEWLINE> <INDENT> compat_ord , <NEWLINE> compat_urllib_parse , <NEWLINE> compat_urllib_parse_unquote , <NEWLINE> <DEDENT> ) <NEWLINE> from . . utils import ( <NEWLINE> <INDENT> ExtractorError , <NEWLINE> sanitized_Request , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {}}], ["580b08ad0a155774e37916d3226afa1b", {"code_string": "from __future__ import print_function\nfrom WindowsWifi import getWirelessInterfaces\nfrom WindowsWifi import getWirelessProfiles\nif __name__ == \"__main__\":\n    ifaces = getWirelessInterfaces()\n    for iface in ifaces:\n        print(iface)\n        guid = iface.guid\n        profiles = getWirelessProfiles(iface)\n        print(\"\")\n        for profile in profiles:\n            print(profile)\n            print(\"-\" * 20)\n        print(\"\")\n", "code_toks_joined": "from __future__ import print_function <NEWLINE> from WindowsWifi import getWirelessInterfaces <NEWLINE> from WindowsWifi import getWirelessProfiles <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> ifaces = getWirelessInterfaces ( ) <NEWLINE> for iface in ifaces : <NEWLINE> <INDENT> print ( iface ) <NEWLINE> guid = iface . guid <NEWLINE> profiles = getWirelessProfiles ( iface ) <NEWLINE> print ( <STRING> ) <NEWLINE> for profile in profiles : <NEWLINE> <INDENT> print ( profile ) <NEWLINE> print ( <STRING> * 20 ) <NEWLINE> <DEDENT> print ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"__main__\"", "\"\"", "\"-\"", "\"\""]}}], ["5ae262a72421c4608328a23eff419126", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('ojuser', '0003_auto_20160502_0103'),\n    ]\n    operations = [\n        migrations.AddField(\n            model_name = 'groupprofile',\n            name = 'name',\n            field = models.CharField(default = 1, unique = True, max_length = 50),\n            preserve_default = False,\n        ),\n        migrations.AlterField(\n            model_name = 'groupprofile',\n            name = 'nickname',\n            field = models.CharField(max_length = 50),\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . AddField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . CharField ( default = 1 , unique = True , max_length = 50 ) , <NEWLINE> preserve_default = False , <NEWLINE> <DEDENT> ) , <NEWLINE> migrations . AlterField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . CharField ( max_length = 50 ) , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'ojuser'", "'0003_auto_20160502_0103'", "'groupprofile'", "'name'", "'groupprofile'", "'nickname'"]}}], ["db31492d3623f749e6209d91e7a98768", {"code_string": "def deserialize(self):\n    request = self.get_django_request()\n    return{'data': request.POST,\n        'files': request.FILES, }\n", "code_toks_joined": "def deserialize ( self ) : <NEWLINE> <INDENT> request = self . get_django_request ( ) <NEWLINE> return { <STRING> : request . POST , <NEWLINE> <INDENT> <STRING> : request . FILES , } <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'data'", "'files'"]}}], ["397a3e0b13f356765aaf317ea9fa73ff", {"code_string": "def run_command(self, command):\n    proc = subprocess.Popen(command,\n        shell = True,\n        stdout = subprocess.PIPE,\n        stderr = subprocess.PIPE)\n    out, err = proc.communicate()\n    if err:\n        logger.error(\"Unable to run command %s,  ERROR- %s\" %\n            (command, err))\n        return None\n    return out\n", "code_toks_joined": "def run_command ( self , command ) : <NEWLINE> <INDENT> proc = subprocess . Popen ( command , <NEWLINE> <INDENT> shell = True , <NEWLINE> stdout = subprocess . PIPE , <NEWLINE> stderr = subprocess . PIPE ) <NEWLINE> <DEDENT> out , err = proc . communicate ( ) <NEWLINE> if err : <NEWLINE> <INDENT> logger . error ( <STRING> % <NEWLINE> <INDENT> ( command , err ) ) <NEWLINE> <DEDENT> return None <NEWLINE> <DEDENT> return out <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Unable to run command %s,  ERROR- %s\""]}}], ["be0e9dc381e81c24753d31576649d165", {"code_string": "import mlt\nfrom PIL import Image\nmlt.Factory.init()\nprofile = mlt.Profile()\nprod = mlt.Producer(profile, 'test.wav')\nsize = (320, 240)\nfor i in range(0, prod.get_length()):\n    frm = prod.get_frame()\n    wav = mlt.frame_get_waveform(frm, size[0], size[1])\n    img = Image.fromstring('L', size, wav)\n    img.save('test-%04d.pgm' %(i))\n", "code_toks_joined": "import mlt <NEWLINE> from PIL import Image <NEWLINE> mlt . Factory . init ( ) <NEWLINE> profile = mlt . Profile ( ) <NEWLINE> prod = mlt . Producer ( profile , <STRING> ) <NEWLINE> size = ( 320 , 240 ) <NEWLINE> for i in range ( 0 , prod . get_length ( ) ) : <NEWLINE> <INDENT> frm = prod . get_frame ( ) <NEWLINE> wav = mlt . frame_get_waveform ( frm , size [ 0 ] , size [ 1 ] ) <NEWLINE> img = Image . fromstring ( <STRING> , size , wav ) <NEWLINE> img . save ( <STRING> % ( i ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'test.wav'", "'L'", "'test-%04d.pgm'"]}}], ["e593692bd3e6f0652a003421681f33cb", {"code_string": "\"\"\"Data model classes for the Groups Provisioning API.\"\"\"\n__author__ = 'Shraddha gupta <shraddhag@google.com>'\nimport atom.data\nimport gdata.apps\nimport gdata.apps.apps_property_entry\nimport gdata.apps_property\nimport gdata.data\npyproperty = property\nGROUP_ID = 'groupId'\nGROUP_NAME = 'groupName'\nDESCRIPTION = 'description'\nEMAIL_PERMISSION = 'emailPermission'\nMEMBER_ID = 'memberId'\nMEMBER_TYPE = 'memberType'\nDIRECT_MEMBER = 'directMember'\n", "code_toks_joined": "<STRING> <NEWLINE> __author__ = <STRING> <NEWLINE> import atom . data <NEWLINE> import gdata . apps <NEWLINE> import gdata . apps . apps_property_entry <NEWLINE> import gdata . apps_property <NEWLINE> import gdata . data <NEWLINE> pyproperty = property <NEWLINE> GROUP_ID = <STRING> <NEWLINE> GROUP_NAME = <STRING> <NEWLINE> DESCRIPTION = <STRING> <NEWLINE> EMAIL_PERMISSION = <STRING> <NEWLINE> MEMBER_ID = <STRING> <NEWLINE> MEMBER_TYPE = <STRING> <NEWLINE> DIRECT_MEMBER = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Data model classes for the Groups Provisioning API.\"\"\"", "'Shraddha gupta <shraddhag@google.com>'", "'groupId'", "'groupName'", "'description'", "'emailPermission'", "'memberId'", "'memberType'", "'directMember'"]}}], ["608c1ee2a34ab115d4810c422da10b45", {"code_string": "def get_word_features(all_words):\n    wordlist = nltk.FreqDist(all_words)\n    word_features = wordlist.keys()\n    return word_features\n", "code_toks_joined": "def get_word_features ( all_words ) : <NEWLINE> <INDENT> wordlist = nltk . FreqDist ( all_words ) <NEWLINE> word_features = wordlist . keys ( ) <NEWLINE> return word_features <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["9dedaa7ab3d22f479e34c0f7c93a6602", {"code_string": "class User(object):\n    \"\"\"Classe Usuario\"\"\"\n    def __init__(self, nome, email, password, id = id):\n        self.nome = nome\n        self.email = email\n        self.password = convert_md5(password)\n        self.id = id\n", "code_toks_joined": "class User ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , nome , email , password , id = id ) : <NEWLINE> <INDENT> self . nome = nome <NEWLINE> self . email = email <NEWLINE> self . password = convert_md5 ( password ) <NEWLINE> self . id = id <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Classe Usuario\"\"\""]}}], ["1001cebfb297d541ad7643eb918c20a1", {"code_string": "def python_help(help_string):\n    try:\n        needle = help_string\n        if needle.startswith(\"'\") and needle.endswith(\"'\"):\n            needle = needle[1: - 1]\n        elif needle.startswith('\"') and needle.endswith('\"'):\n            needle = needle[1: - 1]\n        help(needle)\n    except Exception as e:\n        print(e)\n        sys.stderr.write(\"\u2022naked\u2022 There was an error processing the query.\")\n        sys.exit(1)\n", "code_toks_joined": "def python_help ( help_string ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> needle = help_string <NEWLINE> if needle . startswith ( <STRING> ) and needle . endswith ( <STRING> ) : <NEWLINE> <INDENT> needle = needle [ 1 : - 1 ] <NEWLINE> <DEDENT> elif needle . startswith ( <STRING> ) and needle . endswith ( <STRING> ) : <NEWLINE> <INDENT> needle = needle [ 1 : - 1 ] <NEWLINE> <DEDENT> help ( needle ) <NEWLINE> <DEDENT> except Exception as e : <NEWLINE> <INDENT> print ( e ) <NEWLINE> sys . stderr . write ( <STRING> ) <NEWLINE> sys . exit ( 1 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"'\"", "\"'\"", "'\"'", "'\"'", "\"\u2022naked\u2022 There was an error processing the query.\""]}}], ["2ac91c17b591f79d077bb1ec06947b05", {"code_string": "def pytest_collect_file(parent, path):\n    if(path.ext == \".hy\"\n        and NATIVE_TESTS in path.dirname + os.sep\n        and path.basename != \"__init__.hy\"\n        and not(\"py3_only\" in path.basename and not PY3)\n        and not(\"py35_only\" in path.basename and not PY35)):\n        m = _pytest.python.pytest_pycollect_makemodule(path, parent)\n        m.name = m.name[: - len(\".hy\")] + \".py\"\n        return m\n", "code_toks_joined": "def pytest_collect_file ( parent , path ) : <NEWLINE> <INDENT> if ( path . ext == <STRING> <NEWLINE> <INDENT> and NATIVE_TESTS in path . dirname + os . sep <NEWLINE> and path . basename != <STRING> <NEWLINE> and not ( <STRING> in path . basename and not PY3 ) <NEWLINE> and not ( <STRING> in path . basename and not PY35 ) ) : <NEWLINE> m = _pytest . python . pytest_pycollect_makemodule ( path , parent ) <NEWLINE> m . name = m . name [ : - len ( <STRING> ) ] + <STRING> <NEWLINE> return m <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\".hy\"", "\"__init__.hy\"", "\"py3_only\"", "\"py35_only\"", "\".hy\"", "\".py\""]}}], ["8659e286d92ab9370ea6f186baeb4bad", {"code_string": "from __future__ import unicode_literals\nimport random\nimport re\nfrom.common import InfoExtractor\nfrom..compat import compat_str\nfrom..utils import(\n    determine_ext,\n    float_or_none,\n    parse_age_limit,\n    qualities,\n    try_get,\n    unified_timestamp,\n    urljoin,\n)\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> import random <NEWLINE> import re <NEWLINE> from . common import InfoExtractor <NEWLINE> from . . compat import compat_str <NEWLINE> from . . utils import ( <NEWLINE> <INDENT> determine_ext , <NEWLINE> float_or_none , <NEWLINE> parse_age_limit , <NEWLINE> qualities , <NEWLINE> try_get , <NEWLINE> unified_timestamp , <NEWLINE> urljoin , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {}}], ["521be0f84d9fbfa1a3edace2bf45a3c8", {"code_string": "import os\nfrom modularodm import Q\nfrom modularodm.exceptions import ModularOdmException\nfrom framework.auth.core import User\nfrom website import settings\nfrom website.app import init_app\nfrom website.conferences.model import Conference\n", "code_toks_joined": "import os <NEWLINE> from modularodm import Q <NEWLINE> from modularodm . exceptions import ModularOdmException <NEWLINE> from framework . auth . core import User <NEWLINE> from website import settings <NEWLINE> from website . app import init_app <NEWLINE> from website . conferences . model import Conference <NEWLINE>", "anonymize_dict": {}}], ["59af98da1a28ab2079c7fbd35f7635d9", {"code_string": "def restoreIpAddresses(self, s):\n    res = []\n    cand = []\n    self.restore_ip(s, cand, res)\n    return res\n", "code_toks_joined": "def restoreIpAddresses ( self , s ) : <NEWLINE> <INDENT> res = [ ] <NEWLINE> cand = [ ] <NEWLINE> self . restore_ip ( s , cand , res ) <NEWLINE> return res <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["61d61a8a855fa39f278f3826efa2307a", {"code_string": "def upgrade():\n    op.get_bind()\n    op.execute('update users set password_changed_at = created_at where password_changed_at is null')\n    op.alter_column('users', 'password_changed_at', nullable = False)\n", "code_toks_joined": "def upgrade ( ) : <NEWLINE> <INDENT> op . get_bind ( ) <NEWLINE> op . execute ( <STRING> ) <NEWLINE> op . alter_column ( <STRING> , <STRING> , nullable = False ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'update users set password_changed_at = created_at where password_changed_at is null'", "'users'", "'password_changed_at'"]}}], ["466d9260a4dba3f3a75418d80882f0f7", {"code_string": "def main(argv):\n    _, device, command = argv\n    import serial\n    arduino = Arduino(serial.Serial(device, 9600))\n    print(arduino.send(command.encode('ascii')))\n", "code_toks_joined": "def main ( argv ) : <NEWLINE> <INDENT> _ , device , command = argv <NEWLINE> import serial <NEWLINE> arduino = Arduino ( serial . Serial ( device , 9600 ) ) <NEWLINE> print ( arduino . send ( command . encode ( <STRING> ) ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'ascii'"]}}], ["7665cc20126ef50529fbe086f1801cb4", {"code_string": "def control_verification_request(self, params = None, ** kwargs):\n    warnings.warn('nexmo.Client#control_verification_request is deprecated', DeprecationWarning, stacklevel = 2)\n    return self.post(self.api_host, '/verify/control/json', params or kwargs)\n", "code_toks_joined": "def control_verification_request ( self , params = None , ** kwargs ) : <NEWLINE> <INDENT> warnings . warn ( <STRING> , DeprecationWarning , stacklevel = 2 ) <NEWLINE> return self . post ( self . api_host , <STRING> , params or kwargs ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'nexmo.Client#control_verification_request is deprecated'", "'/verify/control/json'"]}}], ["fadb5ab45ea78a4d7551eeab0a3a35e6", {"code_string": "def __init__(self, data, cols = COLUMNS, max_field_size = MAX_FIELD_SIZE):\n    self.cols = cols\n    self.max_field_size = max_field_size\n    self.data = data\n", "code_toks_joined": "def __init__ ( self , data , cols = COLUMNS , max_field_size = MAX_FIELD_SIZE ) : <NEWLINE> <INDENT> self . cols = cols <NEWLINE> self . max_field_size = max_field_size <NEWLINE> self . data = data <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["8d49a7b7abc30206bbb3b59879f3857b", {"code_string": "def forwards(apps, schema_editor):\n    from autoslug.settings import slugify\n    Deck = apps.get_model('flashcards', 'Deck')\n    for deck in Deck.objects.all().iterator():\n        deck.slug = slugify(deck.name)\n        deck.save(update_fields = ['slug'])\n", "code_toks_joined": "def forwards ( apps , schema_editor ) : <NEWLINE> <INDENT> from autoslug . settings import slugify <NEWLINE> Deck = apps . get_model ( <STRING> , <STRING> ) <NEWLINE> for deck in Deck . objects . all ( ) . iterator ( ) : <NEWLINE> <INDENT> deck . slug = slugify ( deck . name ) <NEWLINE> deck . save ( update_fields = [ <STRING> ] ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'flashcards'", "'Deck'", "'slug'"]}}], ["a04202e73d1ba4b0652c083f74e36361", {"code_string": "def test_len_collection(self):\n    first_feed = next(self._container.itervalues())\n    collection = first_feed.OpenCollection()\n    with RequestsMock() as rsp:\n        rsp.add(rsp.GET, re.compile('.*SELECT\\+COUNT.*'),\n            json = json_count(collection.name), match_querystring = True)\n        len_collection = len(collection)\n    self.assertEqual(len_collection, NUM_TEST_POINTS)\n", "code_toks_joined": "def test_len_collection ( self ) : <NEWLINE> <INDENT> first_feed = next ( self . _container . itervalues ( ) ) <NEWLINE> collection = first_feed . OpenCollection ( ) <NEWLINE> with RequestsMock ( ) as rsp : <NEWLINE> <INDENT> rsp . add ( rsp . GET , re . compile ( <STRING> ) , <NEWLINE> <INDENT> json = json_count ( collection . name ) , match_querystring = True ) <NEWLINE> <DEDENT> len_collection = len ( collection ) <NEWLINE> <DEDENT> self . assertEqual ( len_collection , NUM_TEST_POINTS ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'.*SELECT\\+COUNT.*'"]}}], ["de47f0007bb45440e49db8e101f6bcf2", {"code_string": "def hilite(string, bold):\n    attr = []\n    attr.append('32')\n    if bold:\n        attr.append('1')\n    return '\\x1b[%sm%s\\x1b[0m' %(';'.join(attr), string)\n", "code_toks_joined": "def hilite ( string , bold ) : <NEWLINE> <INDENT> attr = [ ] <NEWLINE> attr . append ( <STRING> ) <NEWLINE> if bold : <NEWLINE> <INDENT> attr . append ( <STRING> ) <NEWLINE> <DEDENT> return <STRING> % ( <STRING> . join ( attr ) , string ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'32'", "'1'", "'\\x1b[%sm%s\\x1b[0m'", "';'"]}}], ["31b783568d332cd1698cdbec3a63ebb8", {"code_string": "from socket import socket, AF_INET, SOCK_DGRAM\nfrom optparse import OptionParser\nfrom time import time\n", "code_toks_joined": "from socket import socket , AF_INET , SOCK_DGRAM <NEWLINE> from optparse import OptionParser <NEWLINE> from time import time <NEWLINE>", "anonymize_dict": {}}], ["5ac77672cd0dfc357e8e0a815c952f7d", {"code_string": "import logging\nimport re\nfrom webkitpy.common.host import Host\nfrom webkitpy.common.webkit_finder import WebKitFinder\nfrom HTMLParser import HTMLParser\n_log = logging.getLogger(__name__)\n", "code_toks_joined": "import logging <NEWLINE> import re <NEWLINE> from webkitpy . common . host import Host <NEWLINE> from webkitpy . common . webkit_finder import WebKitFinder <NEWLINE> from HTMLParser import HTMLParser <NEWLINE> _log = logging . getLogger ( __name__ ) <NEWLINE>", "anonymize_dict": {}}], ["304a700c3b077f7b351969fae282370f", {"code_string": "class CampListView(ListView):\n    allow_empty = True\n    model = Camp\n    template_name = \"list.html\"\n", "code_toks_joined": "class CampListView ( ListView ) : <NEWLINE> <INDENT> allow_empty = True <NEWLINE> model = Camp <NEWLINE> template_name = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"list.html\""]}}], ["af826be3c252c144194c31f0fd951ee6", {"code_string": "def handle_result(self, parseResult):\n    for member in self.get_hostgroup().get_members():\n        for failKey, pingResult in parseResult.items():\n            for task in member.get_tasks():\n                if failKey == task.get_task_type():\n                    task._execute()\n", "code_toks_joined": "def handle_result ( self , parseResult ) : <NEWLINE> <INDENT> for member in self . get_hostgroup ( ) . get_members ( ) : <NEWLINE> <INDENT> for failKey , pingResult in parseResult . items ( ) : <NEWLINE> <INDENT> for task in member . get_tasks ( ) : <NEWLINE> <INDENT> if failKey == task . get_task_type ( ) : <NEWLINE> <INDENT> task . _execute ( ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["d0e4464b4b5e9bad0641b47ce8f9bfef", {"code_string": "class ClassFactory(object):\n    def instance(self):\n        return Class(attribute_1 = \"Value 1\", attribute_2 = \"Value 2\", attribute_3 = \"Value 3\")\n", "code_toks_joined": "class ClassFactory ( object ) : <NEWLINE> <INDENT> def instance ( self ) : <NEWLINE> <INDENT> return Class ( attribute_1 = <STRING> , attribute_2 = <STRING> , attribute_3 = <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Value 1\"", "\"Value 2\"", "\"Value 3\""]}}], ["16d969e388ee09dbb24b2fc2a883f842", {"code_string": "import pyeapi\nimport json\nfrom pprint import pprint\npynet_sw3 = pyeapi.connect_to(\"pynet-sw3\")\nresult = pynet_sw3.enable(\"show interfaces\")\nparse = result[0]['result']\ninterfaces = parse['interfaces']\nfor i in interfaces:\n    print(\"Interface: \" + i)\n    counters = interfaces[i]['interfaceCounters']\n    print(\"inOctets: \" + str(counters['inOctets']))\n    print(\"outOctets: \" + str(counters['outOctets']))\n", "code_toks_joined": "import pyeapi <NEWLINE> import json <NEWLINE> from pprint import pprint <NEWLINE> pynet_sw3 = pyeapi . connect_to ( <STRING> ) <NEWLINE> result = pynet_sw3 . enable ( <STRING> ) <NEWLINE> parse = result [ 0 ] [ <STRING> ] <NEWLINE> interfaces = parse [ <STRING> ] <NEWLINE> for i in interfaces : <NEWLINE> <INDENT> print ( <STRING> + i ) <NEWLINE> counters = interfaces [ i ] [ <STRING> ] <NEWLINE> print ( <STRING> + str ( counters [ <STRING> ] ) ) <NEWLINE> print ( <STRING> + str ( counters [ <STRING> ] ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"pynet-sw3\"", "\"show interfaces\"", "'result'", "'interfaces'", "\"Interface: \"", "'interfaceCounters'", "\"inOctets: \"", "'inOctets'", "\"outOctets: \"", "'outOctets'"]}}], ["198f975a744cce2f800ddc7c7352f9b6", {"code_string": "from evoque.api import hooks\napp = {\n    'root': 'evoque.api.controllers.root.RootController',\n    'modules': ['evoque.api'],\n    'debug': False,\n    'hooks': [\n        hooks.ContextHook(),\n        hooks.RPCHook(),\n    ],\n    'acl_public_routes': [\n        '/'\n    ],\n}\n", "code_toks_joined": "from evoque . api import hooks <NEWLINE> app = { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : [ <STRING> ] , <NEWLINE> <STRING> : False , <NEWLINE> <STRING> : [ <NEWLINE> <INDENT> hooks . ContextHook ( ) , <NEWLINE> hooks . RPCHook ( ) , <NEWLINE> <DEDENT> ] , <NEWLINE> <STRING> : [ <NEWLINE> <INDENT> <STRING> <NEWLINE> <DEDENT> ] , <NEWLINE> <DEDENT> } <NEWLINE>", "anonymize_dict": {"<STRING>": ["'root'", "'evoque.api.controllers.root.RootController'", "'modules'", "'evoque.api'", "'debug'", "'hooks'", "'acl_public_routes'", "'/'"]}}], ["3b9071ff8ec08af48fd55925099e6ba0", {"code_string": "\"\"\"InaSAFE Disaster risk assessment tool developed by AusAid and World Bank\"\"\"\n__author__ = 'ismail@kartoza.com'\n__date__ = '14/09/2012'\n__copyright__ = ('Copyright 2012, Australia Indonesia Facility for '\n    'Disaster Reduction')\nimport unittest\nimport os\nimport qgis\nfrom PyQt4.QtGui import QDialogButtonBox\nfrom safe.gui.tools.shake_grid.shakemap_converter_dialog import(\n    ShakemapConverterDialog)\nfrom safe.common.utilities import unique_filename, temp_dir\nfrom safe.test.utilities import standard_data_path, get_qgis_app, TESTDATA\nQGIS_APP, CANVAS, IFACE, PARENT = get_qgis_app()\n", "code_toks_joined": "<STRING> <NEWLINE> __author__ = <STRING> <NEWLINE> __date__ = <STRING> <NEWLINE> __copyright__ = ( <STRING> <NEWLINE> <INDENT> <STRING> ) <NEWLINE> <DEDENT> import unittest <NEWLINE> import os <NEWLINE> import qgis <NEWLINE> from PyQt4 . QtGui import QDialogButtonBox <NEWLINE> from safe . gui . tools . shake_grid . shakemap_converter_dialog import ( <NEWLINE> <INDENT> ShakemapConverterDialog ) <NEWLINE> <DEDENT> from safe . common . utilities import unique_filename , temp_dir <NEWLINE> from safe . test . utilities import standard_data_path , get_qgis_app , TESTDATA <NEWLINE> QGIS_APP , CANVAS , IFACE , PARENT = get_qgis_app ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"InaSAFE Disaster risk assessment tool developed by AusAid and World Bank\"\"\"", "'ismail@kartoza.com'", "'14/09/2012'", "'Copyright 2012, Australia Indonesia Facility for '", "'Disaster Reduction'"]}}], ["b14f46b471eb03f1083f796dc949e5d5", {"code_string": "def readdict(fin):\n    \"\"\"Reconstruct a dictionary or enrollment information from an open .csv file previously created by writedict\"\"\"\n    retDict = {}\n    fin.next()\n    for[uid, cid, edate] in fin:\n        retDict[uid] = course_enrollment(uid, cid, edate)\n    return retDict\n", "code_toks_joined": "def readdict ( fin ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> retDict = { } <NEWLINE> fin . next ( ) <NEWLINE> for [ uid , cid , edate ] in fin : <NEWLINE> <INDENT> retDict [ uid ] = course_enrollment ( uid , cid , edate ) <NEWLINE> <DEDENT> return retDict <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Reconstruct a dictionary or enrollment information from an open .csv file previously created by writedict\"\"\""]}}], ["5b14221af96dc2e8191abc44667e91f6", {"code_string": "\"\"\"Trac Fold Out Macro.\"\"\"\nimport trac.core\nimport trac.wiki\nimport trac.wiki.macros\nfrom genshi.builder import tag\nimport genshi.core\nimport uuid\nimport StringIO\nARROW_RIGHT = u'\\u25B6'\nARROW_DOWN = u'\\u25BC'\n", "code_toks_joined": "<STRING> <NEWLINE> import trac . core <NEWLINE> import trac . wiki <NEWLINE> import trac . wiki . macros <NEWLINE> from genshi . builder import tag <NEWLINE> import genshi . core <NEWLINE> import uuid <NEWLINE> import StringIO <NEWLINE> ARROW_RIGHT = <STRING> <NEWLINE> ARROW_DOWN = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Trac Fold Out Macro.\"\"\"", "u'\\u25B6'", "u'\\u25BC'"]}}], ["9b8dc461bc77806f5a82021eb75bc068", {"code_string": "import guiClass\napp = guiClass.GUI()\napp.version = 'Video Downloader Beta 0.9.4 r(20161221)'\napp.appVer = 0.94\napp.appUrl = 'http://evilcult.github.io/Video-Downloader'\napp.gitUrl = 'https://github.com/EvilCult/Video-Downloader'\napp.feedUrl = 'https://github.com/EvilCult/Video-Downloader/issues'\napp.run()\n", "code_toks_joined": "import guiClass <NEWLINE> app = guiClass . GUI ( ) <NEWLINE> app . version = <STRING> <NEWLINE> app . appVer = 0.94 <NEWLINE> app . appUrl = <STRING> <NEWLINE> app . gitUrl = <STRING> <NEWLINE> app . feedUrl = <STRING> <NEWLINE> app . run ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'Video Downloader Beta 0.9.4 r(20161221)'", "'http://evilcult.github.io/Video-Downloader'", "'https://github.com/EvilCult/Video-Downloader'", "'https://github.com/EvilCult/Video-Downloader/issues'"]}}], ["6507838a6f1a546ca63892b5cd17214a", {"code_string": "def process_stop(self, address, stop, verbose, mode = 'walking'):\n    if verbose:\n        print('processing stop: {}, {}, id: {}'.\n            format(stop.latitude, stop.longitude, stop.id))\n    result = self.wrapper.get_distance_from_api(address, stop, mode)\n    if verbose:\n        print('distance: {}, time: {}'.format(result[\"distance\"],\n            result[\"time\"]))\n    self.handler.add_route(address.id,\n        stop.id,\n        result[\"distance\"],\n        result[\"time\"])\n", "code_toks_joined": "def process_stop ( self , address , stop , verbose , mode = <STRING> ) : <NEWLINE> <INDENT> if verbose : <NEWLINE> <INDENT> print ( <STRING> . <NEWLINE> <INDENT> format ( stop . latitude , stop . longitude , stop . id ) ) <NEWLINE> <DEDENT> <DEDENT> result = self . wrapper . get_distance_from_api ( address , stop , mode ) <NEWLINE> if verbose : <NEWLINE> <INDENT> print ( <STRING> . format ( result [ <STRING> ] , <NEWLINE> <INDENT> result [ <STRING> ] ) ) <NEWLINE> <DEDENT> <DEDENT> self . handler . add_route ( address . id , <NEWLINE> <INDENT> stop . id , <NEWLINE> result [ <STRING> ] , <NEWLINE> result [ <STRING> ] ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'walking'", "'processing stop: {}, {}, id: {}'", "'distance: {}, time: {}'", "\"distance\"", "\"time\"", "\"distance\"", "\"time\""]}}], ["53c5394471c427c82065d698a54284c7", {"code_string": "def url_rewritable(self, task, entry):\n    if entry['url'].startswith('http://www.google.com/cse?'):\n        return True\n    if entry['url'].startswith('http://www.google.com/custom?'):\n        return True\n    return False\n", "code_toks_joined": "def url_rewritable ( self , task , entry ) : <NEWLINE> <INDENT> if entry [ <STRING> ] . startswith ( <STRING> ) : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> if entry [ <STRING> ] . startswith ( <STRING> ) : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> return False <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'url'", "'http://www.google.com/cse?'", "'url'", "'http://www.google.com/custom?'"]}}], ["d6584dc91568701fb5756b3a1e7aef18", {"code_string": "\"\"\"Contains WithSimilarityScore mixin.\"\"\"\nfrom sqlalchemy import and_\nfrom sqlalchemy import case\nfrom sqlalchemy import literal\nfrom sqlalchemy import or_\nfrom sqlalchemy.orm import aliased\nfrom sqlalchemy.sql import func\nfrom ggrc import db\nfrom ggrc.models.relationship import Relationship\n", "code_toks_joined": "<STRING> <NEWLINE> from sqlalchemy import and_ <NEWLINE> from sqlalchemy import case <NEWLINE> from sqlalchemy import literal <NEWLINE> from sqlalchemy import or_ <NEWLINE> from sqlalchemy . orm import aliased <NEWLINE> from sqlalchemy . sql import func <NEWLINE> from ggrc import db <NEWLINE> from ggrc . models . relationship import Relationship <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Contains WithSimilarityScore mixin.\"\"\""]}}], ["f339f1b10d5f059a9036a41b8b63c1e2", {"code_string": "def siteinfo(request):\n    try:\n        siteinfo = SiteInformation.objects.get(pk = 1)\n    except:\n        siteinfo = \"not found \"\n    return{'siteinfo': siteinfo}\n", "code_toks_joined": "def siteinfo ( request ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> siteinfo = SiteInformation . objects . get ( pk = 1 ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> siteinfo = <STRING> <NEWLINE> <DEDENT> return { <STRING> : siteinfo } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"not found \"", "'siteinfo'"]}}], ["1b7aa047c9553eedfbb313e849251d11", {"code_string": "def __init__(self, module):\n    self.module = module\n    self.state = module.params['state']\n    self.name = module.params['name']\n    self.gid = module.params['gid']\n    self.system = module.params['system']\n", "code_toks_joined": "def __init__ ( self , module ) : <NEWLINE> <INDENT> self . module = module <NEWLINE> self . state = module . params [ <STRING> ] <NEWLINE> self . name = module . params [ <STRING> ] <NEWLINE> self . gid = module . params [ <STRING> ] <NEWLINE> self . system = module . params [ <STRING> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'state'", "'name'", "'gid'", "'system'"]}}], ["d6eee0fffacc2063142742c0e6707e13", {"code_string": "def Variable(data, * args, ** kwargs):\n    var = autograd.Variable(data, * args, ** kwargs)\n    if USE_CUDA:\n        var = var.cuda()\n    return var\n", "code_toks_joined": "def Variable ( data , * args , ** kwargs ) : <NEWLINE> <INDENT> var = autograd . Variable ( data , * args , ** kwargs ) <NEWLINE> if USE_CUDA : <NEWLINE> <INDENT> var = var . cuda ( ) <NEWLINE> <DEDENT> return var <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["9090e9b0190439807e66a067fc7891f7", {"code_string": "def raw_entry(word):\n    word_range = (0, len(word))\n    dictionary_result = DCSCopyTextDefinition(None, word, word_range)\n    if not dictionary_result:\n        print(\"{} not found in Dictionary.\".format(word))\n        return None\n    else:\n        return dictionary_result\n", "code_toks_joined": "def raw_entry ( word ) : <NEWLINE> <INDENT> word_range = ( 0 , len ( word ) ) <NEWLINE> dictionary_result = DCSCopyTextDefinition ( None , word , word_range ) <NEWLINE> if not dictionary_result : <NEWLINE> <INDENT> print ( <STRING> . format ( word ) ) <NEWLINE> return None <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return dictionary_result <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"{} not found in Dictionary.\""]}}], ["dd1f3142e3a672d51b17e5a1013ae91d", {"code_string": "def testGET(self):\n    '''Test HTTP GET'''\n    MyHTTPHandler.get = echo_path_get\n    http = httpclass.HTTPClient()\n    path = \"abcdef/gjkd/dsadas\"\n    url = \"http://%s:%d/%s\" %(BASEHOST, BASEPORT, path)\n    req = http.GET(url)\n    self.assertTrue(req != None, \"None Returned!\")\n    self.assertTrue(req.code == 200)\n    self.assertTrue(req.body.find(path) >= 0, \"Data: [%s] \" % req.body)\n", "code_toks_joined": "def testGET ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> MyHTTPHandler . get = echo_path_get <NEWLINE> http = httpclass . HTTPClient ( ) <NEWLINE> path = <STRING> <NEWLINE> url = <STRING> % ( BASEHOST , BASEPORT , path ) <NEWLINE> req = http . GET ( url ) <NEWLINE> self . assertTrue ( req != None , <STRING> ) <NEWLINE> self . assertTrue ( req . code == 200 ) <NEWLINE> self . assertTrue ( req . body . find ( path ) >= 0 , <STRING> % req . body ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Test HTTP GET'''", "\"abcdef/gjkd/dsadas\"", "\"http://%s:%d/%s\"", "\"None Returned!\"", "\"Data: [%s] \""]}}], ["dfde38c37ac38e99026aff6c7c359202", {"code_string": "class World:\n    \"\"\"Znaki z ktorych sklada sie mapa swiata.\"\"\"\n    EXIT = 'W'\n    \"\"\"Znak umieszczany mapie oznaczajacy pole z wyjsciem.\"\"\"\n    CAVE = 'J'\n    \"\"\"Znak umieszczany mapie oznaczajacy pole z jama.\"\"\"\n    EMPTY = '.'\n    \"\"\"Znak umieszczany mapie oznaczajacy puste pole.\"\"\"\n", "code_toks_joined": "class World : <NEWLINE> <INDENT> <STRING> <NEWLINE> EXIT = <STRING> <NEWLINE> <STRING> <NEWLINE> CAVE = <STRING> <NEWLINE> <STRING> <NEWLINE> EMPTY = <STRING> <NEWLINE> <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Znaki z ktorych sklada sie mapa swiata.\"\"\"", "'W'", "\"\"\"Znak umieszczany mapie oznaczajacy pole z wyjsciem.\"\"\"", "'J'", "\"\"\"Znak umieszczany mapie oznaczajacy pole z jama.\"\"\"", "'.'", "\"\"\"Znak umieszczany mapie oznaczajacy puste pole.\"\"\""]}}], ["30c87a589f3261cb4689844a90013bad", {"code_string": "from itertools import tee\nfrom cryptotools.xor import xor_bytes\nfrom cryptotools.cipher.block import blockify\n", "code_toks_joined": "from itertools import tee <NEWLINE> from cryptotools . xor import xor_bytes <NEWLINE> from cryptotools . cipher . block import blockify <NEWLINE>", "anonymize_dict": {}}], ["6dd05708e9ecba52597ee2f837fa2f78", {"code_string": "def get_largest_area(reg_props):\n    \"\"\"GET_LARGEST_AREA: returns the largest area and the label of the corresponding\"\"\"\n    a = [_x['area'] for _x in reg_props]\n    l = [_x['label'] for _x in reg_props]\n    i = np.argmax(a)\n    return a[i], l[i]\n", "code_toks_joined": "def get_largest_area ( reg_props ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> a = [ _x [ <STRING> ] for _x in reg_props ] <NEWLINE> l = [ _x [ <STRING> ] for _x in reg_props ] <NEWLINE> i = np . argmax ( a ) <NEWLINE> return a [ i ] , l [ i ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"GET_LARGEST_AREA: returns the largest area and the label of the corresponding\"\"\"", "'area'", "'label'"]}}], ["2c9e812d07059390f1aed4dac980216d", {"code_string": "import glob\nimport itertools\nimport json\nimport operator\nimport os\nfrom mako.template import Template\nfrom openerp.modules import module\nfrom.main import module_topological_sort\nfrom..import http\nNOMODULE_TEMPLATE = Template(u\"\"\"<!DOCTYPE html>\"\"\")\nNOTFOUND = Template(u\"\"\"<p>Unable to find the module [${module}], please check that the module\"\"\")\nTESTING = Template(u\"\"\"<!DOCTYPE html>\"\"\")\n", "code_toks_joined": "import glob <NEWLINE> import itertools <NEWLINE> import json <NEWLINE> import operator <NEWLINE> import os <NEWLINE> from mako . template import Template <NEWLINE> from openerp . modules import module <NEWLINE> from . main import module_topological_sort <NEWLINE> from . . import http <NEWLINE> NOMODULE_TEMPLATE = Template ( <STRING> ) <NEWLINE> NOTFOUND = Template ( <STRING> ) <NEWLINE> TESTING = Template ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["u\"\"\"<!DOCTYPE html>\"\"\"", "u\"\"\"<p>Unable to find the module [${module}], please check that the module\"\"\"", "u\"\"\"<!DOCTYPE html>\"\"\""]}}], ["14eefcc08e356ebebfd3184bc70629a4", {"code_string": "def has_handler(self, handler_name):\n    \"\"\"Return whether the current driver has defined the given handler.\"\"\"\n    return handler_name in self._handlers\n", "code_toks_joined": "def has_handler ( self , handler_name ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return handler_name in self . _handlers <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Return whether the current driver has defined the given handler.\"\"\""]}}], ["48b8b76d455642c11e5b980ecb947793", {"code_string": "def conv_bn_dr(net, num_filt, dr, k = 3):\n    net = conv_bn(net, num_filt, k)\n    return l.Dropout(dr)(net)\n", "code_toks_joined": "def conv_bn_dr ( net , num_filt , dr , k = 3 ) : <NEWLINE> <INDENT> net = conv_bn ( net , num_filt , k ) <NEWLINE> return l . Dropout ( dr ) ( net ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["e70a1f1942965f0bafe98c140683cd53", {"code_string": "class Constants(object):\n    \"\"\"Constant declarations.\"\"\"\n    API_URL = 'https://i.instagram.com/api/v1/'\n    VERSION = '9.2.0'\n    IG_SIG_KEY = '012a54f51c49aa8c5c322416ab1410909add32c966bbaa0fe3dc58ac43fd7ede'\n    EXPERIMENTS = 'ig_android_ad_holdout_16m5_universe,ig_android_progressive_jpeg,ig_creation_growth_holdout,ig_android_oppo_app_badging,ig_android_ad_remove_username_from_caption_universe,ig_android_enable_share_to_whatsapp,ig_android_direct_drawing_in_quick_cam_universe,ig_android_ad_always_send_ad_attribution_id_universe,ig_android_universe_video_production,ig_android_direct_plus_button,ig_android_ads_heatmap_overlay_universe,ig_android_http_stack_experiment_2016,ig_android_infinite_scrolling,ig_fbns_blocked,ig_android_post_auto_retry_v7_21,ig_fbns_push,ig_android_video_playback_bandwidth_threshold,ig_android_direct_link_preview,ig_android_direct_typing_indicator,ig_android_preview_capture,ig_android_feed_pill,ig_android_profile_link_iab,ig_android_story_caption,ig_android_network_cancellation,ig_android_histogram_reporter,ig_android_anrwatchdog,ig_android_search_client_matching,ig_android_follow_request_text_buttons,ig_android_feed_zoom,ig_android_drafts_universe,ig_android_disable_comment,ig_android_user_detail_endpoint,ig_android_os_version_blocking,ig_android_blocked_list,ig_android_event_creation,ig_android_high_res_upload_2,ig_android_2fac,ig_android_mark_reel_seen_on_Swipe_forward,ig_android_comment_redesign,ig_android_ad_sponsored_label_universe,ig_android_mentions_dismiss_rule,ig_android_disable_chroma_subsampling,ig_android_share_spinner,ig_android_video_reuse_surface,ig_explore_v3_android_universe,ig_android_media_favorites,ig_android_nux_holdout,ig_android_insta_video_universe,ig_android_search_null_state,ig_android_universe_reel_video_production,liger_instagram_android_univ,ig_android_direct_emoji_picker,ig_feed_holdout_universe,ig_android_direct_send_auto_retry_universe,ig_android_samsung_app_badging,ig_android_disk_usage,ig_android_business_promotion,ig_android_direct_swipe_to_inbox,ig_android_feed_reshare_button_nux,ig_android_react_native_boost_post,ig_android_boomerang_feed_attribution,ig_fbns_shared,ig_fbns_dump_ids,ig_android_react_native_universe,ig_show_promote_button_in_feed,ig_android_ad_metadata_behavior_universe,ig_android_video_loopcount_int,ig_android_inline_gallery_backoff_hours_universe,ig_android_rendering_controls,ig_android_profile_photo_as_media,ig_android_async_stack_image_cache,ig_video_max_duration_qe_preuniverse,ig_video_copyright_whitelist,ig_android_render_stories_with_content_override,ig_android_ad_intent_to_highlight_universe,ig_android_swipe_navigation_x_angle_universe,ig_android_disable_comment_public_test,ig_android_profile,ig_android_direct_blue_tab,ig_android_enable_share_to_messenger,ig_android_fetch_reel_tray_on_resume_universe,ig_android_promote_again,ig_feed_event_landing_page_channel,ig_ranking_following,ig_android_pending_request_search_bar,ig_android_feed_ufi_redesign,ig_android_pending_edits_dialog_universe,ig_android_business_conversion_flow_universe,ig_android_show_your_story_when_empty_universe,ig_android_ad_drop_cookie_early,ig_android_app_start_config,ig_android_fix_ise_two_phase,ig_android_ppage_toggle_universe,ig_android_pbia_normal_weight_universe,ig_android_profanity_filter,ig_ios_su_activity_feed,ig_android_search,ig_android_boomerang_entry,ig_android_mute_story,ig_android_inline_gallery_universe,ig_android_ad_remove_one_tap_indicator_universe,ig_android_view_count_decouple_likes_universe,ig_android_contact_button_redesign_v2,ig_android_periodic_analytics_upload_v2,ig_android_send_direct_typing_indicator,ig_android_ad_holdout_16h2m1_universe,ig_android_react_native_comment_moderation_settings,ig_video_use_sve_universe,ig_android_inline_gallery_no_backoff_on_launch_universe,ig_android_immersive_viewer,ig_android_discover_people_icon,ig_android_profile_follow_back_button,is_android_feed_seen_state,ig_android_dense_feed_unit_cards,ig_android_drafts_video_universe,ig_android_exoplayer,ig_android_add_to_last_post,ig_android_ad_remove_cta_chevron_universe,ig_android_ad_comment_cta_universe,ig_android_ad_chevron_universe,ig_android_ad_comment_cta_universe,ig_android_search_event_icon,ig_android_channels_home,ig_android_feed,ig_android_dv2_realtime_private_share,ig_android_non_square_first,ig_android_video_interleaved_v2,ig_android_video_cache_policy,ig_android_react_native_universe_kill_switch,ig_android_video_captions_universe,ig_android_follow_search_bar,ig_android_last_edits,ig_android_two_step_capture_flow,ig_android_video_download_logging,ig_android_share_link_to_whatsapp,ig_android_facebook_twitter_profile_photos,ig_android_swipeable_filters_blacklist,ig_android_ad_pbia_profile_tap_universe,ig_android_use_software_layer_for_kc_drawing_universe,ig_android_react_native_ota,ig_android_direct_mutually_exclusive_experiment_universe,ig_android_following_follower_social_context'\n    LOGIN_EXPERIMENTS = 'ig_android_reg_login_btn_active_state,ig_android_ci_opt_in_at_reg,ig_android_one_click_in_old_flow,ig_android_merge_fb_and_ci_friends_page,ig_android_non_fb_sso,ig_android_mandatory_full_name,ig_android_reg_enable_login_password_btn,ig_android_reg_phone_email_active_state,ig_android_analytics_data_loss,ig_fbns_blocked,ig_android_contact_point_triage,ig_android_reg_next_btn_active_state,ig_android_prefill_phone_number,ig_android_show_fb_social_context_in_nux,ig_android_one_tap_login_upsell,ig_fbns_push,ig_android_phoneid_sync_interval'\n    SIG_KEY_VERSION = '4'\n    ANDROID_VERSION = 18\n    ANDROID_RELEASE = '4.3'\n", "code_toks_joined": "class Constants ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> API_URL = <STRING> <NEWLINE> VERSION = <STRING> <NEWLINE> IG_SIG_KEY = <STRING> <NEWLINE> EXPERIMENTS = <STRING> <NEWLINE> LOGIN_EXPERIMENTS = <STRING> <NEWLINE> SIG_KEY_VERSION = <STRING> <NEWLINE> ANDROID_VERSION = 18 <NEWLINE> ANDROID_RELEASE = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Constant declarations.\"\"\"", "'https://i.instagram.com/api/v1/'", "'9.2.0'", "'012a54f51c49aa8c5c322416ab1410909add32c966bbaa0fe3dc58ac43fd7ede'", "'ig_android_ad_holdout_16m5_universe,ig_android_progressive_jpeg,ig_creation_growth_holdout,ig_android_oppo_app_badging,ig_android_ad_remove_username_from_caption_universe,ig_android_enable_share_to_whatsapp,ig_android_direct_drawing_in_quick_cam_universe,ig_android_ad_always_send_ad_attribution_id_universe,ig_android_universe_video_production,ig_android_direct_plus_button,ig_android_ads_heatmap_overlay_universe,ig_android_http_stack_experiment_2016,ig_android_infinite_scrolling,ig_fbns_blocked,ig_android_post_auto_retry_v7_21,ig_fbns_push,ig_android_video_playback_bandwidth_threshold,ig_android_direct_link_preview,ig_android_direct_typing_indicator,ig_android_preview_capture,ig_android_feed_pill,ig_android_profile_link_iab,ig_android_story_caption,ig_android_network_cancellation,ig_android_histogram_reporter,ig_android_anrwatchdog,ig_android_search_client_matching,ig_android_follow_request_text_buttons,ig_android_feed_zoom,ig_android_drafts_universe,ig_android_disable_comment,ig_android_user_detail_endpoint,ig_android_os_version_blocking,ig_android_blocked_list,ig_android_event_creation,ig_android_high_res_upload_2,ig_android_2fac,ig_android_mark_reel_seen_on_Swipe_forward,ig_android_comment_redesign,ig_android_ad_sponsored_label_universe,ig_android_mentions_dismiss_rule,ig_android_disable_chroma_subsampling,ig_android_share_spinner,ig_android_video_reuse_surface,ig_explore_v3_android_universe,ig_android_media_favorites,ig_android_nux_holdout,ig_android_insta_video_universe,ig_android_search_null_state,ig_android_universe_reel_video_production,liger_instagram_android_univ,ig_android_direct_emoji_picker,ig_feed_holdout_universe,ig_android_direct_send_auto_retry_universe,ig_android_samsung_app_badging,ig_android_disk_usage,ig_android_business_promotion,ig_android_direct_swipe_to_inbox,ig_android_feed_reshare_button_nux,ig_android_react_native_boost_post,ig_android_boomerang_feed_attribution,ig_fbns_shared,ig_fbns_dump_ids,ig_android_react_native_universe,ig_show_promote_button_in_feed,ig_android_ad_metadata_behavior_universe,ig_android_video_loopcount_int,ig_android_inline_gallery_backoff_hours_universe,ig_android_rendering_controls,ig_android_profile_photo_as_media,ig_android_async_stack_image_cache,ig_video_max_duration_qe_preuniverse,ig_video_copyright_whitelist,ig_android_render_stories_with_content_override,ig_android_ad_intent_to_highlight_universe,ig_android_swipe_navigation_x_angle_universe,ig_android_disable_comment_public_test,ig_android_profile,ig_android_direct_blue_tab,ig_android_enable_share_to_messenger,ig_android_fetch_reel_tray_on_resume_universe,ig_android_promote_again,ig_feed_event_landing_page_channel,ig_ranking_following,ig_android_pending_request_search_bar,ig_android_feed_ufi_redesign,ig_android_pending_edits_dialog_universe,ig_android_business_conversion_flow_universe,ig_android_show_your_story_when_empty_universe,ig_android_ad_drop_cookie_early,ig_android_app_start_config,ig_android_fix_ise_two_phase,ig_android_ppage_toggle_universe,ig_android_pbia_normal_weight_universe,ig_android_profanity_filter,ig_ios_su_activity_feed,ig_android_search,ig_android_boomerang_entry,ig_android_mute_story,ig_android_inline_gallery_universe,ig_android_ad_remove_one_tap_indicator_universe,ig_android_view_count_decouple_likes_universe,ig_android_contact_button_redesign_v2,ig_android_periodic_analytics_upload_v2,ig_android_send_direct_typing_indicator,ig_android_ad_holdout_16h2m1_universe,ig_android_react_native_comment_moderation_settings,ig_video_use_sve_universe,ig_android_inline_gallery_no_backoff_on_launch_universe,ig_android_immersive_viewer,ig_android_discover_people_icon,ig_android_profile_follow_back_button,is_android_feed_seen_state,ig_android_dense_feed_unit_cards,ig_android_drafts_video_universe,ig_android_exoplayer,ig_android_add_to_last_post,ig_android_ad_remove_cta_chevron_universe,ig_android_ad_comment_cta_universe,ig_android_ad_chevron_universe,ig_android_ad_comment_cta_universe,ig_android_search_event_icon,ig_android_channels_home,ig_android_feed,ig_android_dv2_realtime_private_share,ig_android_non_square_first,ig_android_video_interleaved_v2,ig_android_video_cache_policy,ig_android_react_native_universe_kill_switch,ig_android_video_captions_universe,ig_android_follow_search_bar,ig_android_last_edits,ig_android_two_step_capture_flow,ig_android_video_download_logging,ig_android_share_link_to_whatsapp,ig_android_facebook_twitter_profile_photos,ig_android_swipeable_filters_blacklist,ig_android_ad_pbia_profile_tap_universe,ig_android_use_software_layer_for_kc_drawing_universe,ig_android_react_native_ota,ig_android_direct_mutually_exclusive_experiment_universe,ig_android_following_follower_social_context'", "'ig_android_reg_login_btn_active_state,ig_android_ci_opt_in_at_reg,ig_android_one_click_in_old_flow,ig_android_merge_fb_and_ci_friends_page,ig_android_non_fb_sso,ig_android_mandatory_full_name,ig_android_reg_enable_login_password_btn,ig_android_reg_phone_email_active_state,ig_android_analytics_data_loss,ig_fbns_blocked,ig_android_contact_point_triage,ig_android_reg_next_btn_active_state,ig_android_prefill_phone_number,ig_android_show_fb_social_context_in_nux,ig_android_one_tap_login_upsell,ig_fbns_push,ig_android_phoneid_sync_interval'", "'4'", "'4.3'"]}}], ["ac2f2e2ed2350152a38a1ace7b93b0dd", {"code_string": "__revision__ = \"__FILE__ __REVISION__ __DATE__ __DEVELOPER__\"\nimport TestSCons\ntest = TestSCons.TestSCons()\ntest.write('SConstruct', \"\")\ntest.run(arguments = '-Z',\n    stderr = \"\"\"usage: scons [OPTION] [TARGET] ...\"\"\",\n    status = 2)\ntest.run(arguments = '--ZizzerZazzerZuzz',\n    stderr = \"\"\"usage: scons [OPTION] [TARGET] ...\"\"\",\n    status = 2)\ntest.pass_test()\n", "code_toks_joined": "__revision__ = <STRING> <NEWLINE> import TestSCons <NEWLINE> test = TestSCons . TestSCons ( ) <NEWLINE> test . write ( <STRING> , <STRING> ) <NEWLINE> test . run ( arguments = <STRING> , <NEWLINE> <INDENT> stderr = <STRING> , <NEWLINE> status = 2 ) <NEWLINE> <DEDENT> test . run ( arguments = <STRING> , <NEWLINE> <INDENT> stderr = <STRING> , <NEWLINE> status = 2 ) <NEWLINE> <DEDENT> test . pass_test ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"__FILE__ __REVISION__ __DATE__ __DEVELOPER__\"", "'SConstruct'", "\"\"", "'-Z'", "\"\"\"usage: scons [OPTION] [TARGET] ...\"\"\"", "'--ZizzerZazzerZuzz'", "\"\"\"usage: scons [OPTION] [TARGET] ...\"\"\""]}}], ["b81e8f7d3193ab8a2c6f34d402517882", {"code_string": "def _dense(attrs):\n    op_name, new_attrs = 'dense', {}\n    new_attrs['units'] = _required_attr(attrs, 'num_hidden')\n    new_attrs['use_bias'] = not _parse_bool_str(attrs, 'no_bias')\n    major, minor, micro = _get_mxnet_version()\n    if major >= 0 and minor >= 11 and micro >= 1:\n        new_attrs['flatten'] = _parse_bool_str(attrs, 'flatten', 'True')\n    return op_name, new_attrs\n", "code_toks_joined": "def _dense ( attrs ) : <NEWLINE> <INDENT> op_name , new_attrs = <STRING> , { } <NEWLINE> new_attrs [ <STRING> ] = _required_attr ( attrs , <STRING> ) <NEWLINE> new_attrs [ <STRING> ] = not _parse_bool_str ( attrs , <STRING> ) <NEWLINE> major , minor , micro = _get_mxnet_version ( ) <NEWLINE> if major >= 0 and minor >= 11 and micro >= 1 : <NEWLINE> <INDENT> new_attrs [ <STRING> ] = _parse_bool_str ( attrs , <STRING> , <STRING> ) <NEWLINE> <DEDENT> return op_name , new_attrs <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'dense'", "'units'", "'num_hidden'", "'use_bias'", "'no_bias'", "'flatten'", "'flatten'", "'True'"]}}], ["3c29d259ee46641a8f46d5ae4fcdac1d", {"code_string": "class IfOperStatusIfTable(SnmpTable):\n    def table_names(self):\n        return 'ifOperStatus'\n    def ifOperStatus_translator(self, snmp_dict):\n        self.data = {}\n        for x in snmp_dict['vars']:\n            self.data[int(x.iid)] = self.normalize(x)\n    def py_obj(self):\n        return self.data\n", "code_toks_joined": "class IfOperStatusIfTable ( SnmpTable ) : <NEWLINE> <INDENT> def table_names ( self ) : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> def ifOperStatus_translator ( self , snmp_dict ) : <NEWLINE> <INDENT> self . data = { } <NEWLINE> for x in snmp_dict [ <STRING> ] : <NEWLINE> <INDENT> self . data [ int ( x . iid ) ] = self . normalize ( x ) <NEWLINE> <DEDENT> <DEDENT> def py_obj ( self ) : <NEWLINE> <INDENT> return self . data <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'ifOperStatus'", "'vars'"]}}], ["6ad91e759702b998096ea2ee7b14b84b", {"code_string": "def check_request_method(method):\n    if method.upper() != 'GET':\n        return 500\n", "code_toks_joined": "def check_request_method ( method ) : <NEWLINE> <INDENT> if method . upper ( ) != <STRING> : <NEWLINE> <INDENT> return 500 <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'GET'"]}}], ["091d28b662df9ce09d000a344508bb81", {"code_string": "def config_setup():\n    config = Config()\n    config.trace_filter = GlobbingFilter(include = ['hangman.*'])\n    return config\n", "code_toks_joined": "def config_setup ( ) : <NEWLINE> <INDENT> config = Config ( ) <NEWLINE> config . trace_filter = GlobbingFilter ( include = [ <STRING> ] ) <NEWLINE> return config <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'hangman.*'"]}}], ["0a02851312935001166aa2dd87005345", {"code_string": "class Solution:\n    \"\"\"@param root: The root of binary tree.\"\"\"\n    def isValidBST(self, root):\n        def validate(bst, mini, maxi):\n            if(bst is None):\n                return True\n            if(bst.val <= mini or bst.val >= maxi):\n                return False\n            isLeftValid = validate(bst.left, mini, bst.val)\n            isRightValid = validate(bst.right, bst.val, maxi)\n            return isLeftValid and isRightValid\n        return validate(root, - sys.maxsize - 1, sys.maxsize)\n", "code_toks_joined": "class Solution : <NEWLINE> <INDENT> <STRING> <NEWLINE> def isValidBST ( self , root ) : <NEWLINE> <INDENT> def validate ( bst , mini , maxi ) : <NEWLINE> <INDENT> if ( bst is None ) : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> if ( bst . val <= mini or bst . val >= maxi ) : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> isLeftValid = validate ( bst . left , mini , bst . val ) <NEWLINE> isRightValid = validate ( bst . right , bst . val , maxi ) <NEWLINE> return isLeftValid and isRightValid <NEWLINE> <DEDENT> return validate ( root , - sys . maxsize - 1 , sys . maxsize ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"@param root: The root of binary tree.\"\"\""]}}], ["59b0f19fa912278b6043ec4ec1542259", {"code_string": "def checar(cliente_sat):\n    \"\"\"Checa em sequ\u00eancia os alertas registrados (veja :func:`registrar`) contra os\"\"\"\n    resposta = cliente_sat.consultar_status_operacional()\n    alertas = []\n    for classe_alerta in AlertaOperacao.alertas_registrados:\n        alerta = classe_alerta(resposta)\n        if alerta.checar():\n            alertas.append(alerta)\n    return alertas\n", "code_toks_joined": "def checar ( cliente_sat ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> resposta = cliente_sat . consultar_status_operacional ( ) <NEWLINE> alertas = [ ] <NEWLINE> for classe_alerta in AlertaOperacao . alertas_registrados : <NEWLINE> <INDENT> alerta = classe_alerta ( resposta ) <NEWLINE> if alerta . checar ( ) : <NEWLINE> <INDENT> alertas . append ( alerta ) <NEWLINE> <DEDENT> <DEDENT> return alertas <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Checa em sequ\u00eancia os alertas registrados (veja :func:`registrar`) contra os\"\"\""]}}], ["40a8740afe6a5e4f8a7772cf8db04970", {"code_string": "def _check_recursion(self, cr, uid, ids, context = None):\n    level = 100\n    while len(ids):\n        cr.execute(\n            'select distinct parent_id from hr_job where id IN %s',\n            (tuple(ids), )\n        )\n        ids = filter(None, map(lambda x: x[0], cr.fetchall()))\n        if not level:\n            return False\n        level -= 1\n    return True\n", "code_toks_joined": "def _check_recursion ( self , cr , uid , ids , context = None ) : <NEWLINE> <INDENT> level = 100 <NEWLINE> while len ( ids ) : <NEWLINE> <INDENT> cr . execute ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> ( tuple ( ids ) , ) <NEWLINE> <DEDENT> ) <NEWLINE> ids = filter ( None , map ( lambda x : x [ 0 ] , cr . fetchall ( ) ) ) <NEWLINE> if not level : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> level -= 1 <NEWLINE> <DEDENT> return True <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'select distinct parent_id from hr_job where id IN %s'"]}}], ["20c034efab012311050aee06e05d09e3", {"code_string": "class FluentdHttpIntegration(Integration):\n    def __init__(self, fluentd_http_url):\n        self.fluentd_http_url = fluentd_http_url\n    def after_function(self, func_name, args, kwargs, result):\n        status_code = requests.post(\n            self.fluentd_http_url,\n            data = json.dumps({\n                \"func_name\": func_name,\n                \"args\": args,\n                \"kwargs\": kwargs,\n                \"result\": result\n            })\n        ).status_code\n        if status_code >= 400:\n            sys.stderr.write(\"Fluentd transmission failed.\\n\")\n", "code_toks_joined": "class FluentdHttpIntegration ( Integration ) : <NEWLINE> <INDENT> def __init__ ( self , fluentd_http_url ) : <NEWLINE> <INDENT> self . fluentd_http_url = fluentd_http_url <NEWLINE> <DEDENT> def after_function ( self , func_name , args , kwargs , result ) : <NEWLINE> <INDENT> status_code = requests . post ( <NEWLINE> <INDENT> self . fluentd_http_url , <NEWLINE> data = json . dumps ( { <NEWLINE> <INDENT> <STRING> : func_name , <NEWLINE> <STRING> : args , <NEWLINE> <STRING> : kwargs , <NEWLINE> <STRING> : result <NEWLINE> <DEDENT> } ) <NEWLINE> <DEDENT> ) . status_code <NEWLINE> if status_code >= 400 : <NEWLINE> <INDENT> sys . stderr . write ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"func_name\"", "\"args\"", "\"kwargs\"", "\"result\"", "\"Fluentd transmission failed.\\n\""]}}], ["b1cb2e887f8ce16169f20541b7f4b3cb", {"code_string": "def store(path, l):\n    f = open(path, \"w\")\n    for w in l:\n        w = u\"%s\\n\" % w\n        f.write(w.encode(\"utf-8\"))\n    f.close()\n", "code_toks_joined": "def store ( path , l ) : <NEWLINE> <INDENT> f = open ( path , <STRING> ) <NEWLINE> for w in l : <NEWLINE> <INDENT> w = <STRING> % w <NEWLINE> f . write ( w . encode ( <STRING> ) ) <NEWLINE> <DEDENT> f . close ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"w\"", "u\"%s\\n\"", "\"utf-8\""]}}], ["9185d73cd53b629ba7c196df914b23fb", {"code_string": "def Goal(self):\n    if self.lex.token in['num', 'var', '(']:\n        val = self.Expr()\n        self.lex.match('\\0')\n        print(val)\n    elif self.lex.token == 'set':\n        self.Assign()\n        self.lex.match('\\0')\n    else:\n        raise SyntaxError()\n", "code_toks_joined": "def Goal ( self ) : <NEWLINE> <INDENT> if self . lex . token in [ <STRING> , <STRING> , <STRING> ] : <NEWLINE> <INDENT> val = self . Expr ( ) <NEWLINE> self . lex . match ( <STRING> ) <NEWLINE> print ( val ) <NEWLINE> <DEDENT> elif self . lex . token == <STRING> : <NEWLINE> <INDENT> self . Assign ( ) <NEWLINE> self . lex . match ( <STRING> ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> raise SyntaxError ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'num'", "'var'", "'('", "'\\0'", "'set'", "'\\0'"]}}], ["6140ae7505f4410ceee7e3e363f1b0f4", {"code_string": "def check_changed(self, new_params):\n    if self.check_exists():\n        old_params = self.get_params()\n        if \"signal_processing\" not in old_params:\n            old_params[\"signal_processing\"] = \"mfcc\"\n        if \"language\" not in old_params:\n            old_params[\"language\"] = \"\"\n        return old_params[\"num_layers\"] != new_params[\"num_layers\"] or old_params[\"hidden_size\"] != new_params[\"hidden_size\"] or old_params[\"signal_processing\"] != new_params[\"signal_processing\"] or old_params[\"language\"] != new_params[\"language\"]\n    else:\n        return False\n", "code_toks_joined": "def check_changed ( self , new_params ) : <NEWLINE> <INDENT> if self . check_exists ( ) : <NEWLINE> <INDENT> old_params = self . get_params ( ) <NEWLINE> if <STRING> not in old_params : <NEWLINE> <INDENT> old_params [ <STRING> ] = <STRING> <NEWLINE> <DEDENT> if <STRING> not in old_params : <NEWLINE> <INDENT> old_params [ <STRING> ] = <STRING> <NEWLINE> <DEDENT> return old_params [ <STRING> ] != new_params [ <STRING> ] or old_params [ <STRING> ] != new_params [ <STRING> ] or old_params [ <STRING> ] != new_params [ <STRING> ] or old_params [ <STRING> ] != new_params [ <STRING> ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"signal_processing\"", "\"signal_processing\"", "\"mfcc\"", "\"language\"", "\"language\"", "\"\"", "\"num_layers\"", "\"num_layers\"", "\"hidden_size\"", "\"hidden_size\"", "\"signal_processing\"", "\"signal_processing\"", "\"language\"", "\"language\""]}}], ["da411f71bfd835c9c3c2c06c19c0af2e", {"code_string": "\"\"\"Extras for django-taggit\"\"\"\nimport operator\nfrom django.db import router\nfrom django.db.models.fields import BLANK_CHOICE_DASH\nfrom django.contrib.auth.models import AnonymousUser\nfrom taggit.managers import TaggableManager, _TaggableManager\nfrom taggit.models import GenericTaggedItemBase, Tag\nfrom taggit.utils import edit_string_for_tags, require_instance_manager\n", "code_toks_joined": "<STRING> <NEWLINE> import operator <NEWLINE> from django . db import router <NEWLINE> from django . db . models . fields import BLANK_CHOICE_DASH <NEWLINE> from django . contrib . auth . models import AnonymousUser <NEWLINE> from taggit . managers import TaggableManager , _TaggableManager <NEWLINE> from taggit . models import GenericTaggedItemBase , Tag <NEWLINE> from taggit . utils import edit_string_for_tags , require_instance_manager <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Extras for django-taggit\"\"\""]}}], ["830ce69be34e52ff611a75d269003bb5", {"code_string": "def allow_all_perms_policy(wbrequest):\n    \"\"\"Perms policy which always returns a default Perms object\"\"\"\n    return Perms()\n", "code_toks_joined": "def allow_all_perms_policy ( wbrequest ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return Perms ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Perms policy which always returns a default Perms object\"\"\""]}}], ["fb0a8e1d8dbbb55eff239ec19ae0703c", {"code_string": "def __init__(self, path, listeners):\n    self.cs = None\n    self.listeners = listeners\n    inputFile = open(path)\n    try:\n        for line in inputFile:\n            self.parseLine(line)\n    finally:\n        inputFile.close()\n    for listener in self.listeners:\n        listener.finishGroup()\n", "code_toks_joined": "def __init__ ( self , path , listeners ) : <NEWLINE> <INDENT> self . cs = None <NEWLINE> self . listeners = listeners <NEWLINE> inputFile = open ( path ) <NEWLINE> try : <NEWLINE> <INDENT> for line in inputFile : <NEWLINE> <INDENT> self . parseLine ( line ) <NEWLINE> <DEDENT> <DEDENT> finally : <NEWLINE> <INDENT> inputFile . close ( ) <NEWLINE> <DEDENT> for listener in self . listeners : <NEWLINE> <INDENT> listener . finishGroup ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["1549093713ce09569d044e62441c141c", {"code_string": "def on_access(self):\n    self._current_access_list = self.cards_to_access()\n    self._current_rnd_access_list = self.rnd_cards_to_access()\n    self.game.register_choice_provider(\n        timing_phases.ApproachServer_4_5, self, 'access_cards_actions')\n", "code_toks_joined": "def on_access ( self ) : <NEWLINE> <INDENT> self . _current_access_list = self . cards_to_access ( ) <NEWLINE> self . _current_rnd_access_list = self . rnd_cards_to_access ( ) <NEWLINE> self . game . register_choice_provider ( <NEWLINE> <INDENT> timing_phases . ApproachServer_4_5 , self , <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'access_cards_actions'"]}}], ["d7098e94b1de6c524562cbe90a467a63", {"code_string": "def __set__(self, obj, value):\n    if self.setter:\n        if self.cast_to:\n            setattr(_CastTo(obj.__dict__[self.zos_interface_attr], self.cast_to), self.property_name, value)\n        else:\n            setattr(obj.__dict__[self.zos_interface_attr], self.property_name, value)\n    else:\n        raise AttributeError(\"Can't set {}\".format(self.property_name))\n", "code_toks_joined": "def __set__ ( self , obj , value ) : <NEWLINE> <INDENT> if self . setter : <NEWLINE> <INDENT> if self . cast_to : <NEWLINE> <INDENT> setattr ( _CastTo ( obj . __dict__ [ self . zos_interface_attr ] , self . cast_to ) , self . property_name , value ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> setattr ( obj . __dict__ [ self . zos_interface_attr ] , self . property_name , value ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> raise AttributeError ( <STRING> . format ( self . property_name ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Can't set {}\""]}}], ["822cd3d0bf9563a2c91892ceb4bce108", {"code_string": "def get_description_custom(self):\n    \"\"\"Create a custom, abbreviated description for a game.\"\"\"\n    if self.game_dict:\n        desc = self.game_dict.get('_description', '')[0: self.short]\n        _cut = int(\n            (len(desc) -\n                len(desc.replace(',', '').replace('.', '').replace(':', '')))\n            / 2 + self.short)\n        desc = self.game_dict.get('_description', '')[0: _cut]\n        return desc[0: - 3] + '...'\n", "code_toks_joined": "def get_description_custom ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if self . game_dict : <NEWLINE> <INDENT> desc = self . game_dict . get ( <STRING> , <STRING> ) [ 0 : self . short ] <NEWLINE> _cut = int ( <NEWLINE> <INDENT> ( len ( desc ) - <NEWLINE> <INDENT> len ( desc . replace ( <STRING> , <STRING> ) . replace ( <STRING> , <STRING> ) . replace ( <STRING> , <STRING> ) ) ) <NEWLINE> <DEDENT> / 2 + self . short ) <NEWLINE> <DEDENT> desc = self . game_dict . get ( <STRING> , <STRING> ) [ 0 : _cut ] <NEWLINE> return desc [ 0 : - 3 ] + <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Create a custom, abbreviated description for a game.\"\"\"", "'_description'", "''", "','", "''", "'.'", "''", "':'", "''", "'_description'", "''", "'...'"]}}], ["338e02e9275d6abdd1efa84821f3e258", {"code_string": "def loadSettings(self):\n    s = QSettings()\n    s.beginGroup(\"global_font_dialog\")\n    roman = s.value(\"roman\", \"Century Schoolbook L\", str)\n    self.romanCombo.setCurrentFont(QFont(roman))\n    sans = s.value(\"sans\", \"sans-serif\", str)\n    self.sansCombo.setCurrentFont(QFont(sans))\n    typewriter = s.value(\"typewriter\", \"monospace\", str)\n    self.typewriterCombo.setCurrentFont(QFont(typewriter))\n", "code_toks_joined": "def loadSettings ( self ) : <NEWLINE> <INDENT> s = QSettings ( ) <NEWLINE> s . beginGroup ( <STRING> ) <NEWLINE> roman = s . value ( <STRING> , <STRING> , str ) <NEWLINE> self . romanCombo . setCurrentFont ( QFont ( roman ) ) <NEWLINE> sans = s . value ( <STRING> , <STRING> , str ) <NEWLINE> self . sansCombo . setCurrentFont ( QFont ( sans ) ) <NEWLINE> typewriter = s . value ( <STRING> , <STRING> , str ) <NEWLINE> self . typewriterCombo . setCurrentFont ( QFont ( typewriter ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"global_font_dialog\"", "\"roman\"", "\"Century Schoolbook L\"", "\"sans\"", "\"sans-serif\"", "\"typewriter\"", "\"monospace\""]}}], ["fe632857174259130191eb1ef5e4c1c2", {"code_string": "def has_plugin_permission(user, plugin_type, permission_type):\n    \"\"\"Checks that a user has permissions for the plugin-type given to perform\"\"\"\n    from cms.plugin_pool import plugin_pool\n    plugin_class = plugin_pool.get_plugin(plugin_type)\n    plugin_model = plugin_class.model\n    plugin_opts = plugin_model._meta\n    return user.has_perm('%s.%s_%s' %(plugin_opts.app_label, permission_type,\n        plugin_opts.object_name.lower()))\n", "code_toks_joined": "def has_plugin_permission ( user , plugin_type , permission_type ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> from cms . plugin_pool import plugin_pool <NEWLINE> plugin_class = plugin_pool . get_plugin ( plugin_type ) <NEWLINE> plugin_model = plugin_class . model <NEWLINE> plugin_opts = plugin_model . _meta <NEWLINE> return user . has_perm ( <STRING> % ( plugin_opts . app_label , permission_type , <NEWLINE> <INDENT> plugin_opts . object_name . lower ( ) ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Checks that a user has permissions for the plugin-type given to perform\"\"\"", "'%s.%s_%s'"]}}], ["23683cff3bc139d2f0d6b1955edb6b5f", {"code_string": "def __load_rom_content(self, filename):\n    fd = open(filename, 'r')\n    i = 0\n    for line in fd:\n        temp_data = line.split()\n        for t in temp_data:\n            self.__data[i] = int(t, 16)\n            i = i + 1\n", "code_toks_joined": "def __load_rom_content ( self , filename ) : <NEWLINE> <INDENT> fd = open ( filename , <STRING> ) <NEWLINE> i = 0 <NEWLINE> for line in fd : <NEWLINE> <INDENT> temp_data = line . split ( ) <NEWLINE> for t in temp_data : <NEWLINE> <INDENT> self . __data [ i ] = int ( t , 16 ) <NEWLINE> i = i + 1 <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'r'"]}}], ["5fd799eb83622d28c92c3495e9fffbbe", {"code_string": "class PerfilForm(ModelForm):\n    class Meta:\n        model = Perfil\n        widgets = {\n            'descripcio': Textarea(attrs = {'cols': 20, 'rows': 5})\n            }\n        fields = ['descripcio', 'nick']\n", "code_toks_joined": "class PerfilForm ( ModelForm ) : <NEWLINE> <INDENT> class Meta : <NEWLINE> <INDENT> model = Perfil <NEWLINE> widgets = { <NEWLINE> <INDENT> <STRING> : Textarea ( attrs = { <STRING> : 20 , <STRING> : 5 } ) <NEWLINE> } <NEWLINE> <DEDENT> fields = [ <STRING> , <STRING> ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'descripcio'", "'cols'", "'rows'", "'descripcio'", "'nick'"]}}], ["c16cf8d9f432ae583d4f7f5f0a3ba14b", {"code_string": "class Whitewater(FixtureTest):\n    def test_put_in_egress(self):\n        self.load_fixtures(['https://www.openstreetmap.org/node/3134398100'])\n        self.assert_has_feature(\n            16, 19591, 23939, 'pois',\n            {'kind': 'put_in_egress'})\n    def test_portage_way(self):\n        self.load_fixtures(['https://www.openstreetmap.org/way/308154534'])\n        self.assert_has_feature(\n            13, 2448, 2992, 'roads',\n            {'kind': 'portage_way'})\n", "code_toks_joined": "class Whitewater ( FixtureTest ) : <NEWLINE> <INDENT> def test_put_in_egress ( self ) : <NEWLINE> <INDENT> self . load_fixtures ( [ <STRING> ] ) <NEWLINE> self . assert_has_feature ( <NEWLINE> <INDENT> 16 , 19591 , 23939 , <STRING> , <NEWLINE> { <STRING> : <STRING> } ) <NEWLINE> <DEDENT> <DEDENT> def test_portage_way ( self ) : <NEWLINE> <INDENT> self . load_fixtures ( [ <STRING> ] ) <NEWLINE> self . assert_has_feature ( <NEWLINE> <INDENT> 13 , 2448 , 2992 , <STRING> , <NEWLINE> { <STRING> : <STRING> } ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'https://www.openstreetmap.org/node/3134398100'", "'pois'", "'kind'", "'put_in_egress'", "'https://www.openstreetmap.org/way/308154534'", "'roads'", "'kind'", "'portage_way'"]}}], ["3c67ec1016a6aa72181586d6bc22b699", {"code_string": "def retrieve_data(target):\n    url, values, path = target\n    req_data = urllib.urlencode(values)\n    req = urllib2.Request(url, req_data)\n    response = urllib2.urlopen(req)\n    data = response.read()\n    if not data:\n        return\n    data = data.strip()\n    data = data.replace('<br />', '')\n    if data:\n        dill_save_obj(data, path)\n", "code_toks_joined": "def retrieve_data ( target ) : <NEWLINE> <INDENT> url , values , path = target <NEWLINE> req_data = urllib . urlencode ( values ) <NEWLINE> req = urllib2 . Request ( url , req_data ) <NEWLINE> response = urllib2 . urlopen ( req ) <NEWLINE> data = response . read ( ) <NEWLINE> if not data : <NEWLINE> <INDENT> return <NEWLINE> <DEDENT> data = data . strip ( ) <NEWLINE> data = data . replace ( <STRING> , <STRING> ) <NEWLINE> if data : <NEWLINE> <INDENT> dill_save_obj ( data , path ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'<br />'", "''"]}}], ["97a3b881ecceb383bf49677764b7556c", {"code_string": "import os\nimport json\nfrom datetime import datetime, date\nfrom decimal import Decimal\n", "code_toks_joined": "import os <NEWLINE> import json <NEWLINE> from datetime import datetime , date <NEWLINE> from decimal import Decimal <NEWLINE>", "anonymize_dict": {}}], ["cc14c3f1d0dc126c46756b076153fc12", {"code_string": "import sys\nimport atrshmlog\nid = int(sys.argv[1])\nprint('delete : ' + str(id) + ' : ')\nr = atrshmlog.delete(id)\nprint('delete : ' + str(r) + ' : ')\nprint(' ')\nexit(0);\n", "code_toks_joined": "import sys <NEWLINE> import atrshmlog <NEWLINE> id = int ( sys . argv [ 1 ] ) <NEWLINE> print ( <STRING> + str ( id ) + <STRING> ) <NEWLINE> r = atrshmlog . delete ( id ) <NEWLINE> print ( <STRING> + str ( r ) + <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> exit ( 0 ) ; <NEWLINE>", "anonymize_dict": {"<STRING>": ["'delete : '", "' : '", "'delete : '", "' : '", "' '"]}}], ["aa40add52526dd7438b397b3e91db4db", {"code_string": "def map_filter(obj):\n    obj['other'] = 2\n    return obj\n", "code_toks_joined": "def map_filter ( obj ) : <NEWLINE> <INDENT> obj [ <STRING> ] = 2 <NEWLINE> return obj <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'other'"]}}], ["4801b4047343cdd50560304362deec9f", {"code_string": "class Localizable(object):\n    \"\"\"Common interface for Metrics, Rules and Reports.\"\"\"\n    def __init__(self, ID, language, brief, description):\n        \"\"\"Initializer.\"\"\"\n        super(Localizable, self).__init__()\n        self.ID = ID\n        self.language = language\n        self.brief = brief\n        self.description = description\n", "code_toks_joined": "class Localizable ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , ID , language , brief , description ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> super ( Localizable , self ) . __init__ ( ) <NEWLINE> self . ID = ID <NEWLINE> self . language = language <NEWLINE> self . brief = brief <NEWLINE> self . description = description <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Common interface for Metrics, Rules and Reports.\"\"\"", "\"\"\"Initializer.\"\"\""]}}], ["7f4c2e74a0b11f14e5dadb4982194a23", {"code_string": "def google_voice_login(email, passwd):\n    \"\"\"Logs into your Google Voice account with your full email address\"\"\"\n    global _voice\n    if not _gv_available:\n        print(\"The pygooglevoice Python package is required \" \"in order to use Google Voice.\", file = sys.stderr)\n        return\n    _voice = googlevoice.Voice()\n    _voice.login(email, passwd)\n", "code_toks_joined": "def google_voice_login ( email , passwd ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> global _voice <NEWLINE> if not _gv_available : <NEWLINE> <INDENT> print ( <STRING> <STRING> , file = sys . stderr ) <NEWLINE> return <NEWLINE> <DEDENT> _voice = googlevoice . Voice ( ) <NEWLINE> _voice . login ( email , passwd ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Logs into your Google Voice account with your full email address\"\"\"", "\"The pygooglevoice Python package is required \"", "\"in order to use Google Voice.\""]}}], ["939b5e1bda34aabbf55002fa93436fbe", {"code_string": "\"\"\"\"\"\"\n__version__ = \"$Id$\"\nimport smtpd\nimport asyncore\nserver = smtpd.DebuggingServer(('127.0.0.1', 1025), None)\nasyncore.loop()\n", "code_toks_joined": "<STRING> <NEWLINE> __version__ = <STRING> <NEWLINE> import smtpd <NEWLINE> import asyncore <NEWLINE> server = smtpd . DebuggingServer ( ( <STRING> , 1025 ) , None ) <NEWLINE> asyncore . loop ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"\"\"\"", "\"$Id$\"", "'127.0.0.1'"]}}], ["901679541ca87423807808415f97d443", {"code_string": "class OperationProcessingFailedException(BaseException):\n    message = \"Unexpected error occurs during the request processing\"\n    def __init__(self, code = \"\", locator = '', layer = '', message = \"\", dump = \"\"):\n        self.message = self.message\n        if len(message) > 0:\n            self.message = message\n            BaseException.__init__(\n                self, self.message, self.code, locator, layer, dump)\n", "code_toks_joined": "class OperationProcessingFailedException ( BaseException ) : <NEWLINE> <INDENT> message = <STRING> <NEWLINE> def __init__ ( self , code = <STRING> , locator = <STRING> , layer = <STRING> , message = <STRING> , dump = <STRING> ) : <NEWLINE> <INDENT> self . message = self . message <NEWLINE> if len ( message ) > 0 : <NEWLINE> <INDENT> self . message = message <NEWLINE> BaseException . __init__ ( <NEWLINE> <INDENT> self , self . message , self . code , locator , layer , dump ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Unexpected error occurs during the request processing\"", "\"\"", "''", "''", "\"\"", "\"\""]}}], ["0a85e2a0f48523adcee9566a5220c457", {"code_string": "def add_tapa(bar, nombre, votos = 0):\n    t = Tapa.objects.get_or_create(bar = bar, nombre = nombre)[0]\n    t.votos = votos\n    t.save()\n    return t\n", "code_toks_joined": "def add_tapa ( bar , nombre , votos = 0 ) : <NEWLINE> <INDENT> t = Tapa . objects . get_or_create ( bar = bar , nombre = nombre ) [ 0 ] <NEWLINE> t . votos = votos <NEWLINE> t . save ( ) <NEWLINE> return t <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["29c3616558062c2857aee748ae57ac51", {"code_string": "import datetime\nfrom Spider import Spider\napp = Spider(\"https://thenewboston.com\", 8, 100)\nprint(datetime.datetime.now())\napp.start()\n", "code_toks_joined": "import datetime <NEWLINE> from Spider import Spider <NEWLINE> app = Spider ( <STRING> , 8 , 100 ) <NEWLINE> print ( datetime . datetime . now ( ) ) <NEWLINE> app . start ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"https://thenewboston.com\""]}}], ["c5c6fd38e62fc9238e8c993433353e8b", {"code_string": "import ctypes\nimport osgDB, osgViewer, osg, osgGA, osgAnimation\nfloatKeys = osgAnimation.FloatKeyframeContainer()\nkey0 = osgAnimation.FloatKeyframe(0.0, 1.0)\nfloatKeys.push_back(key0)\nvec3Keys = osgAnimation.Vec3KeyframeContainer()\nkey0 = osgAnimation.Vec3Keyframe(0.0, osg.Vec3(1, 2, 3))\nvec3Keys.push_back(key0)\nvec4Keys = osgAnimation.Vec4KeyframeContainer()\nkey0 = osgAnimation.Vec4Keyframe(0.0, osg.Vec4(1, 2, 3, 4))\nvec4Keys.push_back(key0)\n", "code_toks_joined": "import ctypes <NEWLINE> import osgDB , osgViewer , osg , osgGA , osgAnimation <NEWLINE> floatKeys = osgAnimation . FloatKeyframeContainer ( ) <NEWLINE> key0 = osgAnimation . FloatKeyframe ( 0.0 , 1.0 ) <NEWLINE> floatKeys . push_back ( key0 ) <NEWLINE> vec3Keys = osgAnimation . Vec3KeyframeContainer ( ) <NEWLINE> key0 = osgAnimation . Vec3Keyframe ( 0.0 , osg . Vec3 ( 1 , 2 , 3 ) ) <NEWLINE> vec3Keys . push_back ( key0 ) <NEWLINE> vec4Keys = osgAnimation . Vec4KeyframeContainer ( ) <NEWLINE> key0 = osgAnimation . Vec4Keyframe ( 0.0 , osg . Vec4 ( 1 , 2 , 3 , 4 ) ) <NEWLINE> vec4Keys . push_back ( key0 ) <NEWLINE>", "anonymize_dict": {}}], ["7a2ed5e1de455992e0f15c9a65198a50", {"code_string": "{\n    'name': 'Fonteyne',\n    'version': '1.0',\n    'category': 'Point of Sale',\n    'sequence': 6,\n    'summary': 'Fonteyne extensions for the Point of Sale',\n    'description': \"\"\"=======================\"\"\",\n    'author': 'OpenERP SA',\n    'depends': ['point_of_sale', 'loyalty'],\n    'data': [\n        'views/views.xml',\n        'views/templates.xml',\n    ],\n    'installable': True,\n    'auto_install': False,\n}\n", "code_toks_joined": "{ <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : 6 , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : [ <STRING> , <STRING> ] , <NEWLINE> <STRING> : [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <DEDENT> ] , <NEWLINE> <STRING> : True , <NEWLINE> <STRING> : False , <NEWLINE> <DEDENT> } <NEWLINE>", "anonymize_dict": {"<STRING>": ["'name'", "'Fonteyne'", "'version'", "'1.0'", "'category'", "'Point of Sale'", "'sequence'", "'summary'", "'Fonteyne extensions for the Point of Sale'", "'description'", "\"\"\"=======================\"\"\"", "'author'", "'OpenERP SA'", "'depends'", "'point_of_sale'", "'loyalty'", "'data'", "'views/views.xml'", "'views/templates.xml'", "'installable'", "'auto_install'"]}}], ["2742878d5b98beae9c30e792730fc96b", {"code_string": "def number_of_comments(self):\n    \"\"\"Alias for get_number_of_comments\"\"\"\n    return self.get_number_of_comments()\n", "code_toks_joined": "def number_of_comments ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . get_number_of_comments ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Alias for get_number_of_comments\"\"\""]}}], ["f70e27e1de96067a5ef1af7cf5f9d895", {"code_string": "def lcs(list_x, list_y):\n    __len_dict = {}\n    __ele_dict = {}\n    end_x = len(list_x) - 1\n    end_y = len(list_y) - 1\n    result = __lcs(list_x, list_y, end_x, end_y, __len_dict, __ele_dict)\n    return{\n        'length': result,\n        'lcs': extra_lcs(__ele_dict, list_x, end_x, end_y)\n    }\n", "code_toks_joined": "def lcs ( list_x , list_y ) : <NEWLINE> <INDENT> __len_dict = { } <NEWLINE> __ele_dict = { } <NEWLINE> end_x = len ( list_x ) - 1 <NEWLINE> end_y = len ( list_y ) - 1 <NEWLINE> result = __lcs ( list_x , list_y , end_x , end_y , __len_dict , __ele_dict ) <NEWLINE> return { <NEWLINE> <INDENT> <STRING> : result , <NEWLINE> <STRING> : extra_lcs ( __ele_dict , list_x , end_x , end_y ) <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'length'", "'lcs'"]}}], ["7019684093dab86f4e12af8e5f9225f7", {"code_string": "def rand_hi(name):\n    \"\"\"SEE LAB HANDOUT.\"\"\"\n    reps = random.randint(1, 100)\n    return multi_hi(name, reps)\n", "code_toks_joined": "def rand_hi ( name ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> reps = random . randint ( 1 , 100 ) <NEWLINE> return multi_hi ( name , reps ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"SEE LAB HANDOUT.\"\"\""]}}], ["f2b82d6527375cb2da628e829a96fb6d", {"code_string": "def __init__(self, docroot, index, errorpage, phpstate, phpexec):\n    self.docroot = docroot\n    self.errorpage = errorpage\n    self.index = index\n    self.sender = PageSender(self.docroot, self.errorpage)\n    self.php = handlePhp(self.docroot, phpexec, self.errorpage)\n    self.phpstate = phpstate\n", "code_toks_joined": "def __init__ ( self , docroot , index , errorpage , phpstate , phpexec ) : <NEWLINE> <INDENT> self . docroot = docroot <NEWLINE> self . errorpage = errorpage <NEWLINE> self . index = index <NEWLINE> self . sender = PageSender ( self . docroot , self . errorpage ) <NEWLINE> self . php = handlePhp ( self . docroot , phpexec , self . errorpage ) <NEWLINE> self . phpstate = phpstate <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["c2c8b5988a31e45cafff150e4df3131d", {"code_string": "import os\nimport xbmcaddon\nADDON = \"plugin.video.tweakers\"\nSETTINGS = xbmcaddon.Addon()\nLANGUAGE = SETTINGS.getLocalizedString\nIMAGES_PATH = os.path.join(xbmcaddon.Addon().getAddonInfo('path'), 'resources', 'images')\nDATE = \"2017-06-28\"\nVERSION = \"1.1.9-SNAPSHOT\"\n", "code_toks_joined": "import os <NEWLINE> import xbmcaddon <NEWLINE> ADDON = <STRING> <NEWLINE> SETTINGS = xbmcaddon . Addon ( ) <NEWLINE> LANGUAGE = SETTINGS . getLocalizedString <NEWLINE> IMAGES_PATH = os . path . join ( xbmcaddon . Addon ( ) . getAddonInfo ( <STRING> ) , <STRING> , <STRING> ) <NEWLINE> DATE = <STRING> <NEWLINE> VERSION = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"plugin.video.tweakers\"", "'path'", "'resources'", "'images'", "\"2017-06-28\"", "\"1.1.9-SNAPSHOT\""]}}], ["d37feaa0235bc4b9b41a7da26850e605", {"code_string": "def itemNames():\n    return['small_mining_tool', 'circuitry', 'electronics_module', 'frequency_jamming_wire', 'unpowered_installation_repair_device',\n    'wiring_teal']\n", "code_toks_joined": "def itemNames ( ) : <NEWLINE> <INDENT> return [ <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <NEWLINE> <STRING> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'small_mining_tool'", "'circuitry'", "'electronics_module'", "'frequency_jamming_wire'", "'unpowered_installation_repair_device'", "'wiring_teal'"]}}], ["54fa7716115946cee7493f62510e3883", {"code_string": "def _check_login_with_skewed_otp(self):\n    interval = 30\n    otp = self.new_user['orm_obj'].totp.at(\n        datetime.datetime.now() - datetime.timedelta(seconds = interval))\n    self._check_login_with_otp(otp)\n    otp = self.new_user['orm_obj'].totp.at(\n        datetime.datetime.now() + datetime.timedelta(seconds = interval))\n    self._check_login_with_otp(otp)\n", "code_toks_joined": "def _check_login_with_skewed_otp ( self ) : <NEWLINE> <INDENT> interval = 30 <NEWLINE> otp = self . new_user [ <STRING> ] . totp . at ( <NEWLINE> <INDENT> datetime . datetime . now ( ) - datetime . timedelta ( seconds = interval ) ) <NEWLINE> <DEDENT> self . _check_login_with_otp ( otp ) <NEWLINE> otp = self . new_user [ <STRING> ] . totp . at ( <NEWLINE> <INDENT> datetime . datetime . now ( ) + datetime . timedelta ( seconds = interval ) ) <NEWLINE> <DEDENT> self . _check_login_with_otp ( otp ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'orm_obj'", "'orm_obj'"]}}], ["9ce6872e90a797aee027c7b39b8c51a7", {"code_string": "def opStringTuple1(self, s1, current = None):\n    test(isinstance(s1, tuple))\n    return(s1, s1)\n", "code_toks_joined": "def opStringTuple1 ( self , s1 , current = None ) : <NEWLINE> <INDENT> test ( isinstance ( s1 , tuple ) ) <NEWLINE> return ( s1 , s1 ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["aa7a58400407a2cac56cb898da6923a6", {"code_string": "import django_filters\nfrom nodeconductor.core import filters as core_filters\nfrom.import models\n", "code_toks_joined": "import django_filters <NEWLINE> from nodeconductor . core import filters as core_filters <NEWLINE> from . import models <NEWLINE>", "anonymize_dict": {}}], ["5a3762f82a3bc1cb76496110e64e641b", {"code_string": "def define_simple_tag(tag_name, self_closing_tag = False):\n    class new_tag(Element):\n        tag = tag_name\n        self_closing = self_closing_tag\n    new_tag.__name__ = tag_name\n    return new_tag\n", "code_toks_joined": "def define_simple_tag ( tag_name , self_closing_tag = False ) : <NEWLINE> <INDENT> class new_tag ( Element ) : <NEWLINE> <INDENT> tag = tag_name <NEWLINE> self_closing = self_closing_tag <NEWLINE> <DEDENT> new_tag . __name__ = tag_name <NEWLINE> return new_tag <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["72d1fbadca37aa464fd665e397de746f", {"code_string": "class DateField(DateTimeField):\n    \"\"\"Same as the DateTimeField, but stores only the date portion.\"\"\"\n    def __init__(self, label = None, validators = None, parse_kwargs = None,\n        display_format = '%Y-%m-%d', ** kwargs):\n        super(DateField, self).__init__(label, validators, parse_kwargs = parse_kwargs, display_format = display_format, ** kwargs)\n    def process_formdata(self, valuelist):\n        super(DateField, self).process_formdata(valuelist)\n        if self.data is not None and hasattr(self.data, 'date'):\n            self.data = self.data.date()\n", "code_toks_joined": "class DateField ( DateTimeField ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , label = None , validators = None , parse_kwargs = None , <NEWLINE> <INDENT> display_format = <STRING> , ** kwargs ) : <NEWLINE> super ( DateField , self ) . __init__ ( label , validators , parse_kwargs = parse_kwargs , display_format = display_format , ** kwargs ) <NEWLINE> <DEDENT> def process_formdata ( self , valuelist ) : <NEWLINE> <INDENT> super ( DateField , self ) . process_formdata ( valuelist ) <NEWLINE> if self . data is not None and hasattr ( self . data , <STRING> ) : <NEWLINE> <INDENT> self . data = self . data . date ( ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Same as the DateTimeField, but stores only the date portion.\"\"\"", "'%Y-%m-%d'", "'date'"]}}], ["3d5b05b496187f11525f2c9877f953f9", {"code_string": "def test_update_plugin_by_copying_its_files_to_plugins_path(mock_update_operations, runner):\n    runner.invoke(cli.main, ['-u', 'plugin-name', '-c', 'pelicanconf.py'])\n    src_path = os.path.join(PLUGINS_LOCAL_REPOSITORY, 'plugin-name')\n    dst_path = '/tmp/plugins/plugin-name'\n    shutil.rmtree.assert_called_once_with(dst_path)\n    shutil.copytree.assert_called_once_with(src_path, dst_path)\n", "code_toks_joined": "def test_update_plugin_by_copying_its_files_to_plugins_path ( mock_update_operations , runner ) : <NEWLINE> <INDENT> runner . invoke ( cli . main , [ <STRING> , <STRING> , <STRING> , <STRING> ] ) <NEWLINE> src_path = os . path . join ( PLUGINS_LOCAL_REPOSITORY , <STRING> ) <NEWLINE> dst_path = <STRING> <NEWLINE> shutil . rmtree . assert_called_once_with ( dst_path ) <NEWLINE> shutil . copytree . assert_called_once_with ( src_path , dst_path ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'-u'", "'plugin-name'", "'-c'", "'pelicanconf.py'", "'plugin-name'", "'/tmp/plugins/plugin-name'"]}}], ["558cca670b78722f258c8f4b86878374", {"code_string": "class test_init(common.basetest):\n    def test_exists(self):\n        self.assertRaises(hglib.error.CommandError, hglib.init)\n    def test_basic(self):\n        self.client.close()\n        self.client = None\n        shutil.rmtree('.hg')\n        self.client = hglib.init().open()\n        self.assertTrue(self.client.root().endswith('test_init'))\n", "code_toks_joined": "class test_init ( common . basetest ) : <NEWLINE> <INDENT> def test_exists ( self ) : <NEWLINE> <INDENT> self . assertRaises ( hglib . error . CommandError , hglib . init ) <NEWLINE> <DEDENT> def test_basic ( self ) : <NEWLINE> <INDENT> self . client . close ( ) <NEWLINE> self . client = None <NEWLINE> shutil . rmtree ( <STRING> ) <NEWLINE> self . client = hglib . init ( ) . open ( ) <NEWLINE> self . assertTrue ( self . client . root ( ) . endswith ( <STRING> ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'.hg'", "'test_init'"]}}], ["ce33102c4fa3330d7385600f3ceafa70", {"code_string": "import unittest\nfrom urllib3.connectionpool import(\n    connection_from_url,\n    HTTPConnection,\n    HTTPConnectionPool,\n)\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.packages.ssl_match_hostname import CertificateError\nfrom urllib3.exceptions import(\n    ClosedPoolError,\n    EmptyPoolError,\n    HostChangedError,\n    LocationValueError,\n    MaxRetryError,\n    ProtocolError,\n    SSLError,\n)\nfrom socket import error as SocketError\nfrom ssl import SSLError as BaseSSLError\ntry:\n    from queue import Empty\n    from http.client import HTTPException\nexcept ImportError:\n    from Queue import Empty\n    from httplib import HTTPException\n", "code_toks_joined": "import unittest <NEWLINE> from urllib3 . connectionpool import ( <NEWLINE> <INDENT> connection_from_url , <NEWLINE> HTTPConnection , <NEWLINE> HTTPConnectionPool , <NEWLINE> <DEDENT> ) <NEWLINE> from urllib3 . util . timeout import Timeout <NEWLINE> from urllib3 . packages . ssl_match_hostname import CertificateError <NEWLINE> from urllib3 . exceptions import ( <NEWLINE> <INDENT> ClosedPoolError , <NEWLINE> EmptyPoolError , <NEWLINE> HostChangedError , <NEWLINE> LocationValueError , <NEWLINE> MaxRetryError , <NEWLINE> ProtocolError , <NEWLINE> SSLError , <NEWLINE> <DEDENT> ) <NEWLINE> from socket import error as SocketError <NEWLINE> from ssl import SSLError as BaseSSLError <NEWLINE> try : <NEWLINE> <INDENT> from queue import Empty <NEWLINE> from http . client import HTTPException <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> from Queue import Empty <NEWLINE> from httplib import HTTPException <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["3d60237a915ef6839b5545a0c270e055", {"code_string": "def generateIV128(pwdhash):\n    from genutils import invertWord\n    import struct\n    res = \"\"\n    i = 0\n    while(i < 16):\n        a = struct.unpack('<H', invertWord(pwdhash[i: i + 2]))[0]\n        b = struct.unpack('<H', pwdhash[i + 16: i + 16 + 2])[0]\n        res += struct.pack('<H', a ^ b)\n        i += 2\n    return res\n", "code_toks_joined": "def generateIV128 ( pwdhash ) : <NEWLINE> <INDENT> from genutils import invertWord <NEWLINE> import struct <NEWLINE> res = <STRING> <NEWLINE> i = 0 <NEWLINE> while ( i < 16 ) : <NEWLINE> <INDENT> a = struct . unpack ( <STRING> , invertWord ( pwdhash [ i : i + 2 ] ) ) [ 0 ] <NEWLINE> b = struct . unpack ( <STRING> , pwdhash [ i + 16 : i + 16 + 2 ] ) [ 0 ] <NEWLINE> res += struct . pack ( <STRING> , a ^ b ) <NEWLINE> i += 2 <NEWLINE> <DEDENT> return res <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"", "'<H'", "'<H'", "'<H'"]}}], ["9e54198ad5ce53db6f0721eda55001b8", {"code_string": "class UserMapper(datamapper.ModelDataMapper):\n    class Meta:\n        model = get_user_model()\n        fields = (get_user_model().USERNAME_FIELD, )\n        readonly = (get_user_model().USERNAME_FIELD, )\n", "code_toks_joined": "class UserMapper ( datamapper . ModelDataMapper ) : <NEWLINE> <INDENT> class Meta : <NEWLINE> <INDENT> model = get_user_model ( ) <NEWLINE> fields = ( get_user_model ( ) . USERNAME_FIELD , ) <NEWLINE> readonly = ( get_user_model ( ) . USERNAME_FIELD , ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["4c0d64891409654f8f706017ceb5ff90", {"code_string": "def get_form_class(self):\n    if not hasattr(self, '_form_class'):\n        kw = self.kwargs\n        kw['form_cls'] = self.form_class\n        kw['widgets'] = self.form_class.Meta.widgets\n        self._form_class = form_repository.get_generic_form(** self.kwargs)\n    return self._form_class\n", "code_toks_joined": "def get_form_class ( self ) : <NEWLINE> <INDENT> if not hasattr ( self , <STRING> ) : <NEWLINE> <INDENT> kw = self . kwargs <NEWLINE> kw [ <STRING> ] = self . form_class <NEWLINE> kw [ <STRING> ] = self . form_class . Meta . widgets <NEWLINE> self . _form_class = form_repository . get_generic_form ( ** self . kwargs ) <NEWLINE> <DEDENT> return self . _form_class <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'_form_class'", "'form_cls'", "'widgets'"]}}], ["991ee880dbd11582f78bdcda8acb5400", {"code_string": "import numpy as np\nimport cv2\nfrom matplotlib import pyplot as plt\nimg = cv2.imread('Heidelberg.jpg', 0)\nplt.imshow(img, cmap = 'gray', interpolation = 'bicubic')\nplt.xticks([]), plt.yticks([])\nplt.show()\ncv2.imshow('opencv', img)\ncv2.waitKey(0)\n", "code_toks_joined": "import numpy as np <NEWLINE> import cv2 <NEWLINE> from matplotlib import pyplot as plt <NEWLINE> img = cv2 . imread ( <STRING> , 0 ) <NEWLINE> plt . imshow ( img , cmap = <STRING> , interpolation = <STRING> ) <NEWLINE> plt . xticks ( [ ] ) , plt . yticks ( [ ] ) <NEWLINE> plt . show ( ) <NEWLINE> cv2 . imshow ( <STRING> , img ) <NEWLINE> cv2 . waitKey ( 0 ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'Heidelberg.jpg'", "'gray'", "'bicubic'", "'opencv'"]}}], ["ace03174413eed51baa0e0b3a0447d14", {"code_string": "from bs4 import BeautifulSoup\nimport requests\nfrom pprint import pprint\nurl = \"hyotynen.iki.fi/trekfailure\"\nr = requests.get(\"http://\" + url)\ndata = r.text\nsoup = BeautifulSoup(data)\nfrom sqlitedict import SqliteDict\ndict_db = SqliteDict('resources/treknobabble.sqlite', autocommit = True)\ntreknobabble = []\nfailure = {}\nmyset = []\n", "code_toks_joined": "from bs4 import BeautifulSoup <NEWLINE> import requests <NEWLINE> from pprint import pprint <NEWLINE> url = <STRING> <NEWLINE> r = requests . get ( <STRING> + url ) <NEWLINE> data = r . text <NEWLINE> soup = BeautifulSoup ( data ) <NEWLINE> from sqlitedict import SqliteDict <NEWLINE> dict_db = SqliteDict ( <STRING> , autocommit = True ) <NEWLINE> treknobabble = [ ] <NEWLINE> failure = { } <NEWLINE> myset = [ ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"hyotynen.iki.fi/trekfailure\"", "\"http://\"", "'resources/treknobabble.sqlite'"]}}], ["8da6aab8f03726bfb9cb1a6235de8634", {"code_string": "def scale_x(x):\n    \"\"\"\u0412\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u044d\u043a\u0440\u0430\u043d\u043d\u0443\u044e **x** \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0443 \u043f\u043e **x** \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0435 \u043c\u043e\u0434\u0435\u043b\u0438.\"\"\"\n    return int(x * scale_factor) + window_width // 2\n", "code_toks_joined": "def scale_x ( x ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return int ( x * scale_factor ) + window_width // 2 <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"\u0412\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u044d\u043a\u0440\u0430\u043d\u043d\u0443\u044e **x** \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0443 \u043f\u043e **x** \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0435 \u043c\u043e\u0434\u0435\u043b\u0438.\"\"\""]}}], ["a6adbd3abb8cb43d33bcc326bf2c4ae2", {"code_string": "import os\nfrom app import create_app, db\nfrom app.models import User\nfrom flask_script import Manager, Shell, Command\nfrom flask_migrate import Migrate, MigrateCommand\napp = create_app(os.getenv('FLASK_CONFIG') or 'default')\nmanager = Manager(app)\nmigrate = Migrate(app, db)\n", "code_toks_joined": "import os <NEWLINE> from app import create_app , db <NEWLINE> from app . models import User <NEWLINE> from flask_script import Manager , Shell , Command <NEWLINE> from flask_migrate import Migrate , MigrateCommand <NEWLINE> app = create_app ( os . getenv ( <STRING> ) or <STRING> ) <NEWLINE> manager = Manager ( app ) <NEWLINE> migrate = Migrate ( app , db ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'FLASK_CONFIG'", "'default'"]}}], ["1c44fcdefd260bfae1c2e8eaadfc9dbf", {"code_string": "def add_marker(self, lon, lat, cls = MapMarker, options = None):\n    if options is None:\n        options = {}\n    marker = Marker(lon, lat, cls, options)\n    self.cluster_markers.append(marker)\n    return marker\n", "code_toks_joined": "def add_marker ( self , lon , lat , cls = MapMarker , options = None ) : <NEWLINE> <INDENT> if options is None : <NEWLINE> <INDENT> options = { } <NEWLINE> <DEDENT> marker = Marker ( lon , lat , cls , options ) <NEWLINE> self . cluster_markers . append ( marker ) <NEWLINE> return marker <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["097c9cfa1b1a34eb53dbaa21d59f440d", {"code_string": "class Type(Enum):\n    \"\"\"Enum of the diffrent possible types of exporting\"\"\"\n    CSV = 0\n    XLSX = 1\n    XML = 2\n", "code_toks_joined": "class Type ( Enum ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> CSV = 0 <NEWLINE> XLSX = 1 <NEWLINE> XML = 2 <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Enum of the diffrent possible types of exporting\"\"\""]}}], ["7f12a5b6d274269e60171373c3cefe31", {"code_string": "from django.utils.safestring import mark_safe\nfrom rest_framework.utils import formatting\nfrom rest_framework.compat import smart_text\n", "code_toks_joined": "from django . utils . safestring import mark_safe <NEWLINE> from rest_framework . utils import formatting <NEWLINE> from rest_framework . compat import smart_text <NEWLINE>", "anonymize_dict": {}}], ["15f9d23ceef80f873ca078d0d3832ebd", {"code_string": "def parseContacts(f):\n    contacts = set()\n    for l in open(f):\n        x = l.split()\n        if len(x) != 3:\n            sys.stderr.write('Incorrect format for ' + f)\n            sys.exit(1)\n        if float(x[- 1]) < 8:\n            contacts.add((int(x[0]), int(x[1])))\n    return contacts\n", "code_toks_joined": "def parseContacts ( f ) : <NEWLINE> <INDENT> contacts = set ( ) <NEWLINE> for l in open ( f ) : <NEWLINE> <INDENT> x = l . split ( ) <NEWLINE> if len ( x ) != 3 : <NEWLINE> <INDENT> sys . stderr . write ( <STRING> + f ) <NEWLINE> sys . exit ( 1 ) <NEWLINE> <DEDENT> if float ( x [ - 1 ] ) < 8 : <NEWLINE> <INDENT> contacts . add ( ( int ( x [ 0 ] ) , int ( x [ 1 ] ) ) ) <NEWLINE> <DEDENT> <DEDENT> return contacts <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Incorrect format for '"]}}], ["2728502b0de19fb3dfcddb86db16d819", {"code_string": "import mock\nfrom django.test import TestCase\nfrom django.core.urlresolvers import reverse\n", "code_toks_joined": "import mock <NEWLINE> from django . test import TestCase <NEWLINE> from django . core . urlresolvers import reverse <NEWLINE>", "anonymize_dict": {}}], ["75b5b3c980b7ec861056b7d2a32faf43", {"code_string": "from django.db import models\nfrom lino.api import dd\nfrom lino.utils import join_elems\nfrom lino.utils.xmlgen.html import E\nfrom lino.core.actors import qs2summary\n", "code_toks_joined": "from django . db import models <NEWLINE> from lino . api import dd <NEWLINE> from lino . utils import join_elems <NEWLINE> from lino . utils . xmlgen . html import E <NEWLINE> from lino . core . actors import qs2summary <NEWLINE>", "anonymize_dict": {}}], ["0d7a6e67e4b4cbdf10db27b394c7cc0d", {"code_string": "class TestCbh_core_ws(TestCase):\n    def setUp(self):\n        pass\n    def test_something(self):\n        pass\n    def tearDown(self):\n        pass\n", "code_toks_joined": "class TestCbh_core_ws ( TestCase ) : <NEWLINE> <INDENT> def setUp ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def test_something ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def tearDown ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["1075485048aca67e0de69e831274bade", {"code_string": "def _get_interface_state(self):\n    if 'shutdown' in self._raw_configuration:\n        return 'shut'\n    else:\n        return 'unshut'\n", "code_toks_joined": "def _get_interface_state ( self ) : <NEWLINE> <INDENT> if <STRING> in self . _raw_configuration : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'shutdown'", "'shut'", "'unshut'"]}}], ["188aa8066a5439e23b539fe3554d039d", {"code_string": "def test_no_rules_with_grandparent_filter(self):\n    res = self.app.get(self.lawless_url + 'filter[parents]={}'.format(self.subA.pk))\n    assert_equal(res.status_code, 200)\n    assert_equal(res.json['links']['meta']['total'], 3)\n", "code_toks_joined": "def test_no_rules_with_grandparent_filter ( self ) : <NEWLINE> <INDENT> res = self . app . get ( self . lawless_url + <STRING> . format ( self . subA . pk ) ) <NEWLINE> assert_equal ( res . status_code , 200 ) <NEWLINE> assert_equal ( res . json [ <STRING> ] [ <STRING> ] [ <STRING> ] , 3 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'filter[parents]={}'", "'links'", "'meta'", "'total'"]}}], ["ccf75e445bfc2faeca0d0fcf0624eb95", {"code_string": "def AppendMemSRAMStartAddress(mem, address):\n    mem.append(0x800000 + address)\n    return mem\n", "code_toks_joined": "def AppendMemSRAMStartAddress ( mem , address ) : <NEWLINE> <INDENT> mem . append ( 0x800000 + address ) <NEWLINE> return mem <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["c6123e5bbadb96d03230677e4ec655a7", {"code_string": "def update_keyword(node, keyword):\n    found = False\n    for i in range(len(node.keywords)):\n        if node.keywords[i].arg == keyword.arg:\n            node.keywords[i] = keyword\n            found = True\n            break\n    if not found:\n        node.keywords.append(keyword)\n", "code_toks_joined": "def update_keyword ( node , keyword ) : <NEWLINE> <INDENT> found = False <NEWLINE> for i in range ( len ( node . keywords ) ) : <NEWLINE> <INDENT> if node . keywords [ i ] . arg == keyword . arg : <NEWLINE> <INDENT> node . keywords [ i ] = keyword <NEWLINE> found = True <NEWLINE> break <NEWLINE> <DEDENT> <DEDENT> if not found : <NEWLINE> <INDENT> node . keywords . append ( keyword ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["00f1d95bc0fea6b9364fb55c8249b24f", {"code_string": "def ack_host(host_name, message):\n    \"\"\" Helper Function: Acknowledge a host problem with a comment.\"\"\"\n    cmd = \"ACKNOWLEDGE_HOST_PROBLEM;%(host_name)s;0;0;0;nagiosadmin;%(message)s\\n\" % locals()\n    command(cmd)\n", "code_toks_joined": "def ack_host ( host_name , message ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> cmd = <STRING> % locals ( ) <NEWLINE> command ( cmd ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Helper Function: Acknowledge a host problem with a comment.\"\"\"", "\"ACKNOWLEDGE_HOST_PROBLEM;%(host_name)s;0;0;0;nagiosadmin;%(message)s\\n\""]}}], ["7becedbd84db773d7419287c239e13a0", {"code_string": "\"\"\"Adapted from ``django.core.management.commands.shell``.\"\"\"\nimport os\nfrom feedplatform.management import NoArgsCommand\nfrom optparse import make_option\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> from feedplatform . management import NoArgsCommand <NEWLINE> from optparse import make_option <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Adapted from ``django.core.management.commands.shell``.\"\"\""]}}], ["4baf781bdf87fec0c4a386dc9d0c8b68", {"code_string": "import os\nimport subprocess\nimport re\nif os.name == 'nt':\n    from ctypes import windll, create_unicode_buffer\ntry:\n    import sublime\nexcept(ImportError):\n    sublime = None\nfrom.console_write import console_write\nfrom.unicode import unicode_from_os\nfrom.show_error import show_error\ntry:\n    str_cls = unicode\nexcept(NameError):\n    str_cls = str\n", "code_toks_joined": "import os <NEWLINE> import subprocess <NEWLINE> import re <NEWLINE> if os . name == <STRING> : <NEWLINE> <INDENT> from ctypes import windll , create_unicode_buffer <NEWLINE> <DEDENT> try : <NEWLINE> <INDENT> import sublime <NEWLINE> <DEDENT> except ( ImportError ) : <NEWLINE> <INDENT> sublime = None <NEWLINE> <DEDENT> from . console_write import console_write <NEWLINE> from . unicode import unicode_from_os <NEWLINE> from . show_error import show_error <NEWLINE> try : <NEWLINE> <INDENT> str_cls = unicode <NEWLINE> <DEDENT> except ( NameError ) : <NEWLINE> <INDENT> str_cls = str <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'nt'"]}}], ["0632bc2e761c3f4f493fe7a5fddeedbe", {"code_string": "def __get_select_area(self, pos):\n    (x, y) = self._img_position\n    x *= self.scale\n    y *= self.scale\n    x_min = x -(self.GRIP_SIZE / 2)\n    y_min = y -(self.GRIP_SIZE / 2)\n    x_max = x +(self.GRIP_SIZE / 2)\n    y_max = y +(self.GRIP_SIZE / 2)\n    return((x_min, y_min), (x_max, y_max))\n", "code_toks_joined": "def __get_select_area ( self , pos ) : <NEWLINE> <INDENT> ( x , y ) = self . _img_position <NEWLINE> x *= self . scale <NEWLINE> y *= self . scale <NEWLINE> x_min = x - ( self . GRIP_SIZE / 2 ) <NEWLINE> y_min = y - ( self . GRIP_SIZE / 2 ) <NEWLINE> x_max = x + ( self . GRIP_SIZE / 2 ) <NEWLINE> y_max = y + ( self . GRIP_SIZE / 2 ) <NEWLINE> return ( ( x_min , y_min ) , ( x_max , y_max ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["bf9613782627ab05c47c1073d4b18e0c", {"code_string": "from twitfin.testsuite import main\nmain()\n", "code_toks_joined": "from twitfin . testsuite import main <NEWLINE> main ( ) <NEWLINE>", "anonymize_dict": {}}], ["ba260c0be045bcddbc99303f429d147b", {"code_string": "\"\"\"playitagainsam.eventlog:  event reader/writer for playitagainsam\"\"\"\nimport os\nimport json\nfrom tempfile import NamedTemporaryFile\nimport six\nfrom playitagainsam.util import get_default_shell\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> import json <NEWLINE> from tempfile import NamedTemporaryFile <NEWLINE> import six <NEWLINE> from playitagainsam . util import get_default_shell <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"playitagainsam.eventlog:  event reader/writer for playitagainsam\"\"\""]}}], ["f274086cc7c8584e750ae348366def5e", {"code_string": "def selfdir():\n    cwd = os.path.dirname(os.path.abspath(__file__))\n    return os.path.dirname(cwd)\n", "code_toks_joined": "def selfdir ( ) : <NEWLINE> <INDENT> cwd = os . path . dirname ( os . path . abspath ( __file__ ) ) <NEWLINE> return os . path . dirname ( cwd ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["19116a45211c72bfefeff80bf44eeb46", {"code_string": "class PickleSerializer(api.Serializer):\n    \"\"\"Just a toy! Rather use migrations that are user editable!\"\"\"\n    supports_backward_migration = True\n    extension = \"bin\"\n    saves_migration_name = True\n    def _save(self, file, migration):\n        import pickle\n        pickle.dump(migration, file)\n    def _load(self, file, migration_name, is_guess):\n        import pickle\n        return pickle.load(file)\n", "code_toks_joined": "class PickleSerializer ( api . Serializer ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> supports_backward_migration = True <NEWLINE> extension = <STRING> <NEWLINE> saves_migration_name = True <NEWLINE> def _save ( self , file , migration ) : <NEWLINE> <INDENT> import pickle <NEWLINE> pickle . dump ( migration , file ) <NEWLINE> <DEDENT> def _load ( self , file , migration_name , is_guess ) : <NEWLINE> <INDENT> import pickle <NEWLINE> return pickle . load ( file ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Just a toy! Rather use migrations that are user editable!\"\"\"", "\"bin\""]}}], ["0865ceea23ca1107d8ac16d503b66c8b", {"code_string": "class UsersView(LoginRequiredMixin, TemplateView):\n    template_name = 'users.html'\n    def get_context_data(self, ** kwargs):\n        return{\n            'users': self.request.user.get_users().prefetch_related('organizations'),\n            'organizations': self.request.user.get_organizations()\n        }\n", "code_toks_joined": "class UsersView ( LoginRequiredMixin , TemplateView ) : <NEWLINE> <INDENT> template_name = <STRING> <NEWLINE> def get_context_data ( self , ** kwargs ) : <NEWLINE> <INDENT> return { <NEWLINE> <INDENT> <STRING> : self . request . user . get_users ( ) . prefetch_related ( <STRING> ) , <NEWLINE> <STRING> : self . request . user . get_organizations ( ) <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'users.html'", "'users'", "'organizations'", "'organizations'"]}}], ["2e2f707a31db84962839ae5a81d7acc0", {"code_string": "def main():\n    ''' Wrapper for the real main '''\n    try:\n        realmain()\n    except:\n        sys.stderr.write('%s\\n' % str(asyncore.compact_traceback()))\n        sys.exit(1)\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> try : <NEWLINE> <INDENT> realmain ( ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> sys . stderr . write ( <STRING> % str ( asyncore . compact_traceback ( ) ) ) <NEWLINE> sys . exit ( 1 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["''' Wrapper for the real main '''", "'%s\\n'"]}}], ["19f6bb696005ad8058b3236d97fe09d7", {"code_string": "def get_filename(self, runSetName, fileExtension):\n    '''This function returns the name of the file for a run set'''\n    fileName = self.benchmark.output_base_name + \".results.\"\n    if runSetName:\n        fileName += runSetName + \".\"\n    return fileName + fileExtension\n", "code_toks_joined": "def get_filename ( self , runSetName , fileExtension ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> fileName = self . benchmark . output_base_name + <STRING> <NEWLINE> if runSetName : <NEWLINE> <INDENT> fileName += runSetName + <STRING> <NEWLINE> <DEDENT> return fileName + fileExtension <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''This function returns the name of the file for a run set'''", "\".results.\"", "\".\""]}}], ["486afdb79eb43221d66a065f25c7cf9e", {"code_string": "def kill_topology_by_name(topology_name, wait_time = 0):\n    id = StormUI.getTopologyIdByName(topology_name)\n    if id is not None:\n        return StormUI.killTopology(id, wait_time)\n    return None\n", "code_toks_joined": "def kill_topology_by_name ( topology_name , wait_time = 0 ) : <NEWLINE> <INDENT> id = StormUI . getTopologyIdByName ( topology_name ) <NEWLINE> if id is not None : <NEWLINE> <INDENT> return StormUI . killTopology ( id , wait_time ) <NEWLINE> <DEDENT> return None <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["63bcaf2de1c68694e0d2dd34ab08dfa4", {"code_string": "def draw_screen():\n    global stdscr, query\n    stdscr.erase()\n    stdscr.addstr(0, 0, \"Query string (press shift-q to exit)\")\n    stdscr.addstr(2, 0, query)\n    for i in range(len(matches)):\n        stdscr.addstr(4 + i, 0, matches[i][1])\n    stdscr.refresh()\n", "code_toks_joined": "def draw_screen ( ) : <NEWLINE> <INDENT> global stdscr , query <NEWLINE> stdscr . erase ( ) <NEWLINE> stdscr . addstr ( 0 , 0 , <STRING> ) <NEWLINE> stdscr . addstr ( 2 , 0 , query ) <NEWLINE> for i in range ( len ( matches ) ) : <NEWLINE> <INDENT> stdscr . addstr ( 4 + i , 0 , matches [ i ] [ 1 ] ) <NEWLINE> <DEDENT> stdscr . refresh ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Query string (press shift-q to exit)\""]}}], ["98cd817c98166c296e5c768e1a8fc450", {"code_string": "def _randFloat(self, shape):\n    vals = np.random.normal(0, 1, np.prod(shape)).reshape(shape)\n    return np.array(vals, dtype = np.float32)\n", "code_toks_joined": "def _randFloat ( self , shape ) : <NEWLINE> <INDENT> vals = np . random . normal ( 0 , 1 , np . prod ( shape ) ) . reshape ( shape ) <NEWLINE> return np . array ( vals , dtype = np . float32 ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["97d2a246337fe103b152cef249e97550", {"code_string": "import os\nimport sys\ntry:\n    from setuptools import setup, find_packages\nexcept ImportError:\n    from distutils.core import setup, find_packages\nif sys.version_info <(2, 6):\n    raise NotImplementedError(\"Sorry, you need at least Python 2.6 or Python  3.x to use jsobject.\")\nfrom setuptools.command.test import test as TestCommand\n", "code_toks_joined": "import os <NEWLINE> import sys <NEWLINE> try : <NEWLINE> <INDENT> from setuptools import setup , find_packages <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> from distutils . core import setup , find_packages <NEWLINE> <DEDENT> if sys . version_info < ( 2 , 6 ) : <NEWLINE> <INDENT> raise NotImplementedError ( <STRING> ) <NEWLINE> <DEDENT> from setuptools . command . test import test as TestCommand <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"Sorry, you need at least Python 2.6 or Python  3.x to use jsobject.\""]}}], ["3a63a4faf5b7bdd2a7ffdefa04a608c1", {"code_string": "def _bounds_changed(self, old, new):\n    super(DataView, self)._bounds_changed(old, new)\n    self._update_mappers()\n", "code_toks_joined": "def _bounds_changed ( self , old , new ) : <NEWLINE> <INDENT> super ( DataView , self ) . _bounds_changed ( old , new ) <NEWLINE> self . _update_mappers ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["0bc363628a71cb6c8d4de0c9d359072f", {"code_string": "\"\"\"Main querystringsafe_base64 module.\"\"\"\nimport sys\nfrom base64 import urlsafe_b64encode, urlsafe_b64decode\n__version__ = '0.2.0'\nPY2 = sys.version_info <(3, 0)\n", "code_toks_joined": "<STRING> <NEWLINE> import sys <NEWLINE> from base64 import urlsafe_b64encode , urlsafe_b64decode <NEWLINE> __version__ = <STRING> <NEWLINE> PY2 = sys . version_info < ( 3 , 0 ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Main querystringsafe_base64 module.\"\"\"", "'0.2.0'"]}}], ["b600bf68055787f454290d54fe0ac5b8", {"code_string": "from sha import sha as sha1\n", "code_toks_joined": "from sha import sha as sha1 <NEWLINE>", "anonymize_dict": {}}], ["182abe7062cdf813fb26108f9d12b866", {"code_string": "def unframe(self, bytestring):\n    if is_valid_frame(bytestring):\n        u = unescape(bytestring[: - 1])\n        return u[: - 1]\n    else:\n        return bytestring\n", "code_toks_joined": "def unframe ( self , bytestring ) : <NEWLINE> <INDENT> if is_valid_frame ( bytestring ) : <NEWLINE> <INDENT> u = unescape ( bytestring [ : - 1 ] ) <NEWLINE> return u [ : - 1 ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return bytestring <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["fcdc68bd4207082abdc1490f0e41c6ea", {"code_string": "import numpy as np\nfrom OpenGL.GL import *\nfrom..GLGraphicsItem import GLGraphicsItem\nfrom ... import QtGui\n__all__ = ['GLGridItem']\n", "code_toks_joined": "import numpy as np <NEWLINE> from OpenGL . GL import * <NEWLINE> from . . GLGraphicsItem import GLGraphicsItem <NEWLINE> from ... import QtGui <NEWLINE> __all__ = [ <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'GLGridItem'"]}}], ["6b594d4e600ea88bf6aef18041b413da", {"code_string": "def _time_str_to_unix(timestring):\n    \"\"\":type timestring: Union[str, int]\"\"\"\n    if isinstance(timestring, (int, float)):\n        return timestring\n    try:\n        t = int(time.mktime(datetime.strptime(timestring, '%a, %d %b %Y %H:%M:%S %Z').timetuple()))\n    except:\n        t = None\n    return t\n", "code_toks_joined": "def _time_str_to_unix ( timestring ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if isinstance ( timestring , ( int , float ) ) : <NEWLINE> <INDENT> return timestring <NEWLINE> <DEDENT> try : <NEWLINE> <INDENT> t = int ( time . mktime ( datetime . strptime ( timestring , <STRING> ) . timetuple ( ) ) ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> t = None <NEWLINE> <DEDENT> return t <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\":type timestring: Union[str, int]\"\"\"", "'%a, %d %b %Y %H:%M:%S %Z'"]}}], ["2d4848219bf26634ca0e580e4d190684", {"code_string": "def getUsage(self, ** kwargs):\n    t = usage.Options.getUsage(self, ** kwargs)\n    return t + \"\\nPlease run 'tahoe <command> --help' for more details on each command.\\n\"\n", "code_toks_joined": "def getUsage ( self , ** kwargs ) : <NEWLINE> <INDENT> t = usage . Options . getUsage ( self , ** kwargs ) <NEWLINE> return t + <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\\nPlease run 'tahoe <command> --help' for more details on each command.\\n\""]}}], ["ded7c33713e4f63d5e8fc16d98657428", {"code_string": "def get_magnet(self, pageLink):\n    \"\"\"Function returning the magnet link for the torrent.\"\"\"\n    downloadLocationTest = self.get_specific_tracker(self.domain + pageLink)\n    magnet = False\n    while magnet is False:\n        trackerLink = next(downloadLocationTest, None)\n        if trackerLink is not None:\n            magnet = self.get_magnet_from_tracker(trackerLink)\n        else:\n            break\n    return magnet\n", "code_toks_joined": "def get_magnet ( self , pageLink ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> downloadLocationTest = self . get_specific_tracker ( self . domain + pageLink ) <NEWLINE> magnet = False <NEWLINE> while magnet is False : <NEWLINE> <INDENT> trackerLink = next ( downloadLocationTest , None ) <NEWLINE> if trackerLink is not None : <NEWLINE> <INDENT> magnet = self . get_magnet_from_tracker ( trackerLink ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> break <NEWLINE> <DEDENT> <DEDENT> return magnet <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Function returning the magnet link for the torrent.\"\"\""]}}], ["25c4e8aeb7cba905c92657f3234430c9", {"code_string": "import pytest\nimport json\nimport re\nfrom share.change import ChangeGraph\nfrom share.models import ChangeSet\nfrom tests.share.models.factories import NormalizedDataFactory\n", "code_toks_joined": "import pytest <NEWLINE> import json <NEWLINE> import re <NEWLINE> from share . change import ChangeGraph <NEWLINE> from share . models import ChangeSet <NEWLINE> from tests . share . models . factories import NormalizedDataFactory <NEWLINE>", "anonymize_dict": {}}], ["af727cd52c845a3012d1fd6f646404d8", {"code_string": "def test(self):\n    \"\"\"Retourne le test et le cr\u00e9e si n\u00e9cessaire.\"\"\"\n    if self.__test is None:\n        self.__test = Test(self)\n    return self.__test\n", "code_toks_joined": "def test ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if self . __test is None : <NEWLINE> <INDENT> self . __test = Test ( self ) <NEWLINE> <DEDENT> return self . __test <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Retourne le test et le cr\u00e9e si n\u00e9cessaire.\"\"\""]}}], ["04d2fd32c01f0ddb3dba40f7c65328b1", {"code_string": "def read_hdf_as_results(hdf):\n    \"\"\" Read <hdf> into a 'results' list of dicts matching the format\"\"\"\n    f = h5py.File(name, 'r')\n    pass\n    return results\n", "code_toks_joined": "def read_hdf_as_results ( hdf ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> f = h5py . File ( name , <STRING> ) <NEWLINE> pass <NEWLINE> return results <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Read <hdf> into a 'results' list of dicts matching the format\"\"\"", "'r'"]}}], ["51efafb5eba1f37456d485aa7f43568a", {"code_string": "import ConfigParser\nfrom pygame import Color\nconfig = ConfigParser.RawConfigParser()\nconfig.read('profile.cfg')\nG = 1\nMAXRESPAWNTIME = 3000\nBULLET_LIFE = 7000\nBULLET_MASS = 0.3\nBULLET_VEL = 6\nFUEL_MASS = 0.2\nMAX_FUEL = 16\nMAX_AMMO = 16\nGAME_SPEED = 40\nSYS_FONT = \"font.ttf\"\nSTATS_FONT = \"font_stats.ttf\"\nMAX_OBJECTS = config.getint(\"Misc\", \"max_objects\")\nDEBRIS_R = 6\nDEBRIS_SCALING = 3.0\nDEBRIS_COLORS = (Color(\"#555555\"), Color(\"#888888\"))\nHELLDEBRIS_COLORS = (Color(\"#303030\"), Color(\"#777777\"))\n", "code_toks_joined": "import ConfigParser <NEWLINE> from pygame import Color <NEWLINE> config = ConfigParser . RawConfigParser ( ) <NEWLINE> config . read ( <STRING> ) <NEWLINE> G = 1 <NEWLINE> MAXRESPAWNTIME = 3000 <NEWLINE> BULLET_LIFE = 7000 <NEWLINE> BULLET_MASS = 0.3 <NEWLINE> BULLET_VEL = 6 <NEWLINE> FUEL_MASS = 0.2 <NEWLINE> MAX_FUEL = 16 <NEWLINE> MAX_AMMO = 16 <NEWLINE> GAME_SPEED = 40 <NEWLINE> SYS_FONT = <STRING> <NEWLINE> STATS_FONT = <STRING> <NEWLINE> MAX_OBJECTS = config . getint ( <STRING> , <STRING> ) <NEWLINE> DEBRIS_R = 6 <NEWLINE> DEBRIS_SCALING = 3.0 <NEWLINE> DEBRIS_COLORS = ( Color ( <STRING> ) , Color ( <STRING> ) ) <NEWLINE> HELLDEBRIS_COLORS = ( Color ( <STRING> ) , Color ( <STRING> ) ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'profile.cfg'", "\"font.ttf\"", "\"font_stats.ttf\"", "\"Misc\"", "\"max_objects\"", "\"#555555\"", "\"#888888\"", "\"#303030\"", "\"#777777\""]}}], ["2f47e99729892d1e8af346f9d5afbdf1", {"code_string": "def mood(self):\n    unhappiness = self.hunger + self.boredom\n    if unhappiness < 5:\n        m = \"happy\"\n    elif 5 <= unhappiness <= 10:\n        m = \"okay\"\n    elif 11 <= unhappiness <= 15:\n        m = \"frustrated\"\n    else:\n        m = \"mad\"\n    return m\n", "code_toks_joined": "def mood ( self ) : <NEWLINE> <INDENT> unhappiness = self . hunger + self . boredom <NEWLINE> if unhappiness < 5 : <NEWLINE> <INDENT> m = <STRING> <NEWLINE> <DEDENT> elif 5 <= unhappiness <= 10 : <NEWLINE> <INDENT> m = <STRING> <NEWLINE> <DEDENT> elif 11 <= unhappiness <= 15 : <NEWLINE> <INDENT> m = <STRING> <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> m = <STRING> <NEWLINE> <DEDENT> return m <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"happy\"", "\"okay\"", "\"frustrated\"", "\"mad\""]}}], ["532257aa63f07c830de9f8644db7240c", {"code_string": "def get_table(key):\n    m = hashlib.md5()\n    m.update(key)\n    s = m.digest()\n    (a, b) = struct.unpack('<QQ', s)\n    table = [c for c in string.maketrans('', '')]\n    for i in xrange(1, 1024):\n        table.sort(lambda x, y: int(a %(ord(x) + i) - a %(ord(y) + i)))\n    return table\n", "code_toks_joined": "def get_table ( key ) : <NEWLINE> <INDENT> m = hashlib . md5 ( ) <NEWLINE> m . update ( key ) <NEWLINE> s = m . digest ( ) <NEWLINE> ( a , b ) = struct . unpack ( <STRING> , s ) <NEWLINE> table = [ c for c in string . maketrans ( <STRING> , <STRING> ) ] <NEWLINE> for i in xrange ( 1 , 1024 ) : <NEWLINE> <INDENT> table . sort ( lambda x , y : int ( a % ( ord ( x ) + i ) - a % ( ord ( y ) + i ) ) ) <NEWLINE> <DEDENT> return table <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'<QQ'", "''", "''"]}}], ["2a93d8726cf2353bb35d91974b1bd354", {"code_string": "import re\nimport urlparse\nfrom pyload.plugin.internal.SimpleHoster import SimpleHoster\nfrom pyload.utils import html_unescape\n", "code_toks_joined": "import re <NEWLINE> import urlparse <NEWLINE> from pyload . plugin . internal . SimpleHoster import SimpleHoster <NEWLINE> from pyload . utils import html_unescape <NEWLINE>", "anonymize_dict": {}}], ["2b822e9d056a8c75c29bec1e1cb9a281", {"code_string": "from datetime import datetime\nimport random\nimport numpy\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision.datasets.folder import *\nfrom torch.optim import SGD, Adadelta, Adam, Adagrad, RMSprop, ASGD\nOPTIMIZERS = {\n    'sgd': SGD,\n    'adadelta': Adadelta,\n    'adam': Adam,\n    'adagrad': Adagrad,\n    'rmsprop': RMSprop,\n    'asgd': ASGD\n}\n", "code_toks_joined": "from datetime import datetime <NEWLINE> import random <NEWLINE> import numpy <NEWLINE> import torch <NEWLINE> import torch . nn as nn <NEWLINE> import torch . nn . functional as F <NEWLINE> import torchvision <NEWLINE> from torchvision . datasets . folder import * <NEWLINE> from torch . optim import SGD , Adadelta , Adam , Adagrad , RMSprop , ASGD <NEWLINE> OPTIMIZERS = { <NEWLINE> <INDENT> <STRING> : SGD , <NEWLINE> <STRING> : Adadelta , <NEWLINE> <STRING> : Adam , <NEWLINE> <STRING> : Adagrad , <NEWLINE> <STRING> : RMSprop , <NEWLINE> <STRING> : ASGD <NEWLINE> <DEDENT> } <NEWLINE>", "anonymize_dict": {"<STRING>": ["'sgd'", "'adadelta'", "'adam'", "'adagrad'", "'rmsprop'", "'asgd'"]}}], ["977e242d8251046cafe013db825b4874", {"code_string": "class DjangoBNRApp(AppConfig):\n    name = 'django_bnr'\n    verbose_name = 'BNR Exchange Rates'\n", "code_toks_joined": "class DjangoBNRApp ( AppConfig ) : <NEWLINE> <INDENT> name = <STRING> <NEWLINE> verbose_name = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'django_bnr'", "'BNR Exchange Rates'"]}}], ["4e06120d7b269a2d0fb9cbddd39da3b1", {"code_string": "def _mapdamage_plot(self, config, destination, prefix, files_and_nodes):\n    title = \"mapDamage plot for library %r\" %(self.name, )\n    dependencies = files_and_nodes.values()\n    plot = MapDamagePlotNode.customize(config = config,\n        reference = prefix[\"Path\"],\n        input_files = files_and_nodes.keys(),\n        output_directory = destination,\n        title = title,\n        dependencies = dependencies)\n    apply_options(plot.command, self.options[\"mapDamage\"])\n    return plot.build_node()\n", "code_toks_joined": "def _mapdamage_plot ( self , config , destination , prefix , files_and_nodes ) : <NEWLINE> <INDENT> title = <STRING> % ( self . name , ) <NEWLINE> dependencies = files_and_nodes . values ( ) <NEWLINE> plot = MapDamagePlotNode . customize ( config = config , <NEWLINE> <INDENT> reference = prefix [ <STRING> ] , <NEWLINE> input_files = files_and_nodes . keys ( ) , <NEWLINE> output_directory = destination , <NEWLINE> title = title , <NEWLINE> dependencies = dependencies ) <NEWLINE> <DEDENT> apply_options ( plot . command , self . options [ <STRING> ] ) <NEWLINE> return plot . build_node ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"mapDamage plot for library %r\"", "\"Path\"", "\"mapDamage\""]}}], ["611afc580bf1f9aedb22b6ce3c0bc9e0", {"code_string": "class Command(migrate.Command):\n    def handle(self, * args, ** kwargs):\n        patch_sae_restful_mysql()\n        kwargs.setdefault('database', DEFAULT_DB_ALIAS)\n        super(Command, self).handle(* args, ** kwargs)\n", "code_toks_joined": "class Command ( migrate . Command ) : <NEWLINE> <INDENT> def handle ( self , * args , ** kwargs ) : <NEWLINE> <INDENT> patch_sae_restful_mysql ( ) <NEWLINE> kwargs . setdefault ( <STRING> , DEFAULT_DB_ALIAS ) <NEWLINE> super ( Command , self ) . handle ( * args , ** kwargs ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'database'"]}}], ["4f66a769993c62b3980c721962244554", {"code_string": "def close(self):\n    \"\"\" Close the link. \"\"\"\n    self._thread.stop()\n    try:\n        if self.cradio:\n            self.cradio.close()\n    except:\n        pass\n    self.cradio = None\n    while not self.out_queue.empty():\n        self.out_queue.get()\n    self.link_error_callback = None\n    self.link_quality_callback = None\n", "code_toks_joined": "def close ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . _thread . stop ( ) <NEWLINE> try : <NEWLINE> <INDENT> if self . cradio : <NEWLINE> <INDENT> self . cradio . close ( ) <NEWLINE> <DEDENT> <DEDENT> except : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> self . cradio = None <NEWLINE> while not self . out_queue . empty ( ) : <NEWLINE> <INDENT> self . out_queue . get ( ) <NEWLINE> <DEDENT> self . link_error_callback = None <NEWLINE> self . link_quality_callback = None <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Close the link. \"\"\""]}}], ["353fe14e1dbf4b515668647b9822d6f8", {"code_string": "import sys\nlines = [line.decode('utf-8').rstrip(u'\\r\\n') for line in sys.stdin.readlines()]\nlines = sorted(lines, key = lambda l: l.split(u'\\t')[0])\nlines = sorted(lines, key = lambda l: l.split(u'\\t')[1])\nfor line in lines:\n    print(line.encode('utf-8'))\n", "code_toks_joined": "import sys <NEWLINE> lines = [ line . decode ( <STRING> ) . rstrip ( <STRING> ) for line in sys . stdin . readlines ( ) ] <NEWLINE> lines = sorted ( lines , key = lambda l : l . split ( <STRING> ) [ 0 ] ) <NEWLINE> lines = sorted ( lines , key = lambda l : l . split ( <STRING> ) [ 1 ] ) <NEWLINE> for line in lines : <NEWLINE> <INDENT> print ( line . encode ( <STRING> ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'utf-8'", "u'\\r\\n'", "u'\\t'", "u'\\t'", "'utf-8'"]}}], ["4b0bc2655c89070b4cf8d14e5abaaf0d", {"code_string": "def test_08_bury(self):\n    \"\"\" Bury keyfile in a image file \"\"\"\n    self.assertTrue(tbury(\n        self.keyfile, self.passphrase2, self.imagefile\n        )[0]\n        )\n", "code_toks_joined": "def test_08_bury ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . assertTrue ( tbury ( <NEWLINE> <INDENT> self . keyfile , self . passphrase2 , self . imagefile <NEWLINE> ) [ 0 ] <NEWLINE> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Bury keyfile in a image file \"\"\""]}}], ["4b4c642895258686ad06ebebc9632f35", {"code_string": "class FeuerFreiTestCase(unittest.TestCase):\n    def test_equal_1(self):\n        self.assertEqual(feuer_frei(5, 20), 'Perfekt!')\n    def test_equal_2(self):\n        self.assertEqual(feuer_frei(5, 200), 900)\n    def test_equal_3(self):\n        self.assertEqual(feuer_frei(5, 2),\n            '90 Stunden mehr Benzin ben\\xf6tigt.')\n", "code_toks_joined": "class FeuerFreiTestCase ( unittest . TestCase ) : <NEWLINE> <INDENT> def test_equal_1 ( self ) : <NEWLINE> <INDENT> self . assertEqual ( feuer_frei ( 5 , 20 ) , <STRING> ) <NEWLINE> <DEDENT> def test_equal_2 ( self ) : <NEWLINE> <INDENT> self . assertEqual ( feuer_frei ( 5 , 200 ) , 900 ) <NEWLINE> <DEDENT> def test_equal_3 ( self ) : <NEWLINE> <INDENT> self . assertEqual ( feuer_frei ( 5 , 2 ) , <NEWLINE> <INDENT> <STRING> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Perfekt!'", "'90 Stunden mehr Benzin ben\\xf6tigt.'"]}}], ["de76458667a79cf95ff7397972afcd9a", {"code_string": "def computeCost(X, y, theta):\n    \"\"\"computes the cost of using theta as the parameter for linear\"\"\"\n    m = len(y)\n    J = 0\n    h = X.dot(theta)\n    J = (1.0 /(2 * m)) * np.sum(np.square(h - y))\n    return J\n", "code_toks_joined": "def computeCost ( X , y , theta ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> m = len ( y ) <NEWLINE> J = 0 <NEWLINE> h = X . dot ( theta ) <NEWLINE> J = ( 1.0 / ( 2 * m ) ) * np . sum ( np . square ( h - y ) ) <NEWLINE> return J <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"computes the cost of using theta as the parameter for linear\"\"\""]}}], ["759e92841698b0ab6e157d03cbee56d5", {"code_string": "def remove_all_subsequent_objects(root, objects):\n    if objects.has_key(root):\n        while root in objects and objects[root]:\n            child = objects[root].pop()\n            remove_all_subsequent_objects(child, objects)\n        if objects.has_key(root):\n            remove_edge_from_objects(root, objects)\n            del objects[root]\n    else:\n        remove_edge_from_objects(root, objects)\n", "code_toks_joined": "def remove_all_subsequent_objects ( root , objects ) : <NEWLINE> <INDENT> if objects . has_key ( root ) : <NEWLINE> <INDENT> while root in objects and objects [ root ] : <NEWLINE> <INDENT> child = objects [ root ] . pop ( ) <NEWLINE> remove_all_subsequent_objects ( child , objects ) <NEWLINE> <DEDENT> if objects . has_key ( root ) : <NEWLINE> <INDENT> remove_edge_from_objects ( root , objects ) <NEWLINE> del objects [ root ] <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> remove_edge_from_objects ( root , objects ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["2832141dff32c1a6e75adc29fc3ad82a", {"code_string": "def tweetWordCount(kvs):\n    lines = kvs.map(lambda x: x[1])\n    counts = lines.flatMap(lambda line: json.loads(line)[\"text\"].split(\" \")).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n    sys.stdout.flush()\n    return counts\n", "code_toks_joined": "def tweetWordCount ( kvs ) : <NEWLINE> <INDENT> lines = kvs . map ( lambda x : x [ 1 ] ) <NEWLINE> counts = lines . flatMap ( lambda line : json . loads ( line ) [ <STRING> ] . split ( <STRING> ) ) . map ( lambda word : ( word , 1 ) ) . reduceByKey ( lambda a , b : a + b ) <NEWLINE> sys . stdout . flush ( ) <NEWLINE> return counts <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"text\"", "\" \""]}}], ["6193c5491c33d56b340d30a49997d861", {"code_string": "from django.db import models\nfrom perfil.models import Persona\nfrom especialidad import Especialidad\n", "code_toks_joined": "from django . db import models <NEWLINE> from perfil . models import Persona <NEWLINE> from especialidad import Especialidad <NEWLINE>", "anonymize_dict": {}}], ["85c8a594ee05fd3b2d1b90078d9d0fda", {"code_string": "class Connection(protocol.Protocol):\n    \"\"\"Class that simulates client connection to tcp server\"\"\"\n    db = adbapi.ConnectionPool(\n        'MySQLdb', db = 'squid_auth', user = 'squid',\n        passwd = 'not_secure_pass', host = '91.202.128.106')\n    def dataReceived(self, data):\n        \"\"\"Method called when new connection received\"\"\"\n        self.db.runQuery(\n            'SELECT * FROM users_all WHERE login=%s AND passwd=%s',\n            ('login', 'pass')\n        ).addCallback(self.respond)\n    def respond(self, _):\n        \"\"\"Dummy callback to sql query\"\"\"\n        self.transport.write('OK')\n        self.transport.loseConnection()\n", "code_toks_joined": "class Connection ( protocol . Protocol ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> db = adbapi . ConnectionPool ( <NEWLINE> <INDENT> <STRING> , db = <STRING> , user = <STRING> , <NEWLINE> passwd = <STRING> , host = <STRING> ) <NEWLINE> <DEDENT> def dataReceived ( self , data ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . db . runQuery ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> ( <STRING> , <STRING> ) <NEWLINE> <DEDENT> ) . addCallback ( self . respond ) <NEWLINE> <DEDENT> def respond ( self , _ ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . transport . write ( <STRING> ) <NEWLINE> self . transport . loseConnection ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Class that simulates client connection to tcp server\"\"\"", "'MySQLdb'", "'squid_auth'", "'squid'", "'not_secure_pass'", "'91.202.128.106'", "\"\"\"Method called when new connection received\"\"\"", "'SELECT * FROM users_all WHERE login=%s AND passwd=%s'", "'login'", "'pass'", "\"\"\"Dummy callback to sql query\"\"\"", "'OK'"]}}], ["1beb1b1ac036aace055b7132a9cdeb0f", {"code_string": "from test_framework.mininode import *\nfrom test_framework.test_framework import InfinitumTestFramework\nfrom test_framework.util import *\nimport time\nfrom test_framework.blocktools import create_block, create_coinbase\n'''AcceptBlockTest -- test processing of unrequested blocks.'''\n", "code_toks_joined": "from test_framework . mininode import * <NEWLINE> from test_framework . test_framework import InfinitumTestFramework <NEWLINE> from test_framework . util import * <NEWLINE> import time <NEWLINE> from test_framework . blocktools import create_block , create_coinbase <NEWLINE> <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''AcceptBlockTest -- test processing of unrequested blocks.'''"]}}], ["831446dd2641eb3cf7a638935e7054b1", {"code_string": "def encode(self, o):\n    \"\"\"Load and then dump the result using parse_constant kwarg\"\"\"\n    encoded_o = super(PlotlyJSONEncoder, self).encode(o)\n    try:\n        new_o = _json.loads(encoded_o,\n            parse_constant = self.coerce_to_strict)\n    except ValueError:\n        raise ValueError(\n            \"Encoding into strict JSON failed. Did you set the separators \"\n            \"valid JSON separators?\"\n        )\n    else:\n        return _json.dumps(new_o, sort_keys = self.sort_keys,\n            indent = self.indent,\n            separators = (self.item_separator,\n                self.key_separator))\n", "code_toks_joined": "def encode ( self , o ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> encoded_o = super ( PlotlyJSONEncoder , self ) . encode ( o ) <NEWLINE> try : <NEWLINE> <INDENT> new_o = _json . loads ( encoded_o , <NEWLINE> <INDENT> parse_constant = self . coerce_to_strict ) <NEWLINE> <DEDENT> <DEDENT> except ValueError : <NEWLINE> <INDENT> raise ValueError ( <NEWLINE> <INDENT> <STRING> <NEWLINE> <STRING> <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return _json . dumps ( new_o , sort_keys = self . sort_keys , <NEWLINE> <INDENT> indent = self . indent , <NEWLINE> separators = ( self . item_separator , <NEWLINE> <INDENT> self . key_separator ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Load and then dump the result using parse_constant kwarg\"\"\"", "\"Encoding into strict JSON failed. Did you set the separators \"", "\"valid JSON separators?\""]}}], ["0b024fcf740936e2c9486217a39b8520", {"code_string": "import aiohttp\nimport logging\nimport json\nimport collections\nlogger = logging.getLogger(__name__)\n", "code_toks_joined": "import aiohttp <NEWLINE> import logging <NEWLINE> import json <NEWLINE> import collections <NEWLINE> logger = logging . getLogger ( __name__ ) <NEWLINE>", "anonymize_dict": {}}], ["0166c83cd2ca267df46fdc9fc0143532", {"code_string": "def simplify(robot):\n    \"\"\"Utility function: replaces a robot's geometry with simplified bounding\"\"\"\n    for i in range(robot.numLinks()):\n        geom = robot.link(i).geometry()\n        if geom.empty(): continue\n        BB = geom.getBB()\n        print(BB[0], BB[1])\n        BBgeom = GeometricPrimitive()\n        BBgeom.setAABB(BB[0], BB[1])\n        geom.setGeometricPrimitive(BBgeom)\n", "code_toks_joined": "def simplify ( robot ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> for i in range ( robot . numLinks ( ) ) : <NEWLINE> <INDENT> geom = robot . link ( i ) . geometry ( ) <NEWLINE> if geom . empty ( ) : continue <NEWLINE> BB = geom . getBB ( ) <NEWLINE> print ( BB [ 0 ] , BB [ 1 ] ) <NEWLINE> BBgeom = GeometricPrimitive ( ) <NEWLINE> BBgeom . setAABB ( BB [ 0 ] , BB [ 1 ] ) <NEWLINE> geom . setGeometricPrimitive ( BBgeom ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Utility function: replaces a robot's geometry with simplified bounding\"\"\""]}}], ["2df6b18b395132ff6de184bfd57c2a54", {"code_string": "from django.db import models\nfrom dbmail import app_installed\nHTMLField = models.TextField\nif app_installed('tinymce'):\n    try:\n        from tinymce.models import HTMLField\n    except ImportError:\n        pass\n", "code_toks_joined": "from django . db import models <NEWLINE> from dbmail import app_installed <NEWLINE> HTMLField = models . TextField <NEWLINE> if app_installed ( <STRING> ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> from tinymce . models import HTMLField <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'tinymce'"]}}], ["e593f6a348c2f1a830fc52d3ad03e0c5", {"code_string": "def module_test():\n    '''runs doctest on modules'''\n    print('testing modules')\n    doctest.testmod(convert)\n    doctest.testmod(file_data)\n    doctest.testmod(uv_data)\n", "code_toks_joined": "def module_test ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> print ( <STRING> ) <NEWLINE> doctest . testmod ( convert ) <NEWLINE> doctest . testmod ( file_data ) <NEWLINE> doctest . testmod ( uv_data ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''runs doctest on modules'''", "'testing modules'"]}}], ["b5c62e54b84b838313ebc1ec39efca01", {"code_string": "class SponsorListView(ListView):\n    model = Sponsor\n    context_object_name = \"sponsors\"\n    template_name = \"sponsors/sponsor_list.html\"\n    def get_queryset(self):\n        return super(SponsorListView, self).get_queryset().order_by('name')\n", "code_toks_joined": "class SponsorListView ( ListView ) : <NEWLINE> <INDENT> model = Sponsor <NEWLINE> context_object_name = <STRING> <NEWLINE> template_name = <STRING> <NEWLINE> def get_queryset ( self ) : <NEWLINE> <INDENT> return super ( SponsorListView , self ) . get_queryset ( ) . order_by ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"sponsors\"", "\"sponsors/sponsor_list.html\"", "'name'"]}}], ["b7b7ca65ab87f63e1e609f46c8c71d03", {"code_string": "import sys\nimport json\nDIR = sys.argv.pop + sys.argv.pop\nmetadata = open(DIR)\nprint(json.load(metadata))\n", "code_toks_joined": "import sys <NEWLINE> import json <NEWLINE> DIR = sys . argv . pop + sys . argv . pop <NEWLINE> metadata = open ( DIR ) <NEWLINE> print ( json . load ( metadata ) ) <NEWLINE>", "anonymize_dict": {}}], ["9eba2d231d785e0e5b2ecc9edadf81cf", {"code_string": "def _fft_factory(invec, outvec, nbatch = 1, size = None):\n    backend = get_backend()\n    cls = getattr(backend, 'FFT')\n    return cls\n", "code_toks_joined": "def _fft_factory ( invec , outvec , nbatch = 1 , size = None ) : <NEWLINE> <INDENT> backend = get_backend ( ) <NEWLINE> cls = getattr ( backend , <STRING> ) <NEWLINE> return cls <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'FFT'"]}}], ["7e99f1c8bb59d19de4b347ca7c238f15", {"code_string": "def get_user(keystone, name):\n    \"\"\" Retrieve a user by name\"\"\"\n    users = [x for x in keystone.users.list() if x.name == name]\n    count = len(users)\n    if count == 0:\n        raise KeyError(\"No keystone users with name %s\" % name)\n    elif count > 1:\n        raise ValueError(\"%d users with name %s\" %(count, name))\n    else:\n        return users[0]\n", "code_toks_joined": "def get_user ( keystone , name ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> users = [ x for x in keystone . users . list ( ) if x . name == name ] <NEWLINE> count = len ( users ) <NEWLINE> if count == 0 : <NEWLINE> <INDENT> raise KeyError ( <STRING> % name ) <NEWLINE> <DEDENT> elif count > 1 : <NEWLINE> <INDENT> raise ValueError ( <STRING> % ( count , name ) ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return users [ 0 ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Retrieve a user by name\"\"\"", "\"No keystone users with name %s\"", "\"%d users with name %s\""]}}], ["24f6d312cfa0737f72346a32797af54b", {"code_string": "\"\"\" Extracts album art from an MP3 file.\"\"\"\nimport os\nimport sys\nimport mutagen.mp3\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> import sys <NEWLINE> import mutagen . mp3 <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\" Extracts album art from an MP3 file.\"\"\""]}}], ["85943c46dec0093b634555f52f5adebb", {"code_string": "def rms(input):\n    sum = 0\n    for v in input:\n        sum += v * v\n    sum /= float(len(input))\n    return sum ** 0.5\n", "code_toks_joined": "def rms ( input ) : <NEWLINE> <INDENT> sum = 0 <NEWLINE> for v in input : <NEWLINE> <INDENT> sum += v * v <NEWLINE> <DEDENT> sum /= float ( len ( input ) ) <NEWLINE> return sum ** 0.5 <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["b377e5a2483fd5db2ca38bc54b81946f", {"code_string": "def set_config(self, section_id = None, custom_thumb = '', do_notify = 1, keep_history = 1, do_notify_created = 1):\n    if section_id:\n        monitor_db = database.MonitorDatabase()\n        key_dict = {'section_id': section_id}\n        value_dict = {'custom_thumb_url': custom_thumb,\n            'do_notify': do_notify,\n            'do_notify_created': do_notify_created,\n            'keep_history': keep_history}\n        try:\n            monitor_db.upsert('library_sections', value_dict, key_dict)\n        except:\n            logger.warn(u\"PlexPy Libraries :: Unable to execute database query for set_config: %s.\" % e)\n", "code_toks_joined": "def set_config ( self , section_id = None , custom_thumb = <STRING> , do_notify = 1 , keep_history = 1 , do_notify_created = 1 ) : <NEWLINE> <INDENT> if section_id : <NEWLINE> <INDENT> monitor_db = database . MonitorDatabase ( ) <NEWLINE> key_dict = { <STRING> : section_id } <NEWLINE> value_dict = { <STRING> : custom_thumb , <NEWLINE> <INDENT> <STRING> : do_notify , <NEWLINE> <STRING> : do_notify_created , <NEWLINE> <STRING> : keep_history } <NEWLINE> <DEDENT> try : <NEWLINE> <INDENT> monitor_db . upsert ( <STRING> , value_dict , key_dict ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> logger . warn ( <STRING> % e ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["''", "'section_id'", "'custom_thumb_url'", "'do_notify'", "'do_notify_created'", "'keep_history'", "'library_sections'", "u\"PlexPy Libraries :: Unable to execute database query for set_config: %s.\""]}}], ["ab895c96ec272a26c31438e7df9fec48", {"code_string": "import re\nimport requests\nWORDS = [\"WHO\", \"HOME\"]\n", "code_toks_joined": "import re <NEWLINE> import requests <NEWLINE> WORDS = [ <STRING> , <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"WHO\"", "\"HOME\""]}}], ["b58a9e4a673df26d21608a68c50f60a7", {"code_string": "from __future__ import print_function\nimport tensorflow as tf\nwith tf.Session():\n    input1 = tf.constant([1.0, 1.0, 1.0, 1.0])\n    input2 = tf.constant([2.0, 2.0, 2.0, 2.0])\n    output = tf.add(input1, input2)\n    result = output.eval()\n    print(\"result: \", result)\n", "code_toks_joined": "from __future__ import print_function <NEWLINE> import tensorflow as tf <NEWLINE> with tf . Session ( ) : <NEWLINE> <INDENT> input1 = tf . constant ( [ 1.0 , 1.0 , 1.0 , 1.0 ] ) <NEWLINE> input2 = tf . constant ( [ 2.0 , 2.0 , 2.0 , 2.0 ] ) <NEWLINE> output = tf . add ( input1 , input2 ) <NEWLINE> result = output . eval ( ) <NEWLINE> print ( <STRING> , result ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"result: \""]}}], ["2d12572b7ebe8ac8267c32c247590534", {"code_string": "class CharaModelAdmin(admin.ModelAdmin):\n    list_display = [\"firstname\", \"lastname\", \"username\", \"created_on\"]\n    search_fields = [\"firstname\", \"lastname\", \"username\"]\n    class Meta:\n        model = Character\n", "code_toks_joined": "class CharaModelAdmin ( admin . ModelAdmin ) : <NEWLINE> <INDENT> list_display = [ <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE> search_fields = [ <STRING> , <STRING> , <STRING> ] <NEWLINE> class Meta : <NEWLINE> <INDENT> model = Character <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"firstname\"", "\"lastname\"", "\"username\"", "\"created_on\"", "\"firstname\"", "\"lastname\"", "\"username\""]}}], ["f2e376f85824fc2c6ee0d48f93fca24b", {"code_string": "__author__ = \"Alexander Weigl <Alexander.Weigl@kit.edu>\"\n__version__ = \"0.2\"\n__license__ = \"GPLv3\"\nimport sys\nimport os, os.path\nfrom functools import partial\nfrom jinja2 import Environment\nfrom collections import defaultdict\nfrom argparse import ArgumentParser\nimport click\n", "code_toks_joined": "__author__ = <STRING> <NEWLINE> __version__ = <STRING> <NEWLINE> __license__ = <STRING> <NEWLINE> import sys <NEWLINE> import os , os . path <NEWLINE> from functools import partial <NEWLINE> from jinja2 import Environment <NEWLINE> from collections import defaultdict <NEWLINE> from argparse import ArgumentParser <NEWLINE> import click <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"Alexander Weigl <Alexander.Weigl@kit.edu>\"", "\"0.2\"", "\"GPLv3\""]}}], ["c24c708322370a4d2201da6a427d2f56", {"code_string": "import supybot.conf as conf\nimport supybot.registry as registry\nimport supybot.callbacks as callbacks\nfrom supybot.i18n import PluginInternationalization, internationalizeDocstring\n_ = PluginInternationalization('RSS')\n", "code_toks_joined": "import supybot . conf as conf <NEWLINE> import supybot . registry as registry <NEWLINE> import supybot . callbacks as callbacks <NEWLINE> from supybot . i18n import PluginInternationalization , internationalizeDocstring <NEWLINE> _ = PluginInternationalization ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'RSS'"]}}], ["89309aaa868b5ecbec05a03fdd575c7b", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('core', '0003_add_permissions'),\n    ]\n    operations = [\n        migrations.AlterField(\n            model_name = 'news',\n            name = 'publication_date',\n            field = models.DateTimeField(blank = True, default = None, null = True, unique = True),\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . AlterField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . DateTimeField ( blank = True , default = None , null = True , unique = True ) , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'core'", "'0003_add_permissions'", "'news'", "'publication_date'"]}}], ["3727671e808c3b8b16578c7704bdae48", {"code_string": "from setuptools import setup, find_packages\nsetup(\n    name = 'django-media-manager',\n    version = '3.4.0',\n    description = 'Media-Management with the Django Admin-Interface.',\n    author = ['Patrick Kranzlmueller', 'Six Foot'],\n    author_email = 'dev@6ft.com',\n    url = 'https://github.com/oliverseal/django-media-manager',\n    packages = find_packages(),\n    include_package_data = True,\n    zip_safe = False,\n    classifiers = [\n        'Development Status :: 4 - Beta',\n        'Environment :: Web Environment',\n        'Intended Audience :: Developers',\n        'License :: OSI Approved :: BSD License',\n        'Operating System :: OS Independent',\n        'Programming Language :: Python',\n        'Framework :: Django',\n    ],\n    install_requires = [\n        \"Django>=1.5\",\n        \"pillow\",\n    ],\n)\n", "code_toks_joined": "from setuptools import setup , find_packages <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> author = [ <STRING> , <STRING> ] , <NEWLINE> author_email = <STRING> , <NEWLINE> url = <STRING> , <NEWLINE> packages = find_packages ( ) , <NEWLINE> include_package_data = True , <NEWLINE> zip_safe = False , <NEWLINE> classifiers = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <DEDENT> ] , <NEWLINE> install_requires = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <DEDENT> ] , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'django-media-manager'", "'3.4.0'", "'Media-Management with the Django Admin-Interface.'", "'Patrick Kranzlmueller'", "'Six Foot'", "'dev@6ft.com'", "'https://github.com/oliverseal/django-media-manager'", "'Development Status :: 4 - Beta'", "'Environment :: Web Environment'", "'Intended Audience :: Developers'", "'License :: OSI Approved :: BSD License'", "'Operating System :: OS Independent'", "'Programming Language :: Python'", "'Framework :: Django'", "\"Django>=1.5\"", "\"pillow\""]}}], ["f4d601cc702a1c1ad50017df90afc388", {"code_string": "import sys\nline = sys.stdin.readline();\nlines = []\ncount = 0;\nwhile line != \"\":\n    count += 1\n    lines.append(line);\n    line = sys.stdin.readline()\n", "code_toks_joined": "import sys <NEWLINE> line = sys . stdin . readline ( ) ; <NEWLINE> lines = [ ] <NEWLINE> count = 0 ; <NEWLINE> while line != <STRING> : <NEWLINE> <INDENT> count += 1 <NEWLINE> lines . append ( line ) ; <NEWLINE> line = sys . stdin . readline ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\""]}}], ["964554a0f7038a83d98e463306429a72", {"code_string": "def test_long_options_error_handling():\n    with raises(DocoptExit):\n        docopt('Usage: prog', '--non-existent')\n    with raises(DocoptExit):\n        docopt('''Usage: prog [--version --verbose]nn''', '--ver')\n    with raises(DocoptLanguageError):\n        docopt('Usage: prog --long\\n\\n--long ARG')\n    with raises(DocoptExit):\n        docopt('Usage: prog --long ARG\\n\\n--long ARG', '--long')\n    with raises(DocoptLanguageError):\n        docopt('Usage: prog --long=ARG\\n\\n--long')\n    with raises(DocoptExit):\n        docopt('Usage: prog --long\\n\\n--long', '--long=ARG')\n", "code_toks_joined": "def test_long_options_error_handling ( ) : <NEWLINE> <INDENT> with raises ( DocoptExit ) : <NEWLINE> <INDENT> docopt ( <STRING> , <STRING> ) <NEWLINE> <DEDENT> with raises ( DocoptExit ) : <NEWLINE> <INDENT> docopt ( <STRING> , <STRING> ) <NEWLINE> <DEDENT> with raises ( DocoptLanguageError ) : <NEWLINE> <INDENT> docopt ( <STRING> ) <NEWLINE> <DEDENT> with raises ( DocoptExit ) : <NEWLINE> <INDENT> docopt ( <STRING> , <STRING> ) <NEWLINE> <DEDENT> with raises ( DocoptLanguageError ) : <NEWLINE> <INDENT> docopt ( <STRING> ) <NEWLINE> <DEDENT> with raises ( DocoptExit ) : <NEWLINE> <INDENT> docopt ( <STRING> , <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Usage: prog'", "'--non-existent'", "'''Usage: prog [--version --verbose]nn'''", "'--ver'", "'Usage: prog --long\\n\\n--long ARG'", "'Usage: prog --long ARG\\n\\n--long ARG'", "'--long'", "'Usage: prog --long=ARG\\n\\n--long'", "'Usage: prog --long\\n\\n--long'", "'--long=ARG'"]}}], ["0fdf75992832748fda9b8958158ec4af", {"code_string": "\"\"\"Crypto related utilities.\"\"\"\nfrom __future__ import unicode_literals\nimport base64\nimport random\nimport string\nfrom django.utils.encoding import force_bytes, force_text\nfrom Crypto.Cipher import AES\nfrom modoboa.parameters import tools as param_tools\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import unicode_literals <NEWLINE> import base64 <NEWLINE> import random <NEWLINE> import string <NEWLINE> from django . utils . encoding import force_bytes , force_text <NEWLINE> from Crypto . Cipher import AES <NEWLINE> from modoboa . parameters import tools as param_tools <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Crypto related utilities.\"\"\""]}}], ["931e6c54e8df3e2cfe9abba140c760d6", {"code_string": "class UsagepanelTabs(tabs.TabGroup):\n    slug = \"usagepanel_tabs\"\n    tabs = (UsageTab, )\n    sticky = True\n", "code_toks_joined": "class UsagepanelTabs ( tabs . TabGroup ) : <NEWLINE> <INDENT> slug = <STRING> <NEWLINE> tabs = ( UsageTab , ) <NEWLINE> sticky = True <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"usagepanel_tabs\""]}}], ["1de146a64fb70b86a64ddd373e6501b1", {"code_string": "def __init__(self):\n    self.log_config = None\n    self.ctrl_adv = False\n    self.ctrl_ip = ip_address(\"192.168.100.158\")\n    self.ctrl_port = 5533\n    self.ctrl_adv_iface = \"wlp2s0\"\n", "code_toks_joined": "def __init__ ( self ) : <NEWLINE> <INDENT> self . log_config = None <NEWLINE> self . ctrl_adv = False <NEWLINE> self . ctrl_ip = ip_address ( <STRING> ) <NEWLINE> self . ctrl_port = 5533 <NEWLINE> self . ctrl_adv_iface = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"192.168.100.158\"", "\"wlp2s0\""]}}], ["1320b895b024585ae47e4ac6f74f8c20", {"code_string": "from test.test_support import TestFailed, verbose\nt = (1, 2, 3)\nl = [4, 5, 6]\n", "code_toks_joined": "from test . test_support import TestFailed , verbose <NEWLINE> t = ( 1 , 2 , 3 ) <NEWLINE> l = [ 4 , 5 , 6 ] <NEWLINE>", "anonymize_dict": {}}], ["37f3064dda3144841830efd3b2877e1c", {"code_string": "def is_divisible(* args):\n    f = args[0]\n    return all(f % x == 0 for x in args[1: ])\n", "code_toks_joined": "def is_divisible ( * args ) : <NEWLINE> <INDENT> f = args [ 0 ] <NEWLINE> return all ( f % x == 0 for x in args [ 1 : ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["01a3763502debc4efbae2a310308b9ac", {"code_string": "def files_in(package, directory):\n    paths = []\n    for root, dirs, files in walk(join_path(package, directory)):\n        for file in files:\n            paths.append(join_path(root, file)[(len(package) + 1): ])\n    return paths\n", "code_toks_joined": "def files_in ( package , directory ) : <NEWLINE> <INDENT> paths = [ ] <NEWLINE> for root , dirs , files in walk ( join_path ( package , directory ) ) : <NEWLINE> <INDENT> for file in files : <NEWLINE> <INDENT> paths . append ( join_path ( root , file ) [ ( len ( package ) + 1 ) : ] ) <NEWLINE> <DEDENT> <DEDENT> return paths <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["570071432acec4f26975d3648bf01c8b", {"code_string": "def processMessage(self, currentMessage, envelope):\n    '''This function processes an individual message'''\n    if envelope['type'] == 'flood' or envelope['type'] == 'classType' or envelope['destination'] == self.chordNode.nodeLocation.id:\n        self.classChordClientObj.receiveMessage(currentMessage, envelope)\n        return\n", "code_toks_joined": "def processMessage ( self , currentMessage , envelope ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if envelope [ <STRING> ] == <STRING> or envelope [ <STRING> ] == <STRING> or envelope [ <STRING> ] == self . chordNode . nodeLocation . id : <NEWLINE> <INDENT> self . classChordClientObj . receiveMessage ( currentMessage , envelope ) <NEWLINE> return <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''This function processes an individual message'''", "'type'", "'flood'", "'type'", "'classType'", "'destination'"]}}], ["f99dbe55431dcefedea895ca15929ff9", {"code_string": "def test_single_line_comment_is_ignored(self):\n    lexer.input('// this is a comment')\n    token = lexer.token()\n    self.assertEqual(lexer.lineno, 1)\n    self.assertIsNone(token)\n", "code_toks_joined": "def test_single_line_comment_is_ignored ( self ) : <NEWLINE> <INDENT> lexer . input ( <STRING> ) <NEWLINE> token = lexer . token ( ) <NEWLINE> self . assertEqual ( lexer . lineno , 1 ) <NEWLINE> self . assertIsNone ( token ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'// this is a comment'"]}}], ["47e2d9ed7abc139272726989ee979e85", {"code_string": "'''Over time music21 has gained a lot of features that never became fully developed'''\n__all__ = [\n    'analysis',\n    'counterpoint',\n    'theoryAnalysis',\n    'trecento',\n    'webapps',\n    'chant',\n    'contour',\n    'medren']\nfrom music21.alpha import analysis\nfrom music21.alpha import counterpoint\nfrom music21.alpha import theoryAnalysis\nfrom music21.alpha import trecento\nfrom music21.alpha import webapps\nfrom music21.alpha import chant\nfrom music21.alpha import contour\nfrom music21.alpha import medren\n", "code_toks_joined": "<STRING> <NEWLINE> __all__ = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> ] <NEWLINE> <DEDENT> from music21 . alpha import analysis <NEWLINE> from music21 . alpha import counterpoint <NEWLINE> from music21 . alpha import theoryAnalysis <NEWLINE> from music21 . alpha import trecento <NEWLINE> from music21 . alpha import webapps <NEWLINE> from music21 . alpha import chant <NEWLINE> from music21 . alpha import contour <NEWLINE> from music21 . alpha import medren <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Over time music21 has gained a lot of features that never became fully developed'''", "'analysis'", "'counterpoint'", "'theoryAnalysis'", "'trecento'", "'webapps'", "'chant'", "'contour'", "'medren'"]}}], ["db848f3963296c33fd75556d4968c221", {"code_string": "def toggle_capture():\n    \"\"\"Activamos o desactivamos el modo captura, seg\u00fan toque\"\"\"\n    screen.tracer(0)\n    global capture_mode\n    capture_mode = not capture_mode\n    if capture_mode:\n        turtobj_cm.fillcolor('green')\n        turtobj_main.shape('classic')\n    else:\n        turtobj_cm.fillcolor('red')\n        capture_shape()\n    screen.tracer(1)\n", "code_toks_joined": "def toggle_capture ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> screen . tracer ( 0 ) <NEWLINE> global capture_mode <NEWLINE> capture_mode = not capture_mode <NEWLINE> if capture_mode : <NEWLINE> <INDENT> turtobj_cm . fillcolor ( <STRING> ) <NEWLINE> turtobj_main . shape ( <STRING> ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> turtobj_cm . fillcolor ( <STRING> ) <NEWLINE> capture_shape ( ) <NEWLINE> <DEDENT> screen . tracer ( 1 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Activamos o desactivamos el modo captura, seg\u00fan toque\"\"\"", "'green'", "'classic'", "'red'"]}}], ["ecacfe6517cfaa325c1902c12039fbbe", {"code_string": "class PhaseRunner:\n    def stand_phase(self):\n        print(\"test\")\n    def draw_phase(self):\n        print(\"test\")\n    def ride_phase(self):\n        print(\"test\")\n    def main_phase(self):\n        print(\"test\")\n    def battle_phase(self):\n        print(\"test\")\n    def end_phase(self):\n        print(\"test\")\n", "code_toks_joined": "class PhaseRunner : <NEWLINE> <INDENT> def stand_phase ( self ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> def draw_phase ( self ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> def ride_phase ( self ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> def main_phase ( self ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> def battle_phase ( self ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> def end_phase ( self ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"test\"", "\"test\"", "\"test\"", "\"test\"", "\"test\"", "\"test\""]}}], ["dbbf14eb5680953518077402a22f392a", {"code_string": "def kill(self):\n    if self.is_running() == True:\n        try:\n            os.kill(self.get_property('pid'), signal.SIGKILL)\n            killedpid, stat = os.wait()\n            self.set_property('pid', 0)\n        except OSError:\n            sys.stderr.write(\"Process %s does not exist\\n\" % self.pid)\n", "code_toks_joined": "def kill ( self ) : <NEWLINE> <INDENT> if self . is_running ( ) == True : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> os . kill ( self . get_property ( <STRING> ) , signal . SIGKILL ) <NEWLINE> killedpid , stat = os . wait ( ) <NEWLINE> self . set_property ( <STRING> , 0 ) <NEWLINE> <DEDENT> except OSError : <NEWLINE> <INDENT> sys . stderr . write ( <STRING> % self . pid ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'pid'", "'pid'", "\"Process %s does not exist\\n\""]}}], ["48ff438642b7428d1b0ce4ae9801f8f7", {"code_string": "import os\nimport json\nfrom datetime import datetime, timedelta\nfrom settings import TEMPDIR, TEXTDIR, JSONDIR\nfrom settings import logging\nfrom defs import dump_data, load_data\n", "code_toks_joined": "import os <NEWLINE> import json <NEWLINE> from datetime import datetime , timedelta <NEWLINE> from settings import TEMPDIR , TEXTDIR , JSONDIR <NEWLINE> from settings import logging <NEWLINE> from defs import dump_data , load_data <NEWLINE>", "anonymize_dict": {}}], ["9f286dff06ce05ed9e628953308b85d5", {"code_string": "def peewee_init(config):\n    \"\"\"Sample env.ini::\"\"\"\n    env = config.env['orm']\n    db_class = getattr(peewee_async, env.get('driver') or 'PostgresqlDatabase')\n    db = db_class(\n        env.get('dbname'),\n        user = env.get('user'),\n        password = env.get('password')\n    )\n    db_proxy.initialize(db)\n", "code_toks_joined": "def peewee_init ( config ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> env = config . env [ <STRING> ] <NEWLINE> db_class = getattr ( peewee_async , env . get ( <STRING> ) or <STRING> ) <NEWLINE> db = db_class ( <NEWLINE> <INDENT> env . get ( <STRING> ) , <NEWLINE> user = env . get ( <STRING> ) , <NEWLINE> password = env . get ( <STRING> ) <NEWLINE> <DEDENT> ) <NEWLINE> db_proxy . initialize ( db ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Sample env.ini::\"\"\"", "'orm'", "'driver'", "'PostgresqlDatabase'", "'dbname'", "'user'", "'password'"]}}], ["2e4849108bb48a50985b8b17f60f9eaa", {"code_string": "class GetReportByIdChoreographyExecution(ChoreographyExecution):\n    def _make_result_set(self, response, path):\n        return GetReportByIdResultSet(response, path)\n", "code_toks_joined": "class GetReportByIdChoreographyExecution ( ChoreographyExecution ) : <NEWLINE> <INDENT> def _make_result_set ( self , response , path ) : <NEWLINE> <INDENT> return GetReportByIdResultSet ( response , path ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["1e710aa2a0781bc01e22d550a6da0b88", {"code_string": "def combine_name_pair(name, suffix):\n    if suffix:\n        if suffix[0] == \":\":\n            return name + suffix\n        else:\n            return name + \" \" + suffix\n    else:\n        return name\n", "code_toks_joined": "def combine_name_pair ( name , suffix ) : <NEWLINE> <INDENT> if suffix : <NEWLINE> <INDENT> if suffix [ 0 ] == <STRING> : <NEWLINE> <INDENT> return name + suffix <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return name + <STRING> + suffix <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> return name <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\":\"", "\" \""]}}], ["fa79c1c55a3c6993c97bf5e21764730f", {"code_string": "class NetworkError(HangupsError):\n    \"\"\"hangups network operation failed.\"\"\"\n    pass\n", "code_toks_joined": "class NetworkError ( HangupsError ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"hangups network operation failed.\"\"\""]}}], ["f6b1eb1bf0d635c3d18e0a0eea4b02d0", {"code_string": "class HideChoicesCharField(models.CharField):\n    \"\"\"For Django 1.7, hide the 'choices' for a field.\"\"\"\n    def deconstruct(self):\n        name, path, args, kwargs = models.CharField.deconstruct(self)\n        if path == 'fluent_utils.dry.fields.HideChoicesCharField':\n            path = 'django.db.models.CharField'\n        try:\n            del kwargs['choices']\n        except KeyError:\n            pass\n        return name, path, args, kwargs\n", "code_toks_joined": "class HideChoicesCharField ( models . CharField ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def deconstruct ( self ) : <NEWLINE> <INDENT> name , path , args , kwargs = models . CharField . deconstruct ( self ) <NEWLINE> if path == <STRING> : <NEWLINE> <INDENT> path = <STRING> <NEWLINE> <DEDENT> try : <NEWLINE> <INDENT> del kwargs [ <STRING> ] <NEWLINE> <DEDENT> except KeyError : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> return name , path , args , kwargs <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"For Django 1.7, hide the 'choices' for a field.\"\"\"", "'fluent_utils.dry.fields.HideChoicesCharField'", "'django.db.models.CharField'", "'choices'"]}}], ["ff3f4a09bf4f6f51a6382c955f9dd15c", {"code_string": "class MyHtmlParser(HTMLParser):\n    def handle_starttag(self, tag, attrs):\n        print('<%s>' % tag)\n", "code_toks_joined": "class MyHtmlParser ( HTMLParser ) : <NEWLINE> <INDENT> def handle_starttag ( self , tag , attrs ) : <NEWLINE> <INDENT> print ( <STRING> % tag ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'<%s>'"]}}], ["17c616c69e2d265aedeeb89988ffd0b4", {"code_string": "def update_user_type(self):\n    \"\"\"Return either 'tutor' or 'student' based on which radio\"\"\"\n    if self.rb_tutor.isChecked():\n        self.user_type = 'tutor'\n    elif self.rb_student.isChecked():\n        self.user_type = 'student'\n    self.accept()\n", "code_toks_joined": "def update_user_type ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if self . rb_tutor . isChecked ( ) : <NEWLINE> <INDENT> self . user_type = <STRING> <NEWLINE> <DEDENT> elif self . rb_student . isChecked ( ) : <NEWLINE> <INDENT> self . user_type = <STRING> <NEWLINE> <DEDENT> self . accept ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Return either 'tutor' or 'student' based on which radio\"\"\"", "'tutor'", "'student'"]}}], ["657b17e15dcecaa9cf818ae9e3b1cfd1", {"code_string": "def is_valid_us_zip_code(zip):\n    \"\"\"A valid zipcode fulfills one of the following conditions:\"\"\"\n    if re.match('^\\d{5}(-\\d{4})?$', zip) is not None:\n        return True\n    return False\n", "code_toks_joined": "def is_valid_us_zip_code ( zip ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if re . match ( <STRING> , zip ) is not None : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> return False <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"A valid zipcode fulfills one of the following conditions:\"\"\"", "'^\\d{5}(-\\d{4})?$'"]}}], ["af106a6bde9668f182beae8526e36692", {"code_string": "import sys\nfrom app.standalone_app import StandaloneApp\nif __name__ == \"__main__\":\n    StandaloneApp().run()\n", "code_toks_joined": "import sys <NEWLINE> from app . standalone_app import StandaloneApp <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> StandaloneApp ( ) . run ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"__main__\""]}}], ["a6c9b13f57160d338607f84a19d71942", {"code_string": "def get_yaml_config(file_name):\n    with open(file_name, 'rb') as open_file:\n        contents = yaml.load(open_file)\n        LOGGER.debug(contents)\n        return contents\n    return None\n", "code_toks_joined": "def get_yaml_config ( file_name ) : <NEWLINE> <INDENT> with open ( file_name , <STRING> ) as open_file : <NEWLINE> <INDENT> contents = yaml . load ( open_file ) <NEWLINE> LOGGER . debug ( contents ) <NEWLINE> return contents <NEWLINE> <DEDENT> return None <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'rb'"]}}], ["df5781ca5c8fd9028255517bcd8a893a", {"code_string": "def my_handler(channel, data):\n    msg = example_t.decode(data)\n    print(\"Received message on channel \\\"%s\\\"\" % channel)\n    print(\"   x   = %s\" % str(msg.position[0]))\n    print(\"   y   = %s\" % str(msg.position[1]))\n    print(\"   z   = %s\" % str(msg.position[2]))\n    print(\"\")\n", "code_toks_joined": "def my_handler ( channel , data ) : <NEWLINE> <INDENT> msg = example_t . decode ( data ) <NEWLINE> print ( <STRING> % channel ) <NEWLINE> print ( <STRING> % str ( msg . position [ 0 ] ) ) <NEWLINE> print ( <STRING> % str ( msg . position [ 1 ] ) ) <NEWLINE> print ( <STRING> % str ( msg . position [ 2 ] ) ) <NEWLINE> print ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Received message on channel \\\"%s\\\"\"", "\"   x   = %s\"", "\"   y   = %s\"", "\"   z   = %s\"", "\"\""]}}], ["db5b4ad524a321d5d02d233ca90d960e", {"code_string": "from pkg_resources import resource_filename\nimport dclab\ncfgfile = resource_filename(\"dclab\", 'dclab.cfg')\ndatas = [(cfgfile, \"dclab\")]\nhiddenimports = [\"nptdms\", \"nptdms.version\", \"nptdms.tdms\", \"nptdms.tdmsinfo\"]\nhiddenimports +=[\"scipy.stats\"]\n", "code_toks_joined": "from pkg_resources import resource_filename <NEWLINE> import dclab <NEWLINE> cfgfile = resource_filename ( <STRING> , <STRING> ) <NEWLINE> datas = [ ( cfgfile , <STRING> ) ] <NEWLINE> hiddenimports = [ <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE> hiddenimports += [ <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"dclab\"", "'dclab.cfg'", "\"dclab\"", "\"nptdms\"", "\"nptdms.version\"", "\"nptdms.tdms\"", "\"nptdms.tdmsinfo\"", "\"scipy.stats\""]}}], ["3c8dcdd42adace498f5bcb9e80abb694", {"code_string": "from trump.orm import SymbolManager\nsm = SymbolManager()\noil = sm.get(\"oil_front_month\")\noil.cache()\nprint(oil.df.tail())\nsm.finish()\n", "code_toks_joined": "from trump . orm import SymbolManager <NEWLINE> sm = SymbolManager ( ) <NEWLINE> oil = sm . get ( <STRING> ) <NEWLINE> oil . cache ( ) <NEWLINE> print ( oil . df . tail ( ) ) <NEWLINE> sm . finish ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"oil_front_month\""]}}], ["c58430eb0f4330d12704b201c7921dc0", {"code_string": "\"\"\"1x (Images)\"\"\"\nfrom urllib import urlencode\nfrom urlparse import urljoin\nfrom lxml import html\nimport string\nimport re\ncategories = ['images']\npaging = False\nbase_url = 'https://1x.com'\nsearch_url = base_url + '/backend/search.php?{query}'\n", "code_toks_joined": "<STRING> <NEWLINE> from urllib import urlencode <NEWLINE> from urlparse import urljoin <NEWLINE> from lxml import html <NEWLINE> import string <NEWLINE> import re <NEWLINE> categories = [ <STRING> ] <NEWLINE> paging = False <NEWLINE> base_url = <STRING> <NEWLINE> search_url = base_url + <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"1x (Images)\"\"\"", "'images'", "'https://1x.com'", "'/backend/search.php?{query}'"]}}], ["cd85ad316a4b7f23b0c7bd5f7b5a9ea5", {"code_string": "def get_boundary_length(boundary_file_name, island_file_names):\n    l = 0.0\n    boundary_points = read_points(boundary_file_name)\n    l += get_polygon_length(boundary_points)\n    for island_file in island_file_names:\n        islands_points = read_points(island_file)\n        l += get_polygon_length(islands_points)\n    return l\n", "code_toks_joined": "def get_boundary_length ( boundary_file_name , island_file_names ) : <NEWLINE> <INDENT> l = 0.0 <NEWLINE> boundary_points = read_points ( boundary_file_name ) <NEWLINE> l += get_polygon_length ( boundary_points ) <NEWLINE> for island_file in island_file_names : <NEWLINE> <INDENT> islands_points = read_points ( island_file ) <NEWLINE> l += get_polygon_length ( islands_points ) <NEWLINE> <DEDENT> return l <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["32a27266fd5d568540e1f80f891d2ba5", {"code_string": "class ShowSymbol(Filter):\n    \"\"\" toggle showing the symbols \"\"\"\n    def __call__(self, * a, ** kw):\n        return get_symbols()\n", "code_toks_joined": "class ShowSymbol ( Filter ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __call__ ( self , * a , ** kw ) : <NEWLINE> <INDENT> return get_symbols ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" toggle showing the symbols \"\"\""]}}], ["d24041326591275bb530a2debcdc0bd4", {"code_string": "def deconstruct(self):\n    name, path, args, kwargs = super(AggregateField, self).deconstruct()\n    del kwargs['editable']\n    args = [self.denorm.manager_name] + args\n    return name, path, args, kwargs\n", "code_toks_joined": "def deconstruct ( self ) : <NEWLINE> <INDENT> name , path , args , kwargs = super ( AggregateField , self ) . deconstruct ( ) <NEWLINE> del kwargs [ <STRING> ] <NEWLINE> args = [ self . denorm . manager_name ] + args <NEWLINE> return name , path , args , kwargs <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'editable'"]}}], ["786112a4857278a2e5e5c37d5a456952", {"code_string": "class GameSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = Game\n", "code_toks_joined": "class GameSerializer ( serializers . ModelSerializer ) : <NEWLINE> <INDENT> class Meta : <NEWLINE> <INDENT> model = Game <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["cd0917bc6568ca9b1a811aaf96c6ae99", {"code_string": "def test_http_get_P1(self):\n    self.conn.build_request(\"http://www.aliyun.com/\")\n    response = self.conn.execute_request()\n    self.assertTrue(response.ok())\n    self.assertIn(\"\u4e91\u670d\u52a1\u5668\u3001\u4e91\u4e3b\u673a\u3001\u4e91\u5b58\u50a8\u3001\u5f00\u653e\u5b58\u50a8\u3001\u6570\u636e\u5e93\u3001RDS\", response.response_text())\n", "code_toks_joined": "def test_http_get_P1 ( self ) : <NEWLINE> <INDENT> self . conn . build_request ( <STRING> ) <NEWLINE> response = self . conn . execute_request ( ) <NEWLINE> self . assertTrue ( response . ok ( ) ) <NEWLINE> self . assertIn ( <STRING> , response . response_text ( ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"http://www.aliyun.com/\"", "\"\u4e91\u670d\u52a1\u5668\u3001\u4e91\u4e3b\u673a\u3001\u4e91\u5b58\u50a8\u3001\u5f00\u653e\u5b58\u50a8\u3001\u6570\u636e\u5e93\u3001RDS\""]}}], ["d71e51851f5ef1e47300837ea69cce3b", {"code_string": "class Command(BaseCommand):\n    help = (\"\"\"create new Layers for ekr scores\"\"\")\n    option_list = BaseCommand.option_list +(\n        make_option('--slug',\n            help = 'slug of existing Layer',\n            type = 'str',\n            default = 'vss_area_value'), )\n    @ transaction.commit_on_success\n    def handle(self, * args, ** options):\n        slug = options['slug']\n        sync_layers_ekr_task(slug)\n", "code_toks_joined": "class Command ( BaseCommand ) : <NEWLINE> <INDENT> help = ( <STRING> ) <NEWLINE> option_list = BaseCommand . option_list + ( <NEWLINE> <INDENT> make_option ( <STRING> , <NEWLINE> <INDENT> help = <STRING> , <NEWLINE> type = <STRING> , <NEWLINE> default = <STRING> ) , ) <NEWLINE> <DEDENT> <DEDENT> @ transaction . commit_on_success <NEWLINE> def handle ( self , * args , ** options ) : <NEWLINE> <INDENT> slug = options [ <STRING> ] <NEWLINE> sync_layers_ekr_task ( slug ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"create new Layers for ekr scores\"\"\"", "'--slug'", "'slug of existing Layer'", "'str'", "'vss_area_value'", "'slug'"]}}], ["816478ce03a26e102cdeb30fdbb700c0", {"code_string": "def index(request):\n    if request.user.is_authenticated():\n        return redirect(current_user_profile)\n    else:\n        return render(request, 'index.html')\n", "code_toks_joined": "def index ( request ) : <NEWLINE> <INDENT> if request . user . is_authenticated ( ) : <NEWLINE> <INDENT> return redirect ( current_user_profile ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return render ( request , <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'index.html'"]}}], ["afc513c05f8c3b6b3e3b045bbfa4ee5d", {"code_string": "def alienvault(ipInput):\n    url = \"http://labs.alienvault.com/labs/index.php/projects/open-source-ip-reputation-portal/information-about-ip/?ip=\" + ipInput\n    proxy = urllib2.ProxyHandler()\n    opener = urllib2.build_opener(proxy)\n    response = opener.open(\"http://labs.alienvault.com/labs/index.php/projects/open-source-ip-reputation-portal/information-about-ip/?ip=\" + ipInput)\n    content = response.read()\n    contentString = str(content)\n    rpd = re.compile('.*IP not found.*')\n    rpdFind = re.findall(rpd, contentString)\n    if not rpdFind:\n        print('[+] IP is listed in AlienVault IP reputation database at ' + url)\n    else:\n        print('[-] IP is not listed in AlienVault IP reputation database')\n", "code_toks_joined": "def alienvault ( ipInput ) : <NEWLINE> <INDENT> url = <STRING> + ipInput <NEWLINE> proxy = urllib2 . ProxyHandler ( ) <NEWLINE> opener = urllib2 . build_opener ( proxy ) <NEWLINE> response = opener . open ( <STRING> + ipInput ) <NEWLINE> content = response . read ( ) <NEWLINE> contentString = str ( content ) <NEWLINE> rpd = re . compile ( <STRING> ) <NEWLINE> rpdFind = re . findall ( rpd , contentString ) <NEWLINE> if not rpdFind : <NEWLINE> <INDENT> print ( <STRING> + url ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"http://labs.alienvault.com/labs/index.php/projects/open-source-ip-reputation-portal/information-about-ip/?ip=\"", "\"http://labs.alienvault.com/labs/index.php/projects/open-source-ip-reputation-portal/information-about-ip/?ip=\"", "'.*IP not found.*'", "'[+] IP is listed in AlienVault IP reputation database at '", "'[-] IP is not listed in AlienVault IP reputation database'"]}}], ["3432e8f09d97ff3eb91439847e71e27f", {"code_string": "def getTag(self):\n    \"Return an XML tag representation\"\n    attrs = []\n    for(k, v) in self.__dict__.items():\n        if k not in['timeModified']:\n            if v:\n                attrs.append('%s=%s' %(k, quoteattr(str(v))))\n    return '<font ' + ' '.join(attrs) + '/>'\n", "code_toks_joined": "def getTag ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> attrs = [ ] <NEWLINE> for ( k , v ) in self . __dict__ . items ( ) : <NEWLINE> <INDENT> if k not in [ <STRING> ] : <NEWLINE> <INDENT> if v : <NEWLINE> <INDENT> attrs . append ( <STRING> % ( k , quoteattr ( str ( v ) ) ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> return <STRING> + <STRING> . join ( attrs ) + <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Return an XML tag representation\"", "'timeModified'", "'%s=%s'", "'<font '", "' '", "'/>'"]}}], ["130a10b323dbfe015b28a39156a90fb9", {"code_string": "def initialize(self):\n    self.parser = LILACSQuestionParser()\n    self.service = KnowledgeService(self.emitter)\n    self.build_intents()\n    self.make_bump_thread()\n", "code_toks_joined": "def initialize ( self ) : <NEWLINE> <INDENT> self . parser = LILACSQuestionParser ( ) <NEWLINE> self . service = KnowledgeService ( self . emitter ) <NEWLINE> self . build_intents ( ) <NEWLINE> self . make_bump_thread ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["509ca3bb64685a1eefa321afc3289db4", {"code_string": "def format_bw(bits):\n    if not bits % 1000000:\n        return str(bits / 1000000) + 'mbit'\n    if not bits % 1000:\n        return str(bits / 1000) + 'kbit'\n    return str(bits) + 'bit'\n", "code_toks_joined": "def format_bw ( bits ) : <NEWLINE> <INDENT> if not bits % 1000000 : <NEWLINE> <INDENT> return str ( bits / 1000000 ) + <STRING> <NEWLINE> <DEDENT> if not bits % 1000 : <NEWLINE> <INDENT> return str ( bits / 1000 ) + <STRING> <NEWLINE> <DEDENT> return str ( bits ) + <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'mbit'", "'kbit'", "'bit'"]}}], ["3f2f25e56e19a418d9464b6a8323336c", {"code_string": "def from_topp(topp_traj):\n    return FunctionalChunk(\n        duration = topp_traj.duration,\n        q_fun = topp_traj.Eval,\n        qd_fun = topp_traj.Evald,\n        qdd_fun = topp_traj.Evaldd)\n", "code_toks_joined": "def from_topp ( topp_traj ) : <NEWLINE> <INDENT> return FunctionalChunk ( <NEWLINE> <INDENT> duration = topp_traj . duration , <NEWLINE> q_fun = topp_traj . Eval , <NEWLINE> qd_fun = topp_traj . Evald , <NEWLINE> qdd_fun = topp_traj . Evaldd ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["9662f7bcf17ee58ca0e6331183c99a7f", {"code_string": "def __init__(self, db, user = None):\n    self.db = db\n    self.user = user\n    self.lock = threading.RLock()\n", "code_toks_joined": "def __init__ ( self , db , user = None ) : <NEWLINE> <INDENT> self . db = db <NEWLINE> self . user = user <NEWLINE> self . lock = threading . RLock ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["3de8c266874258188321c5f0b48931ef", {"code_string": "'''Loads standard spectra from Oke 1990 (Aj, 99, 1621).'''\nimport os\nimport numpy as np\nunits = 'Wavelength [A], Flux [erg/s/cm/cm/A 10**16], flux [mJy], bin [A]'\ndir = os.path.join(os.path.dirname(__file__), 'standard_stars')\nfiles = os.listdir(dir)\nStandards = {}\nfor file in files:\n    if file[0] != 'f': continue\n    std_name = file[1: - 4]\n    dat = np.loadtxt(os.path.join(dir, file))\n    Standards[std_name] = dat\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> import numpy as np <NEWLINE> units = <STRING> <NEWLINE> dir = os . path . join ( os . path . dirname ( __file__ ) , <STRING> ) <NEWLINE> files = os . listdir ( dir ) <NEWLINE> Standards = { } <NEWLINE> for file in files : <NEWLINE> <INDENT> if file [ 0 ] != <STRING> : continue <NEWLINE> std_name = file [ 1 : - 4 ] <NEWLINE> dat = np . loadtxt ( os . path . join ( dir , file ) ) <NEWLINE> Standards [ std_name ] = dat <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Loads standard spectra from Oke 1990 (Aj, 99, 1621).'''", "'Wavelength [A], Flux [erg/s/cm/cm/A 10**16], flux [mJy], bin [A]'", "'standard_stars'", "'f'"]}}], ["95a3f7c8e9f16457ca4b39091134b37e", {"code_string": "def addblockInputReference0(self, * blockInputReference0):\n    for obj in blockInputReference0:\n        obj.metaBlockInput0 = self\n", "code_toks_joined": "def addblockInputReference0 ( self , * blockInputReference0 ) : <NEWLINE> <INDENT> for obj in blockInputReference0 : <NEWLINE> <INDENT> obj . metaBlockInput0 = self <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["0dc141ac5222cc9cd09c956c78f6563c", {"code_string": "class Family(family.Family):\n    def __init__(self):\n        super(Family, self).__init__()\n        self.name = 'wikitech'\n        self.langs = {\n            'en': 'wikitech.wikimedia.org',\n        }\n    def version(self, code):\n        return '1.21wmf8'\n", "code_toks_joined": "class Family ( family . Family ) : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> super ( Family , self ) . __init__ ( ) <NEWLINE> self . name = <STRING> <NEWLINE> self . langs = { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT> def version ( self , code ) : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'wikitech'", "'en'", "'wikitech.wikimedia.org'", "'1.21wmf8'"]}}], ["fb924e255429144f6b3fc32c5126a2af", {"code_string": "def print_verbose(s):\n    \"\"\"Print the message if verbose mode is on.\"\"\"\n    if verbose: print(\"# {}\".format(s))\n", "code_toks_joined": "def print_verbose ( s ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if verbose : print ( <STRING> . format ( s ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Print the message if verbose mode is on.\"\"\"", "\"# {}\""]}}], ["0b5fb5e88532ce600e6b6f36839bda2d", {"code_string": "from pyromaths.outils.Arithmetique import pgcd, valeur_alea\nfrom random import choice, randrange\nimport string, math\n", "code_toks_joined": "from pyromaths . outils . Arithmetique import pgcd , valeur_alea <NEWLINE> from random import choice , randrange <NEWLINE> import string , math <NEWLINE>", "anonymize_dict": {}}], ["339d2be3b99bea5ffddf9dfad02101c0", {"code_string": "from bson.objectid import ObjectId\nimport json\nfrom pymongo import MongoClient\n", "code_toks_joined": "from bson . objectid import ObjectId <NEWLINE> import json <NEWLINE> from pymongo import MongoClient <NEWLINE>", "anonymize_dict": {}}], ["3fb9129af1676ed7f2ff74e7eea8dcb2", {"code_string": "def test_init_invalid_url_path_leading_slash(self):\n    bases = (rest_requests.RestResource, )\n    attrs = dict(url_path = '/something')\n    self.assertRaises(ValueError, type, 'Resource', bases, attrs)\n", "code_toks_joined": "def test_init_invalid_url_path_leading_slash ( self ) : <NEWLINE> <INDENT> bases = ( rest_requests . RestResource , ) <NEWLINE> attrs = dict ( url_path = <STRING> ) <NEWLINE> self . assertRaises ( ValueError , type , <STRING> , bases , attrs ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/something'", "'Resource'"]}}], ["8abca6420c5a130fd5d3f9a09f5a454a", {"code_string": "def main(cisco_file = 'cisco_ipsec.txt'):\n    '''Find all of the crypto map entries in the file (lines that begin with'''\n    cisco_cfg = CiscoConfParse(cisco_file)\n    for crypto_map in cisco_cfg.find_objects(r'^crypto map CRYPTO'):\n        print\n        print(crypto_map.text)\n        for child in crypto_map.children:\n            print(child.text)\n    print\n", "code_toks_joined": "def main ( cisco_file = <STRING> ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> cisco_cfg = CiscoConfParse ( cisco_file ) <NEWLINE> for crypto_map in cisco_cfg . find_objects ( <STRING> ) : <NEWLINE> <INDENT> print <NEWLINE> print ( crypto_map . text ) <NEWLINE> for child in crypto_map . children : <NEWLINE> <INDENT> print ( child . text ) <NEWLINE> <DEDENT> <DEDENT> print <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'cisco_ipsec.txt'", "'''Find all of the crypto map entries in the file (lines that begin with'''", "r'^crypto map CRYPTO'"]}}], ["da19b9d65c6664a15610782adc050356", {"code_string": "def search(** kwargs):\n    kwargs = {k: v for k, v in kwargs.items() if v}\n    return InternshipSpeciality.objects.filter(** kwargs).select_related(\"learning_unit\").order_by('acronym', 'name')\n", "code_toks_joined": "def search ( ** kwargs ) : <NEWLINE> <INDENT> kwargs = { k : v for k , v in kwargs . items ( ) if v } <NEWLINE> return InternshipSpeciality . objects . filter ( ** kwargs ) . select_related ( <STRING> ) . order_by ( <STRING> , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"learning_unit\"", "'acronym'", "'name'"]}}], ["2788338e4a4c40991bd1cee419bd0d9f", {"code_string": "from distutils.core import setup\nsetup(name = \"pyuom\",\n    version = \"1.0\",\n    description = \"A Units of Measure Library\",\n    author = 'K. Hanson',\n    url = 'https://github.com/katerina7479/python-units-of-measure.git',\n    package_dir = {'': 'pyuom'},\n    py_modules = ['PhysicalQuantity', 'UnitOfMeasure', 'Acceleration', 'Angle',\n        'Area', 'Length', 'ElectricCurrent', 'LuminousIntensity',\n        'Mass', 'Pressure', 'Temperature', 'Time', 'Velocity', 'Volume'])\n", "code_toks_joined": "from distutils . core import setup <NEWLINE> setup ( name = <STRING> , <NEWLINE> <INDENT> version = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> url = <STRING> , <NEWLINE> package_dir = { <STRING> : <STRING> } , <NEWLINE> py_modules = [ <STRING> , <STRING> , <STRING> , <STRING> , <NEWLINE> <INDENT> <STRING> , <STRING> , <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ] ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"pyuom\"", "\"1.0\"", "\"A Units of Measure Library\"", "'K. Hanson'", "'https://github.com/katerina7479/python-units-of-measure.git'", "''", "'pyuom'", "'PhysicalQuantity'", "'UnitOfMeasure'", "'Acceleration'", "'Angle'", "'Area'", "'Length'", "'ElectricCurrent'", "'LuminousIntensity'", "'Mass'", "'Pressure'", "'Temperature'", "'Time'", "'Velocity'", "'Volume'"]}}], ["7857e11e42303869445eab7f1f7db10c", {"code_string": "\"\"\"Portable file locking utilities.\"\"\"\nimport os\n__all__ = ('LOCK_EX', 'LOCK_SH', 'LOCK_NB', 'lock', 'unlock')\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> __all__ = ( <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Portable file locking utilities.\"\"\"", "'LOCK_EX'", "'LOCK_SH'", "'LOCK_NB'", "'lock'", "'unlock'"]}}], ["5a9bfee9f26c559344dbd538509bb8ed", {"code_string": "def test_basic(self):\n    sot = health_monitor.HealthMonitor()\n    self.assertEqual('healthmonitor', sot.resource_key)\n    self.assertEqual('healthmonitors', sot.resources_key)\n    self.assertEqual('/lbaas/healthmonitors', sot.base_path)\n    self.assertEqual('network', sot.service.service_type)\n    self.assertTrue(sot.allow_create)\n    self.assertTrue(sot.allow_retrieve)\n    self.assertTrue(sot.allow_update)\n    self.assertTrue(sot.allow_delete)\n    self.assertTrue(sot.allow_list)\n", "code_toks_joined": "def test_basic ( self ) : <NEWLINE> <INDENT> sot = health_monitor . HealthMonitor ( ) <NEWLINE> self . assertEqual ( <STRING> , sot . resource_key ) <NEWLINE> self . assertEqual ( <STRING> , sot . resources_key ) <NEWLINE> self . assertEqual ( <STRING> , sot . base_path ) <NEWLINE> self . assertEqual ( <STRING> , sot . service . service_type ) <NEWLINE> self . assertTrue ( sot . allow_create ) <NEWLINE> self . assertTrue ( sot . allow_retrieve ) <NEWLINE> self . assertTrue ( sot . allow_update ) <NEWLINE> self . assertTrue ( sot . allow_delete ) <NEWLINE> self . assertTrue ( sot . allow_list ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'healthmonitor'", "'healthmonitors'", "'/lbaas/healthmonitors'", "'network'"]}}], ["e3c070654a442e954ebe8ab99417d67a", {"code_string": "def config(self, app = None, cpu = None, cores = None, cache = None, ** params):\n    r = CPULimitedHost.config(self, cpu, cores, ** params)\n    self.setParam(r, 'app', app = app)\n    self.setParam(r, 'cache', cache = cache)\n    return r\n", "code_toks_joined": "def config ( self , app = None , cpu = None , cores = None , cache = None , ** params ) : <NEWLINE> <INDENT> r = CPULimitedHost . config ( self , cpu , cores , ** params ) <NEWLINE> self . setParam ( r , <STRING> , app = app ) <NEWLINE> self . setParam ( r , <STRING> , cache = cache ) <NEWLINE> return r <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'app'", "'cache'"]}}], ["14a8429d7f9bebd1e96cd98ed0cfddab", {"code_string": "def load_config():\n    \"\"\"Read prex.json for default FASTA and GFF3\"\"\"\n    if os.path.isfile('prex.json'):\n        with open('prex.json', 'r') as f:\n            config = json.load(f)\n        return config\n    else:\n        return dict()\n", "code_toks_joined": "def load_config ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if os . path . isfile ( <STRING> ) : <NEWLINE> <INDENT> with open ( <STRING> , <STRING> ) as f : <NEWLINE> <INDENT> config = json . load ( f ) <NEWLINE> <DEDENT> return config <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return dict ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Read prex.json for default FASTA and GFF3\"\"\"", "'prex.json'", "'prex.json'", "'r'"]}}], ["93d73e634836639140bbcbbcb9bec034", {"code_string": "class LanguageChangerMixin(object):\n    \"\"\"Convenience mixin that adds CMS Language Changer support.\"\"\"\n    def get(self, request, * args, ** kwargs):\n        if not hasattr(self, 'object'):\n            self.object = self.get_object()\n        set_language_changer(request, self.object.get_absolute_url)\n        return super(LanguageChangerMixin, self).get(request, * args, ** kwargs)\n", "code_toks_joined": "class LanguageChangerMixin ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def get ( self , request , * args , ** kwargs ) : <NEWLINE> <INDENT> if not hasattr ( self , <STRING> ) : <NEWLINE> <INDENT> self . object = self . get_object ( ) <NEWLINE> <DEDENT> set_language_changer ( request , self . object . get_absolute_url ) <NEWLINE> return super ( LanguageChangerMixin , self ) . get ( request , * args , ** kwargs ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Convenience mixin that adds CMS Language Changer support.\"\"\"", "'object'"]}}], ["7e2826532ddf2fc46ce43926a94d0b24", {"code_string": "from __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\nfrom setuptools import setup\nsetup(\n    name = str('pure_python_package'),\n    version = '0.1.0',\n    url = 'example.com',\n    author = 'nobody',\n    author_email = 'nobody@example.com',\n    py_modules = [str('pure_python_package')],\n    entry_points = {\n        'console_scripts': [\n            'pure-python-script = pure_python_package:main',\n        ],\n    },\n)\n", "code_toks_joined": "from __future__ import absolute_import <NEWLINE> from __future__ import print_function <NEWLINE> from __future__ import unicode_literals <NEWLINE> from setuptools import setup <NEWLINE> setup ( <NEWLINE> <INDENT> name = str ( <STRING> ) , <NEWLINE> version = <STRING> , <NEWLINE> url = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> py_modules = [ str ( <STRING> ) ] , <NEWLINE> entry_points = { <NEWLINE> <INDENT> <STRING> : [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <DEDENT> ] , <NEWLINE> <DEDENT> } , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'pure_python_package'", "'0.1.0'", "'example.com'", "'nobody'", "'nobody@example.com'", "'pure_python_package'", "'console_scripts'", "'pure-python-script = pure_python_package:main'"]}}], ["9d639bd7bad497eebb59401aa9ec3b02", {"code_string": "def test_finish_job_started_registry(redis):\n    \"\"\"Finish job removes job from started job registry.\"\"\"\n    yield from enqueue_job(redis = redis, ** stubs.job)\n    stored_id, stored_spec = yield from dequeue_job(redis, stubs.queue)\n    stored_id = stored_id.decode()\n    queue = stored_spec[b'origin'].decode()\n    timeout = stored_spec[b'timeout']\n    yield from start_job(redis, queue, stored_id, timeout)\n    yield from finish_job(redis, queue, stored_id, stubs.job_result)\n    assert not(yield from started_jobs(redis, stubs.queue))\n", "code_toks_joined": "def test_finish_job_started_registry ( redis ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> yield from enqueue_job ( redis = redis , ** stubs . job ) <NEWLINE> stored_id , stored_spec = yield from dequeue_job ( redis , stubs . queue ) <NEWLINE> stored_id = stored_id . decode ( ) <NEWLINE> queue = stored_spec [ <STRING> ] . decode ( ) <NEWLINE> timeout = stored_spec [ <STRING> ] <NEWLINE> yield from start_job ( redis , queue , stored_id , timeout ) <NEWLINE> yield from finish_job ( redis , queue , stored_id , stubs . job_result ) <NEWLINE> assert not ( yield from started_jobs ( redis , stubs . queue ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Finish job removes job from started job registry.\"\"\"", "b'origin'", "b'timeout'"]}}], ["dc72750331107a76854c3bf3828afdb8", {"code_string": "def test_previous_and_next_in_order(self):\n    a1 = self.q1.answer_set.all()[0]\n    self.assertEqual(a1.text, \"John\")\n    self.assertEqual(a1.get_next_in_order().text, \"Paul\")\n    a2 = list(self.q1.answer_set.all())[- 1]\n    self.assertEqual(a2.text, \"Ringo\")\n    self.assertEqual(a2.get_previous_in_order().text, \"George\")\n", "code_toks_joined": "def test_previous_and_next_in_order ( self ) : <NEWLINE> <INDENT> a1 = self . q1 . answer_set . all ( ) [ 0 ] <NEWLINE> self . assertEqual ( a1 . text , <STRING> ) <NEWLINE> self . assertEqual ( a1 . get_next_in_order ( ) . text , <STRING> ) <NEWLINE> a2 = list ( self . q1 . answer_set . all ( ) ) [ - 1 ] <NEWLINE> self . assertEqual ( a2 . text , <STRING> ) <NEWLINE> self . assertEqual ( a2 . get_previous_in_order ( ) . text , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"John\"", "\"Paul\"", "\"Ringo\"", "\"George\""]}}], ["704c3aa86bf314d6d38b55346c289e87", {"code_string": "def is_disconnect(self, e, connection, cursor):\n    for msg in(\n        \"Adaptive Server connection timed out\",\n        \"Net-Lib error during Connection reset by peer\",\n        \"message 20003\",\n        \"Error 10054\",\n        \"Not connected to any MS SQL server\",\n        \"Connection is closed\",\n        \"message 20006\",\n        \"message 20017\",\n    ):\n        if msg in str(e):\n            return True\n    else:\n        return False\n", "code_toks_joined": "def is_disconnect ( self , e , connection , cursor ) : <NEWLINE> <INDENT> for msg in ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <DEDENT> ) : <NEWLINE> <INDENT> if msg in str ( e ) : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Adaptive Server connection timed out\"", "\"Net-Lib error during Connection reset by peer\"", "\"message 20003\"", "\"Error 10054\"", "\"Not connected to any MS SQL server\"", "\"Connection is closed\"", "\"message 20006\"", "\"message 20017\""]}}], ["b30f27b98a6441cdcd4cc6fc9ca63558", {"code_string": "def test_post_auth_digest(self):\n    auth = HTTPDigestAuth('user', 'pa$$')\n    self._http = self.successResultOf(\n        httpclientservice.HTTPClientService.getService(self.parent, 'http://foo',\n            auth = auth))\n    self._http.post('/bar', data = {'foo': 'bar'})\n    self._http._session.request.assert_called_once_with('post', 'http://foo/bar',\n        background_callback = mock.ANY,\n        data = dict(\n            foo = 'bar'),\n        auth = auth,\n        headers = {\n        })\n", "code_toks_joined": "def test_post_auth_digest ( self ) : <NEWLINE> <INDENT> auth = HTTPDigestAuth ( <STRING> , <STRING> ) <NEWLINE> self . _http = self . successResultOf ( <NEWLINE> <INDENT> httpclientservice . HTTPClientService . getService ( self . parent , <STRING> , <NEWLINE> <INDENT> auth = auth ) ) <NEWLINE> <DEDENT> <DEDENT> self . _http . post ( <STRING> , data = { <STRING> : <STRING> } ) <NEWLINE> self . _http . _session . request . assert_called_once_with ( <STRING> , <STRING> , <NEWLINE> <INDENT> background_callback = mock . ANY , <NEWLINE> data = dict ( <NEWLINE> <INDENT> foo = <STRING> ) , <NEWLINE> <DEDENT> auth = auth , <NEWLINE> headers = { <NEWLINE> } ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'user'", "'pa$$'", "'http://foo'", "'/bar'", "'foo'", "'bar'", "'post'", "'http://foo/bar'", "'bar'"]}}], ["2489bbfb3f989931525c2894f929089a", {"code_string": "from.git_commit_utils import *\nfrom.git_etl import GitETL\nfrom.git_client import GitClient\n", "code_toks_joined": "from . git_commit_utils import * <NEWLINE> from . git_etl import GitETL <NEWLINE> from . git_client import GitClient <NEWLINE>", "anonymize_dict": {}}], ["c184f55e7c91dd4fb44e8ae617206e50", {"code_string": "def assertContent(self, vt, content):\n    with open(os.path.join(vt.results_dir, self._filename), 'r') as f:\n        self.assertEquals(f.read(), content)\n", "code_toks_joined": "def assertContent ( self , vt , content ) : <NEWLINE> <INDENT> with open ( os . path . join ( vt . results_dir , self . _filename ) , <STRING> ) as f : <NEWLINE> <INDENT> self . assertEquals ( f . read ( ) , content ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'r'"]}}], ["8f3249b867467e72ebb73fd2dc1d73af", {"code_string": "def replaceNone(input):\n    if input is None:\n        return \"Unknown\"\n    else:\n        return input\n", "code_toks_joined": "def replaceNone ( input ) : <NEWLINE> <INDENT> if input is None : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return input <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Unknown\""]}}], ["99b59d215566c39b46a163934cbe8159", {"code_string": "from warnings import warn\nfrom djangotoolbox.fields import RawField, AbstractIterableField, EmbeddedModelField\n__all__ = ['A']\nDJANGOTOOLBOX_FIELDS = (RawField, AbstractIterableField, EmbeddedModelField)\n", "code_toks_joined": "from warnings import warn <NEWLINE> from djangotoolbox . fields import RawField , AbstractIterableField , EmbeddedModelField <NEWLINE> __all__ = [ <STRING> ] <NEWLINE> DJANGOTOOLBOX_FIELDS = ( RawField , AbstractIterableField , EmbeddedModelField ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'A'"]}}], ["4c141c20bf710f538b52b732333310df", {"code_string": "class Comment(APIMixin, Base):\n    __tablename__ = 'comments'\n    id = Column(Integer, primary_key = True)\n    content = Column(UnicodeText)\n    user_id = Column(Integer, ForeignKey('users.id'))\n    post_id = Column(Integer, ForeignKey('posts.id'))\n    user = relationship('User', lazy = 'joined',\n        backref = backref('comments', lazy = 'dynamic'))\n    post = relationship('Post', lazy = 'joined',\n        backref = backref('comments', lazy = 'dynamic'))\n", "code_toks_joined": "class Comment ( APIMixin , Base ) : <NEWLINE> <INDENT> __tablename__ = <STRING> <NEWLINE> id = Column ( Integer , primary_key = True ) <NEWLINE> content = Column ( UnicodeText ) <NEWLINE> user_id = Column ( Integer , ForeignKey ( <STRING> ) ) <NEWLINE> post_id = Column ( Integer , ForeignKey ( <STRING> ) ) <NEWLINE> user = relationship ( <STRING> , lazy = <STRING> , <NEWLINE> <INDENT> backref = backref ( <STRING> , lazy = <STRING> ) ) <NEWLINE> <DEDENT> post = relationship ( <STRING> , lazy = <STRING> , <NEWLINE> <INDENT> backref = backref ( <STRING> , lazy = <STRING> ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'comments'", "'users.id'", "'posts.id'", "'User'", "'joined'", "'comments'", "'dynamic'", "'Post'", "'joined'", "'comments'", "'dynamic'"]}}], ["a876220c41d606a0fe1daa73afbd10f7", {"code_string": "def __init__(self, frame_buffer, movie_length):\n    self.last_time = self.current_milli_time()\n    self.current_frame = 0\n    self.frame_buffer = frame_buffer\n    self.movie_length = movie_length\n    self.times = []\n    threading.Thread.__init__(self)\n", "code_toks_joined": "def __init__ ( self , frame_buffer , movie_length ) : <NEWLINE> <INDENT> self . last_time = self . current_milli_time ( ) <NEWLINE> self . current_frame = 0 <NEWLINE> self . frame_buffer = frame_buffer <NEWLINE> self . movie_length = movie_length <NEWLINE> self . times = [ ] <NEWLINE> threading . Thread . __init__ ( self ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["0628768628b065c2abc8ae349d0306be", {"code_string": "\"\"\"Process execution wrappers\"\"\"\nfrom __future__ import unicode_literals\nimport os\nimport sys\nimport time\nimport subprocess\nfrom tempfile import TemporaryFile\nimport warnings\nfrom applib.misc import xjoin\nfrom applib.misc import safe_unicode\n__all__ = ['run', 'RunError', 'RunNonZeroReturn', 'RunTimedout']\nwarnings.filterwarnings('ignore', message = '.*With\\-statements.*',\n    category = DeprecationWarning)\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import unicode_literals <NEWLINE> import os <NEWLINE> import sys <NEWLINE> import time <NEWLINE> import subprocess <NEWLINE> from tempfile import TemporaryFile <NEWLINE> import warnings <NEWLINE> from applib . misc import xjoin <NEWLINE> from applib . misc import safe_unicode <NEWLINE> __all__ = [ <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE> warnings . filterwarnings ( <STRING> , message = <STRING> , <NEWLINE> <INDENT> category = DeprecationWarning ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Process execution wrappers\"\"\"", "'run'", "'RunError'", "'RunNonZeroReturn'", "'RunTimedout'", "'ignore'", "'.*With\\-statements.*'"]}}], ["b4f3a8dfb93c5b686f91a208ae73d568", {"code_string": "def setUp(self):\n    self.crud.delete(self.ncc, ietf_aug_base_1.Cpython())\n    self.crud.delete(self.ncc, ietf_aug_base_2.Cpython())\n", "code_toks_joined": "def setUp ( self ) : <NEWLINE> <INDENT> self . crud . delete ( self . ncc , ietf_aug_base_1 . Cpython ( ) ) <NEWLINE> self . crud . delete ( self . ncc , ietf_aug_base_2 . Cpython ( ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["b9f2881c98fec26b233e4c52721dc5c2", {"code_string": "import re\nfrom json.decoder import JSONDecoder\n__all__ = (\n    \"not_found\",\n    \"cannot_parse_JSON\",\n    \"find_JSON_format_data_structure\"\n)\n", "code_toks_joined": "import re <NEWLINE> from json . decoder import JSONDecoder <NEWLINE> __all__ = ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"not_found\"", "\"cannot_parse_JSON\"", "\"find_JSON_format_data_structure\""]}}], ["34a87ff897c7b8b0427c777c93bd5fed", {"code_string": "def __init__(self, nmarea, g2area, nmmodule, options):\n    lev = nmmodule.params.Level\n    if getv(lev) == 127 and not lev.knob and not lev.morph and not lev.ctrl:\n        self.maing2module = '2-Out'\n    if len(filter(isxoutput, nmarea.modules)) < 2:\n        self.maing2module = '2-Out'\n    Convert.__init__(self, nmarea, g2area, nmmodule, options)\n", "code_toks_joined": "def __init__ ( self , nmarea , g2area , nmmodule , options ) : <NEWLINE> <INDENT> lev = nmmodule . params . Level <NEWLINE> if getv ( lev ) == 127 and not lev . knob and not lev . morph and not lev . ctrl : <NEWLINE> <INDENT> self . maing2module = <STRING> <NEWLINE> <DEDENT> if len ( filter ( isxoutput , nmarea . modules ) ) < 2 : <NEWLINE> <INDENT> self . maing2module = <STRING> <NEWLINE> <DEDENT> Convert . __init__ ( self , nmarea , g2area , nmmodule , options ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'2-Out'", "'2-Out'"]}}], ["71c253a62ae2ce4bba2ea82853fc6122", {"code_string": "def keepInWindow(self):\n    x, y = self.position\n    if self.outOfBoundsLeft():\n        x = 0\n    elif self.outOfBoundsRight():\n        x = GameConstants.SCREEN_SIZE[0] - self.size[0]\n    elif self.outOfBoundsAbove():\n        y = 0\n    elif self.outOfBoundsBelow():\n        y = GameConstants.SCREEN_SIZE[1] - self.size[1]\n    self.position = (x, y)\n", "code_toks_joined": "def keepInWindow ( self ) : <NEWLINE> <INDENT> x , y = self . position <NEWLINE> if self . outOfBoundsLeft ( ) : <NEWLINE> <INDENT> x = 0 <NEWLINE> <DEDENT> elif self . outOfBoundsRight ( ) : <NEWLINE> <INDENT> x = GameConstants . SCREEN_SIZE [ 0 ] - self . size [ 0 ] <NEWLINE> <DEDENT> elif self . outOfBoundsAbove ( ) : <NEWLINE> <INDENT> y = 0 <NEWLINE> <DEDENT> elif self . outOfBoundsBelow ( ) : <NEWLINE> <INDENT> y = GameConstants . SCREEN_SIZE [ 1 ] - self . size [ 1 ] <NEWLINE> <DEDENT> self . position = ( x , y ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ce3c639f02b6c717cc8aa6532b86a6af", {"code_string": "import sqlite3\nimport os\ntry:\n    os.remove('data.db')\nexcept:\n    pass\ndb = sqlite3.connect('data.db')\nc = db.cursor()\nc.execute(\"CREATE TABLE distance ( from_station TEXT, to_station TEXT, distance integer, operator TEXT, min_distance integer);\")\nc.execute(\"CREATE index distance_idx ON DISTANCE (from_station,to_station);\")\nfor line in open('data/distance.csv'):\n    values = line[: - 1].split(',')\n    c.execute(\"INSERT INTO distance (from_station,to_station, distance, operator) VALUES (?,?,?,?)\", values)\nc.execute(\n\"\"\"CREATE TABLE fareunit_price (\"\"\")\nc.execute(\"CREATE INDEX fareunit_price_idx on fareunit_price(distance);\")\nc.execute(\"CREATE INDEX fareunit_price_keydist_idx on fareunit_price(key,distance);\")\n", "code_toks_joined": "import sqlite3 <NEWLINE> import os <NEWLINE> try : <NEWLINE> <INDENT> os . remove ( <STRING> ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> db = sqlite3 . connect ( <STRING> ) <NEWLINE> c = db . cursor ( ) <NEWLINE> c . execute ( <STRING> ) <NEWLINE> c . execute ( <STRING> ) <NEWLINE> for line in open ( <STRING> ) : <NEWLINE> <INDENT> values = line [ : - 1 ] . split ( <STRING> ) <NEWLINE> c . execute ( <STRING> , values ) <NEWLINE> <DEDENT> c . execute ( <NEWLINE> <STRING> ) <NEWLINE> c . execute ( <STRING> ) <NEWLINE> c . execute ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'data.db'", "'data.db'", "\"CREATE TABLE distance ( from_station TEXT, to_station TEXT, distance integer, operator TEXT, min_distance integer);\"", "\"CREATE index distance_idx ON DISTANCE (from_station,to_station);\"", "'data/distance.csv'", "','", "\"INSERT INTO distance (from_station,to_station, distance, operator) VALUES (?,?,?,?)\"", "\"\"\"CREATE TABLE fareunit_price (\"\"\"", "\"CREATE INDEX fareunit_price_idx on fareunit_price(distance);\"", "\"CREATE INDEX fareunit_price_keydist_idx on fareunit_price(key,distance);\""]}}], ["438b789d4725dc7f80534501de15ef39", {"code_string": "class TestCommand(ExternCmdPackagerBase):\n    \"\"\"Checks if something is installed by running a command.\"\"\"\n    name = 'cmd'\n    pkgtype = 'cmd'\n    def __init__(self):\n        ExternCmdPackagerBase.__init__(self)\n        self.packager = ExternalTestCmd(self.log)\n    def supported(self):\n        \" We can always run commands. \"\n        return True\n", "code_toks_joined": "class TestCommand ( ExternCmdPackagerBase ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> name = <STRING> <NEWLINE> pkgtype = <STRING> <NEWLINE> def __init__ ( self ) : <NEWLINE> <INDENT> ExternCmdPackagerBase . __init__ ( self ) <NEWLINE> self . packager = ExternalTestCmd ( self . log ) <NEWLINE> <DEDENT> def supported ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return True <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Checks if something is installed by running a command.\"\"\"", "'cmd'", "'cmd'", "\" We can always run commands. \""]}}], ["de07b90fcbf0939e44be18da0e50cd6a", {"code_string": "def test_get_cached_minifest_caching_force(self, storage_mock):\n    storage_mock.size.return_value = 999\n    minifest = json.loads(get_cached_minifest(self.webapp)[0])\n    eq_(minifest['size'], 999)\n    storage_mock.size.return_value = 666\n    new_minifest = json.loads(\n        get_cached_minifest(self.webapp, force = True)[0])\n    ok_(new_minifest != minifest)\n    eq_(new_minifest['size'], 666)\n", "code_toks_joined": "def test_get_cached_minifest_caching_force ( self , storage_mock ) : <NEWLINE> <INDENT> storage_mock . size . return_value = 999 <NEWLINE> minifest = json . loads ( get_cached_minifest ( self . webapp ) [ 0 ] ) <NEWLINE> eq_ ( minifest [ <STRING> ] , 999 ) <NEWLINE> storage_mock . size . return_value = 666 <NEWLINE> new_minifest = json . loads ( <NEWLINE> <INDENT> get_cached_minifest ( self . webapp , force = True ) [ 0 ] ) <NEWLINE> <DEDENT> ok_ ( new_minifest != minifest ) <NEWLINE> eq_ ( new_minifest [ <STRING> ] , 666 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'size'", "'size'"]}}], ["c2c776f93339d1099f2b2c37f1dfdbab", {"code_string": "def inject_nomination_status(organizations, assume_nominated = False):\n    nominations = {}\n    if c.user_is_loggedin:\n        if not assume_nominated:\n            nominations = DonationNominationsByAccount.fast_query(\n                c.user, organizations)\n        else:\n            nominations = {(c.user, org): True for org in organizations}\n    wrapped = []\n    for org in organizations:\n        data = org.data.copy()\n        data[\"Nominated\"] = (c.user, org) in nominations\n        wrapped.append(data)\n    return wrapped\n", "code_toks_joined": "def inject_nomination_status ( organizations , assume_nominated = False ) : <NEWLINE> <INDENT> nominations = { } <NEWLINE> if c . user_is_loggedin : <NEWLINE> <INDENT> if not assume_nominated : <NEWLINE> <INDENT> nominations = DonationNominationsByAccount . fast_query ( <NEWLINE> <INDENT> c . user , organizations ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> nominations = { ( c . user , org ) : True for org in organizations } <NEWLINE> <DEDENT> <DEDENT> wrapped = [ ] <NEWLINE> for org in organizations : <NEWLINE> <INDENT> data = org . data . copy ( ) <NEWLINE> data [ <STRING> ] = ( c . user , org ) in nominations <NEWLINE> wrapped . append ( data ) <NEWLINE> <DEDENT> return wrapped <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Nominated\""]}}], ["279d5387ead54d6fd644d4222e56973e", {"code_string": "def select_data_assets(self):\n    \"\"\"Return: lib.page.widget.generic_widget.DataAssets\"\"\"\n    return self._select(element.WidgetBar.DATA_ASSETS)\n", "code_toks_joined": "def select_data_assets ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . _select ( element . WidgetBar . DATA_ASSETS ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Return: lib.page.widget.generic_widget.DataAssets\"\"\""]}}], ["5f64284a23686d7eeae03c23106d2976", {"code_string": "import os.path\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import scoped_session, sessionmaker\nfrom sqlalchemy.ext.declarative import declarative_base\nengine = create_engine(\"sqlite:///rank.db\", convert_unicode = True)\nsession = scoped_session(sessionmaker(autocommit = False, autoflush = False,\n    bind = engine))\nBase = declarative_base()\nBase.query = session.query_property()\n", "code_toks_joined": "import os . path <NEWLINE> from sqlalchemy import create_engine <NEWLINE> from sqlalchemy . orm import scoped_session , sessionmaker <NEWLINE> from sqlalchemy . ext . declarative import declarative_base <NEWLINE> engine = create_engine ( <STRING> , convert_unicode = True ) <NEWLINE> session = scoped_session ( sessionmaker ( autocommit = False , autoflush = False , <NEWLINE> <INDENT> bind = engine ) ) <NEWLINE> <DEDENT> Base = declarative_base ( ) <NEWLINE> Base . query = session . query_property ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"sqlite:///rank.db\""]}}], ["875e1b5bfa16040f90c0f44f729dfb90", {"code_string": "def __init__(self, capacity, speed):\n    self.cap = capacity\n    self.speed = speed\n    self.onBus = 0\n", "code_toks_joined": "def __init__ ( self , capacity , speed ) : <NEWLINE> <INDENT> self . cap = capacity <NEWLINE> self . speed = speed <NEWLINE> self . onBus = 0 <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["d015282c08a2eea6d7e586a8b4045e0d", {"code_string": "class CreateSeriesView(LibraryMixin, CreateView):\n    model = Series\n    template_name = \"series_edit.html\"\n    fields = ['name', 'author']\n    def get_success_url(self):\n        return reverse('series-list')\n    def get_context_data(self, ** kwargs):\n        context = super(CreateSeriesView, self).get_context_data(** kwargs)\n        context['action'] = reverse('series-create')\n        return context\n", "code_toks_joined": "class CreateSeriesView ( LibraryMixin , CreateView ) : <NEWLINE> <INDENT> model = Series <NEWLINE> template_name = <STRING> <NEWLINE> fields = [ <STRING> , <STRING> ] <NEWLINE> def get_success_url ( self ) : <NEWLINE> <INDENT> return reverse ( <STRING> ) <NEWLINE> <DEDENT> def get_context_data ( self , ** kwargs ) : <NEWLINE> <INDENT> context = super ( CreateSeriesView , self ) . get_context_data ( ** kwargs ) <NEWLINE> context [ <STRING> ] = reverse ( <STRING> ) <NEWLINE> return context <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"series_edit.html\"", "'name'", "'author'", "'series-list'", "'action'", "'series-create'"]}}], ["605a7cb74cfc8392ccd8d29cd2cb351f", {"code_string": "def upload_file(request):\n    if request.method == 'POST':\n        form = UploadFileForm(request.POST, request.FILES)\n        if form.is_valid():\n            handle_uploaded_file(request.FILES['file'])\n            return HttpResponseRedirect('/success/url/')\n    else:\n        form = UploadFileForm()\n    return render_to_response('upload.html', {'form': form})\n", "code_toks_joined": "def upload_file ( request ) : <NEWLINE> <INDENT> if request . method == <STRING> : <NEWLINE> <INDENT> form = UploadFileForm ( request . POST , request . FILES ) <NEWLINE> if form . is_valid ( ) : <NEWLINE> <INDENT> handle_uploaded_file ( request . FILES [ <STRING> ] ) <NEWLINE> return HttpResponseRedirect ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> form = UploadFileForm ( ) <NEWLINE> <DEDENT> return render_to_response ( <STRING> , { <STRING> : form } ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'POST'", "'file'", "'/success/url/'", "'upload.html'", "'form'"]}}], ["52ad30ee4c429d7fbe35f4b5969d13fb", {"code_string": "class SwitchTelnetFactory(Factory):\n    def __init__(self, switch_core):\n        self.switch_core = switch_core\n    def protocol(self):\n        return SwitchTelnetShell(self.switch_core)\n", "code_toks_joined": "class SwitchTelnetFactory ( Factory ) : <NEWLINE> <INDENT> def __init__ ( self , switch_core ) : <NEWLINE> <INDENT> self . switch_core = switch_core <NEWLINE> <DEDENT> def protocol ( self ) : <NEWLINE> <INDENT> return SwitchTelnetShell ( self . switch_core ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["d8348c993ddb6493dd063733bf288960", {"code_string": "def convert_to_unicode(input_str):\n    \"\"\"A function for converting a unicode to by string\"\"\"\n    if isinstance(input_str, binary_type):\n        input_str = input_str.decode(\"utf-8\")\n    return input_str\n", "code_toks_joined": "def convert_to_unicode ( input_str ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if isinstance ( input_str , binary_type ) : <NEWLINE> <INDENT> input_str = input_str . decode ( <STRING> ) <NEWLINE> <DEDENT> return input_str <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"A function for converting a unicode to by string\"\"\"", "\"utf-8\""]}}], ["1150788c287675f910cf8c4300c35eab", {"code_string": "def get_profile(var, doy, depth, lat, lon):\n    print(\"get_profile is deprecated. You should migrate to extract()\")\n    return extract(var = var, doy = doy, depth = depth, lat = lat, lon = lon)\n", "code_toks_joined": "def get_profile ( var , doy , depth , lat , lon ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> return extract ( var = var , doy = doy , depth = depth , lat = lat , lon = lon ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"get_profile is deprecated. You should migrate to extract()\""]}}], ["5806e72ba788e7ff7deac1b6f43d0ad9", {"code_string": "def test_agent_default_not_present(self):\n    self.flags(use_agent_default = False, group = 'xenserver')\n    instance = {\"system_metadata\": []}\n    self.assertFalse(agent.should_use_agent(instance))\n", "code_toks_joined": "def test_agent_default_not_present ( self ) : <NEWLINE> <INDENT> self . flags ( use_agent_default = False , group = <STRING> ) <NEWLINE> instance = { <STRING> : [ ] } <NEWLINE> self . assertFalse ( agent . should_use_agent ( instance ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'xenserver'", "\"system_metadata\""]}}], ["67c0a9bd7b4db2a244f928f3458f15eb", {"code_string": "def override_file_copy(self, expected_from_path, expected_to_dir):\n    def file_copy(from_path, to_path):\n        if not from_path.endswith(names.PICKLED_MAIN_SESSION_FILE):\n            self.assertEqual(expected_from_path, from_path)\n            self.assertEqual(utils.path.join(expected_to_dir,\n                names.DATAFLOW_SDK_TARBALL_FILE),\n                to_path)\n        if from_path.startswith('gs://') or to_path.startswith('gs://'):\n            logging.info('Faking file_copy(%s, %s)', from_path, to_path)\n        else:\n            shutil.copyfile(from_path, to_path)\n    dependency._dependency_file_copy = file_copy\n", "code_toks_joined": "def override_file_copy ( self , expected_from_path , expected_to_dir ) : <NEWLINE> <INDENT> def file_copy ( from_path , to_path ) : <NEWLINE> <INDENT> if not from_path . endswith ( names . PICKLED_MAIN_SESSION_FILE ) : <NEWLINE> <INDENT> self . assertEqual ( expected_from_path , from_path ) <NEWLINE> self . assertEqual ( utils . path . join ( expected_to_dir , <NEWLINE> <INDENT> names . DATAFLOW_SDK_TARBALL_FILE ) , <NEWLINE> to_path ) <NEWLINE> <DEDENT> <DEDENT> if from_path . startswith ( <STRING> ) or to_path . startswith ( <STRING> ) : <NEWLINE> <INDENT> logging . info ( <STRING> , from_path , to_path ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> shutil . copyfile ( from_path , to_path ) <NEWLINE> <DEDENT> <DEDENT> dependency . _dependency_file_copy = file_copy <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'gs://'", "'gs://'", "'Faking file_copy(%s, %s)'"]}}], ["4c8b24d0209012a4f27ad7a51d224adb", {"code_string": "def iter(self):\n    \"\"\"Boucle sur les conversations contenues\"\"\"\n    return list(self._conversations)\n", "code_toks_joined": "def iter ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return list ( self . _conversations ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Boucle sur les conversations contenues\"\"\""]}}], ["5fccdbf15019e49fb69058144093dc7b", {"code_string": "def _extract_description(self):\n    section = self.soup.select(\n        \".product_summary\")[0].select(\".data\")[0]\n    collapsed = section.select(\".blurb_collapsed\")\n    description = \"\"\n    if(collapsed):\n        expanded = section.select(\".blurb_expanded\")\n        description = (collapsed[0].text + expanded[0].text).strip()\n    else:\n        description = (section.text.strip())\n    return(description)\n", "code_toks_joined": "def _extract_description ( self ) : <NEWLINE> <INDENT> section = self . soup . select ( <NEWLINE> <INDENT> <STRING> ) [ 0 ] . select ( <STRING> ) [ 0 ] <NEWLINE> <DEDENT> collapsed = section . select ( <STRING> ) <NEWLINE> description = <STRING> <NEWLINE> if ( collapsed ) : <NEWLINE> <INDENT> expanded = section . select ( <STRING> ) <NEWLINE> description = ( collapsed [ 0 ] . text + expanded [ 0 ] . text ) . strip ( ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> description = ( section . text . strip ( ) ) <NEWLINE> <DEDENT> return ( description ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\".product_summary\"", "\".data\"", "\".blurb_collapsed\"", "\"\"", "\".blurb_expanded\""]}}], ["893f9a19a7db7d3f2d686d2f3f50b2d7", {"code_string": "\"\"\" Copyright 2013 Board of Trustees, University of Illinois\"\"\"\nfrom django.conf import settings\nfrom django.core.exceptions import ImproperlyConfigured\nfrom spotseeker_server.load_module import load_object_by_name\n", "code_toks_joined": "<STRING> <NEWLINE> from django . conf import settings <NEWLINE> from django . core . exceptions import ImproperlyConfigured <NEWLINE> from spotseeker_server . load_module import load_object_by_name <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\" Copyright 2013 Board of Trustees, University of Illinois\"\"\""]}}], ["3e71a3b928c346b54de17e318dd0a9ce", {"code_string": "def advertising_save(self, ** kwargs):\n    \"\"\"Save :class:`~mediadrop.forms.admin.settings.AdvertisingForm`.\"\"\"\n    return self._save(advertising_form, 'advertising', values = kwargs)\n", "code_toks_joined": "def advertising_save ( self , ** kwargs ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . _save ( advertising_form , <STRING> , values = kwargs ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Save :class:`~mediadrop.forms.admin.settings.AdvertisingForm`.\"\"\"", "'advertising'"]}}], ["2163df853d412927c29a187d12e81361", {"code_string": "def decode_jwt(self, token):\n    \"\"\"Find the registration that signed this JWT and return it.\"\"\"\n    import jwt\n    target_check = jwt.decode(token, verify = False)\n    if target_check[ATTR_TARGET] in self.registrations:\n        possible_target = self.registrations[target_check[ATTR_TARGET]]\n        key = possible_target[ATTR_SUBSCRIPTION][ATTR_KEYS][ATTR_AUTH]\n        try:\n            return jwt.decode(token, key)\n        except jwt.exceptions.DecodeError:\n            pass\n    return self.json_message('No target found in JWT',\n        status_code = HTTP_UNAUTHORIZED)\n", "code_toks_joined": "def decode_jwt ( self , token ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> import jwt <NEWLINE> target_check = jwt . decode ( token , verify = False ) <NEWLINE> if target_check [ ATTR_TARGET ] in self . registrations : <NEWLINE> <INDENT> possible_target = self . registrations [ target_check [ ATTR_TARGET ] ] <NEWLINE> key = possible_target [ ATTR_SUBSCRIPTION ] [ ATTR_KEYS ] [ ATTR_AUTH ] <NEWLINE> try : <NEWLINE> <INDENT> return jwt . decode ( token , key ) <NEWLINE> <DEDENT> except jwt . exceptions . DecodeError : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT> return self . json_message ( <STRING> , <NEWLINE> <INDENT> status_code = HTTP_UNAUTHORIZED ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Find the registration that signed this JWT and return it.\"\"\"", "'No target found in JWT'"]}}], ["959721dfa0498267143e26173dee6630", {"code_string": "def deploy():\n    \"\"\"\u90e8\u7f72\"\"\"\n    env.host_string = config.HOST_STRING\n    with cd('/var/www/#{project}'):\n        with shell_env(MODE = 'PRODUCTION'):\n            run('git reset --hard HEAD')\n            run('git pull')\n            with prefix('source venv/bin/activate'):\n                run('pip install -r requirements.txt')\n                run('python manage.py db upgrade')\n                run('python manage.py build_assets')\n            run('supervisorctl restart #{project}')\n", "code_toks_joined": "def deploy ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> env . host_string = config . HOST_STRING <NEWLINE> with cd ( <STRING> ) : <NEWLINE> <INDENT> with shell_env ( MODE = <STRING> ) : <NEWLINE> <INDENT> run ( <STRING> ) <NEWLINE> run ( <STRING> ) <NEWLINE> with prefix ( <STRING> ) : <NEWLINE> <INDENT> run ( <STRING> ) <NEWLINE> run ( <STRING> ) <NEWLINE> run ( <STRING> ) <NEWLINE> <DEDENT> run ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"\u90e8\u7f72\"\"\"", "'/var/www/#{project}'", "'PRODUCTION'", "'git reset --hard HEAD'", "'git pull'", "'source venv/bin/activate'", "'pip install -r requirements.txt'", "'python manage.py db upgrade'", "'python manage.py build_assets'", "'supervisorctl restart #{project}'"]}}], ["960cb9df4fe89b229d2b513e87966042", {"code_string": "def Draw(obj, jsDrawMethod = 'draw', objIsJSON = False):\n    if objIsJSON:\n        dat = obj\n    else:\n        dat = ROOT.TBufferJSON.ConvertToJSON(obj)\n        dat = str(dat).replace(\"\\n\", \"\")\n    JsDraw.__divUID += 1\n    display(HTML(JsDraw.__jsCode.substitute({\n        'funcName': jsDrawMethod,\n        'divid': 'jstmva_' + str(JsDraw.__divUID),\n        'dat': dat,\n        'width': JsDraw.jsCanvasWidth,\n        'height': JsDraw.jsCanvasHeight\n        })))\n", "code_toks_joined": "def Draw ( obj , jsDrawMethod = <STRING> , objIsJSON = False ) : <NEWLINE> <INDENT> if objIsJSON : <NEWLINE> <INDENT> dat = obj <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> dat = ROOT . TBufferJSON . ConvertToJSON ( obj ) <NEWLINE> dat = str ( dat ) . replace ( <STRING> , <STRING> ) <NEWLINE> <DEDENT> JsDraw . __divUID += 1 <NEWLINE> display ( HTML ( JsDraw . __jsCode . substitute ( { <NEWLINE> <INDENT> <STRING> : jsDrawMethod , <NEWLINE> <STRING> : <STRING> + str ( JsDraw . __divUID ) , <NEWLINE> <STRING> : dat , <NEWLINE> <STRING> : JsDraw . jsCanvasWidth , <NEWLINE> <STRING> : JsDraw . jsCanvasHeight <NEWLINE> } ) ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'draw'", "\"\\n\"", "\"\"", "'funcName'", "'divid'", "'jstmva_'", "'dat'", "'width'", "'height'"]}}], ["50f4f374e76d8a58b33cb69dac7c1261", {"code_string": "def togglestate():\n    new_state = not get_pyrevit_env_var(SYNC_VIEW_ENV_VAR)\n    set_pyrevit_env_var(SYNC_VIEW_ENV_VAR, new_state)\n    this_script.toggle_icon(new_state)\n", "code_toks_joined": "def togglestate ( ) : <NEWLINE> <INDENT> new_state = not get_pyrevit_env_var ( SYNC_VIEW_ENV_VAR ) <NEWLINE> set_pyrevit_env_var ( SYNC_VIEW_ENV_VAR , new_state ) <NEWLINE> this_script . toggle_icon ( new_state ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["388b47d6149ca4321e60d49c2d32366e", {"code_string": "def rsum(so_far, place):\n    global coins, ways\n    coin = coins[place]\n    max_p = (200 - so_far) / coin + 1\n    for p in xrange(max_p):\n        with_p_coins = so_far + coin * p\n        if with_p_coins == 200:\n            ways += 1\n        if with_p_coins < 200 and place + 1 < len(coins):\n            rsum(with_p_coins, place + 1)\n", "code_toks_joined": "def rsum ( so_far , place ) : <NEWLINE> <INDENT> global coins , ways <NEWLINE> coin = coins [ place ] <NEWLINE> max_p = ( 200 - so_far ) / coin + 1 <NEWLINE> for p in xrange ( max_p ) : <NEWLINE> <INDENT> with_p_coins = so_far + coin * p <NEWLINE> if with_p_coins == 200 : <NEWLINE> <INDENT> ways += 1 <NEWLINE> <DEDENT> if with_p_coins < 200 and place + 1 < len ( coins ) : <NEWLINE> <INDENT> rsum ( with_p_coins , place + 1 ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["8a08c8bd93c18530a5d3e0d270ee9005", {"code_string": "from actions import script\nprint(script.run(1, {\n    'username': 'misa',\n    'groupname': 'misa',\n    'now': '2004-02-20 09:00:00',\n    'script': \"\"\" #!/usr/bin/python\"\"\",\n}))\n", "code_toks_joined": "from actions import script <NEWLINE> print ( script . run ( 1 , { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <DEDENT> } ) ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'username'", "'misa'", "'groupname'", "'misa'", "'now'", "'2004-02-20 09:00:00'", "'script'", "\"\"\" #!/usr/bin/python\"\"\""]}}], ["bb138562a9b2b8d93ec51e660fe4f3c3", {"code_string": "def NG50(numlist, reference_length, percentage = 50.0):\n    \"\"\"Abstract: Returns the NG50 value of the passed list of numbers.\"\"\"\n    assert percentage >= 0.0\n    assert percentage <= 100.0\n    numlist.sort(reverse = True)\n    s = reference_length\n    limit = reference_length *(100.0 - percentage) / 100.0\n    for l in numlist:\n        s -= l\n        if s <= limit:\n            return l\n", "code_toks_joined": "def NG50 ( numlist , reference_length , percentage = 50.0 ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> assert percentage >= 0.0 <NEWLINE> assert percentage <= 100.0 <NEWLINE> numlist . sort ( reverse = True ) <NEWLINE> s = reference_length <NEWLINE> limit = reference_length * ( 100.0 - percentage ) / 100.0 <NEWLINE> for l in numlist : <NEWLINE> <INDENT> s -= l <NEWLINE> if s <= limit : <NEWLINE> <INDENT> return l <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Abstract: Returns the NG50 value of the passed list of numbers.\"\"\""]}}], ["0ed62796e0be23b1c180140b157bac3c", {"code_string": "class PRC(DstTzInfo):\n    '''PRC timezone definition. See datetime.tzinfo for details'''\n    zone = 'PRC'\n", "code_toks_joined": "class PRC ( DstTzInfo ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> zone = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''PRC timezone definition. See datetime.tzinfo for details'''", "'PRC'"]}}], ["5fff7251f64706925c70482860eb54b1", {"code_string": "class BaseMagnet(BaseElement):\n    \"\"\"Base interface for magnets.\"\"\"\n    def _mad_backend(self):\n        return self._construct(self.mad_cls())\n    @ property\n    def dvm_params(self):\n        return self.dvm_converter.param_info\n", "code_toks_joined": "class BaseMagnet ( BaseElement ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def _mad_backend ( self ) : <NEWLINE> <INDENT> return self . _construct ( self . mad_cls ( ) ) <NEWLINE> <DEDENT> @ property <NEWLINE> def dvm_params ( self ) : <NEWLINE> <INDENT> return self . dvm_converter . param_info <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Base interface for magnets.\"\"\""]}}], ["888e604525e76c611584774850dd5ac6", {"code_string": "def test_index_of(self, predicate, iterable, expected):\n    actual = index_of(predicate, iterable)\n    self.assertEqual(actual, expected)\n", "code_toks_joined": "def test_index_of ( self , predicate , iterable , expected ) : <NEWLINE> <INDENT> actual = index_of ( predicate , iterable ) <NEWLINE> self . assertEqual ( actual , expected ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["f60a70e45b9b88e902ee54a1a4f68665", {"code_string": "\"\"\"**sitecustomize.py**\"\"\"\n__author__ = \"Thomas Mansencal\"\n__copyright__ = \"Copyright (C) 2008 - 2014 - Thomas Mansencal\"\n__license__ = \"GPL V3.0 - http://www.gnu.org/licenses/\"\n__maintainer__ = \"Thomas Mansencal\"\n__email__ = \"thomas.mansencal@gmail.com\"\n__status__ = \"Production\"\n__all__ = []\nimport sys\nsys.setdefaultencoding(\"utf-8\")\n", "code_toks_joined": "<STRING> <NEWLINE> __author__ = <STRING> <NEWLINE> __copyright__ = <STRING> <NEWLINE> __license__ = <STRING> <NEWLINE> __maintainer__ = <STRING> <NEWLINE> __email__ = <STRING> <NEWLINE> __status__ = <STRING> <NEWLINE> __all__ = [ ] <NEWLINE> import sys <NEWLINE> sys . setdefaultencoding ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"**sitecustomize.py**\"\"\"", "\"Thomas Mansencal\"", "\"Copyright (C) 2008 - 2014 - Thomas Mansencal\"", "\"GPL V3.0 - http://www.gnu.org/licenses/\"", "\"Thomas Mansencal\"", "\"thomas.mansencal@gmail.com\"", "\"Production\"", "\"utf-8\""]}}], ["a39ba9151282a0b40b8c2eab6d7d72b4", {"code_string": "def _auditpol_import():\n    dict_return = {}\n    export = _auditpol_export()\n    auditpol_csv = csv.DictReader(export)\n    for row in auditpol_csv:\n        if row:\n            dict_return[row['Subcategory']] = row['Inclusion Setting']\n    return dict_return\n", "code_toks_joined": "def _auditpol_import ( ) : <NEWLINE> <INDENT> dict_return = { } <NEWLINE> export = _auditpol_export ( ) <NEWLINE> auditpol_csv = csv . DictReader ( export ) <NEWLINE> for row in auditpol_csv : <NEWLINE> <INDENT> if row : <NEWLINE> <INDENT> dict_return [ row [ <STRING> ] ] = row [ <STRING> ] <NEWLINE> <DEDENT> <DEDENT> return dict_return <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Subcategory'", "'Inclusion Setting'"]}}], ["de2886eb084aed2ac20dda4061d8f9b1", {"code_string": "class OverusedBufferScrapy(OverusedBuffer):\n    \"\"\"Scrapy optimized version of OverusedBuffer. Url parsing and dns resolving are made using Scrapy primitives.\"\"\"\n    def _get_key(self, request, type):\n        key = urlparse_cached(request).hostname or ''\n        if type == 'ip':\n            key = dnscache.get(key, key)\n        return key\n", "code_toks_joined": "class OverusedBufferScrapy ( OverusedBuffer ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def _get_key ( self , request , type ) : <NEWLINE> <INDENT> key = urlparse_cached ( request ) . hostname or <STRING> <NEWLINE> if type == <STRING> : <NEWLINE> <INDENT> key = dnscache . get ( key , key ) <NEWLINE> <DEDENT> return key <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Scrapy optimized version of OverusedBuffer. Url parsing and dns resolving are made using Scrapy primitives.\"\"\"", "''", "'ip'"]}}], ["7c6085dc1ebc5cd6cda76beaa23fec45", {"code_string": "\"\"\"Sam Huston 2007\"\"\"\nfrom nltk_contrib import classify\nfrom nltk import detect\nfrom nltk.corpus import udhr\nimport string\n", "code_toks_joined": "<STRING> <NEWLINE> from nltk_contrib import classify <NEWLINE> from nltk import detect <NEWLINE> from nltk . corpus import udhr <NEWLINE> import string <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Sam Huston 2007\"\"\""]}}], ["51b2e6345f7d6defdfcad23765154428", {"code_string": "\"\"\"Ipset iptables generator.  This is a subclass of Iptables generator.\"\"\"\n__author__ = 'vklimovs@google.com (Vjaceslavs Klimovs)'\nimport string\nimport iptables\nimport nacaddr\n", "code_toks_joined": "<STRING> <NEWLINE> __author__ = <STRING> <NEWLINE> import string <NEWLINE> import iptables <NEWLINE> import nacaddr <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Ipset iptables generator.  This is a subclass of Iptables generator.\"\"\"", "'vklimovs@google.com (Vjaceslavs Klimovs)'"]}}], ["09bf973fb93148c601805e1c29d93076", {"code_string": "def test_no_int_if_ifs(self):\n    params = self.params.copy()\n    del params['int_if']\n    system = self.system_class(** params)\n    self.assertSequenceEqual(system.int_if.ifsv4, [ipaddress.IPv4Interface('148.241.178.106/24')],\n        'incorrect int_if ifsv4')\n    self.assertSequenceEqual(self.system.int_if.ifsv6, [ipaddress.IPv6Interface('1c02:4f8:0f0:14e6::0:0:1/110')],\n        'incorrect ext_if ifsv6')\n", "code_toks_joined": "def test_no_int_if_ifs ( self ) : <NEWLINE> <INDENT> params = self . params . copy ( ) <NEWLINE> del params [ <STRING> ] <NEWLINE> system = self . system_class ( ** params ) <NEWLINE> self . assertSequenceEqual ( system . int_if . ifsv4 , [ ipaddress . IPv4Interface ( <STRING> ) ] , <NEWLINE> <INDENT> <STRING> ) <NEWLINE> <DEDENT> self . assertSequenceEqual ( self . system . int_if . ifsv6 , [ ipaddress . IPv6Interface ( <STRING> ) ] , <NEWLINE> <INDENT> <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'int_if'", "'148.241.178.106/24'", "'incorrect int_if ifsv4'", "'1c02:4f8:0f0:14e6::0:0:1/110'", "'incorrect ext_if ifsv6'"]}}], ["e9fcbe4426217a4bc54dc9d44f508454", {"code_string": "class SkiaBuildbotDesktopPage(page_module.Page):\n    def __init__(self, url, page_set):\n        super(SkiaBuildbotDesktopPage, self).__init__(\n            url = url,\n            page_set = page_set,\n            credentials_path = 'data/credentials.json')\n        self.user_agent_type = 'desktop'\n        self.archive_data_file = 'data/skia_baidu_desktop.json'\n    def RunNavigateSteps(self, action_runner):\n        action_runner.NavigateToPage(self)\n        action_runner.Wait(90)\n", "code_toks_joined": "class SkiaBuildbotDesktopPage ( page_module . Page ) : <NEWLINE> <INDENT> def __init__ ( self , url , page_set ) : <NEWLINE> <INDENT> super ( SkiaBuildbotDesktopPage , self ) . __init__ ( <NEWLINE> <INDENT> url = url , <NEWLINE> page_set = page_set , <NEWLINE> credentials_path = <STRING> ) <NEWLINE> <DEDENT> self . user_agent_type = <STRING> <NEWLINE> self . archive_data_file = <STRING> <NEWLINE> <DEDENT> def RunNavigateSteps ( self , action_runner ) : <NEWLINE> <INDENT> action_runner . NavigateToPage ( self ) <NEWLINE> action_runner . Wait ( 90 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'data/credentials.json'", "'desktop'", "'data/skia_baidu_desktop.json'"]}}], ["18169f9138dcc43595dae8d69cbd0c8b", {"code_string": "def client(self):\n    return client_context(addressbook.AddressBookService,\n        host = \"localhost\", port = self.PORT,\n        proto_factory = self.PROTOCOL_FACTORY,\n        trans_factory = self.TRANSPORT_FACTORY)\n", "code_toks_joined": "def client ( self ) : <NEWLINE> <INDENT> return client_context ( addressbook . AddressBookService , <NEWLINE> <INDENT> host = <STRING> , port = self . PORT , <NEWLINE> proto_factory = self . PROTOCOL_FACTORY , <NEWLINE> trans_factory = self . TRANSPORT_FACTORY ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"localhost\""]}}], ["9b4d7c64ccb59df55cfb4caafe5d3877", {"code_string": "def rsync_target(self):\n    fmt = self.fmt('{env.user}@{host}:')\n    if self.env.use_ssh_config:\n        fmt = self.fmt('{env.user}@{env.host_string}:')\n    if self.local_deployment:\n        fmt = ''\n    return fmt\n", "code_toks_joined": "def rsync_target ( self ) : <NEWLINE> <INDENT> fmt = self . fmt ( <STRING> ) <NEWLINE> if self . env . use_ssh_config : <NEWLINE> <INDENT> fmt = self . fmt ( <STRING> ) <NEWLINE> <DEDENT> if self . local_deployment : <NEWLINE> <INDENT> fmt = <STRING> <NEWLINE> <DEDENT> return fmt <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'{env.user}@{host}:'", "'{env.user}@{env.host_string}:'", "''"]}}], ["ddcf1289a68715a23e31a4e2845c10ca", {"code_string": "import blue_yellow_app.infrastructure.static_cache as static_cache\nimport pyramid.renderers\nimport pyramid.httpexceptions as exc\n", "code_toks_joined": "import blue_yellow_app . infrastructure . static_cache as static_cache <NEWLINE> import pyramid . renderers <NEWLINE> import pyramid . httpexceptions as exc <NEWLINE>", "anonymize_dict": {}}], ["a0f41815bdf4ac055a81a04868cd0ea0", {"code_string": "def system(self, cmd):\n    buf = pack(\">Bi\", RAP_SYSTEM, len(str(cmd)))\n    self.fd.send(buf)\n    self.fd.send(cmd)\n    buf = self.fd.recv(5)\n    (c, l) = unpack(\">Bi\", buf)\n    if c != RAP_SYSTEM | RAP_REPLY:\n        print(\"rmt-system: Invalid response packet\")\n        return \"\"\n    if l > 0:\n        buf = self.fd.recv(l)\n    return buf\n", "code_toks_joined": "def system ( self , cmd ) : <NEWLINE> <INDENT> buf = pack ( <STRING> , RAP_SYSTEM , len ( str ( cmd ) ) ) <NEWLINE> self . fd . send ( buf ) <NEWLINE> self . fd . send ( cmd ) <NEWLINE> buf = self . fd . recv ( 5 ) <NEWLINE> ( c , l ) = unpack ( <STRING> , buf ) <NEWLINE> if c != RAP_SYSTEM | RAP_REPLY : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> return <STRING> <NEWLINE> <DEDENT> if l > 0 : <NEWLINE> <INDENT> buf = self . fd . recv ( l ) <NEWLINE> <DEDENT> return buf <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\">Bi\"", "\">Bi\"", "\"rmt-system: Invalid response packet\"", "\"\""]}}], ["7024b627671deea425f49ab4425f100f", {"code_string": "class TestSum(unittest.TestCase):\n    def test_sum(self):\n        self.assertEqual(sum(1, 2), 3)\n", "code_toks_joined": "class TestSum ( unittest . TestCase ) : <NEWLINE> <INDENT> def test_sum ( self ) : <NEWLINE> <INDENT> self . assertEqual ( sum ( 1 , 2 ) , 3 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["c4a29e93aea99ca4c364393c29d6f35a", {"code_string": "class ActorRef(StdoutConnector):\n    def __init__(self, path):\n        self.path = path\n    def tell(self, message):\n        output = {\n            'type': \"message\",\n            'path': self.path,\n            'message': message\n        }\n        self.write(output)\n", "code_toks_joined": "class ActorRef ( StdoutConnector ) : <NEWLINE> <INDENT> def __init__ ( self , path ) : <NEWLINE> <INDENT> self . path = path <NEWLINE> <DEDENT> def tell ( self , message ) : <NEWLINE> <INDENT> output = { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : self . path , <NEWLINE> <STRING> : message <NEWLINE> <DEDENT> } <NEWLINE> self . write ( output ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'type'", "\"message\"", "'path'", "'message'"]}}], ["59a7d382756db104991d3b389e444d68", {"code_string": "def reportValidity(self):\n    s_report = \"\\n\".join([self.__type_message,\n        self.__value_message])\n    return s_report\n", "code_toks_joined": "def reportValidity ( self ) : <NEWLINE> <INDENT> s_report = <STRING> . join ( [ self . __type_message , <NEWLINE> <INDENT> self . __value_message ] ) <NEWLINE> <DEDENT> return s_report <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\\n\""]}}], ["590ca8c4adf89948e7bb2519afa5a334", {"code_string": "\"\"\"Platform MSYS2 and Cygwin.\"\"\"\nfrom craftr.utils import path\nimport os\nimport sys\n", "code_toks_joined": "<STRING> <NEWLINE> from craftr . utils import path <NEWLINE> import os <NEWLINE> import sys <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Platform MSYS2 and Cygwin.\"\"\""]}}], ["ab7650b2463e2fa03111535456c4c148", {"code_string": "def assert_equal(self, G, data = False):\n    (fd, fname) = tempfile.mkstemp()\n    nx.write_yaml(G, fname)\n    Gin = nx.read_yaml(fname);\n    assert_equal(sorted(G.nodes()), sorted(Gin.nodes()))\n    assert_equal(G.edges(data = data), Gin.edges(data = data))\n    os.close(fd)\n    os.unlink(fname)\n", "code_toks_joined": "def assert_equal ( self , G , data = False ) : <NEWLINE> <INDENT> ( fd , fname ) = tempfile . mkstemp ( ) <NEWLINE> nx . write_yaml ( G , fname ) <NEWLINE> Gin = nx . read_yaml ( fname ) ; <NEWLINE> assert_equal ( sorted ( G . nodes ( ) ) , sorted ( Gin . nodes ( ) ) ) <NEWLINE> assert_equal ( G . edges ( data = data ) , Gin . edges ( data = data ) ) <NEWLINE> os . close ( fd ) <NEWLINE> os . unlink ( fname ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["bf7009fae163a20ede5ea99268b5859c", {"code_string": "def calculateTip():\n    try:\n        total = float(raw_input(\"Please enter the total amount: \"))\n        rate = float(raw_input(\"Please enter the tax rate (ie .15): \"))\n    except:\n        print(\"Whoops, please enter a correct value next time!\")\n        exit()\n    tip = total * rate\n    print(\"The tip is: \", tip)\n    return tip\n", "code_toks_joined": "def calculateTip ( ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> total = float ( raw_input ( <STRING> ) ) <NEWLINE> rate = float ( raw_input ( <STRING> ) ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> exit ( ) <NEWLINE> <DEDENT> tip = total * rate <NEWLINE> print ( <STRING> , tip ) <NEWLINE> return tip <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Please enter the total amount: \"", "\"Please enter the tax rate (ie .15): \"", "\"Whoops, please enter a correct value next time!\"", "\"The tip is: \""]}}], ["7e4ff018892e3c4b71daad6c0ace52f2", {"code_string": "from twisted.spread import pb\nfrom twisted.internet import reactor\nfrom twisted.cred import credentials\n", "code_toks_joined": "from twisted . spread import pb <NEWLINE> from twisted . internet import reactor <NEWLINE> from twisted . cred import credentials <NEWLINE>", "anonymize_dict": {}}], ["962c917614703410a9688ee53657f816", {"code_string": "def validate_review_groups(form, field = 'review_groups'):\n    \"\"\"Validates that the review groups all have valid, matching LocalSites.\"\"\"\n    groups = form.cleaned_data.get(field, [])\n    local_site = form.cleaned_data['local_site']\n    for group in groups:\n        if group.local_site != local_site:\n            raise forms.ValidationError(\n                [\"The review group %s does not exist.\" % group.name])\n    return groups\n", "code_toks_joined": "def validate_review_groups ( form , field = <STRING> ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> groups = form . cleaned_data . get ( field , [ ] ) <NEWLINE> local_site = form . cleaned_data [ <STRING> ] <NEWLINE> for group in groups : <NEWLINE> <INDENT> if group . local_site != local_site : <NEWLINE> <INDENT> raise forms . ValidationError ( <NEWLINE> <INDENT> [ <STRING> % group . name ] ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> return groups <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'review_groups'", "\"\"\"Validates that the review groups all have valid, matching LocalSites.\"\"\"", "'local_site'", "\"The review group %s does not exist.\""]}}], ["5b08187ba6644e86b51e02399be60388", {"code_string": "def decorate_A(function):\n    def wrap_function(* args, ** kwargs):\n        kwargs['str'] = 'Hello!'\n        return function(* args, ** kwargs)\n    return wrap_function\n", "code_toks_joined": "def decorate_A ( function ) : <NEWLINE> <INDENT> def wrap_function ( * args , ** kwargs ) : <NEWLINE> <INDENT> kwargs [ <STRING> ] = <STRING> <NEWLINE> return function ( * args , ** kwargs ) <NEWLINE> <DEDENT> return wrap_function <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'str'", "'Hello!'"]}}], ["5589bfe3e97bf2db09e3d4de0c77ab19", {"code_string": "def test_has_right_heading(self):\n    body = self.browser.find_element_by_tag_name('body')\n    self.assertIn('Create Event', body.text)\n", "code_toks_joined": "def test_has_right_heading ( self ) : <NEWLINE> <INDENT> body = self . browser . find_element_by_tag_name ( <STRING> ) <NEWLINE> self . assertIn ( <STRING> , body . text ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'body'", "'Create Event'"]}}], ["53bd4f711a4965c62bd1a4f61d20621f", {"code_string": "class Severity(object):\n    low = 0\n    medium = 1\n    high = 2\n    critical = 3\n", "code_toks_joined": "class Severity ( object ) : <NEWLINE> <INDENT> low = 0 <NEWLINE> medium = 1 <NEWLINE> high = 2 <NEWLINE> critical = 3 <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ca49759c3e2cd5061526fb454452bced", {"code_string": "def test_unicode_actor(self):\n    name = \"\u00dc\u00e4\u00f6\u00df \u00c4u\u00df\u00c9\".decode(\"utf-8\")\n    assert len(name) == 9\n    special = Actor._from_string(u\"%s <something@this.com>\" % name)\n    assert special.name == name\n    assert isinstance(special.name, unicode)\n", "code_toks_joined": "def test_unicode_actor ( self ) : <NEWLINE> <INDENT> name = <STRING> . decode ( <STRING> ) <NEWLINE> assert len ( name ) == 9 <NEWLINE> special = Actor . _from_string ( <STRING> % name ) <NEWLINE> assert special . name == name <NEWLINE> assert isinstance ( special . name , unicode ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\u00dc\u00e4\u00f6\u00df \u00c4u\u00df\u00c9\"", "\"utf-8\"", "u\"%s <something@this.com>\""]}}], ["2941ba2408db593a06100d4b869f0f7b", {"code_string": "def __init__(self, max_width = 40):\n    self._lines = []\n    self._max_width = max_width\n", "code_toks_joined": "def __init__ ( self , max_width = 40 ) : <NEWLINE> <INDENT> self . _lines = [ ] <NEWLINE> self . _max_width = max_width <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ec6cde7ed7b1e92bd74c2ca01b0a61f8", {"code_string": "def forwards(self, orm):\n    db.add_column('forms_form', 'redirect_url',\n        self.gf('django.db.models.fields.CharField')(null = True, max_length = 200, blank = True),\n        keep_default = False)\n", "code_toks_joined": "def forwards ( self , orm ) : <NEWLINE> <INDENT> db . add_column ( <STRING> , <STRING> , <NEWLINE> <INDENT> self . gf ( <STRING> ) ( null = True , max_length = 200 , blank = True ) , <NEWLINE> keep_default = False ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'forms_form'", "'redirect_url'", "'django.db.models.fields.CharField'"]}}], ["aee928613e27fc1f6a98969f0cf92176", {"code_string": "def main(fragmentClass):\n    \"\"\"Benchmark L{N_RENDERS} calls of L{renderOnce}.\"\"\"\n    s = Store()\n    start()\n    for i in xrange(N_RENDERS):\n        renderOnce(fragmentClass)\n    stop()\n", "code_toks_joined": "def main ( fragmentClass ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> s = Store ( ) <NEWLINE> start ( ) <NEWLINE> for i in xrange ( N_RENDERS ) : <NEWLINE> <INDENT> renderOnce ( fragmentClass ) <NEWLINE> <DEDENT> stop ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Benchmark L{N_RENDERS} calls of L{renderOnce}.\"\"\""]}}], ["8c0ce9f561b0bcc580e818a01d8c9ea3", {"code_string": "from __future__ import unicode_literals\nfrom django.db import migrations\nfrom django.conf import settings\nfrom corehq.sql_db.operations import RawSQLMigration, HqRunSQL\nmigrator = RawSQLMigration(('corehq', 'sql_proxy_accessors', 'sql_templates'), {\n    'PL_PROXY_CLUSTER_NAME': settings.PL_PROXY_CLUSTER_NAME\n})\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> from django . db import migrations <NEWLINE> from django . conf import settings <NEWLINE> from corehq . sql_db . operations import RawSQLMigration , HqRunSQL <NEWLINE> migrator = RawSQLMigration ( ( <STRING> , <STRING> , <STRING> ) , { <NEWLINE> <INDENT> <STRING> : settings . PL_PROXY_CLUSTER_NAME <NEWLINE> <DEDENT> } ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'corehq'", "'sql_proxy_accessors'", "'sql_templates'", "'PL_PROXY_CLUSTER_NAME'"]}}], ["4c8234cd45118779caafc35eabc93ce2", {"code_string": "from setuptools import setup\nsetup(\n    name = 'modes',\n    version = '0.1',\n    license = 'MIT License',\n    author = 'td',\n    description = 'SSR Mode-S decoding tools',\n    install_requires = ['bitstring'],\n    packages = ['modes'],\n    tests_require = ['nose'],\n    test_suite = 'nose.collector'\n)\n", "code_toks_joined": "from setuptools import setup <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> license = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> install_requires = [ <STRING> ] , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> tests_require = [ <STRING> ] , <NEWLINE> test_suite = <STRING> <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'modes'", "'0.1'", "'MIT License'", "'td'", "'SSR Mode-S decoding tools'", "'bitstring'", "'modes'", "'nose'", "'nose.collector'"]}}], ["3062a33e13a776e747f222ea914ae7ad", {"code_string": "class NamespaceSerializer(serializers.Serializer):\n    id = serializers.CharField()\n    abbreviation = serializers.CharField()\n    name = serializers.CharField()\n    comment = serializers.CharField(required = False)\n    schemaRef = serializers.CharField(source = 'schema_ref')\n    def restore_object(self, attrs, instance = None):\n        return Namespace(** attrs)\n", "code_toks_joined": "class NamespaceSerializer ( serializers . Serializer ) : <NEWLINE> <INDENT> id = serializers . CharField ( ) <NEWLINE> abbreviation = serializers . CharField ( ) <NEWLINE> name = serializers . CharField ( ) <NEWLINE> comment = serializers . CharField ( required = False ) <NEWLINE> schemaRef = serializers . CharField ( source = <STRING> ) <NEWLINE> def restore_object ( self , attrs , instance = None ) : <NEWLINE> <INDENT> return Namespace ( ** attrs ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'schema_ref'"]}}], ["b4496e4024bbcfafba8b03d7297b6f52", {"code_string": "class MarkerType(GrampsType):\n    \"\"\"Class for handling data markers.\"\"\"\n    NONE = - 1\n    CUSTOM = 0\n    COMPLETE = 1\n    TODO_TYPE = 2\n    _CUSTOM = CUSTOM\n    _DEFAULT = NONE\n    _DATAMAP = [\n        (NONE, \"\", \"\"),\n        (CUSTOM, _(\"Custom\"), \"Custom\"),\n        (COMPLETE, _(\"Complete\"), \"Complete\"),\n        (TODO_TYPE, _(\"ToDo\"), \"ToDo\"),\n        ]\n    def __init__(self, value = None):\n        GrampsType.__init__(self, value)\n", "code_toks_joined": "class MarkerType ( GrampsType ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> NONE = - 1 <NEWLINE> CUSTOM = 0 <NEWLINE> COMPLETE = 1 <NEWLINE> TODO_TYPE = 2 <NEWLINE> _CUSTOM = CUSTOM <NEWLINE> _DEFAULT = NONE <NEWLINE> _DATAMAP = [ <NEWLINE> <INDENT> ( NONE , <STRING> , <STRING> ) , <NEWLINE> ( CUSTOM , _ ( <STRING> ) , <STRING> ) , <NEWLINE> ( COMPLETE , _ ( <STRING> ) , <STRING> ) , <NEWLINE> ( TODO_TYPE , _ ( <STRING> ) , <STRING> ) , <NEWLINE> ] <NEWLINE> <DEDENT> def __init__ ( self , value = None ) : <NEWLINE> <INDENT> GrampsType . __init__ ( self , value ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Class for handling data markers.\"\"\"", "\"\"", "\"\"", "\"Custom\"", "\"Custom\"", "\"Complete\"", "\"Complete\"", "\"ToDo\"", "\"ToDo\""]}}], ["729b0aadb8488386aad576e02926ebc5", {"code_string": "import os\nimport sys\nimport ConfigParser\nfrom utils import load_json\nfrom datetime import datetime\n", "code_toks_joined": "import os <NEWLINE> import sys <NEWLINE> import ConfigParser <NEWLINE> from utils import load_json <NEWLINE> from datetime import datetime <NEWLINE>", "anonymize_dict": {}}], ["5f208232c330efdb07a3089d8eb6911b", {"code_string": "import math\nCircleArea = lambda r: math.pi * r * r\nprint(CircleArea(1))\n", "code_toks_joined": "import math <NEWLINE> CircleArea = lambda r : math . pi * r * r <NEWLINE> print ( CircleArea ( 1 ) ) <NEWLINE>", "anonymize_dict": {}}], ["59f71ae1e0ede7efab1c936524768666", {"code_string": "'''MirrorManager2 forms.'''\nimport re\nfrom flask.ext import wtf\nimport wtforms\nfrom flask import g\nimport IPy\nfrom mirrormanager2.app import APP\nCOUNTRY_REGEX = '^[a-zA-Z][a-zA-Z]$'\n", "code_toks_joined": "<STRING> <NEWLINE> import re <NEWLINE> from flask . ext import wtf <NEWLINE> import wtforms <NEWLINE> from flask import g <NEWLINE> import IPy <NEWLINE> from mirrormanager2 . app import APP <NEWLINE> COUNTRY_REGEX = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''MirrorManager2 forms.'''", "'^[a-zA-Z][a-zA-Z]$'"]}}], ["cc80bdb4b2171f06e7c3cc5a31ab9c05", {"code_string": "class Command(BaseCommand):\n    def handle(self, * args, ** options):\n        tweet = TweetAPI()\n        tweet.reply_mentions()\n", "code_toks_joined": "class Command ( BaseCommand ) : <NEWLINE> <INDENT> def handle ( self , * args , ** options ) : <NEWLINE> <INDENT> tweet = TweetAPI ( ) <NEWLINE> tweet . reply_mentions ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["e6c8b8176c9841956ef6e1d5cfd8c3a2", {"code_string": "class RandomLinkProviderTest(unittest.TestCase):\n    \"\"\"Test class for RandomLinkProvider.\"\"\"\n    def setUp(self):\n        self.provider = RandomLinkProvider()\n    def testGetValue(self):\n        \"\"\"Tests getValue().\"\"\"\n        value = self.provider.getValue()\n        self.assertTrue('http://' in value)\n", "code_toks_joined": "class RandomLinkProviderTest ( unittest . TestCase ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def setUp ( self ) : <NEWLINE> <INDENT> self . provider = RandomLinkProvider ( ) <NEWLINE> <DEDENT> def testGetValue ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> value = self . provider . getValue ( ) <NEWLINE> self . assertTrue ( <STRING> in value ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test class for RandomLinkProvider.\"\"\"", "\"\"\"Tests getValue().\"\"\"", "'http://'"]}}], ["31827480f58c2549e46adbf7ea719b90", {"code_string": "def show_user_message(self, message, title = _(\"Operator Message\")):\n    dialog = gtk.MessageDialog(self.widgets.window1,\n        gtk.DIALOG_DESTROY_WITH_PARENT,\n        gtk.MESSAGE_INFO,\n        gtk.BUTTONS_OK)\n    if title:\n        dialog.set_title(str(title))\n    dialog.set_markup(message)\n    responce = dialog.run()\n    dialog.destroy()\n    return responce == gtk.RESPONSE_OK\n", "code_toks_joined": "def show_user_message ( self , message , title = _ ( <STRING> ) ) : <NEWLINE> <INDENT> dialog = gtk . MessageDialog ( self . widgets . window1 , <NEWLINE> <INDENT> gtk . DIALOG_DESTROY_WITH_PARENT , <NEWLINE> gtk . MESSAGE_INFO , <NEWLINE> gtk . BUTTONS_OK ) <NEWLINE> <DEDENT> if title : <NEWLINE> <INDENT> dialog . set_title ( str ( title ) ) <NEWLINE> <DEDENT> dialog . set_markup ( message ) <NEWLINE> responce = dialog . run ( ) <NEWLINE> dialog . destroy ( ) <NEWLINE> return responce == gtk . RESPONSE_OK <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Operator Message\""]}}], ["fd596a771b71d8e6f90d0af6459567af", {"code_string": "def grouping(self, faceIds):\n    \"\"\"Divides candidate faces into groups based on face similarity using faceIds.\"\"\"\n    body = {'faceIds': faceIds}\n    return self._invoke('post', _groupingUrl, json = body, headers = {'Ocp-Apim-Subscription-Key': self.key})\n", "code_toks_joined": "def grouping ( self , faceIds ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> body = { <STRING> : faceIds } <NEWLINE> return self . _invoke ( <STRING> , _groupingUrl , json = body , headers = { <STRING> : self . key } ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Divides candidate faces into groups based on face similarity using faceIds.\"\"\"", "'faceIds'", "'post'", "'Ocp-Apim-Subscription-Key'"]}}], ["839b44e514409d1a48caa5f89e1600f6", {"code_string": "from portality.core import app\nimport feedparser\nfrom portality.dao import DomainObject as DomainObject\nfrom copy import deepcopy\nfrom datetime import datetime\n", "code_toks_joined": "from portality . core import app <NEWLINE> import feedparser <NEWLINE> from portality . dao import DomainObject as DomainObject <NEWLINE> from copy import deepcopy <NEWLINE> from datetime import datetime <NEWLINE>", "anonymize_dict": {}}], ["998a65d521a35e9c605bcf5f9d81ab8a", {"code_string": "def f():\n    global a\n    a = a.upper()\n", "code_toks_joined": "def f ( ) : <NEWLINE> <INDENT> global a <NEWLINE> a = a . upper ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["8a8072872265da222426cd40381121e1", {"code_string": "def setup():\n    \"\"\" Module-level setup so this only happens once for all of these tests\"\"\"\n    global db, conn, session\n    def ignore(* args):\n        pass\n    push_exception_handler(handler = ignore, reraise_exceptions = True)\n    db = sql.create_engine('sqlite:///:memory:')\n    metadata.bind = db\n    metadata.create_all()\n    conn = db.connect()\n    session = orm.sessionmaker()()\n", "code_toks_joined": "def setup ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> global db , conn , session <NEWLINE> def ignore ( * args ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> push_exception_handler ( handler = ignore , reraise_exceptions = True ) <NEWLINE> db = sql . create_engine ( <STRING> ) <NEWLINE> metadata . bind = db <NEWLINE> metadata . create_all ( ) <NEWLINE> conn = db . connect ( ) <NEWLINE> session = orm . sessionmaker ( ) ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Module-level setup so this only happens once for all of these tests\"\"\"", "'sqlite:///:memory:'"]}}], ["a5c478241016ddbdb468923c344548a8", {"code_string": "from django.contrib.sites.models import Site\nfrom django.db import models\nfrom django.utils.translation import ugettext as _\n__author__ = 'fearless'\n", "code_toks_joined": "from django . contrib . sites . models import Site <NEWLINE> from django . db import models <NEWLINE> from django . utils . translation import ugettext as _ <NEWLINE> __author__ = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'fearless'"]}}], ["0cbaa1a1811a4fa2962bf9aec771d1c5", {"code_string": "from urllib.parse import urlencode\nfrom rest_framework import serializers\nfrom trackmap import trackmap\n", "code_toks_joined": "from urllib . parse import urlencode <NEWLINE> from rest_framework import serializers <NEWLINE> from trackmap import trackmap <NEWLINE>", "anonymize_dict": {}}], ["9925d65d5872b9a979044f723e3d8496", {"code_string": "from __future__ import unicode_literals\nfrom django.db import models, migrations\nfrom decimal import Decimal\nimport mezzanine.utils.models\nimport mezzanine.core.fields\nimport cartridge.shop.fields\nfrom mezzanine.conf import settings\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> from django . db import models , migrations <NEWLINE> from decimal import Decimal <NEWLINE> import mezzanine . utils . models <NEWLINE> import mezzanine . core . fields <NEWLINE> import cartridge . shop . fields <NEWLINE> from mezzanine . conf import settings <NEWLINE>", "anonymize_dict": {}}], ["14a16c8ffb620f5df641ab48e27c84bd", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('public', '0030_auto_20150526_0506'),\n    ]\n    operations = [\n        migrations.AddField(\n            model_name = 'rating',\n            name = 'new_subject',\n            field = models.SmallIntegerField(default = 0, choices = [(1, b'photography'), (2, b'price'), (3, b'appeal')]),\n            preserve_default = False,\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . AddField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . SmallIntegerField ( default = 0 , choices = [ ( 1 , <STRING> ) , ( 2 , <STRING> ) , ( 3 , <STRING> ) ] ) , <NEWLINE> preserve_default = False , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'public'", "'0030_auto_20150526_0506'", "'rating'", "'new_subject'", "b'photography'", "b'price'", "b'appeal'"]}}], ["fe1775b3fc9b26111cda8534916dd213", {"code_string": "def test_get_text_expanded_deprecated(self):\n    text = self.page.get_expanded()\n    args = self.get_last_api_call_args()\n    assert args['rvexpandtemplates'] == '1'\n", "code_toks_joined": "def test_get_text_expanded_deprecated ( self ) : <NEWLINE> <INDENT> text = self . page . get_expanded ( ) <NEWLINE> args = self . get_last_api_call_args ( ) <NEWLINE> assert args [ <STRING> ] == <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'rvexpandtemplates'", "'1'"]}}], ["505893524258bd6f3aca0b7e6d8a7088", {"code_string": "import os\nimport shutil\nfrom flask import render_template, redirect, request, url_for, flash, send_from_directory\nfrom flask_login import login_user, logout_user, login_required, current_user\nfrom.import log_analyzer\nfrom..import db\nfrom..models import *\nfrom.forms import *\nfrom..FtpHelper import ftp_dl\nimport time\nfrom..import celery\nfrom config import Config\nfrom..common_func import *\nfrom..processLogcat import processLogcat\nimport math\n", "code_toks_joined": "import os <NEWLINE> import shutil <NEWLINE> from flask import render_template , redirect , request , url_for , flash , send_from_directory <NEWLINE> from flask_login import login_user , logout_user , login_required , current_user <NEWLINE> from . import log_analyzer <NEWLINE> from . . import db <NEWLINE> from . . models import * <NEWLINE> from . forms import * <NEWLINE> from . . FtpHelper import ftp_dl <NEWLINE> import time <NEWLINE> from . . import celery <NEWLINE> from config import Config <NEWLINE> from . . common_func import * <NEWLINE> from . . processLogcat import processLogcat <NEWLINE> import math <NEWLINE>", "anonymize_dict": {}}], ["b3493c976dd8b7812ec2e8529b61da36", {"code_string": "def __init__(self):\n    super(ColourSchemeChoice, self).__init__()\n    self._current = DARK_BACKGROUND\n    previous = QSettings().value(self.KEY)\n    if previous and previous in COLOURS:\n        self._current = COLOURS[previous]\n", "code_toks_joined": "def __init__ ( self ) : <NEWLINE> <INDENT> super ( ColourSchemeChoice , self ) . __init__ ( ) <NEWLINE> self . _current = DARK_BACKGROUND <NEWLINE> previous = QSettings ( ) . value ( self . KEY ) <NEWLINE> if previous and previous in COLOURS : <NEWLINE> <INDENT> self . _current = COLOURS [ previous ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["6e71f9c209f43d9baace19f79f4a49c1", {"code_string": "import sqlparse\nfrom rsr.connections.backends.base import BaseDriver\nfrom rsr.schema import dbo\nfrom rsr.schema.base import BaseSchemaProvider\ntry:\n    import cx_Oracle\nexcept ImportError as err:\n    cx_Oracle = None\n", "code_toks_joined": "import sqlparse <NEWLINE> from rsr . connections . backends . base import BaseDriver <NEWLINE> from rsr . schema import dbo <NEWLINE> from rsr . schema . base import BaseSchemaProvider <NEWLINE> try : <NEWLINE> <INDENT> import cx_Oracle <NEWLINE> <DEDENT> except ImportError as err : <NEWLINE> <INDENT> cx_Oracle = None <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ebf5161b70e36d8af8480db91ae1ed3e", {"code_string": "from django.db import models\nMARK_CHOICES = (\n    ('unsure', 'unsure'),\n    ('ham', 'ham'),\n    ('spam', 'spam'),\n)\nTRAIN_CHOICES = (\n    ('', ''),\n    ('ham', 'ham'),\n    ('spam', 'spam'),\n)\n", "code_toks_joined": "from django . db import models <NEWLINE> MARK_CHOICES = ( <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ) <NEWLINE> TRAIN_CHOICES = ( <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'unsure'", "'unsure'", "'ham'", "'ham'", "'spam'", "'spam'", "''", "''", "'ham'", "'ham'", "'spam'", "'spam'"]}}], ["b9f41b40c9e3e0eaa51cfe123bc39eb4", {"code_string": "class Room(object):\n    def __init__(self, name, description):\n        self.name = name\n        self.description = description\n        self.paths = {}\n    def go(self, direction):\n        return self.paths.get(direction, None)\n    def add_paths(self, paths):\n        self.paths.update(paths)\n        return self\n", "code_toks_joined": "class Room ( object ) : <NEWLINE> <INDENT> def __init__ ( self , name , description ) : <NEWLINE> <INDENT> self . name = name <NEWLINE> self . description = description <NEWLINE> self . paths = { } <NEWLINE> <DEDENT> def go ( self , direction ) : <NEWLINE> <INDENT> return self . paths . get ( direction , None ) <NEWLINE> <DEDENT> def add_paths ( self , paths ) : <NEWLINE> <INDENT> self . paths . update ( paths ) <NEWLINE> return self <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["23cc2cd3eae5540663d6cf56fc21facf", {"code_string": "from django.conf.urls import url\nfrom.import views\nurlpatterns = [\n    url(r'^$', views.index, name = 'index'),\n    url(r'schools', views.schools),\n    url(r'teams$', views.teams),\n    url(r'teams/(?P<pk>[0-9,A-Z,a-z,-]+)$', views.team_details),\n]\n", "code_toks_joined": "from django . conf . urls import url <NEWLINE> from . import views <NEWLINE> urlpatterns = [ <NEWLINE> <INDENT> url ( <STRING> , views . index , name = <STRING> ) , <NEWLINE> url ( <STRING> , views . schools ) , <NEWLINE> url ( <STRING> , views . teams ) , <NEWLINE> url ( <STRING> , views . team_details ) , <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["r'^$'", "'index'", "r'schools'", "r'teams$'", "r'teams/(?P<pk>[0-9,A-Z,a-z,-]+)$'"]}}], ["95ed1448d5eb4583d40a72f1b04e3217", {"code_string": "class DnsRecordAdmin(admin.ModelAdmin):\n    search_fields = ('host', 'zone', 'data', 'type')\n    list_filter = ('type', 'ttl')\n    list_display = ('id', 'zone', 'host', 'type', 'data', 'ttl')\n", "code_toks_joined": "class DnsRecordAdmin ( admin . ModelAdmin ) : <NEWLINE> <INDENT> search_fields = ( <STRING> , <STRING> , <STRING> , <STRING> ) <NEWLINE> list_filter = ( <STRING> , <STRING> ) <NEWLINE> list_display = ( <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'host'", "'zone'", "'data'", "'type'", "'type'", "'ttl'", "'id'", "'zone'", "'host'", "'type'", "'data'", "'ttl'"]}}], ["4c58055955dd72c843fa6caba11699ac", {"code_string": "def line(self, x1, y1, x2, y2, pen = 1, ** kwargs):\n    l = sdxf.Line(\n        points = [(x1, y1), (x2, y2)], layer = pen, ** kwargs\n    )\n    self.dxf.append(l)\n    return l\n", "code_toks_joined": "def line ( self , x1 , y1 , x2 , y2 , pen = 1 , ** kwargs ) : <NEWLINE> <INDENT> l = sdxf . Line ( <NEWLINE> <INDENT> points = [ ( x1 , y1 ) , ( x2 , y2 ) ] , layer = pen , ** kwargs <NEWLINE> <DEDENT> ) <NEWLINE> self . dxf . append ( l ) <NEWLINE> return l <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["fdcb8560d5efb6b22704aee0d5913c13", {"code_string": "def collided_with_level(player_state, previous_position):\n    \"\"\"Called whenever the player bumps into a wall.\"\"\"\n    player_state[\"position\"] = previous_position\n    return player_state\n", "code_toks_joined": "def collided_with_level ( player_state , previous_position ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> player_state [ <STRING> ] = previous_position <NEWLINE> return player_state <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Called whenever the player bumps into a wall.\"\"\"", "\"position\""]}}], ["6cc47234a3020f488532cd70ecb02fb2", {"code_string": "def playbook_basedir(self):\n    \"\"\" returns the directory of the current playbook \"\"\"\n    return self._playbook_basedir\n", "code_toks_joined": "def playbook_basedir ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . _playbook_basedir <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" returns the directory of the current playbook \"\"\""]}}], ["7678eb3f1d58d78e6b4066421525e121", {"code_string": "def error(self, text):\n    \"\"\"Logs at the ERROR level.\"\"\"\n    if self.to_cloud:\n        self.safe_cloud_log_text(text, severity = \"ERROR\")\n    else:\n        self.local_logger.error(text)\n", "code_toks_joined": "def error ( self , text ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if self . to_cloud : <NEWLINE> <INDENT> self . safe_cloud_log_text ( text , severity = <STRING> ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . local_logger . error ( text ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Logs at the ERROR level.\"\"\"", "\"ERROR\""]}}], ["2616d860f5783552cb5532ca3581b42e", {"code_string": "def load(target):\n    \"\"\"uses __import__ followed by Ice.updateModules if available.\"\"\"\n    __import__(target)\n    Ice.updateModules()\n", "code_toks_joined": "def load ( target ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> __import__ ( target ) <NEWLINE> Ice . updateModules ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"uses __import__ followed by Ice.updateModules if available.\"\"\""]}}], ["877fc1e2b43baa4124719d8dc7aeb8d3", {"code_string": "def get_date(row, key):\n    if row[key]:\n        return datetime.datetime.strptime(row[key], '%Y-%m-%d')\n    else:\n        return datetime.datetime(1900, 1, 1)\n", "code_toks_joined": "def get_date ( row , key ) : <NEWLINE> <INDENT> if row [ key ] : <NEWLINE> <INDENT> return datetime . datetime . strptime ( row [ key ] , <STRING> ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return datetime . datetime ( 1900 , 1 , 1 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'%Y-%m-%d'"]}}], ["8caf8de759ea4f941a247f15cf41f1e7", {"code_string": "def connect(self):\n    \"\"\"Create blocking connection in RMQ\"\"\"\n    return BlockingConnection(\n        parameters = ConnectionParameters(\n            host = self.host,\n            port = self.port,\n            virtual_host = self.vhost,\n            credentials = PlainCredentials(\n                username = self.user,\n                password = self.passwd,\n            )\n        )\n    )\n", "code_toks_joined": "def connect ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return BlockingConnection ( <NEWLINE> <INDENT> parameters = ConnectionParameters ( <NEWLINE> <INDENT> host = self . host , <NEWLINE> port = self . port , <NEWLINE> virtual_host = self . vhost , <NEWLINE> credentials = PlainCredentials ( <NEWLINE> <INDENT> username = self . user , <NEWLINE> password = self . passwd , <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Create blocking connection in RMQ\"\"\""]}}], ["6f339489eb9962a0b869b559d12f52ef", {"code_string": "def __len__(self):\n    \"\"\"Return number of planets in aspects restrictions.\"\"\"\n    return len(self._dict_)\n", "code_toks_joined": "def __len__ ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return len ( self . _dict_ ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Return number of planets in aspects restrictions.\"\"\""]}}], ["07ea79ed9b2257f82be1ce465646b7bd", {"code_string": "def open(self):\n    print('new connection')\n    self.initialized = False\n", "code_toks_joined": "def open ( self ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> self . initialized = False <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'new connection'"]}}], ["ddc0949872d23eec4f70aa3646ded20d", {"code_string": "def merge_reduce(r, s):\n    print(r)\n    print(s)\n    if r[1] >= s[0]:\n        return[r[0], s[1]]\n    else:\n        return r, s\n", "code_toks_joined": "def merge_reduce ( r , s ) : <NEWLINE> <INDENT> print ( r ) <NEWLINE> print ( s ) <NEWLINE> if r [ 1 ] >= s [ 0 ] : <NEWLINE> <INDENT> return [ r [ 0 ] , s [ 1 ] ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return r , s <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["e8898474bdd0af71eb4183404839cfd4", {"code_string": "def test_connection(port):\n    try:\n        sock = socket.create_connection(('localhost', port))\n    except socket.error:\n        return False\n    else:\n        sock.close()\n        return True\n", "code_toks_joined": "def test_connection ( port ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> sock = socket . create_connection ( ( <STRING> , port ) ) <NEWLINE> <DEDENT> except socket . error : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> sock . close ( ) <NEWLINE> return True <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'localhost'"]}}], ["2e6c9a6e61ec0ab4ab439a032f538b17", {"code_string": "def setup_celery_loader():\n    os.environ.setdefault(\"CELERY_LOADER\",\n        \"amaracelery.loaders.AmaraCeleryLoader\")\n", "code_toks_joined": "def setup_celery_loader ( ) : <NEWLINE> <INDENT> os . environ . setdefault ( <STRING> , <NEWLINE> <INDENT> <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"CELERY_LOADER\"", "\"amaracelery.loaders.AmaraCeleryLoader\""]}}], ["ee83c674b096528aad2f10ac70840feb", {"code_string": "def _api_grid_image_edit(self, method, url, body, headers):\n    body = self.fixtures.load('image_save.json')\n    return(httplib.OK, body, {}, httplib.responses[httplib.OK])\n", "code_toks_joined": "def _api_grid_image_edit ( self , method , url , body , headers ) : <NEWLINE> <INDENT> body = self . fixtures . load ( <STRING> ) <NEWLINE> return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'image_save.json'"]}}], ["8b35e8fe80d596b6d30a90fa15c8fdcf", {"code_string": "from gwt.ui.Image import(\n    ClickHandler,\n    DOM,\n    Event,\n    Factory,\n    Image,\n    MouseHandler,\n    Widget,\n    prefetchImages,\n)\n", "code_toks_joined": "from gwt . ui . Image import ( <NEWLINE> <INDENT> ClickHandler , <NEWLINE> DOM , <NEWLINE> Event , <NEWLINE> Factory , <NEWLINE> Image , <NEWLINE> MouseHandler , <NEWLINE> Widget , <NEWLINE> prefetchImages , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {}}], ["c904989af71e6fdc9a10e6ea521c81c9", {"code_string": "def num_cpus():\n    \"\"\"Returns the total amount of CPU's on the system.\"\"\"\n    if not hasattr(os, 'sysconf'):\n        raise RunTimeError('No sysconf detected.')\n    return os.sysconf('SC_NPROCESSORS_ONLN')\n", "code_toks_joined": "def num_cpus ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if not hasattr ( os , <STRING> ) : <NEWLINE> <INDENT> raise RunTimeError ( <STRING> ) <NEWLINE> <DEDENT> return os . sysconf ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Returns the total amount of CPU's on the system.\"\"\"", "'sysconf'", "'No sysconf detected.'", "'SC_NPROCESSORS_ONLN'"]}}], ["5b2e97d931ff9c31e872662a3ed37c1b", {"code_string": "def load_user(user_id):\n    user = db_user.get(user_id)\n    if user:\n        return User.from_dbrow(user)\n    else:\n        return None\n", "code_toks_joined": "def load_user ( user_id ) : <NEWLINE> <INDENT> user = db_user . get ( user_id ) <NEWLINE> if user : <NEWLINE> <INDENT> return User . from_dbrow ( user ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["d11eb82b1f3aebdd4fbca505509bfda9", {"code_string": "def test_get_new_message_num(self):\n    recipient = users.create_user(username = 'test', password = 'test')\n    epistle = self.create_epistle(recipient = recipient)\n    result = epistle_queries.get_new_message_num(recipient.id)\n    assert result == 1\n", "code_toks_joined": "def test_get_new_message_num ( self ) : <NEWLINE> <INDENT> recipient = users . create_user ( username = <STRING> , password = <STRING> ) <NEWLINE> epistle = self . create_epistle ( recipient = recipient ) <NEWLINE> result = epistle_queries . get_new_message_num ( recipient . id ) <NEWLINE> assert result == 1 <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'test'", "'test'"]}}], ["e3a9a795efd653efe0643dd26d00cff2", {"code_string": "def plot_cx3(hs, cx):\n    ax = df2.gca()\n    rchip = hs.get_chip(cx)\n    ax.imshow(rchip, interpolation = 'nearest')\n    df2.plt.set_cmap('gray')\n    df2.set_ticks([], [])\n    gname = hs.cx2_gname(cx)\n    cid = hs.tables.cx2_cid[cx]\n    ax.set_xlabel(gname)\n    ax.set_title(hs.cxstr(cx))\n", "code_toks_joined": "def plot_cx3 ( hs , cx ) : <NEWLINE> <INDENT> ax = df2 . gca ( ) <NEWLINE> rchip = hs . get_chip ( cx ) <NEWLINE> ax . imshow ( rchip , interpolation = <STRING> ) <NEWLINE> df2 . plt . set_cmap ( <STRING> ) <NEWLINE> df2 . set_ticks ( [ ] , [ ] ) <NEWLINE> gname = hs . cx2_gname ( cx ) <NEWLINE> cid = hs . tables . cx2_cid [ cx ] <NEWLINE> ax . set_xlabel ( gname ) <NEWLINE> ax . set_title ( hs . cxstr ( cx ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'nearest'", "'gray'"]}}], ["c76c22bcc51a904a7cbe556daa6ea4b5", {"code_string": "def get_followers(self, ** kwargs):\n    _base_url = url_join(self.base_url, self.user_id, 'followers')\n    if len(kwargs) > 0:\n        _filters = urllib.urlencode(kwargs)\n        _url = '%s?api_key=%s&%s' %(_base_url, self.auth_key, _filters)\n    else:\n        _url = '%s?api_key=%s' %(_base_url, self.auth_key)\n    return self._parse_data(self._get_api_data(_url)['followers'])\n", "code_toks_joined": "def get_followers ( self , ** kwargs ) : <NEWLINE> <INDENT> _base_url = url_join ( self . base_url , self . user_id , <STRING> ) <NEWLINE> if len ( kwargs ) > 0 : <NEWLINE> <INDENT> _filters = urllib . urlencode ( kwargs ) <NEWLINE> _url = <STRING> % ( _base_url , self . auth_key , _filters ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> _url = <STRING> % ( _base_url , self . auth_key ) <NEWLINE> <DEDENT> return self . _parse_data ( self . _get_api_data ( _url ) [ <STRING> ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'followers'", "'%s?api_key=%s&%s'", "'%s?api_key=%s'", "'followers'"]}}], ["893279f13a0df4f5380accb133dd3ee2", {"code_string": "import sys, os\nimport getopt\nimport re\nimport math\nimport warnings\nfrom Bio import BiopythonExperimentalWarning\nwarnings.simplefilter('ignore', BiopythonExperimentalWarning)\nfrom Bio.SeqRecord import SeqRecord\nfrom Bio import SearchIO\nfrom HMMPileUp import HMMPileUp, HMMSequence\n", "code_toks_joined": "import sys , os <NEWLINE> import getopt <NEWLINE> import re <NEWLINE> import math <NEWLINE> import warnings <NEWLINE> from Bio import BiopythonExperimentalWarning <NEWLINE> warnings . simplefilter ( <STRING> , BiopythonExperimentalWarning ) <NEWLINE> from Bio . SeqRecord import SeqRecord <NEWLINE> from Bio import SearchIO <NEWLINE> from HMMPileUp import HMMPileUp , HMMSequence <NEWLINE>", "anonymize_dict": {"<STRING>": ["'ignore'"]}}], ["621b001619d0e8a64df7d80f74e37aaa", {"code_string": "def check_abort(self):\n    \"\"\"Will be overwritten to determine if control flow should be aborted.\"\"\"\n    if self.abort():\n        raise Abort\n", "code_toks_joined": "def check_abort ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if self . abort ( ) : <NEWLINE> <INDENT> raise Abort <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Will be overwritten to determine if control flow should be aborted.\"\"\""]}}], ["78b8d63fa7cbf0c20046b4fe5c344911", {"code_string": "class TunelSSH():\n    def __init__(self, ssh_address, ssh_port, ssh_username, ssh_password, remote_bind_address, remote_bind_port):\n        self.server = SSHTunnelForwarder(ssh_address = (ssh_address, ssh_port), ssh_username = ssh_username,\n            ssh_password = ssh_password, remote_bind_address = (remote_bind_address, remote_bind_port))\n    def Iniciar(self):\n        self.server.start()\n        return self.server.local_bind_port\n    def Cerrar(self):\n        self.server.stop()\n", "code_toks_joined": "class TunelSSH ( ) : <NEWLINE> <INDENT> def __init__ ( self , ssh_address , ssh_port , ssh_username , ssh_password , remote_bind_address , remote_bind_port ) : <NEWLINE> <INDENT> self . server = SSHTunnelForwarder ( ssh_address = ( ssh_address , ssh_port ) , ssh_username = ssh_username , <NEWLINE> <INDENT> ssh_password = ssh_password , remote_bind_address = ( remote_bind_address , remote_bind_port ) ) <NEWLINE> <DEDENT> <DEDENT> def Iniciar ( self ) : <NEWLINE> <INDENT> self . server . start ( ) <NEWLINE> return self . server . local_bind_port <NEWLINE> <DEDENT> def Cerrar ( self ) : <NEWLINE> <INDENT> self . server . stop ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["d52f1e59e09ee22136846f704b13d6f4", {"code_string": "def __init__(self, ctx, rd):\n    self.db, self.library_id, self.library_map, self.default_library = get_library_data(ctx, rd)\n    self.ctx, self.rd = ctx, rd\n", "code_toks_joined": "def __init__ ( self , ctx , rd ) : <NEWLINE> <INDENT> self . db , self . library_id , self . library_map , self . default_library = get_library_data ( ctx , rd ) <NEWLINE> self . ctx , self . rd = ctx , rd <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["38c220d23784c3bee3cde47bf8b74c68", {"code_string": "def tocke(i):\n    t = [25, 20, 15, 12, 10, 8, 7, 6, 5, 4, 3, 2, 1]\n    if i > len(t) - 1:\n        return 1\n    return t[i]\n", "code_toks_joined": "def tocke ( i ) : <NEWLINE> <INDENT> t = [ 25 , 20 , 15 , 12 , 10 , 8 , 7 , 6 , 5 , 4 , 3 , 2 , 1 ] <NEWLINE> if i > len ( t ) - 1 : <NEWLINE> <INDENT> return 1 <NEWLINE> <DEDENT> return t [ i ] <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["9236769363671d53ba371231f3157dd4", {"code_string": "def test_templates_avoiding_almost_identical_products(self):\n    \"\"\" Tests whether nearly identical products are NOT templates of one another.\"\"\"\n    for i in range(1, dp.N_PROD_NONSENSE):\n        target = \"p_nonsense_\" + str(i)\n        templates = pttfidf.get_product_templates_tfidf(self.session_context, [target]).get(target, {})\n        nose.tools.ok_(len(templates) > 0,\n            \"No templates were generated for product \" + target)\n        template_products = [t[1] for t in templates]\n        way_too_similar = \"p_nonsense_\" + str(i + 1)\n        nose.tools.ok_(way_too_similar not in template_products,\n            \"Nearly identical templates!\")\n", "code_toks_joined": "def test_templates_avoiding_almost_identical_products ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> for i in range ( 1 , dp . N_PROD_NONSENSE ) : <NEWLINE> <INDENT> target = <STRING> + str ( i ) <NEWLINE> templates = pttfidf . get_product_templates_tfidf ( self . session_context , [ target ] ) . get ( target , { } ) <NEWLINE> nose . tools . ok_ ( len ( templates ) > 0 , <NEWLINE> <INDENT> <STRING> + target ) <NEWLINE> <DEDENT> template_products = [ t [ 1 ] for t in templates ] <NEWLINE> way_too_similar = <STRING> + str ( i + 1 ) <NEWLINE> nose . tools . ok_ ( way_too_similar not in template_products , <NEWLINE> <INDENT> <STRING> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Tests whether nearly identical products are NOT templates of one another.\"\"\"", "\"p_nonsense_\"", "\"No templates were generated for product \"", "\"p_nonsense_\"", "\"Nearly identical templates!\""]}}], ["a339d048699b98a06dc6c202da6103a3", {"code_string": "def __init__(self, institution = 'tardis'):\n    self.institution = institution\n    self.sites = None\n    self.site_manager = SiteManager()\n", "code_toks_joined": "def __init__ ( self , institution = <STRING> ) : <NEWLINE> <INDENT> self . institution = institution <NEWLINE> self . sites = None <NEWLINE> self . site_manager = SiteManager ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'tardis'"]}}], ["ad08dd2fff274ef269edaaa83a7fac3b", {"code_string": "def __init__(self, fps, seconds):\n    self.fps = fps\n    self.seconds = seconds\n    self.length = self.secondsToFrames(seconds)\n    self.buffer = deque([], self.length)\n", "code_toks_joined": "def __init__ ( self , fps , seconds ) : <NEWLINE> <INDENT> self . fps = fps <NEWLINE> self . seconds = seconds <NEWLINE> self . length = self . secondsToFrames ( seconds ) <NEWLINE> self . buffer = deque ( [ ] , self . length ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["6f1f83e08f01fd70ef07f10aeec8b131", {"code_string": "def scipy_wrapper_gradient(x, crit_func):\n    \"\"\" Wrapper for the gradient calculation.\"\"\"\n    assert(isinstance(x, np.ndarray))\n    assert(np.all(np.isfinite(x)))\n    assert(x.dtype == 'float')\n    assert(x.ndim == 1)\n    grad = crit_func.evaluate(x, 'gradient')\n    assert(isinstance(grad, np.ndarray))\n    assert(np.all(np.isfinite(grad)))\n    assert(grad.dtype == 'float')\n    return grad\n", "code_toks_joined": "def scipy_wrapper_gradient ( x , crit_func ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> assert ( isinstance ( x , np . ndarray ) ) <NEWLINE> assert ( np . all ( np . isfinite ( x ) ) ) <NEWLINE> assert ( x . dtype == <STRING> ) <NEWLINE> assert ( x . ndim == 1 ) <NEWLINE> grad = crit_func . evaluate ( x , <STRING> ) <NEWLINE> assert ( isinstance ( grad , np . ndarray ) ) <NEWLINE> assert ( np . all ( np . isfinite ( grad ) ) ) <NEWLINE> assert ( grad . dtype == <STRING> ) <NEWLINE> return grad <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Wrapper for the gradient calculation.\"\"\"", "'float'", "'gradient'", "'float'"]}}], ["f94371b0eaf71d2a72d37e2065f768e0", {"code_string": "def is_key_pressed_once(self, key_code):\n    \"\"\"Determine if a key is pressed and signal it only once - key needs to be released before this returns true again.\"\"\"\n    if sf.Keyboard.is_key_pressed(key_code):\n        if self.key_released.get(key_code):\n            self.key_released[key_code] = False\n            return True\n    else:\n        self.key_released[key_code] = True\n    return False\n", "code_toks_joined": "def is_key_pressed_once ( self , key_code ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if sf . Keyboard . is_key_pressed ( key_code ) : <NEWLINE> <INDENT> if self . key_released . get ( key_code ) : <NEWLINE> <INDENT> self . key_released [ key_code ] = False <NEWLINE> return True <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> self . key_released [ key_code ] = True <NEWLINE> <DEDENT> return False <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Determine if a key is pressed and signal it only once - key needs to be released before this returns true again.\"\"\""]}}], ["e7f7c2d18d33442a6ed0bcfeafec87d8", {"code_string": "from setuptools import setup\nsetup(\n    name = 'pyliczba',\n    version = '1.0',\n    description = 'Converts numerical values to Polish text',\n    url = 'http://github.com/sq6jnx/pyliczba',\n    author = 'Micha\u0142 Sadowski',\n    license = 'GNU LGPL',\n    packages = ['pyliczba'],\n    install_requires = [\n        'six',\n    ],\n    test_suite = 'nose.collector',\n    tests_require = ['nose'],\n    zip_safe = False,\n)\n", "code_toks_joined": "from setuptools import setup <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> url = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> license = <STRING> , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> install_requires = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <DEDENT> ] , <NEWLINE> test_suite = <STRING> , <NEWLINE> tests_require = [ <STRING> ] , <NEWLINE> zip_safe = False , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'pyliczba'", "'1.0'", "'Converts numerical values to Polish text'", "'http://github.com/sq6jnx/pyliczba'", "'Micha\u0142 Sadowski'", "'GNU LGPL'", "'pyliczba'", "'six'", "'nose.collector'", "'nose'"]}}], ["5b9b9e63fdce7711a4fadb62cb082c53", {"code_string": "import time\nimport threading\nimport apigen\n__version__ = \"1.0.0\"\n", "code_toks_joined": "import time <NEWLINE> import threading <NEWLINE> import apigen <NEWLINE> __version__ = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"1.0.0\""]}}], ["ca8c207758ed3eb01c4ce6951744f104", {"code_string": "def save(self, path, dir_name):\n    \"\"\"Save cookies to a directory using a path.\"\"\"\n    cookie_jar = os.path.join(path, dir_name)\n    if not os.path.exists(cookie_jar):\n        os.mkdir(dir_name)\n        for paths in self.cookie_paths:\n            try:\n                for filename in os.listdir(paths):\n                    shutil.copy(os.path.join(paths, filename), cookie_jar)\n            except Exception:\n                pass\n", "code_toks_joined": "def save ( self , path , dir_name ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> cookie_jar = os . path . join ( path , dir_name ) <NEWLINE> if not os . path . exists ( cookie_jar ) : <NEWLINE> <INDENT> os . mkdir ( dir_name ) <NEWLINE> for paths in self . cookie_paths : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> for filename in os . listdir ( paths ) : <NEWLINE> <INDENT> shutil . copy ( os . path . join ( paths , filename ) , cookie_jar ) <NEWLINE> <DEDENT> <DEDENT> except Exception : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Save cookies to a directory using a path.\"\"\""]}}], ["dc78df58336e7e953c038ce9b6da977f", {"code_string": "class TimeoutHTTPConnection(httplib.HTTPConnection):\n    def __init__(self, timeout_s, * args, ** kwargs):\n        httplib.HTTPConnection.__init__(self, * args, ** kwargs)\n        self.timeout_s = timeout_s\n    def settimeout(self, timeout_s):\n        self.timeout_s = timeout_s\n        self.sock.settimeout(self.timeout_s)\n    def connect(self):\n        httplib.HTTPConnection.connect(self)\n        self.sock.settimeout(self.timeout_s)\n", "code_toks_joined": "class TimeoutHTTPConnection ( httplib . HTTPConnection ) : <NEWLINE> <INDENT> def __init__ ( self , timeout_s , * args , ** kwargs ) : <NEWLINE> <INDENT> httplib . HTTPConnection . __init__ ( self , * args , ** kwargs ) <NEWLINE> self . timeout_s = timeout_s <NEWLINE> <DEDENT> def settimeout ( self , timeout_s ) : <NEWLINE> <INDENT> self . timeout_s = timeout_s <NEWLINE> self . sock . settimeout ( self . timeout_s ) <NEWLINE> <DEDENT> def connect ( self ) : <NEWLINE> <INDENT> httplib . HTTPConnection . connect ( self ) <NEWLINE> self . sock . settimeout ( self . timeout_s ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["e70e458b584c16ec5211032081191077", {"code_string": "class SubmissionHelpManager(models.Manager):\n    def get_active(self):\n        return self.filter(status = self.model.PUBLISHED)\n", "code_toks_joined": "class SubmissionHelpManager ( models . Manager ) : <NEWLINE> <INDENT> def get_active ( self ) : <NEWLINE> <INDENT> return self . filter ( status = self . model . PUBLISHED ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["4a976fbd1cecf4017f6b7ec7f06e3748", {"code_string": "\"\"\"Script for the paper\"\"\"\nimport time\nimport numpy as np\nimport snr_of_images\nimport urllib\nimport zlib\nfrom io import BytesIO\nimport cv2\nimport h5py\nimport os\nimport matplotlib.pyplot as plt\nimport json\nimport requests\nfrom requests.packages.urllib3.exceptions import InsecureRequestWarning\nsbem_skip = False\natum_skip = False\nfbem_skip = False\ntemca_skip = False\nOCP_server = 'http://cloud.neurodata.io/ocp/ca/'\nn_comp = 100\n", "code_toks_joined": "<STRING> <NEWLINE> import time <NEWLINE> import numpy as np <NEWLINE> import snr_of_images <NEWLINE> import urllib <NEWLINE> import zlib <NEWLINE> from io import BytesIO <NEWLINE> import cv2 <NEWLINE> import h5py <NEWLINE> import os <NEWLINE> import matplotlib . pyplot as plt <NEWLINE> import json <NEWLINE> import requests <NEWLINE> from requests . packages . urllib3 . exceptions import InsecureRequestWarning <NEWLINE> sbem_skip = False <NEWLINE> atum_skip = False <NEWLINE> fbem_skip = False <NEWLINE> temca_skip = False <NEWLINE> OCP_server = <STRING> <NEWLINE> n_comp = 100 <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Script for the paper\"\"\"", "'http://cloud.neurodata.io/ocp/ca/'"]}}], ["e728a4b6ad1aad9135ac052e5025717f", {"code_string": "def StoreFrom(self, sender, authAddress = \"-\"):\n    command = \"QSTOR FROM %s %s\" %(sender, authAddress)\n    self.stream.Write(command)\n    r = self.stream.GetResponse()\n    if r.code != 1000:\n        raise bongo.BongoError(r.message)\n    return r\n", "code_toks_joined": "def StoreFrom ( self , sender , authAddress = <STRING> ) : <NEWLINE> <INDENT> command = <STRING> % ( sender , authAddress ) <NEWLINE> self . stream . Write ( command ) <NEWLINE> r = self . stream . GetResponse ( ) <NEWLINE> if r . code != 1000 : <NEWLINE> <INDENT> raise bongo . BongoError ( r . message ) <NEWLINE> <DEDENT> return r <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"-\"", "\"QSTOR FROM %s %s\""]}}], ["3b24f7d36a2614db07c26ba9f10583b0", {"code_string": "def resttext(text):\n    '''Returns *text* in reST format or plain text if resttext fails'''\n    overrides = {\n        'inital_header_level': 3,\n        'report_level': 5,\n    }\n    if RESTRICT_REST:\n        return text\n    try:\n        from docutils.core import publish_parts\n        parts = publish_parts(source = text, writer_name = 'html',\n            settings_overrides = overrides)\n        return mark_safe(parts['fragment'])\n    except ImportError:\n        return text\n    except Exception as ex1:\n        logger.fatal(repr(ex1))\n        return text\n", "code_toks_joined": "def resttext ( text ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> overrides = { <NEWLINE> <INDENT> <STRING> : 3 , <NEWLINE> <STRING> : 5 , <NEWLINE> <DEDENT> } <NEWLINE> if RESTRICT_REST : <NEWLINE> <INDENT> return text <NEWLINE> <DEDENT> try : <NEWLINE> <INDENT> from docutils . core import publish_parts <NEWLINE> parts = publish_parts ( source = text , writer_name = <STRING> , <NEWLINE> <INDENT> settings_overrides = overrides ) <NEWLINE> <DEDENT> return mark_safe ( parts [ <STRING> ] ) <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> return text <NEWLINE> <DEDENT> except Exception as ex1 : <NEWLINE> <INDENT> logger . fatal ( repr ( ex1 ) ) <NEWLINE> return text <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Returns *text* in reST format or plain text if resttext fails'''", "'inital_header_level'", "'report_level'", "'html'", "'fragment'"]}}], ["cc5f31f3dbfa90f589baba1623b74738", {"code_string": "def onHide(self, event):\n    super(ClothesTaskView, self).onHide(event)\n    self.visualizeFaceMasks(False)\n", "code_toks_joined": "def onHide ( self , event ) : <NEWLINE> <INDENT> super ( ClothesTaskView , self ) . onHide ( event ) <NEWLINE> self . visualizeFaceMasks ( False ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["a736f931e5a3ca4069a590fd740136a8", {"code_string": "def csv(self, request):\n    uuid = request.QUERY_PARAMS.get(\"uuid\", None)\n    if uuid is None:\n        return response.NotFound()\n    project = get_object_or_404(Project, issues_csv_uuid = uuid)\n    queryset = project.issues.all().order_by('ref')\n    data = services.issues_to_csv(project, queryset)\n    csv_response = HttpResponse(data.getvalue(), content_type = 'application/csv; charset=utf-8')\n    csv_response['Content-Disposition'] = 'attachment; filename=\"issues.csv\"'\n    return csv_response\n", "code_toks_joined": "def csv ( self , request ) : <NEWLINE> <INDENT> uuid = request . QUERY_PARAMS . get ( <STRING> , None ) <NEWLINE> if uuid is None : <NEWLINE> <INDENT> return response . NotFound ( ) <NEWLINE> <DEDENT> project = get_object_or_404 ( Project , issues_csv_uuid = uuid ) <NEWLINE> queryset = project . issues . all ( ) . order_by ( <STRING> ) <NEWLINE> data = services . issues_to_csv ( project , queryset ) <NEWLINE> csv_response = HttpResponse ( data . getvalue ( ) , content_type = <STRING> ) <NEWLINE> csv_response [ <STRING> ] = <STRING> <NEWLINE> return csv_response <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"uuid\"", "'ref'", "'application/csv; charset=utf-8'", "'Content-Disposition'", "'attachment; filename=\"issues.csv\"'"]}}], ["ef2027e4f75868c6e425a8f25141d187", {"code_string": "class CredentialsField(models.Field):\n    __metaclass__ = models.SubfieldBase\n    def db_type(self, connection = None):\n        return 'VARCHAR'\n    def to_python(self, value):\n        if not value:\n            return None\n        if isinstance(value, oauth2client.client.Credentials):\n            return value\n        return pickle.loads(base64.b64decode(value))\n    def get_db_prep_value(self, value):\n        return base64.b64encode(pickle.dumps(value))\n", "code_toks_joined": "class CredentialsField ( models . Field ) : <NEWLINE> <INDENT> __metaclass__ = models . SubfieldBase <NEWLINE> def db_type ( self , connection = None ) : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> def to_python ( self , value ) : <NEWLINE> <INDENT> if not value : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> if isinstance ( value , oauth2client . client . Credentials ) : <NEWLINE> <INDENT> return value <NEWLINE> <DEDENT> return pickle . loads ( base64 . b64decode ( value ) ) <NEWLINE> <DEDENT> def get_db_prep_value ( self , value ) : <NEWLINE> <INDENT> return base64 . b64encode ( pickle . dumps ( value ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'VARCHAR'"]}}], ["ff58de71a8b45db6f0e17ce4994eab68", {"code_string": "def get_subcommands():\n    if brkt_cli.crypto.cryptography_library_available:\n        return[MakeKeySubcommand()]\n    else:\n        return[]\n", "code_toks_joined": "def get_subcommands ( ) : <NEWLINE> <INDENT> if brkt_cli . crypto . cryptography_library_available : <NEWLINE> <INDENT> return [ MakeKeySubcommand ( ) ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return [ ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["068a56179f586c491ea27fc0c580d7ff", {"code_string": "def on_postpone_clicked(self, button):\n    \"\"\"Postpone button press event handler.\"\"\"\n    self.postpone_break()\n", "code_toks_joined": "def on_postpone_clicked ( self , button ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . postpone_break ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Postpone button press event handler.\"\"\""]}}], ["1ff74a1aa8188c36b4a95f0ee7a895a2", {"code_string": "class ReceiveMail(RunnableLeaf):\n    ''' Receive all new mail from all accounts '''\n    def __init__(self):\n        RunnableLeaf.__init__(self, name = _(\"Receive All Email\"))\n    def run(self):\n        utils.spawn_async(['claws-mail', '--receive-all'])\n    def get_description(self):\n        return _(\"Receive new messages from all accounts in ClawsMail\")\n    def get_icon_name(self):\n        return \"mail-send-receive\"\n", "code_toks_joined": "class ReceiveMail ( RunnableLeaf ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self ) : <NEWLINE> <INDENT> RunnableLeaf . __init__ ( self , name = _ ( <STRING> ) ) <NEWLINE> <DEDENT> def run ( self ) : <NEWLINE> <INDENT> utils . spawn_async ( [ <STRING> , <STRING> ] ) <NEWLINE> <DEDENT> def get_description ( self ) : <NEWLINE> <INDENT> return _ ( <STRING> ) <NEWLINE> <DEDENT> def get_icon_name ( self ) : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["''' Receive all new mail from all accounts '''", "\"Receive All Email\"", "'claws-mail'", "'--receive-all'", "\"Receive new messages from all accounts in ClawsMail\"", "\"mail-send-receive\""]}}], ["c37d7f1841823e6b7ea50a5d24ee5a73", {"code_string": "def prompt(desc, default = None):\n    if default:\n        desc = \"%s (default: %s)\" %(desc, default)\n    return raw_input('%s: ' % desc) or default\n", "code_toks_joined": "def prompt ( desc , default = None ) : <NEWLINE> <INDENT> if default : <NEWLINE> <INDENT> desc = <STRING> % ( desc , default ) <NEWLINE> <DEDENT> return raw_input ( <STRING> % desc ) or default <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"%s (default: %s)\"", "'%s: '"]}}], ["9aa4abf76ef4a06b03c658d29c4869ef", {"code_string": "def split_input(query_input):\n    quotes_input = []\n    values = query_input.split(\"\\\"\")\n    quotes_input = filter(None, values)\n    spaced_input = []\n    data = []\n    for unit in quotes_input:\n        new_unit = unit.split(\" \")\n        if isinstance(new_unit, list):\n            new_unit = list(filter(None, new_unit))\n            data.append(new_unit)\n        elif new_unit != '':\n            data.append(new_unit)\n    spaced_input.append(data)\n    return spaced_input\n", "code_toks_joined": "def split_input ( query_input ) : <NEWLINE> <INDENT> quotes_input = [ ] <NEWLINE> values = query_input . split ( <STRING> ) <NEWLINE> quotes_input = filter ( None , values ) <NEWLINE> spaced_input = [ ] <NEWLINE> data = [ ] <NEWLINE> for unit in quotes_input : <NEWLINE> <INDENT> new_unit = unit . split ( <STRING> ) <NEWLINE> if isinstance ( new_unit , list ) : <NEWLINE> <INDENT> new_unit = list ( filter ( None , new_unit ) ) <NEWLINE> data . append ( new_unit ) <NEWLINE> <DEDENT> elif new_unit != <STRING> : <NEWLINE> <INDENT> data . append ( new_unit ) <NEWLINE> <DEDENT> <DEDENT> spaced_input . append ( data ) <NEWLINE> return spaced_input <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\\\"\"", "\" \"", "''"]}}], ["b6bdbc9a81f2af27d4229fbedd2b200e", {"code_string": "def write(x, y, z, a, outname):\n    \"\"\"Writes to a CSV file, but intentionally truncates it\"\"\"\n    out = file(outname + '.csv', 'w')\n    out.writelines('x,y,z,a\\n')\n    out.writelines(','.join(str(np.around(s, decimals = 3)) for s in[x, y, z, a]) + '\\n')\n    out.close()\n", "code_toks_joined": "def write ( x , y , z , a , outname ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> out = file ( outname + <STRING> , <STRING> ) <NEWLINE> out . writelines ( <STRING> ) <NEWLINE> out . writelines ( <STRING> . join ( str ( np . around ( s , decimals = 3 ) ) for s in [ x , y , z , a ] ) + <STRING> ) <NEWLINE> out . close ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Writes to a CSV file, but intentionally truncates it\"\"\"", "'.csv'", "'w'", "'x,y,z,a\\n'", "','", "'\\n'"]}}], ["f8ea6a0d152ffe18ebeac9e9d59135b5", {"code_string": "import time\nimport json\nimport sys\nfrom os.path import join, dirname\nfrom cloudify import ctx\nctx.download_resource(\n    join('components', 'utils.py'),\n    join(dirname(__file__), 'utils.py'))\nimport utils\nCONFIG_PATH = \"components/influxdb/config\"\nINFLUX_SERVICE_NAME = 'influxdb'\nctx_properties = utils.ctx_factory.create(INFLUX_SERVICE_NAME)\n", "code_toks_joined": "import time <NEWLINE> import json <NEWLINE> import sys <NEWLINE> from os . path import join , dirname <NEWLINE> from cloudify import ctx <NEWLINE> ctx . download_resource ( <NEWLINE> <INDENT> join ( <STRING> , <STRING> ) , <NEWLINE> join ( dirname ( __file__ ) , <STRING> ) ) <NEWLINE> <DEDENT> import utils <NEWLINE> CONFIG_PATH = <STRING> <NEWLINE> INFLUX_SERVICE_NAME = <STRING> <NEWLINE> ctx_properties = utils . ctx_factory . create ( INFLUX_SERVICE_NAME ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'components'", "'utils.py'", "'utils.py'", "\"components/influxdb/config\"", "'influxdb'"]}}], ["bbfce0f238d587c64d272cc82c009ed9", {"code_string": "class Prob5_Part14:\n    \"\"\"Author: Shen Ting Ang\"\"\"\n    def check_attempt(self, params):\n        self.attempt = params['attempt']\n        self.answer = params['answer']\n        self.att_tree = params['att_tree']\n        self.ans_tree = params['ans_tree']\n        matches = find_matches(params)\n        matching_node = [m[0] for m in matches]\n        try:\n            return 'If X and Y are independent and P(X) = P(Y) = 0.5, what is P(X,Y)?', '0.25'\n        except Exception:\n            return '', ''\n    def get_problems(self):\n        self.problem_list = [\"ExpectationVariance/cov_dep_corr.imd\"]\n        return self.problem_list\n", "code_toks_joined": "class Prob5_Part14 : <NEWLINE> <INDENT> <STRING> <NEWLINE> def check_attempt ( self , params ) : <NEWLINE> <INDENT> self . attempt = params [ <STRING> ] <NEWLINE> self . answer = params [ <STRING> ] <NEWLINE> self . att_tree = params [ <STRING> ] <NEWLINE> self . ans_tree = params [ <STRING> ] <NEWLINE> matches = find_matches ( params ) <NEWLINE> matching_node = [ m [ 0 ] for m in matches ] <NEWLINE> try : <NEWLINE> <INDENT> return <STRING> , <STRING> <NEWLINE> <DEDENT> except Exception : <NEWLINE> <INDENT> return <STRING> , <STRING> <NEWLINE> <DEDENT> <DEDENT> def get_problems ( self ) : <NEWLINE> <INDENT> self . problem_list = [ <STRING> ] <NEWLINE> return self . problem_list <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Author: Shen Ting Ang\"\"\"", "'attempt'", "'answer'", "'att_tree'", "'ans_tree'", "'If X and Y are independent and P(X) = P(Y) = 0.5, what is P(X,Y)?'", "'0.25'", "''", "''", "\"ExpectationVariance/cov_dep_corr.imd\""]}}], ["d6d4698c81239eec5d3da73897e6cc58", {"code_string": "import asyncio\nfrom argparse import Namespace\nfrom protocol.shadowsocks.client import ShadowsocksClientRelayProtocol\nfrom protocol.socks5.header import Socks5AddrHeader\nfrom protocol.socks5.socks5_server import SOCKS5ServerStreamProtocol\n", "code_toks_joined": "import asyncio <NEWLINE> from argparse import Namespace <NEWLINE> from protocol . shadowsocks . client import ShadowsocksClientRelayProtocol <NEWLINE> from protocol . socks5 . header import Socks5AddrHeader <NEWLINE> from protocol . socks5 . socks5_server import SOCKS5ServerStreamProtocol <NEWLINE>", "anonymize_dict": {}}], ["feb1fa3ad50b4919df10a86ac3da38de", {"code_string": "def __get_episode_links(self, video, views, html):\n    pattern = '<h4>(.*?)</h4>(.*?)</ul>'\n    hosters = []\n    for match in re.finditer(pattern, html, re.DOTALL):\n        q_str, fragment = match.groups()\n        hosters += self.__get_links(video, views, fragment, q_str)\n    return hosters\n", "code_toks_joined": "def __get_episode_links ( self , video , views , html ) : <NEWLINE> <INDENT> pattern = <STRING> <NEWLINE> hosters = [ ] <NEWLINE> for match in re . finditer ( pattern , html , re . DOTALL ) : <NEWLINE> <INDENT> q_str , fragment = match . groups ( ) <NEWLINE> hosters += self . __get_links ( video , views , fragment , q_str ) <NEWLINE> <DEDENT> return hosters <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'<h4>(.*?)</h4>(.*?)</ul>'"]}}], ["d49d639c7fbb0e00f0d8d05a5d7f28f1", {"code_string": "import purchase_line_invoice\nimport stock_partial_picking\n", "code_toks_joined": "import purchase_line_invoice <NEWLINE> import stock_partial_picking <NEWLINE>", "anonymize_dict": {}}], ["14c4ee6ac5c33f64d0fd7ff77bc1fe6e", {"code_string": "def save(self, commit = True):\n    user = super(UserEditProfile, self).save(commit = False)\n    user.email = self.cleaned_data[\"email\"]\n    if commit:\n        user.save()\n    return user\n", "code_toks_joined": "def save ( self , commit = True ) : <NEWLINE> <INDENT> user = super ( UserEditProfile , self ) . save ( commit = False ) <NEWLINE> user . email = self . cleaned_data [ <STRING> ] <NEWLINE> if commit : <NEWLINE> <INDENT> user . save ( ) <NEWLINE> <DEDENT> return user <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"email\""]}}], ["32cd260a04e72a40229451510f28396c", {"code_string": "from django.conf.urls import patterns, include, url\nfrom antxetamedia.projects.views import(ProjectList, YearProjectList,\n    ProjectDetail)\nurlpatterns = patterns('',\n    url(r'^$', ProjectList.as_view(), name = 'list'),\n    url(r'^(?P<year>\\d+)/$', YearProjectList.as_view(), name = 'year'),\n    url(r'^(?P<slug>(\\w|\\d|-)+)/$', ProjectDetail.as_view(), name = 'detail'),\n    )\n", "code_toks_joined": "from django . conf . urls import patterns , include , url <NEWLINE> from antxetamedia . projects . views import ( ProjectList , YearProjectList , <NEWLINE> <INDENT> ProjectDetail ) <NEWLINE> <DEDENT> urlpatterns = patterns ( <STRING> , <NEWLINE> <INDENT> url ( <STRING> , ProjectList . as_view ( ) , name = <STRING> ) , <NEWLINE> url ( <STRING> , YearProjectList . as_view ( ) , name = <STRING> ) , <NEWLINE> url ( <STRING> , ProjectDetail . as_view ( ) , name = <STRING> ) , <NEWLINE> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["''", "r'^$'", "'list'", "r'^(?P<year>\\d+)/$'", "'year'", "r'^(?P<slug>(\\w|\\d|-)+)/$'", "'detail'"]}}], ["2886fb56630549b56c89b6916d48640a", {"code_string": "def create_user(self, email, date_of_birth, password = None):\n    \"\"\"Creates and saves a User with the given email, date of\"\"\"\n    if not email:\n        raise ValueError('Users must have an email address')\n    user = self.model(\n        email = MyUserManager.normalize_email(email),\n        date_of_birth = date_of_birth,\n    )\n    user.set_password(password)\n    user.save(using = self._db)\n    return user\n", "code_toks_joined": "def create_user ( self , email , date_of_birth , password = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if not email : <NEWLINE> <INDENT> raise ValueError ( <STRING> ) <NEWLINE> <DEDENT> user = self . model ( <NEWLINE> <INDENT> email = MyUserManager . normalize_email ( email ) , <NEWLINE> date_of_birth = date_of_birth , <NEWLINE> <DEDENT> ) <NEWLINE> user . set_password ( password ) <NEWLINE> user . save ( using = self . _db ) <NEWLINE> return user <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Creates and saves a User with the given email, date of\"\"\"", "'Users must have an email address'"]}}], ["78f4b093cdde2d108a6c27408841c78a", {"code_string": "def header(self, cols, parent_row):\n    \"\"\"Constructs a header row for the csv based on the columns in the table and contents of the parent row\"\"\"\n    out = []\n    for col in cols:\n        if col == 'gau_id':\n            out.append(self.name_for('Geographies', parent_row['geography_id']))\n        elif col == 'oth_1_id':\n            out.append(self.name_for('OtherIndexes', parent_row['other_index_1_id']))\n        elif col == 'oth_2_id':\n            out.append(self.name_for('OtherIndexes', parent_row['other_index_2_id']))\n        else:\n            out.append(col)\n    return out\n", "code_toks_joined": "def header ( self , cols , parent_row ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> out = [ ] <NEWLINE> for col in cols : <NEWLINE> <INDENT> if col == <STRING> : <NEWLINE> <INDENT> out . append ( self . name_for ( <STRING> , parent_row [ <STRING> ] ) ) <NEWLINE> <DEDENT> elif col == <STRING> : <NEWLINE> <INDENT> out . append ( self . name_for ( <STRING> , parent_row [ <STRING> ] ) ) <NEWLINE> <DEDENT> elif col == <STRING> : <NEWLINE> <INDENT> out . append ( self . name_for ( <STRING> , parent_row [ <STRING> ] ) ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> out . append ( col ) <NEWLINE> <DEDENT> <DEDENT> return out <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Constructs a header row for the csv based on the columns in the table and contents of the parent row\"\"\"", "'gau_id'", "'Geographies'", "'geography_id'", "'oth_1_id'", "'OtherIndexes'", "'other_index_1_id'", "'oth_2_id'", "'OtherIndexes'", "'other_index_2_id'"]}}], ["dd43f04d8065511cb38bc57097174357", {"code_string": "class Printer(simplelist.Printer):\n    def __init__(self, name, format = '%(host)s', ** kwargs):\n        super(Printer, self).__init__(name, ** kwargs)\n        self.frmt = format\n    def __repr__(self):\n        '''Not the real representation.'''\n        return '<%s.Printer(%r, %r)>' %(__name__, self.destfile,\n            self.frmt)\n    def print_(self, host, till):\n        self.outf.write(self.frmt %{'host': host, 'till': till} + self.nl)\n", "code_toks_joined": "class Printer ( simplelist . Printer ) : <NEWLINE> <INDENT> def __init__ ( self , name , format = <STRING> , ** kwargs ) : <NEWLINE> <INDENT> super ( Printer , self ) . __init__ ( name , ** kwargs ) <NEWLINE> self . frmt = format <NEWLINE> <DEDENT> def __repr__ ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return <STRING> % ( __name__ , self . destfile , <NEWLINE> <INDENT> self . frmt ) <NEWLINE> <DEDENT> <DEDENT> def print_ ( self , host , till ) : <NEWLINE> <INDENT> self . outf . write ( self . frmt % { <STRING> : host , <STRING> : till } + self . nl ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'%(host)s'", "'''Not the real representation.'''", "'<%s.Printer(%r, %r)>'", "'host'", "'till'"]}}], ["05cfa86f5e4ab2eb418277fe7c1bd9e5", {"code_string": "class c_InternalUseArea(Structure):\n    _fields_ = [\n        (\"format\", c_ubyte),\n        (\"len\", c_int),\n        (\"data\", c_char_p)\n    ]\n", "code_toks_joined": "class c_InternalUseArea ( Structure ) : <NEWLINE> <INDENT> _fields_ = [ <NEWLINE> <INDENT> ( <STRING> , c_ubyte ) , <NEWLINE> ( <STRING> , c_int ) , <NEWLINE> ( <STRING> , c_char_p ) <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"format\"", "\"len\"", "\"data\""]}}], ["b102292e4703cf3a0c1f663d50252353", {"code_string": "import time, shutil\nimport sys, os, string, re\nfrom dict4ini import DictIni\nfrom Karrigell_QuickForm import Karrigell_QuickForm\nqpath = \"q/\"\npubq = qpath + \"easy051201.cfg\"\ncfgf = pubq\ntcode = time.strftime(\"%y%m%d%H%M%S\", time.localtime())\ntcode = time.strftime(\"%y%m%d%H%M%S\", time.localtime())\n", "code_toks_joined": "import time , shutil <NEWLINE> import sys , os , string , re <NEWLINE> from dict4ini import DictIni <NEWLINE> from Karrigell_QuickForm import Karrigell_QuickForm <NEWLINE> qpath = <STRING> <NEWLINE> pubq = qpath + <STRING> <NEWLINE> cfgf = pubq <NEWLINE> tcode = time . strftime ( <STRING> , time . localtime ( ) ) <NEWLINE> tcode = time . strftime ( <STRING> , time . localtime ( ) ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"q/\"", "\"easy051201.cfg\"", "\"%y%m%d%H%M%S\"", "\"%y%m%d%H%M%S\""]}}], ["e8680aa39020f968898ba07359593ac9", {"code_string": "from distutils.core import setup\ndescription = open('README.md').read()\nsetup(name = 'y4m',\n    version = '1.1.1',\n    description = 'YUV4MPEG2 (.y4m) Reader/Writer',\n    author = 'Pierre Gronlier',\n    author_email = 'ticapix@gmail.com',\n    url = 'https://github.com/ticapix/python-y4m',\n    packages = ['y4m'],\n    long_description = description\n    )\n", "code_toks_joined": "from distutils . core import setup <NEWLINE> description = open ( <STRING> ) . read ( ) <NEWLINE> setup ( name = <STRING> , <NEWLINE> <INDENT> version = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> url = <STRING> , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> long_description = description <NEWLINE> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'README.md'", "'y4m'", "'1.1.1'", "'YUV4MPEG2 (.y4m) Reader/Writer'", "'Pierre Gronlier'", "'ticapix@gmail.com'", "'https://github.com/ticapix/python-y4m'", "'y4m'"]}}], ["ef09b41731fd7370ca433dda3e55e7c6", {"code_string": "from nova import db\nfrom nova import exception\nfrom nova import objects\nfrom nova.objects import base\nfrom nova.objects import fields\nfrom nova import utils\n", "code_toks_joined": "from nova import db <NEWLINE> from nova import exception <NEWLINE> from nova import objects <NEWLINE> from nova . objects import base <NEWLINE> from nova . objects import fields <NEWLINE> from nova import utils <NEWLINE>", "anonymize_dict": {}}], ["b5d04557ba9cae41b15e4bb1aceb188a", {"code_string": "def transpile_setup(self):\n    self.add_opcodes(\n        JavaOpcodes.GETSTATIC('org/python/ImportLib', 'modules', 'Ljava/util/Map;'),\n        JavaOpcodes.LDC_W(self.module.descriptor),\n        JavaOpcodes.NEW('org/python/types/Module'),\n        JavaOpcodes.DUP(),\n        JavaOpcodes.LDC_W(self.module.class_name),\n        JavaOpcodes.INVOKESTATIC('java/lang/Class', 'forName', '(Ljava/lang/String;)Ljava/lang/Class;'),\n        JavaOpcodes.INVOKESPECIAL('org/python/types/Module', '<init>', '(Ljava/lang/Class;)V'),\n        JavaOpcodes.INVOKEINTERFACE('java/util/Map', 'put', '(Ljava/lang/Object;Ljava/lang/Object;)Ljava/lang/Object;'),\n        JavaOpcodes.POP()\n    )\n", "code_toks_joined": "def transpile_setup ( self ) : <NEWLINE> <INDENT> self . add_opcodes ( <NEWLINE> <INDENT> JavaOpcodes . GETSTATIC ( <STRING> , <STRING> , <STRING> ) , <NEWLINE> JavaOpcodes . LDC_W ( self . module . descriptor ) , <NEWLINE> JavaOpcodes . NEW ( <STRING> ) , <NEWLINE> JavaOpcodes . DUP ( ) , <NEWLINE> JavaOpcodes . LDC_W ( self . module . class_name ) , <NEWLINE> JavaOpcodes . INVOKESTATIC ( <STRING> , <STRING> , <STRING> ) , <NEWLINE> JavaOpcodes . INVOKESPECIAL ( <STRING> , <STRING> , <STRING> ) , <NEWLINE> JavaOpcodes . INVOKEINTERFACE ( <STRING> , <STRING> , <STRING> ) , <NEWLINE> JavaOpcodes . POP ( ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'org/python/ImportLib'", "'modules'", "'Ljava/util/Map;'", "'org/python/types/Module'", "'java/lang/Class'", "'forName'", "'(Ljava/lang/String;)Ljava/lang/Class;'", "'org/python/types/Module'", "'<init>'", "'(Ljava/lang/Class;)V'", "'java/util/Map'", "'put'", "'(Ljava/lang/Object;Ljava/lang/Object;)Ljava/lang/Object;'"]}}], ["a7121b7b8b1ca645c278de825f276993", {"code_string": "\"\"\"Mock unit tests for the NetApp E-series iscsi driver\"\"\"\nimport mock\nfrom cinder import test\nfrom cinder.tests.volume.drivers.netapp import fakes as na_fakes\nfrom cinder.volume.drivers.netapp.eseries import client as es_client\nfrom cinder.volume.drivers.netapp.eseries import iscsi as es_iscsi\nfrom cinder.volume.drivers.netapp import utils as na_utils\n", "code_toks_joined": "<STRING> <NEWLINE> import mock <NEWLINE> from cinder import test <NEWLINE> from cinder . tests . volume . drivers . netapp import fakes as na_fakes <NEWLINE> from cinder . volume . drivers . netapp . eseries import client as es_client <NEWLINE> from cinder . volume . drivers . netapp . eseries import iscsi as es_iscsi <NEWLINE> from cinder . volume . drivers . netapp import utils as na_utils <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Mock unit tests for the NetApp E-series iscsi driver\"\"\""]}}], ["40cd5ea8aa2b11f329dac61163c34700", {"code_string": "from opus_core.variables.variable import Variable\nfrom variable_functions import my_attribute_label\nfrom urbansim.functions import attribute_label\nfrom numpy import array\n", "code_toks_joined": "from opus_core . variables . variable import Variable <NEWLINE> from variable_functions import my_attribute_label <NEWLINE> from urbansim . functions import attribute_label <NEWLINE> from numpy import array <NEWLINE>", "anonymize_dict": {}}], ["de50cc7ef50c2876910853c2d522f901", {"code_string": "def main():\n    \"\"\"Main\"\"\"\n    app = MouseDetails()\n    app.mainloop()\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> app = MouseDetails ( ) <NEWLINE> app . mainloop ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Main\"\"\""]}}], ["81ac8f457411104b33352bdfe2c395cc", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n    ]\n    operations = [\n        migrations.CreateModel(\n            name = 'People',\n            fields = [\n                ('id', models.AutoField(serialize = False, auto_created = True, primary_key = True, verbose_name = 'ID')),\n                ('name', models.CharField(max_length = 32, verbose_name = '\u540d\u5b57')),\n                ('age', models.IntegerField(verbose_name = '\u5e74\u9f84')),\n            ],\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . CreateModel ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> fields = [ <NEWLINE> <INDENT> ( <STRING> , models . AutoField ( serialize = False , auto_created = True , primary_key = True , verbose_name = <STRING> ) ) , <NEWLINE> ( <STRING> , models . CharField ( max_length = 32 , verbose_name = <STRING> ) ) , <NEWLINE> ( <STRING> , models . IntegerField ( verbose_name = <STRING> ) ) , <NEWLINE> <DEDENT> ] , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'People'", "'id'", "'ID'", "'name'", "'\u540d\u5b57'", "'age'", "'\u5e74\u9f84'"]}}], ["e15f1989563dc9d0132c5d71aba91e4f", {"code_string": "def __init__(self, * args, ** kwargs):\n    \"\"\"Construct the expression engine.\"\"\"\n    super(ExpressionEngine, self).__init__(* args, ** kwargs)\n    self._environment = Environment(self)\n    self._environment.filters.update(builtin_filters)\n    self._register_custom_filters()\n    self._environment.filters['safe'] = self._filter_mark_safe\n    for name, function in self._environment.filters.items():\n        self._environment.filters[name] = self._wrap_jinja_filter(function)\n    self._escape = None\n    self._safe_wrapper = None\n", "code_toks_joined": "def __init__ ( self , * args , ** kwargs ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> super ( ExpressionEngine , self ) . __init__ ( * args , ** kwargs ) <NEWLINE> self . _environment = Environment ( self ) <NEWLINE> self . _environment . filters . update ( builtin_filters ) <NEWLINE> self . _register_custom_filters ( ) <NEWLINE> self . _environment . filters [ <STRING> ] = self . _filter_mark_safe <NEWLINE> for name , function in self . _environment . filters . items ( ) : <NEWLINE> <INDENT> self . _environment . filters [ name ] = self . _wrap_jinja_filter ( function ) <NEWLINE> <DEDENT> self . _escape = None <NEWLINE> self . _safe_wrapper = None <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Construct the expression engine.\"\"\"", "'safe'"]}}], ["7dc4e468f32788e14b52749c2f4f2433", {"code_string": "class Normalizer(BaseEstimator, TransformerMixin):\n    \"\"\"Normalize samples individually to unit norm\"\"\"\n    def __init__(self, norm = 'l2', copy = True):\n        self.norm = norm\n        self.copy = copy\n    def fit(self, X, y = None):\n        \"\"\"Do nothing and return the estimator unchanged\"\"\"\n        return self\n    def transform(self, X, y = None, copy = None):\n        \"\"\"Scale each non zero row of X to unit norm\"\"\"\n        copy = copy if copy is not None else self.copy\n        return normalize(X, norm = self.norm, axis = 1, copy = copy)\n", "code_toks_joined": "class Normalizer ( BaseEstimator , TransformerMixin ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , norm = <STRING> , copy = True ) : <NEWLINE> <INDENT> self . norm = norm <NEWLINE> self . copy = copy <NEWLINE> <DEDENT> def fit ( self , X , y = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self <NEWLINE> <DEDENT> def transform ( self , X , y = None , copy = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> copy = copy if copy is not None else self . copy <NEWLINE> return normalize ( X , norm = self . norm , axis = 1 , copy = copy ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Normalize samples individually to unit norm\"\"\"", "'l2'", "\"\"\"Do nothing and return the estimator unchanged\"\"\"", "\"\"\"Scale each non zero row of X to unit norm\"\"\""]}}], ["2982bf8d59a256948d25bdf53b198122", {"code_string": "def simple_mpi_map(run, args):\n    print('rank: ', rank, 'running..')\n    hypo_set = run(*(args[rank]))\n    global prefix\n    dump(hypo_set, open(prefix + 'hypotheses_' + options.LANG + '_%i' % rank + suffix + \".pkl\", 'w'))\n", "code_toks_joined": "def simple_mpi_map ( run , args ) : <NEWLINE> <INDENT> print ( <STRING> , rank , <STRING> ) <NEWLINE> hypo_set = run ( * ( args [ rank ] ) ) <NEWLINE> global prefix <NEWLINE> dump ( hypo_set , open ( prefix + <STRING> + options . LANG + <STRING> % rank + suffix + <STRING> , <STRING> ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'rank: '", "'running..'", "'hypotheses_'", "'_%i'", "\".pkl\"", "'w'"]}}], ["aa594253ca0d04dacfd124683dddee78", {"code_string": "def test_patch_and_unpatch_method(self):\n    def _list(* args):\n        return list(* args)\n    monkeypatcher = MonkeyPatcher({_list: '__builtin__.set'})\n    self.assertEqual(len(set([1, 2, 1])), 2)\n    monkeypatcher.monkeypatch()\n    self.assertEqual(len(set([1, 2, 1])), 3)\n    monkeypatcher.unpatch()\n    self.assertEqual(len(set([1, 2, 1])), 2)\n", "code_toks_joined": "def test_patch_and_unpatch_method ( self ) : <NEWLINE> <INDENT> def _list ( * args ) : <NEWLINE> <INDENT> return list ( * args ) <NEWLINE> <DEDENT> monkeypatcher = MonkeyPatcher ( { _list : <STRING> } ) <NEWLINE> self . assertEqual ( len ( set ( [ 1 , 2 , 1 ] ) ) , 2 ) <NEWLINE> monkeypatcher . monkeypatch ( ) <NEWLINE> self . assertEqual ( len ( set ( [ 1 , 2 , 1 ] ) ) , 3 ) <NEWLINE> monkeypatcher . unpatch ( ) <NEWLINE> self . assertEqual ( len ( set ( [ 1 , 2 , 1 ] ) ) , 2 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'__builtin__.set'"]}}], ["f8566b73451bc1a01b238899240a9169", {"code_string": "def test_popup_ascii():\n    popup = Popup('Some text.')\n    _id = list(popup.html._children.keys())[0]\n    kw = dict(id = _id,\n        width = '100.0%',\n        height = '100.0%',\n        text = 'Some text.')\n    assert ''.join(popup.html.render().split()) == ''.join(tmpl(** kw).split())\n", "code_toks_joined": "def test_popup_ascii ( ) : <NEWLINE> <INDENT> popup = Popup ( <STRING> ) <NEWLINE> _id = list ( popup . html . _children . keys ( ) ) [ 0 ] <NEWLINE> kw = dict ( id = _id , <NEWLINE> <INDENT> width = <STRING> , <NEWLINE> height = <STRING> , <NEWLINE> text = <STRING> ) <NEWLINE> <DEDENT> assert <STRING> . join ( popup . html . render ( ) . split ( ) ) == <STRING> . join ( tmpl ( ** kw ) . split ( ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Some text.'", "'100.0%'", "'100.0%'", "'Some text.'", "''", "''"]}}], ["939b902eb6cc53aa7baddde172bb92c3", {"code_string": "def serialize(self, include_obsolete = False, raw = False):\n    return self.pipeline(\n        self.tostring(include_obsolete = include_obsolete, raw = raw))\n", "code_toks_joined": "def serialize ( self , include_obsolete = False , raw = False ) : <NEWLINE> <INDENT> return self . pipeline ( <NEWLINE> <INDENT> self . tostring ( include_obsolete = include_obsolete , raw = raw ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["d4583f821b214200b227041458629994", {"code_string": "def train():\n    salary_result = {}\n    train_feature, test_feature, train_id_list, test_id_list, train_tar_list = merge_feature(feature_str)\n    target_list = np.array(train_tar_list)\n    c_feature = train_feature.columns[: ]\n    clf1 = RandomForestClassifier(n_estimators = 200, min_samples_split = 9)\n    clf1.fit(train_feature[c_feature], target_list)\n    preds1 = clf1.predict(test_feature)\n    for j in range(len(preds1)):\n        salary_result[test_id_list[j]] = preds1[j]\n    return salary_result\n", "code_toks_joined": "def train ( ) : <NEWLINE> <INDENT> salary_result = { } <NEWLINE> train_feature , test_feature , train_id_list , test_id_list , train_tar_list = merge_feature ( feature_str ) <NEWLINE> target_list = np . array ( train_tar_list ) <NEWLINE> c_feature = train_feature . columns [ : ] <NEWLINE> clf1 = RandomForestClassifier ( n_estimators = 200 , min_samples_split = 9 ) <NEWLINE> clf1 . fit ( train_feature [ c_feature ] , target_list ) <NEWLINE> preds1 = clf1 . predict ( test_feature ) <NEWLINE> for j in range ( len ( preds1 ) ) : <NEWLINE> <INDENT> salary_result [ test_id_list [ j ] ] = preds1 [ j ] <NEWLINE> <DEDENT> return salary_result <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["c2ea7d61b80b1c5e1d8cc7ef54523a0f", {"code_string": "def do_if(do_then, do_test, do_else):\n    def branch(dv, vv, stack):\n        test_value = stack.pop()\n        if test_value: return 1\n        else: return 1 + len(do_then) + 1\n    def goto(dv, vv, stack):\n        return 1 + len(do_else)\n    return do_test +(branch, ) + do_then +(goto, ) + do_else\n", "code_toks_joined": "def do_if ( do_then , do_test , do_else ) : <NEWLINE> <INDENT> def branch ( dv , vv , stack ) : <NEWLINE> <INDENT> test_value = stack . pop ( ) <NEWLINE> if test_value : return 1 <NEWLINE> else : return 1 + len ( do_then ) + 1 <NEWLINE> <DEDENT> def goto ( dv , vv , stack ) : <NEWLINE> <INDENT> return 1 + len ( do_else ) <NEWLINE> <DEDENT> return do_test + ( branch , ) + do_then + ( goto , ) + do_else <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["4556a5cdaf74bd3a25a89ee7790cef5c", {"code_string": "def cossin(self):\n    \"\"\"return the cos, sin of a vector (dimension 2 only)\"\"\"\n    n = self.norm2()\n    if n == 0.:\n        return 1., 0.\n    n = n ** 0.5\n    p = GeometryPoint(1., 0.)\n    cos = self.scalar(p) / n\n    sin = self.product(p) / n\n    return cos, sin\n", "code_toks_joined": "def cossin ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> n = self . norm2 ( ) <NEWLINE> if n == 0. : <NEWLINE> <INDENT> return 1. , 0. <NEWLINE> <DEDENT> n = n ** 0.5 <NEWLINE> p = GeometryPoint ( 1. , 0. ) <NEWLINE> cos = self . scalar ( p ) / n <NEWLINE> sin = self . product ( p ) / n <NEWLINE> return cos , sin <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"return the cos, sin of a vector (dimension 2 only)\"\"\""]}}], ["c21a052d933f01c2f7f4c0b371452985", {"code_string": "from django import forms\nfrom djforms.core.models import STATE_CHOICES, BINARY_CHOICES\nfrom djforms.biology.genomics.models import PhageHunter\nfrom localflavor.us.forms import USPhoneNumberField, USZipCodeField\n", "code_toks_joined": "from django import forms <NEWLINE> from djforms . core . models import STATE_CHOICES , BINARY_CHOICES <NEWLINE> from djforms . biology . genomics . models import PhageHunter <NEWLINE> from localflavor . us . forms import USPhoneNumberField , USZipCodeField <NEWLINE>", "anonymize_dict": {}}], ["787cba36d78c3fbb9868a5b244eba4b9", {"code_string": "def testInfoBarDisappearByReload(self):\n    \"\"\"Test that Password infobar disappears by the page reload.\"\"\"\n    creds = self.GetPrivateInfo()['test_google_account']\n    test_utils.GoogleAccountsLogin(self, creds['username'], creds['password'])\n    self.PerformActionOnInfobar(\n        'accept', infobar_index = self._GetIndexForSavePasswordInfobar())\n    self.GetBrowserWindow(0).GetTab(0).Reload()\n    self.assertTrue(self.WaitForInfobarCount(0))\n    self.assertFalse(self.GetBrowserInfo()['windows'][0]['tabs'][0]['infobars'])\n", "code_toks_joined": "def testInfoBarDisappearByReload ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> creds = self . GetPrivateInfo ( ) [ <STRING> ] <NEWLINE> test_utils . GoogleAccountsLogin ( self , creds [ <STRING> ] , creds [ <STRING> ] ) <NEWLINE> self . PerformActionOnInfobar ( <NEWLINE> <INDENT> <STRING> , infobar_index = self . _GetIndexForSavePasswordInfobar ( ) ) <NEWLINE> <DEDENT> self . GetBrowserWindow ( 0 ) . GetTab ( 0 ) . Reload ( ) <NEWLINE> self . assertTrue ( self . WaitForInfobarCount ( 0 ) ) <NEWLINE> self . assertFalse ( self . GetBrowserInfo ( ) [ <STRING> ] [ 0 ] [ <STRING> ] [ 0 ] [ <STRING> ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test that Password infobar disappears by the page reload.\"\"\"", "'test_google_account'", "'username'", "'password'", "'accept'", "'windows'", "'tabs'", "'infobars'"]}}], ["65e554f247dc30c370b45516d315d35b", {"code_string": "def stop(self):\n    self.logger.info('Stopping report manager')\n    delete_all_jobs(self.cron)\n", "code_toks_joined": "def stop ( self ) : <NEWLINE> <INDENT> self . logger . info ( <STRING> ) <NEWLINE> delete_all_jobs ( self . cron ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Stopping report manager'"]}}], ["dd4d223e10fd98add23bc2c12b0f9a7f", {"code_string": "def call_ad_extension(self):\n    \"\"\" The call ad extension.\"\"\"\n    return self._ad_extension\n", "code_toks_joined": "def call_ad_extension ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . _ad_extension <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" The call ad extension.\"\"\""]}}], ["f99c5c2bc07be7552c917ba7e56aabd2", {"code_string": "class ConfigOpenNebula:\n    TEMPLATE_CONTEXT = ''\n    TEMPLATE_OTHER = 'GRAPHICS = [type=\"vnc\",listen=\"0.0.0.0\"]'\n    IMAGE_UNAME = ''\n    TTS_URL = 'https://localhost:8443'\n", "code_toks_joined": "class ConfigOpenNebula : <NEWLINE> <INDENT> TEMPLATE_CONTEXT = <STRING> <NEWLINE> TEMPLATE_OTHER = <STRING> <NEWLINE> IMAGE_UNAME = <STRING> <NEWLINE> TTS_URL = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["''", "'GRAPHICS = [type=\"vnc\",listen=\"0.0.0.0\"]'", "''", "'https://localhost:8443'"]}}], ["d471f5610597acb33c2875c7c16b1372", {"code_string": "def angle(self, value):\n    \"\"\" sets the angle \"\"\"\n    self._angle = value\n", "code_toks_joined": "def angle ( self , value ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . _angle = value <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" sets the angle \"\"\""]}}], ["c47c639a060e36ccc19f93772131047c", {"code_string": "def __build_cmd(self, infname, outdir, threads):\n    \"\"\"Build a command-line for makeblastdb\"\"\"\n    cmd = [\"makeblastdb -in\",\n        infname,\n        \"-dbtype nucl\"]\n    self._cmd = ' '.join(cmd)\n", "code_toks_joined": "def __build_cmd ( self , infname , outdir , threads ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> cmd = [ <STRING> , <NEWLINE> <INDENT> infname , <NEWLINE> <STRING> ] <NEWLINE> <DEDENT> self . _cmd = <STRING> . join ( cmd ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Build a command-line for makeblastdb\"\"\"", "\"makeblastdb -in\"", "\"-dbtype nucl\"", "' '"]}}], ["f4156b7bb8fc0eccd39545a6c78b2aa7", {"code_string": "class BasecampOAuth2Adapter(OAuth2Adapter):\n    provider_id = BasecampProvider.id\n    access_token_url = 'https://launchpad.37signals.com/authorization/token?type=web_server'\n    authorize_url = 'https://launchpad.37signals.com/authorization/new'\n    profile_url = 'https://launchpad.37signals.com/authorization.json'\n    def complete_login(self, request, app, token, ** kwargs):\n        headers = {'Authorization': 'Bearer {0}'.format(token.token)}\n        resp = requests.get(self.profile_url, headers = headers)\n        extra_data = resp.json()\n        return self.get_provider().sociallogin_from_response(request,\n            extra_data)\n", "code_toks_joined": "class BasecampOAuth2Adapter ( OAuth2Adapter ) : <NEWLINE> <INDENT> provider_id = BasecampProvider . id <NEWLINE> access_token_url = <STRING> <NEWLINE> authorize_url = <STRING> <NEWLINE> profile_url = <STRING> <NEWLINE> def complete_login ( self , request , app , token , ** kwargs ) : <NEWLINE> <INDENT> headers = { <STRING> : <STRING> . format ( token . token ) } <NEWLINE> resp = requests . get ( self . profile_url , headers = headers ) <NEWLINE> extra_data = resp . json ( ) <NEWLINE> return self . get_provider ( ) . sociallogin_from_response ( request , <NEWLINE> <INDENT> extra_data ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'https://launchpad.37signals.com/authorization/token?type=web_server'", "'https://launchpad.37signals.com/authorization/new'", "'https://launchpad.37signals.com/authorization.json'", "'Authorization'", "'Bearer {0}'"]}}], ["cd7bb8d16b692ec341b55e8cccbc70c0", {"code_string": "def normalize_latent(self, log_p_y_given_x_unnorm):\n    \"\"\"Normalize the latent variable distribution\"\"\"\n    log_z = logsumexp(log_p_y_given_x_unnorm, axis = 2)\n    log_z = log_z.reshape((self.n_hidden, - 1, 1))\n    return np.exp(log_p_y_given_x_unnorm - log_z), log_z\n", "code_toks_joined": "def normalize_latent ( self , log_p_y_given_x_unnorm ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> log_z = logsumexp ( log_p_y_given_x_unnorm , axis = 2 ) <NEWLINE> log_z = log_z . reshape ( ( self . n_hidden , - 1 , 1 ) ) <NEWLINE> return np . exp ( log_p_y_given_x_unnorm - log_z ) , log_z <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Normalize the latent variable distribution\"\"\""]}}], ["dcf66a8bc40cccaa3436d078f8cbe12b", {"code_string": "\"\"\"Test Zenodo Deposit API.\"\"\"\nfrom __future__ import absolute_import, print_function\nfrom copy import deepcopy\nfrom helpers import publish_and_expunge\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import absolute_import , print_function <NEWLINE> from copy import deepcopy <NEWLINE> from helpers import publish_and_expunge <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Test Zenodo Deposit API.\"\"\""]}}], ["a883de31434c7772de59d676b8425802", {"code_string": "\"\"\"Module to manage CRUD operations on saving contributor information\"\"\"\nfrom..import app\nfrom..import utils\nredis_obj = None\nurl = app.config.get('REDIS_CONTRIBUTOR_DB_URL')\nif not url:\n    url = app.config.get('REDISCLOUD_URL')\n    app.logger.debug('Attempting to store hearts with REDISCLOUD_URL')\nelse:\n    app.logger.debug('Attempting to store hearts with REDIS_CONTRIBUTOR_DB_URL')\nif not url:\n    app.logger.warning('No users will be saved, please set REDIS_CONTRIBUTOR_DB_URL or REDISCLOUD_URL environment variable to enable persistent user information.')\nelse:\n    redis_obj = utils.configure_redis_from_url(url)\n    if redis_obj is None:\n        app.logger.warning('No users will be saved, unable to configure redis')\n", "code_toks_joined": "<STRING> <NEWLINE> from . . import app <NEWLINE> from . . import utils <NEWLINE> redis_obj = None <NEWLINE> url = app . config . get ( <STRING> ) <NEWLINE> if not url : <NEWLINE> <INDENT> url = app . config . get ( <STRING> ) <NEWLINE> app . logger . debug ( <STRING> ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> app . logger . debug ( <STRING> ) <NEWLINE> <DEDENT> if not url : <NEWLINE> <INDENT> app . logger . warning ( <STRING> ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> redis_obj = utils . configure_redis_from_url ( url ) <NEWLINE> if redis_obj is None : <NEWLINE> <INDENT> app . logger . warning ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Module to manage CRUD operations on saving contributor information\"\"\"", "'REDIS_CONTRIBUTOR_DB_URL'", "'REDISCLOUD_URL'", "'Attempting to store hearts with REDISCLOUD_URL'", "'Attempting to store hearts with REDIS_CONTRIBUTOR_DB_URL'", "'No users will be saved, please set REDIS_CONTRIBUTOR_DB_URL or REDISCLOUD_URL environment variable to enable persistent user information.'", "'No users will be saved, unable to configure redis'"]}}], ["aad3171ea5dd943525db5392e17a1030", {"code_string": "def feet_to_meters(feet):\n    \"\"\"Converts feet to meters.\"\"\"\n    return feet * 0.3048\n", "code_toks_joined": "def feet_to_meters ( feet ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return feet * 0.3048 <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Converts feet to meters.\"\"\""]}}], ["c0970924790185830ab3a66d5c6e9d35", {"code_string": "class msvs6aTestCase(msvsTestCase):\n    \"\"\"Test MSVS 6 Registry\"\"\"\n    registry = DummyRegistry(regdata_6a + regdata_cv)\n    default_version = '6.0'\n    highest_version = '6.0'\n    number_of_versions = 1\n    install_locs = {\n        '6.0': {'VSINSTALLDIR': 'C:\\\\Program Files\\\\Microsoft Visual Studio\\\\VC98', 'VCINSTALLDIR': 'C:\\\\Program Files\\\\Microsoft Visual Studio\\\\VC98\\\\Bin'},\n        '7.0': {},\n        '7.1': {},\n        '8.0': {},\n        '8.0Exp': {},\n    }\n    default_install_loc = install_locs['6.0']\n", "code_toks_joined": "class msvs6aTestCase ( msvsTestCase ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> registry = DummyRegistry ( regdata_6a + regdata_cv ) <NEWLINE> default_version = <STRING> <NEWLINE> highest_version = <STRING> <NEWLINE> number_of_versions = 1 <NEWLINE> install_locs = { <NEWLINE> <INDENT> <STRING> : { <STRING> : <STRING> , <STRING> : <STRING> } , <NEWLINE> <STRING> : { } , <NEWLINE> <STRING> : { } , <NEWLINE> <STRING> : { } , <NEWLINE> <STRING> : { } , <NEWLINE> <DEDENT> } <NEWLINE> default_install_loc = install_locs [ <STRING> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test MSVS 6 Registry\"\"\"", "'6.0'", "'6.0'", "'6.0'", "'VSINSTALLDIR'", "'C:\\\\Program Files\\\\Microsoft Visual Studio\\\\VC98'", "'VCINSTALLDIR'", "'C:\\\\Program Files\\\\Microsoft Visual Studio\\\\VC98\\\\Bin'", "'7.0'", "'7.1'", "'8.0'", "'8.0Exp'", "'6.0'"]}}], ["b468cba69820432afb8f738d7a9418fc", {"code_string": "def parse_args() -> argparse.Namespace:\n    \"\"\"Parses the Command Line Arguments using argparse\"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"connection\", help = \"The Type of Connection to use\")\n    parser.add_argument(\"-v\", \"--verbose\", action = \"store_true\", help = \"Activates verbose output\")\n    parser.add_argument(\"-d\", \"--debug\", action = \"store_true\", help = \"Activates debug-level logging output\")\n    parser.add_argument(\"-q\", \"--quiet\", action = \"store_true\", help = \"Disables all text output\")\n    parser.add_argument(\"-c\", \"--config\", nargs = \"?\", help = \"Overrides the configuration directory location\")\n    return parser.parse_args()\n", "code_toks_joined": "def parse_args ( ) -> argparse . Namespace : <NEWLINE> <INDENT> <STRING> <NEWLINE> parser = argparse . ArgumentParser ( ) <NEWLINE> parser . add_argument ( <STRING> , help = <STRING> ) <NEWLINE> parser . add_argument ( <STRING> , <STRING> , action = <STRING> , help = <STRING> ) <NEWLINE> parser . add_argument ( <STRING> , <STRING> , action = <STRING> , help = <STRING> ) <NEWLINE> parser . add_argument ( <STRING> , <STRING> , action = <STRING> , help = <STRING> ) <NEWLINE> parser . add_argument ( <STRING> , <STRING> , nargs = <STRING> , help = <STRING> ) <NEWLINE> return parser . parse_args ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Parses the Command Line Arguments using argparse\"\"\"", "\"connection\"", "\"The Type of Connection to use\"", "\"-v\"", "\"--verbose\"", "\"store_true\"", "\"Activates verbose output\"", "\"-d\"", "\"--debug\"", "\"store_true\"", "\"Activates debug-level logging output\"", "\"-q\"", "\"--quiet\"", "\"store_true\"", "\"Disables all text output\"", "\"-c\"", "\"--config\"", "\"?\"", "\"Overrides the configuration directory location\""]}}], ["9573b8ada9551434dd82f224280a0fab", {"code_string": "def get_file_compression(file_name):\n    \"\"\"Return constant that represents compression of a file. The file must be present on disc.\"\"\"\n    if not os.path.isfile(file_name):\n        raise GenestackException('Cannot detect compression of \"%s\", '\n            \"file doesn't exist\" % file_name)\n    return _get_file_compression_unchecked(file_name)\n", "code_toks_joined": "def get_file_compression ( file_name ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if not os . path . isfile ( file_name ) : <NEWLINE> <INDENT> raise GenestackException ( <STRING> <NEWLINE> <INDENT> <STRING> % file_name ) <NEWLINE> <DEDENT> <DEDENT> return _get_file_compression_unchecked ( file_name ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Return constant that represents compression of a file. The file must be present on disc.\"\"\"", "'Cannot detect compression of \"%s\", '", "\"file doesn't exist\""]}}], ["a78eefff3606a083c2b5ce4a50b6d0e7", {"code_string": "'''Created on Aug 8, 2014'''\nimport MySQLdb as mdb\nfrom database import *\nfrom utils import *\nconfig = read_config_file(get_absolute_path(\"config.ini\"))\ncon = get_mysql_con(0, config, debug = False)\nschema = read_config_file(get_absolute_path(\"schema.ini\"))\ntables = schema.sections()\nfor table_name in tables:\n    fields_dict = config_section_map(schema, table_name)\n    create_table(con, table_name, fields_dict, debug = True)\n", "code_toks_joined": "<STRING> <NEWLINE> import MySQLdb as mdb <NEWLINE> from database import * <NEWLINE> from utils import * <NEWLINE> config = read_config_file ( get_absolute_path ( <STRING> ) ) <NEWLINE> con = get_mysql_con ( 0 , config , debug = False ) <NEWLINE> schema = read_config_file ( get_absolute_path ( <STRING> ) ) <NEWLINE> tables = schema . sections ( ) <NEWLINE> for table_name in tables : <NEWLINE> <INDENT> fields_dict = config_section_map ( schema , table_name ) <NEWLINE> create_table ( con , table_name , fields_dict , debug = True ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Created on Aug 8, 2014'''", "\"config.ini\"", "\"schema.ini\""]}}], ["00efd823b05b51a756ce27333384e464", {"code_string": "def check_handshake(self, data):\n    if data[: 20] != BT_HEADER[: 20]:\n        return False\n    if data[28: 48] != self.infohash:\n        return False\n    if data[25] != 16:\n        return False\n    return True\n", "code_toks_joined": "def check_handshake ( self , data ) : <NEWLINE> <INDENT> if data [ : 20 ] != BT_HEADER [ : 20 ] : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> if data [ 28 : 48 ] != self . infohash : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> if data [ 25 ] != 16 : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> return True <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ec35e73b353ed260110927c5796dac5f", {"code_string": "def __str__(self):\n    r = self.powerline.render(\n        width = zsh.columns(),\n        side = self.side,\n        segment_info = {'args': self.args, 'environ': environ}\n    )\n    if type(r) is not str:\n        if type(r) is bytes:\n            return r.decode('utf-8')\n        else:\n            return r.encode('utf-8')\n    return r\n", "code_toks_joined": "def __str__ ( self ) : <NEWLINE> <INDENT> r = self . powerline . render ( <NEWLINE> <INDENT> width = zsh . columns ( ) , <NEWLINE> side = self . side , <NEWLINE> segment_info = { <STRING> : self . args , <STRING> : environ } <NEWLINE> <DEDENT> ) <NEWLINE> if type ( r ) is not str : <NEWLINE> <INDENT> if type ( r ) is bytes : <NEWLINE> <INDENT> return r . decode ( <STRING> ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return r . encode ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT> return r <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'args'", "'environ'", "'utf-8'", "'utf-8'"]}}], ["8559679e40060bbff362ceb0ea44c6ad", {"code_string": "def exp(math_func):\n    if isinstance(math_func, MathFunc):\n        return math_func.op(op = e)\n    else:\n        return e(math_func)\n", "code_toks_joined": "def exp ( math_func ) : <NEWLINE> <INDENT> if isinstance ( math_func , MathFunc ) : <NEWLINE> <INDENT> return math_func . op ( op = e ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return e ( math_func ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["01fbd691730e99cf5cc8a3fb662454ca", {"code_string": "def get_backend():\n    try:\n        backend_class = settings.ADYEN_BACKEND\n    except AttributeError:\n        backend_class = 'django_adyen.backends.SimpleSettingsBackend'\n    return resolve(backend_class)()\n", "code_toks_joined": "def get_backend ( ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> backend_class = settings . ADYEN_BACKEND <NEWLINE> <DEDENT> except AttributeError : <NEWLINE> <INDENT> backend_class = <STRING> <NEWLINE> <DEDENT> return resolve ( backend_class ) ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'django_adyen.backends.SimpleSettingsBackend'"]}}], ["262be06f0e00399da673c59217e6f00c", {"code_string": "def __init__(self, ** kwargs):\n    print(kwargs)\n    self.name = kwargs[\"name\"]\n    self.dir = kwargs[\"dir\"]\n    self.only_the_test_simplesample = True\n", "code_toks_joined": "def __init__ ( self , ** kwargs ) : <NEWLINE> <INDENT> print ( kwargs ) <NEWLINE> self . name = kwargs [ <STRING> ] <NEWLINE> self . dir = kwargs [ <STRING> ] <NEWLINE> self . only_the_test_simplesample = True <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"name\"", "\"dir\""]}}], ["2e2e835732ec2e3df161bb619695649e", {"code_string": "import gtk\nruta = ''\n", "code_toks_joined": "import gtk <NEWLINE> ruta = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["''"]}}], ["07d28e1e27e913f9e87006536e4c4c9a", {"code_string": "def smoke_test_module():\n    unpickable = lambda x: x\n    assert not is_pickable(unpickable)\n    assert is_pickable(1)\n", "code_toks_joined": "def smoke_test_module ( ) : <NEWLINE> <INDENT> unpickable = lambda x : x <NEWLINE> assert not is_pickable ( unpickable ) <NEWLINE> assert is_pickable ( 1 ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["2ad7e97ebbd1a3b2f3f971313268b21a", {"code_string": "class CommentAdmin(TranslationAdmin):\n    \"\"\":class:`Comment` \ubaa8\ub378\uc5d0 \ub300\ud55c \ucee4\uc2a4\ud140 \uc5b4\ub4dc\ubbfc.\"\"\"\n    pass\n", "code_toks_joined": "class CommentAdmin ( TranslationAdmin ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\":class:`Comment` \ubaa8\ub378\uc5d0 \ub300\ud55c \ucee4\uc2a4\ud140 \uc5b4\ub4dc\ubbfc.\"\"\""]}}], ["edbd579e8a419aace652704b8e994bb3", {"code_string": "from __future__ import with_statement\nfrom alembic import context\nfrom sqlalchemy import engine_from_config, pool\nfrom logging.config import fileConfig\nconfig = context.config\nfileConfig(config.config_file_name)\nimport perpetualfailure.db\nimport perpetualfailure.news.models\nimport perpetualfailure.knowledgebase.models\nimport perpetualfailure.authn.user\nimport temporals_web.gmod.models\nimport temporals_web.auth\ntarget_metadata = perpetualfailure.db.Base.metadata\n", "code_toks_joined": "from __future__ import with_statement <NEWLINE> from alembic import context <NEWLINE> from sqlalchemy import engine_from_config , pool <NEWLINE> from logging . config import fileConfig <NEWLINE> config = context . config <NEWLINE> fileConfig ( config . config_file_name ) <NEWLINE> import perpetualfailure . db <NEWLINE> import perpetualfailure . news . models <NEWLINE> import perpetualfailure . knowledgebase . models <NEWLINE> import perpetualfailure . authn . user <NEWLINE> import temporals_web . gmod . models <NEWLINE> import temporals_web . auth <NEWLINE> target_metadata = perpetualfailure . db . Base . metadata <NEWLINE>", "anonymize_dict": {}}], ["addcb323c8dc4e7171a84c122263519b", {"code_string": "import requests\nimport six.moves.http_client as http_client\nfrom st2actions.runners import pythonrunner\n__all__ = [\n    'ListPackagesAction'\n]\nBASE_URL = 'https://%(api_token)s:@packagecloud.io/api/v1/repos/%(repo)s/packages.json'\nMAX_PAGE_NUMBER = 100\n", "code_toks_joined": "import requests <NEWLINE> import six . moves . http_client as http_client <NEWLINE> from st2actions . runners import pythonrunner <NEWLINE> __all__ = [ <NEWLINE> <INDENT> <STRING> <NEWLINE> <DEDENT> ] <NEWLINE> BASE_URL = <STRING> <NEWLINE> MAX_PAGE_NUMBER = 100 <NEWLINE>", "anonymize_dict": {"<STRING>": ["'ListPackagesAction'", "'https://%(api_token)s:@packagecloud.io/api/v1/repos/%(repo)s/packages.json'"]}}], ["9eb8d2c6ed534597b5f4030db8588076", {"code_string": "def get_authors(pr):\n    print(\"getting authors for #%i\" % pr['number'], file = sys.stderr)\n    h = make_auth_header()\n    r = requests.get(pr['commits_url'], headers = h)\n    r.raise_for_status()\n    commits = r.json()\n    authors = []\n    for commit in commits:\n        author = commit['commit']['author']\n        authors.append(\"%s <%s>\" %(author['name'], author['email']))\n    return authors\n", "code_toks_joined": "def get_authors ( pr ) : <NEWLINE> <INDENT> print ( <STRING> % pr [ <STRING> ] , file = sys . stderr ) <NEWLINE> h = make_auth_header ( ) <NEWLINE> r = requests . get ( pr [ <STRING> ] , headers = h ) <NEWLINE> r . raise_for_status ( ) <NEWLINE> commits = r . json ( ) <NEWLINE> authors = [ ] <NEWLINE> for commit in commits : <NEWLINE> <INDENT> author = commit [ <STRING> ] [ <STRING> ] <NEWLINE> authors . append ( <STRING> % ( author [ <STRING> ] , author [ <STRING> ] ) ) <NEWLINE> <DEDENT> return authors <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"getting authors for #%i\"", "'number'", "'commits_url'", "'commit'", "'author'", "\"%s <%s>\"", "'name'", "'email'"]}}], ["4567c857a8f5d894c8bf036123ef1409", {"code_string": "import re\nfrom threading import Lock\nimport crash_utils\nREVIEW_URL_PATTERN = re.compile(r'Review URL:( *)(.*?)/(\\d+)')\n", "code_toks_joined": "import re <NEWLINE> from threading import Lock <NEWLINE> import crash_utils <NEWLINE> REVIEW_URL_PATTERN = re . compile ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["r'Review URL:( *)(.*?)/(\\d+)'"]}}], ["9d832007b4ba07b9966905549b3f794a", {"code_string": "def date_decoder(obj):\n    if '__type__' in obj:\n        if obj['__type__'] == '__date__':\n            return datetime.fromtimestamp(obj['epoc'])\n    return obj\n", "code_toks_joined": "def date_decoder ( obj ) : <NEWLINE> <INDENT> if <STRING> in obj : <NEWLINE> <INDENT> if obj [ <STRING> ] == <STRING> : <NEWLINE> <INDENT> return datetime . fromtimestamp ( obj [ <STRING> ] ) <NEWLINE> <DEDENT> <DEDENT> return obj <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'__type__'", "'__type__'", "'__date__'", "'epoc'"]}}], ["3734d440b9248878ed357256dbede7f7", {"code_string": "import numpy as np\nimport six\nimport warnings\ncoordname = {'G': 'Galactic', 'E': 'Ecliptic', 'C': 'Equatorial'}\n", "code_toks_joined": "import numpy as np <NEWLINE> import six <NEWLINE> import warnings <NEWLINE> coordname = { <STRING> : <STRING> , <STRING> : <STRING> , <STRING> : <STRING> } <NEWLINE>", "anonymize_dict": {"<STRING>": ["'G'", "'Galactic'", "'E'", "'Ecliptic'", "'C'", "'Equatorial'"]}}], ["3a6c77b15ca9288001b9eeebbf823cf7", {"code_string": "def test_page_num_not_int_defaults_to_one(self):\n    request = Mock()\n    request.args = {'page': 'asdf'}\n    request.cookies = {}\n    user = Mock()\n    TASK_ID = 1\n    with self.app.app_context():\n        result = self.vl.task(request, user, TASK_ID)\n    self.ll.get_task_data.assert_called_with(TASK_ID, user,\n        include_deleted = None,\n        include_done = None,\n        page_num = 1, tasks_per_page = 20)\n    self.r.render_template.assert_called()\n", "code_toks_joined": "def test_page_num_not_int_defaults_to_one ( self ) : <NEWLINE> <INDENT> request = Mock ( ) <NEWLINE> request . args = { <STRING> : <STRING> } <NEWLINE> request . cookies = { } <NEWLINE> user = Mock ( ) <NEWLINE> TASK_ID = 1 <NEWLINE> with self . app . app_context ( ) : <NEWLINE> <INDENT> result = self . vl . task ( request , user , TASK_ID ) <NEWLINE> <DEDENT> self . ll . get_task_data . assert_called_with ( TASK_ID , user , <NEWLINE> <INDENT> include_deleted = None , <NEWLINE> include_done = None , <NEWLINE> page_num = 1 , tasks_per_page = 20 ) <NEWLINE> <DEDENT> self . r . render_template . assert_called ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'page'", "'asdf'"]}}], ["6a925e92f6ca2f01f1bd4b7c6f6e24d8", {"code_string": "def delete(self):\n    headers, data = self._requester.requestAndCheck(\n        \"DELETE\",\n        self.url,\n        None,\n        None\n    )\n", "code_toks_joined": "def delete ( self ) : <NEWLINE> <INDENT> headers , data = self . _requester . requestAndCheck ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> self . url , <NEWLINE> None , <NEWLINE> None <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"DELETE\""]}}], ["8592dec019f439c059da959c4ea54eca", {"code_string": "def test_retrieve_activity(self):\n    response = self.client.get(reverse('metrics:sleep-detail', kwargs = {'pk': 1}),\n        format = 'json')\n    self.assertEqual(response.status_code, status.HTTP_200_OK)\n", "code_toks_joined": "def test_retrieve_activity ( self ) : <NEWLINE> <INDENT> response = self . client . get ( reverse ( <STRING> , kwargs = { <STRING> : 1 } ) , <NEWLINE> <INDENT> format = <STRING> ) <NEWLINE> <DEDENT> self . assertEqual ( response . status_code , status . HTTP_200_OK ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'metrics:sleep-detail'", "'pk'", "'json'"]}}], ["7b4501aadb55f7f8639afa603fe7953c", {"code_string": "from pychron.core.ui.factory import toolkit_factory\nLaserStatusEditor = toolkit_factory('laser_status_editor', 'LaserStatusEditor')\n", "code_toks_joined": "from pychron . core . ui . factory import toolkit_factory <NEWLINE> LaserStatusEditor = toolkit_factory ( <STRING> , <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'laser_status_editor'", "'LaserStatusEditor'"]}}], ["8f12b07aee504f2a98dfc2f8c84fb027", {"code_string": "def draw(self, context):\n    layout = self.layout\n    obj = context.object\n    layout.operator_menu_enum(\"object.plasma_modifier_add\", \"types\")\n    modifiers = sorted(obj.plasma_modifiers.modifiers, key = lambda x: x.display_order)\n    for i in modifiers:\n        modLayout = self._draw_modifier_template(i)\n        if i.show_expanded:\n            getattr(modifier_draw, i.pl_id)(i, modLayout, context)\n", "code_toks_joined": "def draw ( self , context ) : <NEWLINE> <INDENT> layout = self . layout <NEWLINE> obj = context . object <NEWLINE> layout . operator_menu_enum ( <STRING> , <STRING> ) <NEWLINE> modifiers = sorted ( obj . plasma_modifiers . modifiers , key = lambda x : x . display_order ) <NEWLINE> for i in modifiers : <NEWLINE> <INDENT> modLayout = self . _draw_modifier_template ( i ) <NEWLINE> if i . show_expanded : <NEWLINE> <INDENT> getattr ( modifier_draw , i . pl_id ) ( i , modLayout , context ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"object.plasma_modifier_add\"", "\"types\""]}}], ["a3f1e73e74312806a9cf73ffaa1e9e64", {"code_string": "from django.conf import settings\nfrom django.db import models\nHOOK_EVENTS = getattr(settings, 'HOOK_EVENTS', None)\nif HOOK_EVENTS is None:\n    raise Exception('You need to define settings.HOOK_EVENTS!')\nAUTH_USER_MODEL = getattr(settings, 'AUTH_USER_MODEL', 'auth.User')\n", "code_toks_joined": "from django . conf import settings <NEWLINE> from django . db import models <NEWLINE> HOOK_EVENTS = getattr ( settings , <STRING> , None ) <NEWLINE> if HOOK_EVENTS is None : <NEWLINE> <INDENT> raise Exception ( <STRING> ) <NEWLINE> <DEDENT> AUTH_USER_MODEL = getattr ( settings , <STRING> , <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'HOOK_EVENTS'", "'You need to define settings.HOOK_EVENTS!'", "'AUTH_USER_MODEL'", "'auth.User'"]}}], ["ca80be1ee46aa279af68e17b99cfb8c7", {"code_string": "def _overwrite_stream(stream: Union[BinaryIO, FileIO], start: int, end: int, data: bytes) -> None:\n    \"\"\"Overwrite data in stream between start and end\"\"\"\n    old_seek = stream.tell()\n    stream.seek(end)\n    previous_data = stream.read()\n    stream.seek(start)\n    stream.truncate()\n    stream.write(b''.join([data, previous_data]))\n    stream.seek(old_seek)\n", "code_toks_joined": "def _overwrite_stream ( stream : Union [ BinaryIO , FileIO ] , start : int , end : int , data : bytes ) -> None : <NEWLINE> <INDENT> <STRING> <NEWLINE> old_seek = stream . tell ( ) <NEWLINE> stream . seek ( end ) <NEWLINE> previous_data = stream . read ( ) <NEWLINE> stream . seek ( start ) <NEWLINE> stream . truncate ( ) <NEWLINE> stream . write ( <STRING> . join ( [ data , previous_data ] ) ) <NEWLINE> stream . seek ( old_seek ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Overwrite data in stream between start and end\"\"\"", "b''"]}}], ["96ce59ed0f7f9dffa08679485ad51144", {"code_string": "def mnemonics_salles(self):\n    \"\"\"Retourne un tuple des mn\u00e9moniques des salles.\"\"\"\n    return tuple(s.mnemonic for s in self.salles.values())\n", "code_toks_joined": "def mnemonics_salles ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return tuple ( s . mnemonic for s in self . salles . values ( ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Retourne un tuple des mn\u00e9moniques des salles.\"\"\""]}}], ["1ed6a70840ae263942e89314388bb642", {"code_string": "def query(self, u, v):\n    \"\"\":returns: the lowest common ancestor of u and v\"\"\"\n    lu = self.last[u]\n    lv = self.last[v]\n    if lu > lv:\n        lu, lv = lv, lu\n    return self.rmq.range_min(lu, lv + 1)[1]\n", "code_toks_joined": "def query ( self , u , v ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> lu = self . last [ u ] <NEWLINE> lv = self . last [ v ] <NEWLINE> if lu > lv : <NEWLINE> <INDENT> lu , lv = lv , lu <NEWLINE> <DEDENT> return self . rmq . range_min ( lu , lv + 1 ) [ 1 ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\":returns: the lowest common ancestor of u and v\"\"\""]}}], ["e113221246692eb757e16b793ba8322d", {"code_string": "from __future__ import unicode_literals\nimport os\nfrom werkzeug.test import Client\nfrom clastic import Application, render_basic, Response\nfrom clastic.middleware.cookie import SignedCookieMiddleware\nfrom clastic.tests.common import cookie_hello_world\n_CUR_DIR = os.path.dirname(os.path.abspath(__file__))\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> import os <NEWLINE> from werkzeug . test import Client <NEWLINE> from clastic import Application , render_basic , Response <NEWLINE> from clastic . middleware . cookie import SignedCookieMiddleware <NEWLINE> from clastic . tests . common import cookie_hello_world <NEWLINE> _CUR_DIR = os . path . dirname ( os . path . abspath ( __file__ ) ) <NEWLINE>", "anonymize_dict": {}}], ["61aa8f33ae64dfac528be7d7b3b3a806", {"code_string": "def tub_ts2():\n    tubts2 = GAL_Cursor.execute('''SELECT''').fetchall()\n    ts2 = tubts2\n    TUB_Cursor.execute('''INSERT OR REPLACE INTO tuberculose (requisicao, data_cadastro, paciente, idade, tipo_idade,''', ts2)\n", "code_toks_joined": "def tub_ts2 ( ) : <NEWLINE> <INDENT> tubts2 = GAL_Cursor . execute ( <STRING> ) . fetchall ( ) <NEWLINE> ts2 = tubts2 <NEWLINE> TUB_Cursor . execute ( <STRING> , ts2 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''SELECT'''", "'''INSERT OR REPLACE INTO tuberculose (requisicao, data_cadastro, paciente, idade, tipo_idade,'''"]}}], ["fb8b756cc4813e46910fddd0ffb4706b", {"code_string": "def _event_unsubscribe(self, packet, _qos, _dup, _retain):\n    LOG.info('Event Unsubscribe received: {} {}'.format(len(packet), packet))\n    messageId = EncodeDecode._decodeValue(packet[: 2])\n    packet = packet[2: ]\n    topics = []\n    while len(packet):\n        topic = EncodeDecode._decodeString(packet)\n        packet = packet[len(topic) + 2: ]\n        topics.append(topic)\n    LOG.info('Mqtt UnSubscribe: {}'.format(topics))\n    self.unsubscribeReceived(topics, messageId)\n", "code_toks_joined": "def _event_unsubscribe ( self , packet , _qos , _dup , _retain ) : <NEWLINE> <INDENT> LOG . info ( <STRING> . format ( len ( packet ) , packet ) ) <NEWLINE> messageId = EncodeDecode . _decodeValue ( packet [ : 2 ] ) <NEWLINE> packet = packet [ 2 : ] <NEWLINE> topics = [ ] <NEWLINE> while len ( packet ) : <NEWLINE> <INDENT> topic = EncodeDecode . _decodeString ( packet ) <NEWLINE> packet = packet [ len ( topic ) + 2 : ] <NEWLINE> topics . append ( topic ) <NEWLINE> <DEDENT> LOG . info ( <STRING> . format ( topics ) ) <NEWLINE> self . unsubscribeReceived ( topics , messageId ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Event Unsubscribe received: {} {}'", "'Mqtt UnSubscribe: {}'"]}}], ["f6c6b3a39f03805a3402f8dc771ab4f4", {"code_string": "'''AppCoordinator module, binds all the elements of the application together.'''\nfrom ui.UserInterface import UserInterface\nfrom controller.HolidayController import HolidayController\nfrom repository.Repository import Repository\n", "code_toks_joined": "<STRING> <NEWLINE> from ui . UserInterface import UserInterface <NEWLINE> from controller . HolidayController import HolidayController <NEWLINE> from repository . Repository import Repository <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''AppCoordinator module, binds all the elements of the application together.'''"]}}], ["825d28a68cdc27418e2bcf18ed32f86a", {"code_string": "from marionette import SkipTest\nimport os\nfrom firefox_puppeteer.api import appinfo\n", "code_toks_joined": "from marionette import SkipTest <NEWLINE> import os <NEWLINE> from firefox_puppeteer . api import appinfo <NEWLINE>", "anonymize_dict": {}}], ["42f0a0b5f830c6c1e0ecf57a7fba8e6e", {"code_string": "import os\nimport sys\nfrom subprocess import call\nif __name__ == \"__main__\":\n    call(\"./scripts/setup.sh\")\n    os.environ[\"DJANGO_SETTINGS_MODULE\"] = \"settings\"\n    from django.core.management import execute_from_command_line\n    execute_from_command_line(sys.argv)\n", "code_toks_joined": "import os <NEWLINE> import sys <NEWLINE> from subprocess import call <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> call ( <STRING> ) <NEWLINE> os . environ [ <STRING> ] = <STRING> <NEWLINE> from django . core . management import execute_from_command_line <NEWLINE> execute_from_command_line ( sys . argv ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"__main__\"", "\"./scripts/setup.sh\"", "\"DJANGO_SETTINGS_MODULE\"", "\"settings\""]}}], ["883d1fbe65ac1f053eb5d083f962d047", {"code_string": "class suite_holder:\n    def __init__(self):\n        self.__suite = unittest.TestSuite();\n    def get_suite(self):\n        return self.__suite;\n    def run(self):\n        return unittest.TextTestRunner(stream = sys.stdout, verbosity = 2).run(self.__suite);\n    @ staticmethod\n    def fill_suite(test_suite):\n        pass;\n", "code_toks_joined": "class suite_holder : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> self . __suite = unittest . TestSuite ( ) ; <NEWLINE> <DEDENT> def get_suite ( self ) : <NEWLINE> <INDENT> return self . __suite ; <NEWLINE> <DEDENT> def run ( self ) : <NEWLINE> <INDENT> return unittest . TextTestRunner ( stream = sys . stdout , verbosity = 2 ) . run ( self . __suite ) ; <NEWLINE> <DEDENT> @ staticmethod <NEWLINE> def fill_suite ( test_suite ) : <NEWLINE> <INDENT> pass ; <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["c83096fd7709bbbf35d156fc4102669e", {"code_string": "import requests\nimport urllib\nfrom pprint import pprint\nimport random\nfrom bs4 import BeautifulSoup\n\"\"\"import ip;ip.test_all('US')\"\"\"\nCOUNTRY = {'US': 'United State',\n    'CA': 'Canada',\n    'CN': 'China',\n    'IN': 'India',\n    'SG': 'Singapore',\n    'SE': 'Sweden',\n    'FR': 'France',\n    'MX': 'Mexico',\n    'BR': 'Brazil',\n    'PL': 'Poland',\n    'DK': 'Denmark',\n    }\nPROXY = {'http': 'socks5://127.0.0.1:1080',\n    'https': 'socks5://127.0.0.1:1080',\n    }\n", "code_toks_joined": "import requests <NEWLINE> import urllib <NEWLINE> from pprint import pprint <NEWLINE> import random <NEWLINE> from bs4 import BeautifulSoup <NEWLINE> <STRING> <NEWLINE> COUNTRY = { <STRING> : <STRING> , <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> } <NEWLINE> <DEDENT> PROXY = { <STRING> : <STRING> , <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"import ip;ip.test_all('US')\"\"\"", "'US'", "'United State'", "'CA'", "'Canada'", "'CN'", "'China'", "'IN'", "'India'", "'SG'", "'Singapore'", "'SE'", "'Sweden'", "'FR'", "'France'", "'MX'", "'Mexico'", "'BR'", "'Brazil'", "'PL'", "'Poland'", "'DK'", "'Denmark'", "'http'", "'socks5://127.0.0.1:1080'", "'https'", "'socks5://127.0.0.1:1080'"]}}], ["4b56c8c2258bd3c4bb99800ebc69818a", {"code_string": "def next(self, doc):\n    ddoc_name, view_name = next(self.view_sequence)\n    params = self.generate_params(** doc)[view_name]\n    params = dict(self.params, ** params)\n    return ddoc_name, view_name, Query(** params)\n", "code_toks_joined": "def next ( self , doc ) : <NEWLINE> <INDENT> ddoc_name , view_name = next ( self . view_sequence ) <NEWLINE> params = self . generate_params ( ** doc ) [ view_name ] <NEWLINE> params = dict ( self . params , ** params ) <NEWLINE> return ddoc_name , view_name , Query ( ** params ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["26ee04a825c96ff9c4bf148c33e176b3", {"code_string": "def handle(self, * args, ** options):\n    self.api = self.get_api()\n    for profile in Profile.objects.all():\n        self.save_user_timeline(profile)\n", "code_toks_joined": "def handle ( self , * args , ** options ) : <NEWLINE> <INDENT> self . api = self . get_api ( ) <NEWLINE> for profile in Profile . objects . all ( ) : <NEWLINE> <INDENT> self . save_user_timeline ( profile ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["654206e32dbbdbaae0751b5a1eeb5049", {"code_string": "def update_logging(self, config):\n    self._config = config\n    self.disable_file_logging()\n    self._logger.setLevel(logging.getLevelName(config.get('logging',\n        'workflow_level')))\n    self._fmlogger.setLevel(logging.getLevelName(config.get('logging',\n        'filemanip_level')))\n    self._iflogger.setLevel(logging.getLevelName(config.get('logging',\n        'interface_level')))\n    if str2bool(config.get('logging', 'log_to_file')):\n        self.enable_file_logging()\n", "code_toks_joined": "def update_logging ( self , config ) : <NEWLINE> <INDENT> self . _config = config <NEWLINE> self . disable_file_logging ( ) <NEWLINE> self . _logger . setLevel ( logging . getLevelName ( config . get ( <STRING> , <NEWLINE> <INDENT> <STRING> ) ) ) <NEWLINE> <DEDENT> self . _fmlogger . setLevel ( logging . getLevelName ( config . get ( <STRING> , <NEWLINE> <INDENT> <STRING> ) ) ) <NEWLINE> <DEDENT> self . _iflogger . setLevel ( logging . getLevelName ( config . get ( <STRING> , <NEWLINE> <INDENT> <STRING> ) ) ) <NEWLINE> <DEDENT> if str2bool ( config . get ( <STRING> , <STRING> ) ) : <NEWLINE> <INDENT> self . enable_file_logging ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'logging'", "'workflow_level'", "'logging'", "'filemanip_level'", "'logging'", "'interface_level'", "'logging'", "'log_to_file'"]}}], ["78994c396003980e7f0109fe928d0655", {"code_string": "def pairs(hand):\n    set_hand = set(hand)\n    number_unique_cards = len(set_hand)\n    pairs = count_pairs(hand)\n    if number_unique_cards == 2:\n        if 4 in pairs:\n            return \"four of a kind\"\n        elif 3 and 2 in pairs:\n            return \"full house\"\n    elif number_unique_cards == 3:\n        if 3 in pairs:\n            return \"trips\"\n        else:\n            return \"two pair\"\n    elif number_unique_cards == 4:\n        return \"pair\"\n    else:\n        return \"no pair\"\n", "code_toks_joined": "def pairs ( hand ) : <NEWLINE> <INDENT> set_hand = set ( hand ) <NEWLINE> number_unique_cards = len ( set_hand ) <NEWLINE> pairs = count_pairs ( hand ) <NEWLINE> if number_unique_cards == 2 : <NEWLINE> <INDENT> if 4 in pairs : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> elif 3 and 2 in pairs : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> <DEDENT> elif number_unique_cards == 3 : <NEWLINE> <INDENT> if 3 in pairs : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> <DEDENT> elif number_unique_cards == 4 : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"four of a kind\"", "\"full house\"", "\"trips\"", "\"two pair\"", "\"pair\"", "\"no pair\""]}}], ["28dfc705b701451838215c3eca0dcfc5", {"code_string": "import json\nimport os\nfrom operator import itemgetter, attrgetter\nimport math\nimport time\na = [1, 2, 3, 4, 5]\nfor i in range(0, len(a)):\n    a.pop()\n    print(i)\n", "code_toks_joined": "import json <NEWLINE> import os <NEWLINE> from operator import itemgetter , attrgetter <NEWLINE> import math <NEWLINE> import time <NEWLINE> a = [ 1 , 2 , 3 , 4 , 5 ] <NEWLINE> for i in range ( 0 , len ( a ) ) : <NEWLINE> <INDENT> a . pop ( ) <NEWLINE> print ( i ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["f3e30ce7a700b0afb07a2d9b4597cc15", {"code_string": "def dead(why):\n    print(why, \"Good Job!\")\n    exit()\n", "code_toks_joined": "def dead ( why ) : <NEWLINE> <INDENT> print ( why , <STRING> ) <NEWLINE> exit ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Good Job!\""]}}], ["559bc01dbae2a58e5c2f266e3754d37d", {"code_string": "def is_dev():\n    if os.environ[\"SERVER_SOFTWARE\"].find(\"Development\") != - 1:\n        return True\n    else:\n        return False\n", "code_toks_joined": "def is_dev ( ) : <NEWLINE> <INDENT> if os . environ [ <STRING> ] . find ( <STRING> ) != - 1 : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"SERVER_SOFTWARE\"", "\"Development\""]}}], ["778921ea60d09c577377ba24f7f9b82e", {"code_string": "def sleep(self):\n    time.sleep(0.1)\n    self.stop()\n", "code_toks_joined": "def sleep ( self ) : <NEWLINE> <INDENT> time . sleep ( 0.1 ) <NEWLINE> self . stop ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["55935a6f0899e8c04985b8d76abf06a8", {"code_string": "def main():\n    data = load_svmlight_file(\"leu\")\n    X_1 = data[0].todense().tolist()\n    y_1 = map(int, data[1])\n    lables = []\n    for i in range(0, len(y_1)):\n        lables = lables +[[y_1[i]]]\n    print(golub(X_1, lables))\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> data = load_svmlight_file ( <STRING> ) <NEWLINE> X_1 = data [ 0 ] . todense ( ) . tolist ( ) <NEWLINE> y_1 = map ( int , data [ 1 ] ) <NEWLINE> lables = [ ] <NEWLINE> for i in range ( 0 , len ( y_1 ) ) : <NEWLINE> <INDENT> lables = lables + [ [ y_1 [ i ] ] ] <NEWLINE> <DEDENT> print ( golub ( X_1 , lables ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"leu\""]}}], ["7af4da4f943ecd18a51feeab54496bde", {"code_string": "def suite():\n    suite = trytond.tests.test_tryton.suite()\n    suite.addTests(unittest.TestLoader().loadTestsFromTestCase(\n        HealthLabTestCase))\n    return suite\n", "code_toks_joined": "def suite ( ) : <NEWLINE> <INDENT> suite = trytond . tests . test_tryton . suite ( ) <NEWLINE> suite . addTests ( unittest . TestLoader ( ) . loadTestsFromTestCase ( <NEWLINE> <INDENT> HealthLabTestCase ) ) <NEWLINE> <DEDENT> return suite <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["6f8b3c163d6275d55595f213f6e56787", {"code_string": "class Command(BaseCommand):\n    help = 'Deletes geodata records that are expired.'\n    def handle(self, * args, ** options):\n        CachedGeodata.objects.all().filter(expires__lte = time.time()).delete()\n", "code_toks_joined": "class Command ( BaseCommand ) : <NEWLINE> <INDENT> help = <STRING> <NEWLINE> def handle ( self , * args , ** options ) : <NEWLINE> <INDENT> CachedGeodata . objects . all ( ) . filter ( expires__lte = time . time ( ) ) . delete ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Deletes geodata records that are expired.'"]}}], ["11b896f78938c500e1920657250bfb77", {"code_string": "def setUpClass(cls):\n    for i in range(1, TestConcurrency.NUM_SOURCE_FILES):\n        shutil.copyfile(\n            os.path.join(ASSETS_DIR, 'concurrency', 'file01.cpp'),\n            os.path.join(ASSETS_DIR, 'concurrency', 'file{:02d}.cpp'.format(i + 1))\n        )\n    cls.sources = []\n    for i in range(1, TestConcurrency.NUM_SOURCE_FILES + 1):\n        cls.sources.append(os.path.join(ASSETS_DIR, 'concurrency', 'file{:02d}.cpp'.format(i)))\n", "code_toks_joined": "def setUpClass ( cls ) : <NEWLINE> <INDENT> for i in range ( 1 , TestConcurrency . NUM_SOURCE_FILES ) : <NEWLINE> <INDENT> shutil . copyfile ( <NEWLINE> <INDENT> os . path . join ( ASSETS_DIR , <STRING> , <STRING> ) , <NEWLINE> os . path . join ( ASSETS_DIR , <STRING> , <STRING> . format ( i + 1 ) ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> cls . sources = [ ] <NEWLINE> for i in range ( 1 , TestConcurrency . NUM_SOURCE_FILES + 1 ) : <NEWLINE> <INDENT> cls . sources . append ( os . path . join ( ASSETS_DIR , <STRING> , <STRING> . format ( i ) ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'concurrency'", "'file01.cpp'", "'concurrency'", "'file{:02d}.cpp'", "'concurrency'", "'file{:02d}.cpp'"]}}], ["e757f147405e9d543de5d1ba0dfd3284", {"code_string": "def plus(x, y):\n    x += 4\n    y = 8\n    print(\"Inside x:\", x)\n    print(\"Inside y:\", y)\n    return\n", "code_toks_joined": "def plus ( x , y ) : <NEWLINE> <INDENT> x += 4 <NEWLINE> y = 8 <NEWLINE> print ( <STRING> , x ) <NEWLINE> print ( <STRING> , y ) <NEWLINE> return <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Inside x:\"", "\"Inside y:\""]}}], ["c3c98c976a87fb192f872782f57d681c", {"code_string": "def __init__(self, * args, ** kwargs):\n    self.client = Http()\n    super(OAuthBaseBackend, self).__init__(* args, ** kwargs)\n", "code_toks_joined": "def __init__ ( self , * args , ** kwargs ) : <NEWLINE> <INDENT> self . client = Http ( ) <NEWLINE> super ( OAuthBaseBackend , self ) . __init__ ( * args , ** kwargs ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["dfcb82338b53ef1739b664ec870e6cb0", {"code_string": "\"\"\"Copyright [2017] [ha62791]\"\"\"\nimport os\nimport fcntl\nimport time\nimport select\nfrom subprocess import Popen, PIPE\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> import fcntl <NEWLINE> import time <NEWLINE> import select <NEWLINE> from subprocess import Popen , PIPE <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Copyright [2017] [ha62791]\"\"\""]}}], ["ce37bd77a3e407fa0e7582d057d71b95", {"code_string": "from django.core.management.base import CommandError\nfrom barbados.barbadosdb import models, tests\nfrom django.conf import settings\nfrom django.db import transaction\nfrom django_docopt_command.command import DocOptCommand\n", "code_toks_joined": "from django . core . management . base import CommandError <NEWLINE> from barbados . barbadosdb import models , tests <NEWLINE> from django . conf import settings <NEWLINE> from django . db import transaction <NEWLINE> from django_docopt_command . command import DocOptCommand <NEWLINE>", "anonymize_dict": {}}], ["16e225f8e77d793e66d1f76b288825a3", {"code_string": "from __future__ import print_function\nimport numpy as np\nimport scipy as sp\nfrom scipy import linalg, optimize, rand\nfrom..base import BaseEstimator, RegressorMixin\nfrom..metrics.pairwise import manhattan_distances\nfrom..utils import check_random_state, check_array, check_X_y\nfrom..utils.validation import check_is_fitted\nfrom.import regression_models as regression\nfrom.import correlation_models as correlation\nMACHINE_EPSILON = np.finfo(np.double).eps\n", "code_toks_joined": "from __future__ import print_function <NEWLINE> import numpy as np <NEWLINE> import scipy as sp <NEWLINE> from scipy import linalg , optimize , rand <NEWLINE> from . . base import BaseEstimator , RegressorMixin <NEWLINE> from . . metrics . pairwise import manhattan_distances <NEWLINE> from . . utils import check_random_state , check_array , check_X_y <NEWLINE> from . . utils . validation import check_is_fitted <NEWLINE> from . import regression_models as regression <NEWLINE> from . import correlation_models as correlation <NEWLINE> MACHINE_EPSILON = np . finfo ( np . double ) . eps <NEWLINE>", "anonymize_dict": {}}], ["1670bf4e8362c0939cc22d91f98062bb", {"code_string": "{\n    'name': 'Account Banking PAIN Base Module',\n    'summary': 'Base module for PAIN file generation',\n    'version': '0.1',\n    'license': 'AGPL-3',\n    'author': 'Akretion, Noviat',\n    'website': 'http://openerp-community-association.org/',\n    'contributors': ['Pedro M. Baeza <pedro.baeza@serviciosbaeza.com>'],\n    'category': 'Hidden',\n    'depends': ['account_banking_payment_export'],\n    'external_dependencies': {\n        'python': ['unidecode', 'lxml'],\n    },\n    'data': [\n        'views/payment_line_view.xml',\n        'views/payment_mode_view.xml',\n        'views/res_company_view.xml',\n    ],\n    'description': '''Base module for PAIN file generation''',\n    'installable': True,\n}\n", "code_toks_joined": "{ <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : [ <STRING> ] , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : [ <STRING> ] , <NEWLINE> <STRING> : { <NEWLINE> <INDENT> <STRING> : [ <STRING> , <STRING> ] , <NEWLINE> <DEDENT> } , <NEWLINE> <STRING> : [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <DEDENT> ] , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : True , <NEWLINE> <DEDENT> } <NEWLINE>", "anonymize_dict": {"<STRING>": ["'name'", "'Account Banking PAIN Base Module'", "'summary'", "'Base module for PAIN file generation'", "'version'", "'0.1'", "'license'", "'AGPL-3'", "'author'", "'Akretion, Noviat'", "'website'", "'http://openerp-community-association.org/'", "'contributors'", "'Pedro M. Baeza <pedro.baeza@serviciosbaeza.com>'", "'category'", "'Hidden'", "'depends'", "'account_banking_payment_export'", "'external_dependencies'", "'python'", "'unidecode'", "'lxml'", "'data'", "'views/payment_line_view.xml'", "'views/payment_mode_view.xml'", "'views/res_company_view.xml'", "'description'", "'''Base module for PAIN file generation'''", "'installable'"]}}], ["a107320321d6094f73e41672f80930f8", {"code_string": "def test_01_03_website(self):\n    url = 'http://cellprofiler.org/CPupdate.html'\n    we_updated = [False]\n    def fn(new_version, info, we_updated = we_updated):\n        we_updated[0] = True\n    vc = cfu.VersionChecker(url, 0, fn,\n        'CellProfiler_unit_test')\n    vc.start()\n    vc.join()\n    self.assertTrue(we_updated[0])\n", "code_toks_joined": "def test_01_03_website ( self ) : <NEWLINE> <INDENT> url = <STRING> <NEWLINE> we_updated = [ False ] <NEWLINE> def fn ( new_version , info , we_updated = we_updated ) : <NEWLINE> <INDENT> we_updated [ 0 ] = True <NEWLINE> <DEDENT> vc = cfu . VersionChecker ( url , 0 , fn , <NEWLINE> <INDENT> <STRING> ) <NEWLINE> <DEDENT> vc . start ( ) <NEWLINE> vc . join ( ) <NEWLINE> self . assertTrue ( we_updated [ 0 ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'http://cellprofiler.org/CPupdate.html'", "'CellProfiler_unit_test'"]}}], ["df49ee1882e91ebdec0d5592e62ef470", {"code_string": "from.import app\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop\nfrom tornado.wsgi import WSGIContainer\nfrom tornado.web import Application, RequestHandler, FallbackHandler\n", "code_toks_joined": "from . import app <NEWLINE> from tornado . httpserver import HTTPServer <NEWLINE> from tornado . ioloop import IOLoop <NEWLINE> from tornado . wsgi import WSGIContainer <NEWLINE> from tornado . web import Application , RequestHandler , FallbackHandler <NEWLINE>", "anonymize_dict": {}}], ["3510156f855c11486ba1bce76654d17f", {"code_string": "import time\nimport unittest\nimport ipv6\nimport node\nimport mle\nimport config\nimport command\nLEADER = 1\nDUT_ROUTER1 = 2\nDUT_REED = 17\n", "code_toks_joined": "import time <NEWLINE> import unittest <NEWLINE> import ipv6 <NEWLINE> import node <NEWLINE> import mle <NEWLINE> import config <NEWLINE> import command <NEWLINE> LEADER = 1 <NEWLINE> DUT_ROUTER1 = 2 <NEWLINE> DUT_REED = 17 <NEWLINE>", "anonymize_dict": {}}], ["cc3625924f95771c0f476a3b73f374fa", {"code_string": "from functools import wraps\nfrom flask import abort\nfrom flask_login import current_user\nfrom app.model import Permission\n", "code_toks_joined": "from functools import wraps <NEWLINE> from flask import abort <NEWLINE> from flask_login import current_user <NEWLINE> from app . model import Permission <NEWLINE>", "anonymize_dict": {}}], ["ee76c9674e9ee3ff7498d94baca97609", {"code_string": "def resolve_path(project_name, file_path, extends):\n    dot_path = get_file_path_by_dot_path(project_name, extends.lower())\n    if dot_path:\n        return dot_path[\"file_path\"]\n    folder_mapping = get_folder_mapping(project_name, file_path)\n    if folder_mapping:\n        full_extends = folder_mapping + \".\" + extends\n        dot_path = get_file_path_by_dot_path(project_name, full_extends.lower())\n        if dot_path:\n            return dot_path[\"file_path\"]\n    return None\n", "code_toks_joined": "def resolve_path ( project_name , file_path , extends ) : <NEWLINE> <INDENT> dot_path = get_file_path_by_dot_path ( project_name , extends . lower ( ) ) <NEWLINE> if dot_path : <NEWLINE> <INDENT> return dot_path [ <STRING> ] <NEWLINE> <DEDENT> folder_mapping = get_folder_mapping ( project_name , file_path ) <NEWLINE> if folder_mapping : <NEWLINE> <INDENT> full_extends = folder_mapping + <STRING> + extends <NEWLINE> dot_path = get_file_path_by_dot_path ( project_name , full_extends . lower ( ) ) <NEWLINE> if dot_path : <NEWLINE> <INDENT> return dot_path [ <STRING> ] <NEWLINE> <DEDENT> <DEDENT> return None <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"file_path\"", "\".\"", "\"file_path\""]}}], ["ec725338223260fc74c500983ef26a2d", {"code_string": "class Vector2:\n    def __init__(self, x = 0, y = 0):\n        self.x = x\n        self.y = y\n    def __str__(self):\n        return \"(%s, %s)\" %(self.x, self.y)\n", "code_toks_joined": "class Vector2 : <NEWLINE> <INDENT> def __init__ ( self , x = 0 , y = 0 ) : <NEWLINE> <INDENT> self . x = x <NEWLINE> self . y = y <NEWLINE> <DEDENT> def __str__ ( self ) : <NEWLINE> <INDENT> return <STRING> % ( self . x , self . y ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"(%s, %s)\""]}}], ["5da30051314c0b00476f023fe5913aa4", {"code_string": "from django.conf.urls import patterns, include, url\nimport views\nurlpatterns = patterns('',\n    url(r'request_rent$', views.request_rent, name = 'request_rent'),\n    url(r'process_rent_request$', views.process_rent_request, name = 'process_rent_req'),\n    url(r'deliver_stock$', views.deliver_stock, name = 'deliver_stock'),\n    url(r'dummy$', views.make_dummy_data, name = 'dummy'),\n)\n", "code_toks_joined": "from django . conf . urls import patterns , include , url <NEWLINE> import views <NEWLINE> urlpatterns = patterns ( <STRING> , <NEWLINE> <INDENT> url ( <STRING> , views . request_rent , name = <STRING> ) , <NEWLINE> url ( <STRING> , views . process_rent_request , name = <STRING> ) , <NEWLINE> url ( <STRING> , views . deliver_stock , name = <STRING> ) , <NEWLINE> url ( <STRING> , views . make_dummy_data , name = <STRING> ) , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["''", "r'request_rent$'", "'request_rent'", "r'process_rent_request$'", "'process_rent_req'", "r'deliver_stock$'", "'deliver_stock'", "r'dummy$'", "'dummy'"]}}], ["0653edcd692264c56179f5fbfc4f26f1", {"code_string": "def __init__(self, api_version = \"1.0\", host = None):\n    super(ApiMethod, self).__init__()\n    if not host:\n        host = \"https://linkfire.com/api/%s\" % api_version\n    self.host = host\n", "code_toks_joined": "def __init__ ( self , api_version = <STRING> , host = None ) : <NEWLINE> <INDENT> super ( ApiMethod , self ) . __init__ ( ) <NEWLINE> if not host : <NEWLINE> <INDENT> host = <STRING> % api_version <NEWLINE> <DEDENT> self . host = host <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"1.0\"", "\"https://linkfire.com/api/%s\""]}}], ["f984d073b8b4fc5033ca01bd39fbea1c", {"code_string": "__revision__ = \"test/scons-time/run/config/initial_commands.py rel_2.5.1:3735:9dc6cee5c168 2016/11/03 14:02:02 bdbaddog\"\n\"\"\"Verify specifying a list of initial commands through a config file.\"\"\"\nimport TestSCons_time\ntest = TestSCons_time.TestSCons_time()\ntest.write_fake_scons_py()\ntest.write_sample_project('foo.tar.gz')\ntest.write('config', \"\"\" def touch(arg):\"\"\" % test.workpath('INITIAL'))\ntest.run(arguments = 'run -f config foo.tar.gz')\ntest.must_exist('foo-000-0.log',\n    'foo-000-0.prof',\n    'foo-000-1.log',\n    'foo-000-1.prof',\n    'foo-000-2.log',\n    'foo-000-2.prof')\ntest.must_exist('INITIAL')\ntest.pass_test()\n", "code_toks_joined": "__revision__ = <STRING> <NEWLINE> <STRING> <NEWLINE> import TestSCons_time <NEWLINE> test = TestSCons_time . TestSCons_time ( ) <NEWLINE> test . write_fake_scons_py ( ) <NEWLINE> test . write_sample_project ( <STRING> ) <NEWLINE> test . write ( <STRING> , <STRING> % test . workpath ( <STRING> ) ) <NEWLINE> test . run ( arguments = <STRING> ) <NEWLINE> test . must_exist ( <STRING> , <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> ) <NEWLINE> <DEDENT> test . must_exist ( <STRING> ) <NEWLINE> test . pass_test ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"test/scons-time/run/config/initial_commands.py rel_2.5.1:3735:9dc6cee5c168 2016/11/03 14:02:02 bdbaddog\"", "\"\"\"Verify specifying a list of initial commands through a config file.\"\"\"", "'foo.tar.gz'", "'config'", "\"\"\" def touch(arg):\"\"\"", "'INITIAL'", "'run -f config foo.tar.gz'", "'foo-000-0.log'", "'foo-000-0.prof'", "'foo-000-1.log'", "'foo-000-1.prof'", "'foo-000-2.log'", "'foo-000-2.prof'", "'INITIAL'"]}}], ["03e2c33ac50cd04c87180e32b724757f", {"code_string": "def is_executable(fpath):\n    \"\"\" Returns True if the fpath is a file executable.\"\"\"\n    return os.path.isfile(fpath) and os.access(fpath, os.X_OK)\n", "code_toks_joined": "def is_executable ( fpath ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return os . path . isfile ( fpath ) and os . access ( fpath , os . X_OK ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Returns True if the fpath is a file executable.\"\"\""]}}], ["4bb2d9bba1b6b5220bf28606845eb39a", {"code_string": "def test_create_rollout_multiple_revision_with_one_resolved(self):\n    expected_logs = \"\"\"Preparing rollout for bug 50000.\"\"\"\n    self.assert_execute_outputs(CreateRollout(), [\"855 852 3001\", \"Reason\"], options = self._default_options(), expected_logs = expected_logs)\n", "code_toks_joined": "def test_create_rollout_multiple_revision_with_one_resolved ( self ) : <NEWLINE> <INDENT> expected_logs = <STRING> <NEWLINE> self . assert_execute_outputs ( CreateRollout ( ) , [ <STRING> , <STRING> ] , options = self . _default_options ( ) , expected_logs = expected_logs ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Preparing rollout for bug 50000.\"\"\"", "\"855 852 3001\"", "\"Reason\""]}}], ["f2088c7ff46e25591de159515b6ceca3", {"code_string": "import sqlalchemy\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\nimport config as appConfig\nengine = create_engine(appConfig.database + '://' + appConfig.db_user + ':' + appConfig.db_password + '@' + appConfig.db_host + '/' + appConfig.db_database_name)\nSession = sessionmaker(bind = engine)\nsession = Session()\n", "code_toks_joined": "import sqlalchemy <NEWLINE> from sqlalchemy import create_engine <NEWLINE> from sqlalchemy . orm import sessionmaker <NEWLINE> import config as appConfig <NEWLINE> engine = create_engine ( appConfig . database + <STRING> + appConfig . db_user + <STRING> + appConfig . db_password + <STRING> + appConfig . db_host + <STRING> + appConfig . db_database_name ) <NEWLINE> Session = sessionmaker ( bind = engine ) <NEWLINE> session = Session ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'://'", "':'", "'@'", "'/'"]}}], ["4a585316e6ccca0fa6ce58777bbf2d91", {"code_string": "def write(self, data):\n    max_bytes_to_write = BLOB_SIZE - self.length - 1\n    done = False\n    if max_bytes_to_write <= len(data):\n        num_bytes_to_write = max_bytes_to_write\n        done = True\n    else:\n        num_bytes_to_write = len(data)\n    self.length += num_bytes_to_write\n    data_to_write = data[: num_bytes_to_write]\n    self.buff += data_to_write\n    self._write_buffer()\n    return done, num_bytes_to_write\n", "code_toks_joined": "def write ( self , data ) : <NEWLINE> <INDENT> max_bytes_to_write = BLOB_SIZE - self . length - 1 <NEWLINE> done = False <NEWLINE> if max_bytes_to_write <= len ( data ) : <NEWLINE> <INDENT> num_bytes_to_write = max_bytes_to_write <NEWLINE> done = True <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> num_bytes_to_write = len ( data ) <NEWLINE> <DEDENT> self . length += num_bytes_to_write <NEWLINE> data_to_write = data [ : num_bytes_to_write ] <NEWLINE> self . buff += data_to_write <NEWLINE> self . _write_buffer ( ) <NEWLINE> return done , num_bytes_to_write <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["8479ccd5d4bc08383072e671dd7d38ba", {"code_string": "__author__ = 'rubico'\nfrom HTMLParser import HTMLParser\nfrom Models.Url import Url\nimport re\n", "code_toks_joined": "__author__ = <STRING> <NEWLINE> from HTMLParser import HTMLParser <NEWLINE> from Models . Url import Url <NEWLINE> import re <NEWLINE>", "anonymize_dict": {"<STRING>": ["'rubico'"]}}], ["d2aed0c2c540bb6329981e89842b8606", {"code_string": "def _ascii_chars(* args, to_chr):\n    for cp in args:\n        if isinstance(cp, int):\n            yield to_chr(cp)\n        else:\n            assert(\n                isinstance(cp, collections.Iterable) and\n                len(cp) == 2)\n            yield from _ascii_range(* cp, to_chr = to_chr)\n", "code_toks_joined": "def _ascii_chars ( * args , to_chr ) : <NEWLINE> <INDENT> for cp in args : <NEWLINE> <INDENT> if isinstance ( cp , int ) : <NEWLINE> <INDENT> yield to_chr ( cp ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> assert ( <NEWLINE> <INDENT> isinstance ( cp , collections . Iterable ) and <NEWLINE> len ( cp ) == 2 ) <NEWLINE> <DEDENT> yield from _ascii_range ( * cp , to_chr = to_chr ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["a86c3fe9802766e2178c26530a7123c9", {"code_string": "def sign_complete(request):\n    user = None\n    try:\n        user = Account.objects.get(id = request.session['user_id'])\n    except:\n        user = None\n    return render(request, 'sign_complete.html', {'user': user})\n", "code_toks_joined": "def sign_complete ( request ) : <NEWLINE> <INDENT> user = None <NEWLINE> try : <NEWLINE> <INDENT> user = Account . objects . get ( id = request . session [ <STRING> ] ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> user = None <NEWLINE> <DEDENT> return render ( request , <STRING> , { <STRING> : user } ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'user_id'", "'sign_complete.html'", "'user'"]}}], ["d64de8e5bb58ad61e20b1958f70fbbfc", {"code_string": "class Tag(models.Model):\n    name = models.CharField(max_length = 200)\n    def __str__(self):\n        return self.name\n", "code_toks_joined": "class Tag ( models . Model ) : <NEWLINE> <INDENT> name = models . CharField ( max_length = 200 ) <NEWLINE> def __str__ ( self ) : <NEWLINE> <INDENT> return self . name <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["caf0584a6812f610907b183e166cad42", {"code_string": "def test_has_html_view_bin_ext(self):\n    blob = M.repository.Blob(MagicMock(), 'INSTALL.zip', 'blob1')\n    assert_equal(blob.has_html_view, False)\n", "code_toks_joined": "def test_has_html_view_bin_ext ( self ) : <NEWLINE> <INDENT> blob = M . repository . Blob ( MagicMock ( ) , <STRING> , <STRING> ) <NEWLINE> assert_equal ( blob . has_html_view , False ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'INSTALL.zip'", "'blob1'"]}}], ["3d05cc6df2e66836ab8480e7f5a32194", {"code_string": "def intercepted_function(raise_error = None):\n    \"\"\"Function used to test the intercept error decorator.\"\"\"\n    if raise_error is not None:\n        raise raise_error\n", "code_toks_joined": "def intercepted_function ( raise_error = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if raise_error is not None : <NEWLINE> <INDENT> raise raise_error <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Function used to test the intercept error decorator.\"\"\""]}}], ["0ff4cadd0fb1fdd06bea18592226312d", {"code_string": "def hexToRaw(hx):\n    raw = binascii.unhexlify(hx);\n    return raw;\n", "code_toks_joined": "def hexToRaw ( hx ) : <NEWLINE> <INDENT> raw = binascii . unhexlify ( hx ) ; <NEWLINE> return raw ; <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["703693bb7d91574d1b6167bd31053262", {"code_string": "def testUserRegisterEvent(self):\n    \"\"\"Test user registration workflow.\"\"\"\n    app = TestApp(application)\n    eventid = self.createPageCommitHelper(app)\n    self.login(LOGGED_IN_USER)\n    response = app.get('/')\n    self.assertEqual('200 OK', response.status)\n    self.assertFalse(TITLE in response)\n    self.userEventEntry(app, eventid)\n    response = app.get('/')\n    self.assertEqual('200 OK', response.status)\n    self.assertTrue(TITLE in response)\n", "code_toks_joined": "def testUserRegisterEvent ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> app = TestApp ( application ) <NEWLINE> eventid = self . createPageCommitHelper ( app ) <NEWLINE> self . login ( LOGGED_IN_USER ) <NEWLINE> response = app . get ( <STRING> ) <NEWLINE> self . assertEqual ( <STRING> , response . status ) <NEWLINE> self . assertFalse ( TITLE in response ) <NEWLINE> self . userEventEntry ( app , eventid ) <NEWLINE> response = app . get ( <STRING> ) <NEWLINE> self . assertEqual ( <STRING> , response . status ) <NEWLINE> self . assertTrue ( TITLE in response ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test user registration workflow.\"\"\"", "'/'", "'200 OK'", "'/'", "'200 OK'"]}}], ["87f7e07ca0b27848da4e5dc1139ffd84", {"code_string": "\"\"\"Trace treadmill application events.\"\"\"\nimport sys\nimport logging\nimport os\nimport subprocess\nimport urllib\nimport click\nfrom treadmill import context\nfrom treadmill import cli\nfrom treadmill import restclient\nfrom treadmill.websocket import client as ws_client\n_LOGGER = logging.getLogger(__name__)\nif sys.platform == 'win32':\n    _DEFAULT_SSH = 'putty.exe'\nelse:\n    _DEFAULT_SSH = 'ssh'\n", "code_toks_joined": "<STRING> <NEWLINE> import sys <NEWLINE> import logging <NEWLINE> import os <NEWLINE> import subprocess <NEWLINE> import urllib <NEWLINE> import click <NEWLINE> from treadmill import context <NEWLINE> from treadmill import cli <NEWLINE> from treadmill import restclient <NEWLINE> from treadmill . websocket import client as ws_client <NEWLINE> _LOGGER = logging . getLogger ( __name__ ) <NEWLINE> if sys . platform == <STRING> : <NEWLINE> <INDENT> _DEFAULT_SSH = <STRING> <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> _DEFAULT_SSH = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Trace treadmill application events.\"\"\"", "'win32'", "'putty.exe'", "'ssh'"]}}], ["a927edf583bdaefe85111c431b1d55b3", {"code_string": "def fspath2url(path):\n    path = os.path.abspath(path)\n    return 'file://' + urllib.pathname2url(path)\n", "code_toks_joined": "def fspath2url ( path ) : <NEWLINE> <INDENT> path = os . path . abspath ( path ) <NEWLINE> return <STRING> + urllib . pathname2url ( path ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'file://'"]}}], ["72fa8d6dc141388a00293a5945e8a0fb", {"code_string": "def loadPlugins(config = {}):\n    import Lib.Applications\n    import Lib.Tasks\n    import Lib.Requirements\n", "code_toks_joined": "def loadPlugins ( config = { } ) : <NEWLINE> <INDENT> import Lib . Applications <NEWLINE> import Lib . Tasks <NEWLINE> import Lib . Requirements <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["e3a5dc94f6672e0969561637aebef3df", {"code_string": "\"\"\"pyetree\"\"\"\n__author__ = \"Josef Grosch\"\n__copyright__ = \"Copyright 2015 - 2016 Moose River, LLC.\"\n__license__ = \"Apache License v2.0\"\n__version__ = \"0.1\"\n__maintainer__ = \"Josef Grosch\"\n__email__ = \"jgrosch@gmail.com\"\n__status__ = \"Development\"\nimport pyetree\nimport pyetree_album\nimport pyetree_artist\nimport pyetree_collection\nimport pyetree_cover\nimport pyetree_genre\nimport pyetree_user\n", "code_toks_joined": "<STRING> <NEWLINE> __author__ = <STRING> <NEWLINE> __copyright__ = <STRING> <NEWLINE> __license__ = <STRING> <NEWLINE> __version__ = <STRING> <NEWLINE> __maintainer__ = <STRING> <NEWLINE> __email__ = <STRING> <NEWLINE> __status__ = <STRING> <NEWLINE> import pyetree <NEWLINE> import pyetree_album <NEWLINE> import pyetree_artist <NEWLINE> import pyetree_collection <NEWLINE> import pyetree_cover <NEWLINE> import pyetree_genre <NEWLINE> import pyetree_user <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"pyetree\"\"\"", "\"Josef Grosch\"", "\"Copyright 2015 - 2016 Moose River, LLC.\"", "\"Apache License v2.0\"", "\"0.1\"", "\"Josef Grosch\"", "\"jgrosch@gmail.com\"", "\"Development\""]}}], ["ad7bb22945ad3a338c1fd4719eac7284", {"code_string": "class TestIserAdmDriver(test_tgt.TestTgtAdmDriver):\n    def setUp(self):\n        super(TestIserAdmDriver, self).setUp()\n        self.configuration.iser_ip_address = '10.9.8.7'\n        self.configuration.iser_target_prefix = 'iqn.2010-10.org.openstack:'\n        self.target = iser.ISERTgtAdm(root_helper = utils.get_root_helper(),\n            configuration = self.configuration)\n", "code_toks_joined": "class TestIserAdmDriver ( test_tgt . TestTgtAdmDriver ) : <NEWLINE> <INDENT> def setUp ( self ) : <NEWLINE> <INDENT> super ( TestIserAdmDriver , self ) . setUp ( ) <NEWLINE> self . configuration . iser_ip_address = <STRING> <NEWLINE> self . configuration . iser_target_prefix = <STRING> <NEWLINE> self . target = iser . ISERTgtAdm ( root_helper = utils . get_root_helper ( ) , <NEWLINE> <INDENT> configuration = self . configuration ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'10.9.8.7'", "'iqn.2010-10.org.openstack:'"]}}], ["e2b3b29571d5225b777307ce645c0772", {"code_string": "def get_results(filename = \"results.yaml\"):\n    \"\"\"Find the results file and return the Manifest instance of it.\"\"\"\n    return manifest.get_manifest(filename)\n", "code_toks_joined": "def get_results ( filename = <STRING> ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return manifest . get_manifest ( filename ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"results.yaml\"", "\"\"\"Find the results file and return the Manifest instance of it.\"\"\""]}}], ["6683033fb1a252b3c74e3e63acfb6d88", {"code_string": "def referencable_models(self):\n    return res_request.referencable_models(\n        self, self.env.cr, self.env.uid, context = self.env.context)\n", "code_toks_joined": "def referencable_models ( self ) : <NEWLINE> <INDENT> return res_request . referencable_models ( <NEWLINE> <INDENT> self , self . env . cr , self . env . uid , context = self . env . context ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["5e3108d95996ae8163cfe7f371924fae", {"code_string": "class MyClient(pyuaf.client.Client):\n    def __init__(self, settings):\n        pyuaf.client.Client.__init__(self, settings)\n        self.noOfSuccessFullyReceivedNotifications = 0\n        self.lock = threading.Lock()\n    def dataChangesReceived(self, notifications):\n        self.lock.acquire()\n        self.noOfSuccessFullyReceivedNotifications += len(notifications)\n        self.lock.release()\n", "code_toks_joined": "class MyClient ( pyuaf . client . Client ) : <NEWLINE> <INDENT> def __init__ ( self , settings ) : <NEWLINE> <INDENT> pyuaf . client . Client . __init__ ( self , settings ) <NEWLINE> self . noOfSuccessFullyReceivedNotifications = 0 <NEWLINE> self . lock = threading . Lock ( ) <NEWLINE> <DEDENT> def dataChangesReceived ( self , notifications ) : <NEWLINE> <INDENT> self . lock . acquire ( ) <NEWLINE> self . noOfSuccessFullyReceivedNotifications += len ( notifications ) <NEWLINE> self . lock . release ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["981455004842e7fae5e9b956236544a2", {"code_string": "import os\nimport subprocess\nimport sys\nimport time\nfrom lib import com_gps\nif not os.getuid() == 0:\n    sys.exit('Needs to be root for running this script.')\nprint('monitoring started')\nutc = ''\nwhile True:\n    gps = com_gps.GPS()\n    utc = gps.gettime()\n    if utc != '':\n        print('Time GPS Fix: ' + str(utc))\n        break\n    else:\n        time.sleep(0.1)\nsubprocess.call(\"timedatectl set-time '\" + str(utc) + \"'\", shell = True)\n", "code_toks_joined": "import os <NEWLINE> import subprocess <NEWLINE> import sys <NEWLINE> import time <NEWLINE> from lib import com_gps <NEWLINE> if not os . getuid ( ) == 0 : <NEWLINE> <INDENT> sys . exit ( <STRING> ) <NEWLINE> <DEDENT> print ( <STRING> ) <NEWLINE> utc = <STRING> <NEWLINE> while True : <NEWLINE> <INDENT> gps = com_gps . GPS ( ) <NEWLINE> utc = gps . gettime ( ) <NEWLINE> if utc != <STRING> : <NEWLINE> <INDENT> print ( <STRING> + str ( utc ) ) <NEWLINE> break <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> time . sleep ( 0.1 ) <NEWLINE> <DEDENT> <DEDENT> subprocess . call ( <STRING> + str ( utc ) + <STRING> , shell = True ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'Needs to be root for running this script.'", "'monitoring started'", "''", "''", "'Time GPS Fix: '", "\"timedatectl set-time '\"", "\"'\""]}}], ["a6ea772a9d68912632b83e8aa42e88d7", {"code_string": "from toscaparser.common.exception import ExceptionCollector\nfrom toscaparser.common.exception import MissingRequiredFieldError\nfrom toscaparser.common.exception import UnknownFieldError\nfrom toscaparser.common.exception import URLException\nfrom toscaparser.utils.gettextutils import _\nimport toscaparser.utils.urlutils\nSECTIONS = (DESCRIPTION, URL, CREDENTIAL) = ('description', 'url', 'credential')\n", "code_toks_joined": "from toscaparser . common . exception import ExceptionCollector <NEWLINE> from toscaparser . common . exception import MissingRequiredFieldError <NEWLINE> from toscaparser . common . exception import UnknownFieldError <NEWLINE> from toscaparser . common . exception import URLException <NEWLINE> from toscaparser . utils . gettextutils import _ <NEWLINE> import toscaparser . utils . urlutils <NEWLINE> SECTIONS = ( DESCRIPTION , URL , CREDENTIAL ) = ( <STRING> , <STRING> , <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'description'", "'url'", "'credential'"]}}], ["42e77dd8b3cd7fe5954366fba42dfc2b", {"code_string": "\"\"\"wiggle_build_index.py - build an index for a wiggle track\"\"\"\nimport psyco_full\nfrom bx.cookbook import doc_optparse\nfrom bx import interval_index_file\nimport bx.wiggle\nimport sys\nimport os.path\nfrom bx.misc.seekbzip2 import SeekableBzip2File\n", "code_toks_joined": "<STRING> <NEWLINE> import psyco_full <NEWLINE> from bx . cookbook import doc_optparse <NEWLINE> from bx import interval_index_file <NEWLINE> import bx . wiggle <NEWLINE> import sys <NEWLINE> import os . path <NEWLINE> from bx . misc . seekbzip2 import SeekableBzip2File <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"wiggle_build_index.py - build an index for a wiggle track\"\"\""]}}], ["a53a81bb20f139858df0b9145407d31e", {"code_string": "import os.path\nimport threading\nimport time\nimport traceback\nfrom mesos.interface.mesos_pb2 import TaskState\nfrom twitter.common import log\nfrom twitter.common.exceptions import ExceptionalThread\nfrom twitter.common.metrics import LambdaGauge\nfrom apache.aurora.common.http_signaler import HttpSignaler\nfrom.status_checker import StatusChecker, StatusCheckerProvider, StatusResult\nfrom.task_info import mesos_task_instance_from_assigned_task, resolve_ports\n", "code_toks_joined": "import os . path <NEWLINE> import threading <NEWLINE> import time <NEWLINE> import traceback <NEWLINE> from mesos . interface . mesos_pb2 import TaskState <NEWLINE> from twitter . common import log <NEWLINE> from twitter . common . exceptions import ExceptionalThread <NEWLINE> from twitter . common . metrics import LambdaGauge <NEWLINE> from apache . aurora . common . http_signaler import HttpSignaler <NEWLINE> from . status_checker import StatusChecker , StatusCheckerProvider , StatusResult <NEWLINE> from . task_info import mesos_task_instance_from_assigned_task , resolve_ports <NEWLINE>", "anonymize_dict": {}}], ["18215a2924f733373529000ea209b481", {"code_string": "def option_processor(a_list):\n    \"\"\" This is almost like the main function of this script. It pretty much\"\"\"\n    processed_dictionary = collections.OrderedDict()\n    for a_pair in a_list:\n        option_title = get_option_title(a_pair[1])\n        if option_title[: 5] == 'Cmake':\n            option_title = option_title[6: ]\n        help_message = a_pair[0].lstrip('//')\n        option_flag = \"%s=\" % get_clean_bool_option(a_pair[1])\n        processed_dictionary[option_title] = [option_flag, help_message]\n    return processed_dictionary\n", "code_toks_joined": "def option_processor ( a_list ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> processed_dictionary = collections . OrderedDict ( ) <NEWLINE> for a_pair in a_list : <NEWLINE> <INDENT> option_title = get_option_title ( a_pair [ 1 ] ) <NEWLINE> if option_title [ : 5 ] == <STRING> : <NEWLINE> <INDENT> option_title = option_title [ 6 : ] <NEWLINE> <DEDENT> help_message = a_pair [ 0 ] . lstrip ( <STRING> ) <NEWLINE> option_flag = <STRING> % get_clean_bool_option ( a_pair [ 1 ] ) <NEWLINE> processed_dictionary [ option_title ] = [ option_flag , help_message ] <NEWLINE> <DEDENT> return processed_dictionary <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" This is almost like the main function of this script. It pretty much\"\"\"", "'Cmake'", "'//'", "\"%s=\""]}}], ["317c9460f001d940f0765115cc1345b2", {"code_string": "def linuxicerik(request, altbaslik):\n    icerikler = icerik.objects.get(altbaslik = altbaslik)\n    return render_to_response(\"linuxicerik.html\", locals(), content_type = RequestContext(request))\n", "code_toks_joined": "def linuxicerik ( request , altbaslik ) : <NEWLINE> <INDENT> icerikler = icerik . objects . get ( altbaslik = altbaslik ) <NEWLINE> return render_to_response ( <STRING> , locals ( ) , content_type = RequestContext ( request ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"linuxicerik.html\""]}}], ["e5822d2bb1ffd546b37c0e0f1861b2f6", {"code_string": "import itertools as itools\nimport unittest\nfrom.import data\nfrom..import engine\nfrom..import events\nfrom..import sequences\nfrom..import streams\n", "code_toks_joined": "import itertools as itools <NEWLINE> import unittest <NEWLINE> from . import data <NEWLINE> from . . import engine <NEWLINE> from . . import events <NEWLINE> from . . import sequences <NEWLINE> from . . import streams <NEWLINE>", "anonymize_dict": {}}], ["82c66ddf4d15ae17a378632c59256325", {"code_string": "def pop(self):\n    maxi = 0\n    for i in range(1, len(self.items)):\n        if self.items[i] < self.items[maxi]:\n            maxi = i\n    item = self.items[maxi]\n    self.items[maxi: maxi + 1] = []\n    return item\n", "code_toks_joined": "def pop ( self ) : <NEWLINE> <INDENT> maxi = 0 <NEWLINE> for i in range ( 1 , len ( self . items ) ) : <NEWLINE> <INDENT> if self . items [ i ] < self . items [ maxi ] : <NEWLINE> <INDENT> maxi = i <NEWLINE> <DEDENT> <DEDENT> item = self . items [ maxi ] <NEWLINE> self . items [ maxi : maxi + 1 ] = [ ] <NEWLINE> return item <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["10e94ec143d23fdcb07d66e03755f1bf", {"code_string": "class UuidField(Field):\n    def display(self, header):\n        value = self._get_value(header)\n        if self.mnemonic:\n            return '%02x%02x%02x%02x-%02x%02x-%02x%02x-%02x%02x-%02x%02x%02x%02x%02x%02x' % tuple([ord(x) for x in value])\n        else:\n            return ''.join([hex(ord(x)) for x in value])\n", "code_toks_joined": "class UuidField ( Field ) : <NEWLINE> <INDENT> def display ( self , header ) : <NEWLINE> <INDENT> value = self . _get_value ( header ) <NEWLINE> if self . mnemonic : <NEWLINE> <INDENT> return <STRING> % tuple ( [ ord ( x ) for x in value ] ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return <STRING> . join ( [ hex ( ord ( x ) ) for x in value ] ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'%02x%02x%02x%02x-%02x%02x-%02x%02x-%02x%02x-%02x%02x%02x%02x%02x%02x'", "''"]}}], ["46b709a668b12c93dcf7438af2e1129e", {"code_string": "from __future__ import print_function\nimport timeit\nimport platform\nimport sys\nimport collections\nimport numpy\n", "code_toks_joined": "from __future__ import print_function <NEWLINE> import timeit <NEWLINE> import platform <NEWLINE> import sys <NEWLINE> import collections <NEWLINE> import numpy <NEWLINE>", "anonymize_dict": {}}], ["d82e9fbdb3d9d222e2cc10d107b8197f", {"code_string": "class Output(object):\n    def __init__(self, braille = True, speech = True):\n        self.braille = braille\n        self.speech = speech\n        self.braille_output = b.brailler.Brailler()\n        self.speech_output = s.speaker.Speaker()\n    def output(self, text):\n        if self.braille:\n            self.braille_output.braille(text)\n        if self.speech:\n            self.speech_output.say(text, interrupt = True)\n", "code_toks_joined": "class Output ( object ) : <NEWLINE> <INDENT> def __init__ ( self , braille = True , speech = True ) : <NEWLINE> <INDENT> self . braille = braille <NEWLINE> self . speech = speech <NEWLINE> self . braille_output = b . brailler . Brailler ( ) <NEWLINE> self . speech_output = s . speaker . Speaker ( ) <NEWLINE> <DEDENT> def output ( self , text ) : <NEWLINE> <INDENT> if self . braille : <NEWLINE> <INDENT> self . braille_output . braille ( text ) <NEWLINE> <DEDENT> if self . speech : <NEWLINE> <INDENT> self . speech_output . say ( text , interrupt = True ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["b77472c5b138a9d488649f0cce854b2c", {"code_string": "\"\"\"Test UpdateCapabilities.\"\"\"\nimport dbus\nfrom twisted.words.xish import xpath, domish\nfrom servicetest import EventPattern\nfrom gabbletest import exec_test, sync_stream\nfrom caps_helper import caps_contain, receive_presence_and_ask_caps, FIXED_CAPS, JINGLE_CAPS, VARIABLE_CAPS, check_caps, disco_caps\nimport constants as cs\nimport ns\n", "code_toks_joined": "<STRING> <NEWLINE> import dbus <NEWLINE> from twisted . words . xish import xpath , domish <NEWLINE> from servicetest import EventPattern <NEWLINE> from gabbletest import exec_test , sync_stream <NEWLINE> from caps_helper import caps_contain , receive_presence_and_ask_caps , FIXED_CAPS , JINGLE_CAPS , VARIABLE_CAPS , check_caps , disco_caps <NEWLINE> import constants as cs <NEWLINE> import ns <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Test UpdateCapabilities.\"\"\""]}}], ["00948f47d3e58fb4fcc66ded043cc990", {"code_string": "def contacts(self, exclude_inactive = True):\n    \"\"\"Get contacts\"\"\"\n    contacts = self._send_request(\n        ContactHelper.URL_CONTACTS_LIST,\n        'GET',\n    )['contacts']\n    return contacts if not exclude_inactive else Helper._filter_inactive(contacts)\n", "code_toks_joined": "def contacts ( self , exclude_inactive = True ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> contacts = self . _send_request ( <NEWLINE> <INDENT> ContactHelper . URL_CONTACTS_LIST , <NEWLINE> <STRING> , <NEWLINE> <DEDENT> ) [ <STRING> ] <NEWLINE> return contacts if not exclude_inactive else Helper . _filter_inactive ( contacts ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Get contacts\"\"\"", "'GET'", "'contacts'"]}}], ["bc1a29769a8666946f0d08384b26dcb8", {"code_string": "from django.conf.urls import url\nfrom spark.courses import views\nurlpatterns = [\n    url(r'^$', views.classes, name = 'classes'),\n    url(r'^(?P<slug>[\\w-]+)/$', views.classe_detail, name = 'classe_detail'),\n    url(r'^(?P<slug>[\\w-]+)/subscribe/$', views.subscribe, name = 'subscribe'),\n    url(r'^(?P<slug>[\\w-]+)/lecture/$', views.lecture, name = 'lecture'),\n    url(r'^(?P<slug>[\\w-]+)/lecture/(?P<pk>\\d+)/$', views.lecture_detail, name = 'lecture_detail'),\n]\n", "code_toks_joined": "from django . conf . urls import url <NEWLINE> from spark . courses import views <NEWLINE> urlpatterns = [ <NEWLINE> <INDENT> url ( <STRING> , views . classes , name = <STRING> ) , <NEWLINE> url ( <STRING> , views . classe_detail , name = <STRING> ) , <NEWLINE> url ( <STRING> , views . subscribe , name = <STRING> ) , <NEWLINE> url ( <STRING> , views . lecture , name = <STRING> ) , <NEWLINE> url ( <STRING> , views . lecture_detail , name = <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["r'^$'", "'classes'", "r'^(?P<slug>[\\w-]+)/$'", "'classe_detail'", "r'^(?P<slug>[\\w-]+)/subscribe/$'", "'subscribe'", "r'^(?P<slug>[\\w-]+)/lecture/$'", "'lecture'", "r'^(?P<slug>[\\w-]+)/lecture/(?P<pk>\\d+)/$'", "'lecture_detail'"]}}], ["ac8330fb18205912fa50ec156941e7f3", {"code_string": "from gaia2 import cvar\nfrom gaia2.classification import ClassificationTaskManager\nimport os, os.path\nimport sys\nimport logging\nfrom optparse import OptionParser\ndebugLevel = logging.INFO\n", "code_toks_joined": "from gaia2 import cvar <NEWLINE> from gaia2 . classification import ClassificationTaskManager <NEWLINE> import os , os . path <NEWLINE> import sys <NEWLINE> import logging <NEWLINE> from optparse import OptionParser <NEWLINE> debugLevel = logging . INFO <NEWLINE>", "anonymize_dict": {}}], ["5d4ebdafe74a51cc73fcfc77d3970706", {"code_string": "from random import choice\nfrom scrapy import signals\nfrom scrapy.exceptions import NotConfigured\n", "code_toks_joined": "from random import choice <NEWLINE> from scrapy import signals <NEWLINE> from scrapy . exceptions import NotConfigured <NEWLINE>", "anonymize_dict": {}}], ["135e21b434bbe3de4cb91e7413e38fbc", {"code_string": "def _resolve_model(future_model, ** kwargs):\n    future_model.poll()\n    return h2o.get_model(future_model.job.dest_key)\n", "code_toks_joined": "def _resolve_model ( future_model , ** kwargs ) : <NEWLINE> <INDENT> future_model . poll ( ) <NEWLINE> return h2o . get_model ( future_model . job . dest_key ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["f788a71802dc5d0d469aaef749645d11", {"code_string": "def registerRtis():\n    registry = RtiRegistry()\n    if '--reset-registry' in sys.argv:\n        registry.deleteSettings()\n    registry.loadOrInitSettings()\n    registry.registerRti('Python File', 'example_plugin.TestFileRti', extensions = ['.py'],\n        pythonPath = SCRIPT_DIR)\n    registry.registerRti('SVG File', 'does_not_exist.svg.SvgFile', extensions = ['.svg'])\n    registry.saveSettings()\n", "code_toks_joined": "def registerRtis ( ) : <NEWLINE> <INDENT> registry = RtiRegistry ( ) <NEWLINE> if <STRING> in sys . argv : <NEWLINE> <INDENT> registry . deleteSettings ( ) <NEWLINE> <DEDENT> registry . loadOrInitSettings ( ) <NEWLINE> registry . registerRti ( <STRING> , <STRING> , extensions = [ <STRING> ] , <NEWLINE> <INDENT> pythonPath = SCRIPT_DIR ) <NEWLINE> <DEDENT> registry . registerRti ( <STRING> , <STRING> , extensions = [ <STRING> ] ) <NEWLINE> registry . saveSettings ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'--reset-registry'", "'Python File'", "'example_plugin.TestFileRti'", "'.py'", "'SVG File'", "'does_not_exist.svg.SvgFile'", "'.svg'"]}}], ["a493c453f7ccfac2d030f3f135a45f4b", {"code_string": "class Follow(db.Model):\n    __tablename__ = 'follows'\n    follower_id = db.Column(db.Integer, db.ForeignKey('users.id'),\n        primary_key = True)\n    followed_id = db.Column(db.Integer, db.ForeignKey('users.id'),\n        primary_key = True)\n    timestamp = db.Column(db.DateTime, default = datetime.now)\n", "code_toks_joined": "class Follow ( db . Model ) : <NEWLINE> <INDENT> __tablename__ = <STRING> <NEWLINE> follower_id = db . Column ( db . Integer , db . ForeignKey ( <STRING> ) , <NEWLINE> <INDENT> primary_key = True ) <NEWLINE> <DEDENT> followed_id = db . Column ( db . Integer , db . ForeignKey ( <STRING> ) , <NEWLINE> <INDENT> primary_key = True ) <NEWLINE> <DEDENT> timestamp = db . Column ( db . DateTime , default = datetime . now ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'follows'", "'users.id'", "'users.id'"]}}], ["de817d257eb28291b53a77436d2c7749", {"code_string": "def chassis_reset(self):\n    \"\"\"Gets the chassis_reset of this Chassis100ChassisActions.\"\"\"\n    return self._chassis_reset\n", "code_toks_joined": "def chassis_reset ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . _chassis_reset <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Gets the chassis_reset of this Chassis100ChassisActions.\"\"\""]}}], ["23bb2eec90d1f038b6f9100c0c97f614", {"code_string": "class MeridionalPatch(object):\n    \"\"\"Abstract base class for defining meridional flowfield.  When called as a\"\"\"\n    def __init__(self):\n        assert False\n    def __call__(self, m, s):\n        assert False\n", "code_toks_joined": "class MeridionalPatch ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self ) : <NEWLINE> <INDENT> assert False <NEWLINE> <DEDENT> def __call__ ( self , m , s ) : <NEWLINE> <INDENT> assert False <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Abstract base class for defining meridional flowfield.  When called as a\"\"\""]}}], ["b8833d2a693807e20b3aa571e5103fe8", {"code_string": "from django.core.paginator import Paginator, PageNotAnInteger, EmptyPage\nfrom django.http import Http404\nfrom django.shortcuts import render\nfrom django.conf import settings\nfrom blogs.models import Blog, Category\n", "code_toks_joined": "from django . core . paginator import Paginator , PageNotAnInteger , EmptyPage <NEWLINE> from django . http import Http404 <NEWLINE> from django . shortcuts import render <NEWLINE> from django . conf import settings <NEWLINE> from blogs . models import Blog , Category <NEWLINE>", "anonymize_dict": {}}], ["bc7212f71e33d76f4ddd45711fe204b9", {"code_string": "class ICategoryMetadataFossil(IFossil):\n    def getId(self):\n        pass\n    def getName(self):\n        pass\n    def getLocator(self):\n        pass\n    getLocator.convert = Conversion.url(urlHandlers.UHCategoryDisplay)\n    getLocator.name = 'url'\n", "code_toks_joined": "class ICategoryMetadataFossil ( IFossil ) : <NEWLINE> <INDENT> def getId ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def getName ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def getLocator ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> getLocator . convert = Conversion . url ( urlHandlers . UHCategoryDisplay ) <NEWLINE> getLocator . name = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'url'"]}}], ["8f77ccea7c8af7d5e5a932d6a18891df", {"code_string": "def render(self):\n    self.render_start()\n    self.render_contents()\n    self.render_stop()\n", "code_toks_joined": "def render ( self ) : <NEWLINE> <INDENT> self . render_start ( ) <NEWLINE> self . render_contents ( ) <NEWLINE> self . render_stop ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ec9778aaa2f55629e7fd7c4f3353312a", {"code_string": "def test_compress():\n    data = 'hello'\n    assert compress.decompress(compress.compress(data)) == data\n", "code_toks_joined": "def test_compress ( ) : <NEWLINE> <INDENT> data = <STRING> <NEWLINE> assert compress . decompress ( compress . compress ( data ) ) == data <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'hello'"]}}], ["bc43831964e81a77b85eb0d6a993a55f", {"code_string": "def get_device_number(mountpoint):\n    device_number = mountpoint_to_number(mountpoint)\n    if device_number < 0:\n        raise StorageError(_('Unable to obtain target information %s') %\n            mountpoint)\n    return device_number\n", "code_toks_joined": "def get_device_number ( mountpoint ) : <NEWLINE> <INDENT> device_number = mountpoint_to_number ( mountpoint ) <NEWLINE> if device_number < 0 : <NEWLINE> <INDENT> raise StorageError ( _ ( <STRING> ) % <NEWLINE> <INDENT> mountpoint ) <NEWLINE> <DEDENT> <DEDENT> return device_number <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Unable to obtain target information %s'"]}}], ["17b6b8d0586288a1833aaff4963d1195", {"code_string": "class Vorlage(models.Model):\n    \"\"\"Hier werden alle angezeigten Texte gespeichert, damit sie nicht fest in den\"\"\"\n    token = models.SlugField(\n        unique = True,\n        null = False,\n        blank = False,\n        help_text = 'Das K\u00fcrzel, \u00fcber das die Vorlage im Code angesprochen wird.'\n    )\n    text = models.TextField(\n        null = False,\n        blank = True,\n        default = '',\n        help_text = \"\"\"Der eigentliche Text der Vorlage, der angezeigt wird.\"\"\"\n    )\n    class Meta:\n        verbose_name = 'Vorlage'\n        verbose_name_plural = 'Vorlagen'\n    def __str__(self):\n        return self.token\n", "code_toks_joined": "class Vorlage ( models . Model ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> token = models . SlugField ( <NEWLINE> <INDENT> unique = True , <NEWLINE> null = False , <NEWLINE> blank = False , <NEWLINE> help_text = <STRING> <NEWLINE> <DEDENT> ) <NEWLINE> text = models . TextField ( <NEWLINE> <INDENT> null = False , <NEWLINE> blank = True , <NEWLINE> default = <STRING> , <NEWLINE> help_text = <STRING> <NEWLINE> <DEDENT> ) <NEWLINE> class Meta : <NEWLINE> <INDENT> verbose_name = <STRING> <NEWLINE> verbose_name_plural = <STRING> <NEWLINE> <DEDENT> def __str__ ( self ) : <NEWLINE> <INDENT> return self . token <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Hier werden alle angezeigten Texte gespeichert, damit sie nicht fest in den\"\"\"", "'Das K\u00fcrzel, \u00fcber das die Vorlage im Code angesprochen wird.'", "''", "\"\"\"Der eigentliche Text der Vorlage, der angezeigt wird.\"\"\"", "'Vorlage'", "'Vorlagen'"]}}], ["b7ec3385f5d73405015778f61450f17f", {"code_string": "def owls_python_version_check():\n    \"\"\"Checks that the current version of Python is supported by OWLS packages,\"\"\"\n    python_version = version_info[0: 2]\n    supported_python_versions = (\n        (2, 7),\n        (3, 3),\n        (3, 4),\n    )\n    if python_version not in supported_python_versions:\n        exit('unsupported Python version')\n", "code_toks_joined": "def owls_python_version_check ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> python_version = version_info [ 0 : 2 ] <NEWLINE> supported_python_versions = ( <NEWLINE> <INDENT> ( 2 , 7 ) , <NEWLINE> ( 3 , 3 ) , <NEWLINE> ( 3 , 4 ) , <NEWLINE> <DEDENT> ) <NEWLINE> if python_version not in supported_python_versions : <NEWLINE> <INDENT> exit ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Checks that the current version of Python is supported by OWLS packages,\"\"\"", "'unsupported Python version'"]}}], ["63e1794fbd933ff0eabd417576a23b52", {"code_string": "\"\"\"My solution to a challenge by Fogcreek.\"\"\"\nfrom __future__ import print_function\nimport argparse\nVERBOSE = False\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import print_function <NEWLINE> import argparse <NEWLINE> VERBOSE = False <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"My solution to a challenge by Fogcreek.\"\"\""]}}], ["97e8a9ed5e80a98af9d93c42fe53aaae", {"code_string": "def can_configure(self, cluster):\n    \"\"\"Optional callback invoked before configuration. Throwing an exception in here will gracefully prevent\"\"\"\n    pass\n", "code_toks_joined": "def can_configure ( self , cluster ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Optional callback invoked before configuration. Throwing an exception in here will gracefully prevent\"\"\""]}}], ["0b2bb43923b44767ad6d33e0f8a01769", {"code_string": "def _make_path(path):\n    if path is None:\n        return[]\n    return path\n", "code_toks_joined": "def _make_path ( path ) : <NEWLINE> <INDENT> if path is None : <NEWLINE> <INDENT> return [ ] <NEWLINE> <DEDENT> return path <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["f439cd7e4e1c3668b45b27e2072319da", {"code_string": "from vumi.transports.vumi_bridge.vumi_bridge import GoConversationTransport\n__all__ = [\n    'GoConversationTransport',\n]\n", "code_toks_joined": "from vumi . transports . vumi_bridge . vumi_bridge import GoConversationTransport <NEWLINE> __all__ = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'GoConversationTransport'"]}}], ["1753e7c5eddf014eef0e2d2b9158b761", {"code_string": "class GalleryItemInline(admin.StackedInline):\n    model = GalleryItem\n    extra = 0\n    sortable_field_name = 'order'\n", "code_toks_joined": "class GalleryItemInline ( admin . StackedInline ) : <NEWLINE> <INDENT> model = GalleryItem <NEWLINE> extra = 0 <NEWLINE> sortable_field_name = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'order'"]}}], ["e585404b80773ff5f4e065b81301fdb9", {"code_string": "def container_style(request):\n    classname = 'container'\n    if getattr(settings, 'ASU_THEME_FLUID', False):\n        classname += '-fluid'\n    return{'asutheme_container_class': classname}\n", "code_toks_joined": "def container_style ( request ) : <NEWLINE> <INDENT> classname = <STRING> <NEWLINE> if getattr ( settings , <STRING> , False ) : <NEWLINE> <INDENT> classname += <STRING> <NEWLINE> <DEDENT> return { <STRING> : classname } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'container'", "'ASU_THEME_FLUID'", "'-fluid'", "'asutheme_container_class'"]}}], ["4679b112a701537ad654bc04d53b6af5", {"code_string": "import os\nimport netifaces\nimport re\nimport logging\nfrom mss.agent.managers.translation import TranslationManager\n_ = TranslationManager().translate\n", "code_toks_joined": "import os <NEWLINE> import netifaces <NEWLINE> import re <NEWLINE> import logging <NEWLINE> from mss . agent . managers . translation import TranslationManager <NEWLINE> _ = TranslationManager ( ) . translate <NEWLINE>", "anonymize_dict": {}}], ["61a4194d8a198f81d3a879416095f236", {"code_string": "class Boolean(Base):\n    \"\"\"expect(true).to.be.true()\"\"\"\n    def matches(self):\n        return self.actual is True\n    @ property\n    def explanation(self):\n        return Explanation(self.actual, self.is_negative, 'be True', negative_action = 'be False')\n", "code_toks_joined": "class Boolean ( Base ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def matches ( self ) : <NEWLINE> <INDENT> return self . actual is True <NEWLINE> <DEDENT> @ property <NEWLINE> def explanation ( self ) : <NEWLINE> <INDENT> return Explanation ( self . actual , self . is_negative , <STRING> , negative_action = <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"expect(true).to.be.true()\"\"\"", "'be True'", "'be False'"]}}], ["362a36069eb997d9a8823c75c8aa0c72", {"code_string": "class HttpGetError(urllib2.HTTPError):\n    def __init__(self, url, code, msg, hdrs, fp):\n        self.url = url\n        self.code = code\n        self.msg = msg\n        self.hdrs = hdrs\n        self.fp = fp\n    def __str__(self):\n        return 'HTTP error: <%s>: %s (%s).' %(self.url, self.msg, self.code)\n", "code_toks_joined": "class HttpGetError ( urllib2 . HTTPError ) : <NEWLINE> <INDENT> def __init__ ( self , url , code , msg , hdrs , fp ) : <NEWLINE> <INDENT> self . url = url <NEWLINE> self . code = code <NEWLINE> self . msg = msg <NEWLINE> self . hdrs = hdrs <NEWLINE> self . fp = fp <NEWLINE> <DEDENT> def __str__ ( self ) : <NEWLINE> <INDENT> return <STRING> % ( self . url , self . msg , self . code ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'HTTP error: <%s>: %s (%s).'"]}}], ["d07fb4dab3ec24ea5d2915bb13fc0d33", {"code_string": "class FeedbackService(object):\n    FEEDBACK_URL = os.environ.get('FEEDBACK_URL')\n    def __init__(self, leap_session):\n        self.leap_session = leap_session\n    def open_ticket(self, feedback):\n        account_mail = self.leap_session.account_email()\n        data = {\n            \"ticket[comments_attributes][0][body]\": feedback,\n            \"ticket[subject]\": \"Feedback user-agent from {0}\".format(account_mail),\n            \"ticket[email]\": account_mail,\n            \"ticket[regarding_user]\": account_mail\n        }\n        return requests.post(self.FEEDBACK_URL, data = data, verify = False)\n", "code_toks_joined": "class FeedbackService ( object ) : <NEWLINE> <INDENT> FEEDBACK_URL = os . environ . get ( <STRING> ) <NEWLINE> def __init__ ( self , leap_session ) : <NEWLINE> <INDENT> self . leap_session = leap_session <NEWLINE> <DEDENT> def open_ticket ( self , feedback ) : <NEWLINE> <INDENT> account_mail = self . leap_session . account_email ( ) <NEWLINE> data = { <NEWLINE> <INDENT> <STRING> : feedback , <NEWLINE> <STRING> : <STRING> . format ( account_mail ) , <NEWLINE> <STRING> : account_mail , <NEWLINE> <STRING> : account_mail <NEWLINE> <DEDENT> } <NEWLINE> return requests . post ( self . FEEDBACK_URL , data = data , verify = False ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'FEEDBACK_URL'", "\"ticket[comments_attributes][0][body]\"", "\"ticket[subject]\"", "\"Feedback user-agent from {0}\"", "\"ticket[email]\"", "\"ticket[regarding_user]\""]}}], ["d66318c031678f91490b113a3cac1cc5", {"code_string": "from __future__ import print_function\nimport random\nfrom time import time\nfrom uuid import uuid4\nfrom zerograph import Graph, Batch\ngraph = None\n", "code_toks_joined": "from __future__ import print_function <NEWLINE> import random <NEWLINE> from time import time <NEWLINE> from uuid import uuid4 <NEWLINE> from zerograph import Graph , Batch <NEWLINE> graph = None <NEWLINE>", "anonymize_dict": {}}], ["95f6f9d273bd3c5c3973e0703ba916f2", {"code_string": "class WebSocketTimeoutException(WebSocketException):\n    \"\"\"WebSocketTimeoutException will be raised at socket timeout during read/write data.\"\"\"\n    pass\n", "code_toks_joined": "class WebSocketTimeoutException ( WebSocketException ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"WebSocketTimeoutException will be raised at socket timeout during read/write data.\"\"\""]}}], ["b13f88261e44528bc0e3bc3feee2ce1b", {"code_string": "import main\nmain.main()\nimport os\nos._exit(0)\n", "code_toks_joined": "import main <NEWLINE> main . main ( ) <NEWLINE> import os <NEWLINE> os . _exit ( 0 ) <NEWLINE>", "anonymize_dict": {}}], ["f3f9e1ae85e46f3891a988e1ca77b34c", {"code_string": "from ggrc import db\nfrom ggrc.models import CustomAttributeDefinition\nfrom ggrc.utils import underscore_from_camelcase\n", "code_toks_joined": "from ggrc import db <NEWLINE> from ggrc . models import CustomAttributeDefinition <NEWLINE> from ggrc . utils import underscore_from_camelcase <NEWLINE>", "anonymize_dict": {}}], ["e05a3d6eb3d3c9e5961b870ae6d3f5f3", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('sos', '0015_auto_20170730_1010'),\n    ]\n    operations = [\n        migrations.AddField(\n            model_name = 'invoice',\n            name = 'additional_address',\n            field = models.CharField(default = 0, max_length = 1),\n            preserve_default = False,\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . AddField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . CharField ( default = 0 , max_length = 1 ) , <NEWLINE> preserve_default = False , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'sos'", "'0015_auto_20170730_1010'", "'invoice'", "'additional_address'"]}}], ["4e94e55732ae307530b51e2918e2cec5", {"code_string": "def saveIrrigationData(self, p_json):\n    \"\"\"Internet data is returned, so update the computer info.\"\"\"\n    l_json = json_tools.decode_json_unicode(p_json)\n    l_ix = int(l_json['Key'])\n    _l_system = l_json['Name']\n    try:\n        l_obj = self.m_pyhouse_obj.House.Irrigation[l_ix]\n    except KeyError:\n        l_obj = IrrigationData()\n        l_obj.DynDns = {}\n    l_obj.Name = l_json['Name']\n    l_obj.Key = 0\n    l_obj.Active = True\n    self.m_pyhouse_obj.House.Irrigation[l_ix] = l_obj\n", "code_toks_joined": "def saveIrrigationData ( self , p_json ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> l_json = json_tools . decode_json_unicode ( p_json ) <NEWLINE> l_ix = int ( l_json [ <STRING> ] ) <NEWLINE> _l_system = l_json [ <STRING> ] <NEWLINE> try : <NEWLINE> <INDENT> l_obj = self . m_pyhouse_obj . House . Irrigation [ l_ix ] <NEWLINE> <DEDENT> except KeyError : <NEWLINE> <INDENT> l_obj = IrrigationData ( ) <NEWLINE> l_obj . DynDns = { } <NEWLINE> <DEDENT> l_obj . Name = l_json [ <STRING> ] <NEWLINE> l_obj . Key = 0 <NEWLINE> l_obj . Active = True <NEWLINE> self . m_pyhouse_obj . House . Irrigation [ l_ix ] = l_obj <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Internet data is returned, so update the computer info.\"\"\"", "'Key'", "'Name'", "'Name'"]}}], ["cc088f7f9f4ad66b3f131cc6d8aca2a7", {"code_string": "def open(self, path, * args, ** kwargs):\n    f = functools.partial(path.open, * args, ** kwargs)\n    return(yield from self.loop.run_in_executor(None, f))\n", "code_toks_joined": "def open ( self , path , * args , ** kwargs ) : <NEWLINE> <INDENT> f = functools . partial ( path . open , * args , ** kwargs ) <NEWLINE> return ( yield from self . loop . run_in_executor ( None , f ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["9ff301ff0b013ce47e18c3d722982c8d", {"code_string": "def update_parser_varname(new_varname, code):\n    lines = filter(lambda x: x != '', code)\n    argparse_code = dropwhile(lambda line: 'import' in line, lines)\n    old_argparser_varname, _ = split_line(argparse_code.next())\n    updated_code = [line.replace(old_argparser_varname, new_varname)\n        for line in lines]\n    return updated_code\n", "code_toks_joined": "def update_parser_varname ( new_varname , code ) : <NEWLINE> <INDENT> lines = filter ( lambda x : x != <STRING> , code ) <NEWLINE> argparse_code = dropwhile ( lambda line : <STRING> in line , lines ) <NEWLINE> old_argparser_varname , _ = split_line ( argparse_code . next ( ) ) <NEWLINE> updated_code = [ line . replace ( old_argparser_varname , new_varname ) <NEWLINE> <INDENT> for line in lines ] <NEWLINE> <DEDENT> return updated_code <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["''", "'import'"]}}], ["765e979a00f262852202456daf23b011", {"code_string": "def setup_platform(hass, config, add_devices, discovery_info = None):\n    \"\"\"Setup the MQTT binary sensor.\"\"\"\n    value_template = config.get(CONF_VALUE_TEMPLATE)\n    if value_template is not None:\n        value_template.hass = hass\n    add_devices([MqttBinarySensor(\n        hass,\n        config.get(CONF_NAME),\n        config.get(CONF_STATE_TOPIC),\n        config.get(CONF_SENSOR_CLASS),\n        config.get(CONF_QOS),\n        config.get(CONF_PAYLOAD_ON),\n        config.get(CONF_PAYLOAD_OFF),\n        value_template\n    )])\n", "code_toks_joined": "def setup_platform ( hass , config , add_devices , discovery_info = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> value_template = config . get ( CONF_VALUE_TEMPLATE ) <NEWLINE> if value_template is not None : <NEWLINE> <INDENT> value_template . hass = hass <NEWLINE> <DEDENT> add_devices ( [ MqttBinarySensor ( <NEWLINE> <INDENT> hass , <NEWLINE> config . get ( CONF_NAME ) , <NEWLINE> config . get ( CONF_STATE_TOPIC ) , <NEWLINE> config . get ( CONF_SENSOR_CLASS ) , <NEWLINE> config . get ( CONF_QOS ) , <NEWLINE> config . get ( CONF_PAYLOAD_ON ) , <NEWLINE> config . get ( CONF_PAYLOAD_OFF ) , <NEWLINE> value_template <NEWLINE> <DEDENT> ) ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Setup the MQTT binary sensor.\"\"\""]}}], ["e1dfdeafa755d3d7e41002927c7cc3a5", {"code_string": "from typing import Dict, List, Any, Optional, Callable, Union\nfrom Modules.Utils.DAL.Common.Dtos import metadataSrv\nfrom Modules.Utils.DAL.Common.Entities.dataContext import DataContext\nfrom Modules.Utils.DAL.Common import utils as dalUtils\nfrom Modules.Utils.DAL.Common.Entities.DataViews.dataViewLocalDto import DataViewLocalDto\n", "code_toks_joined": "from typing import Dict , List , Any , Optional , Callable , Union <NEWLINE> from Modules . Utils . DAL . Common . Dtos import metadataSrv <NEWLINE> from Modules . Utils . DAL . Common . Entities . dataContext import DataContext <NEWLINE> from Modules . Utils . DAL . Common import utils as dalUtils <NEWLINE> from Modules . Utils . DAL . Common . Entities . DataViews . dataViewLocalDto import DataViewLocalDto <NEWLINE>", "anonymize_dict": {}}], ["df3487cbe8ae6f26a75b93ccf8b3382a", {"code_string": "import codecs\nimport sys\nimport re\nimport conllutil3 as cu\ncode = sys.argv[1]\ncomment = \"# nationality: \" + code\nprint(comment, file = sys.stderr)\ncounter = 1\nfor comm, sent in cu.read_conllu(sys.stdin):\n    if comment in comm:\n        cu.plain_print(sys.stdout, comm, sent)\n        counter += 1\nprint(\"sentences=\", counter, sep = \"\", file = sys.stderr)\n", "code_toks_joined": "import codecs <NEWLINE> import sys <NEWLINE> import re <NEWLINE> import conllutil3 as cu <NEWLINE> code = sys . argv [ 1 ] <NEWLINE> comment = <STRING> + code <NEWLINE> print ( comment , file = sys . stderr ) <NEWLINE> counter = 1 <NEWLINE> for comm , sent in cu . read_conllu ( sys . stdin ) : <NEWLINE> <INDENT> if comment in comm : <NEWLINE> <INDENT> cu . plain_print ( sys . stdout , comm , sent ) <NEWLINE> counter += 1 <NEWLINE> <DEDENT> <DEDENT> print ( <STRING> , counter , sep = <STRING> , file = sys . stderr ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"# nationality: \"", "\"sentences=\"", "\"\""]}}], ["a3fae95c753f4f7dba1dafaac825f3bf", {"code_string": "def draw(self, surface):\n    \"\"\"Drawing method, display centered text.\"\"\"\n    super(MessageScreen, self).draw(surface)\n    item_size = None\n    container_size = None\n    n = container_size[self.orientation] / item_size[self.orientation]\n    for i in range(n):\n        item_surface = get_item_surface(item_size)\n        self.renderer(None, item_surface)\n", "code_toks_joined": "def draw ( self , surface ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> super ( MessageScreen , self ) . draw ( surface ) <NEWLINE> item_size = None <NEWLINE> container_size = None <NEWLINE> n = container_size [ self . orientation ] / item_size [ self . orientation ] <NEWLINE> for i in range ( n ) : <NEWLINE> <INDENT> item_surface = get_item_surface ( item_size ) <NEWLINE> self . renderer ( None , item_surface ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Drawing method, display centered text.\"\"\""]}}], ["866c22f9a65e4295aa1a682c34d33f84", {"code_string": "import angr\np = angr.Project('../doublefree.o');\ninit_state = p.factory.entry_state(args = [\"doublefree.o\", angr.StringSpec(sym_length = 3, nonnull = True)], add_options = {\"BYPASS_UNSUPPORTED_SYSCALL\"})\npg = p.factory.path_group(init_state, immutable = False)\npg.explore()\nprint(pg)\n", "code_toks_joined": "import angr <NEWLINE> p = angr . Project ( <STRING> ) ; <NEWLINE> init_state = p . factory . entry_state ( args = [ <STRING> , angr . StringSpec ( sym_length = 3 , nonnull = True ) ] , add_options = { <STRING> } ) <NEWLINE> pg = p . factory . path_group ( init_state , immutable = False ) <NEWLINE> pg . explore ( ) <NEWLINE> print ( pg ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'../doublefree.o'", "\"doublefree.o\"", "\"BYPASS_UNSUPPORTED_SYSCALL\""]}}], ["891114dc69ac2aec4b418fe4358793d3", {"code_string": "class Live(object):\n    \"\"\"This DAO provides real data.  It requires further configuration, e.g.\"\"\"\n    pool = None\n    def getURL(self, url, headers):\n        if Live.pool is None:\n            Live.pool = get_con_pool(\n                settings.RESTCLIENTS_HFS_HOST,\n                settings.RESTCLIENTS_HFS_KEY_FILE,\n                settings.RESTCLIENTS_HFS_CERT_FILE,\n                max_pool_size = HFS_MAX_POOL_SIZE,\n                socket_timeout = HFS_SOCKET_TIMEOUT)\n        return get_live_url(Live.pool,\n            'GET',\n            settings.RESTCLIENTS_HFS_HOST,\n            url,\n            headers = headers,\n            service_name = 'hfs')\n", "code_toks_joined": "class Live ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> pool = None <NEWLINE> def getURL ( self , url , headers ) : <NEWLINE> <INDENT> if Live . pool is None : <NEWLINE> <INDENT> Live . pool = get_con_pool ( <NEWLINE> <INDENT> settings . RESTCLIENTS_HFS_HOST , <NEWLINE> settings . RESTCLIENTS_HFS_KEY_FILE , <NEWLINE> settings . RESTCLIENTS_HFS_CERT_FILE , <NEWLINE> max_pool_size = HFS_MAX_POOL_SIZE , <NEWLINE> socket_timeout = HFS_SOCKET_TIMEOUT ) <NEWLINE> <DEDENT> <DEDENT> return get_live_url ( Live . pool , <NEWLINE> <INDENT> <STRING> , <NEWLINE> settings . RESTCLIENTS_HFS_HOST , <NEWLINE> url , <NEWLINE> headers = headers , <NEWLINE> service_name = <STRING> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"This DAO provides real data.  It requires further configuration, e.g.\"\"\"", "'GET'", "'hfs'"]}}], ["941c24918de0d29adf7e285710d2d697", {"code_string": "def testStandardParameters(self):\n    s = IECoreGL.Shader.constant()\n    self.assertEqual(s.csParameter(), s.uniformParameter(\"Cs\"))\n", "code_toks_joined": "def testStandardParameters ( self ) : <NEWLINE> <INDENT> s = IECoreGL . Shader . constant ( ) <NEWLINE> self . assertEqual ( s . csParameter ( ) , s . uniformParameter ( <STRING> ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Cs\""]}}], ["0f8573b15241a7a7a4f8b6fd9a53c00e", {"code_string": "def eval_clear_score(self, clearflag):\n    if len(self.line_list) > 1 or self.line_list[0] > 0:\n        self.lines_cleared += sum(self.line_list)\n        self.last_score = self.predict_score(clearflag)\n        self.score += self.last_score\n        self.combo_ctr += 1\n        self.current_combo = self.combo_factor ** self.combo_ctr\n    else:\n        self.combo_ctr = 0\n        self.current_combo = 1.0\n", "code_toks_joined": "def eval_clear_score ( self , clearflag ) : <NEWLINE> <INDENT> if len ( self . line_list ) > 1 or self . line_list [ 0 ] > 0 : <NEWLINE> <INDENT> self . lines_cleared += sum ( self . line_list ) <NEWLINE> self . last_score = self . predict_score ( clearflag ) <NEWLINE> self . score += self . last_score <NEWLINE> self . combo_ctr += 1 <NEWLINE> self . current_combo = self . combo_factor ** self . combo_ctr <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . combo_ctr = 0 <NEWLINE> self . current_combo = 1.0 <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["d2fc4ba678cb4832df15252887eb1c48", {"code_string": "def _handle_label(self):\n    x = self._src[self._index]\n    if x == \"'\":\n        label = self._read_quoted_label()\n    else:\n        label = self._read_unquoted_label()\n    if self.prev_token not in[NewickTokenType.OPEN, NewickTokenType.CLOSE, NewickTokenType.COMMA]:\n        m = 'Found \"{}\", but expected a label to be preceded by \"(\", \")\", or a comma'.format(label)\n        self._raise_unexpected(m)\n    self.prev_token = NewickTokenType.LABEL\n    return label\n", "code_toks_joined": "def _handle_label ( self ) : <NEWLINE> <INDENT> x = self . _src [ self . _index ] <NEWLINE> if x == <STRING> : <NEWLINE> <INDENT> label = self . _read_quoted_label ( ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> label = self . _read_unquoted_label ( ) <NEWLINE> <DEDENT> if self . prev_token not in [ NewickTokenType . OPEN , NewickTokenType . CLOSE , NewickTokenType . COMMA ] : <NEWLINE> <INDENT> m = <STRING> . format ( label ) <NEWLINE> self . _raise_unexpected ( m ) <NEWLINE> <DEDENT> self . prev_token = NewickTokenType . LABEL <NEWLINE> return label <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"'\"", "'Found \"{}\", but expected a label to be preceded by \"(\", \")\", or a comma'"]}}], ["8454a9b5c83c295542da31f5bf2a472d", {"code_string": "\"\"\"This file is part of pyCMBS.\"\"\"\n\"\"\"development script for pattern correlation analysis\"\"\"\nfrom pycmbs.diagnostic import PatternCorrelation\nfrom pycmbs.data import Data\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.close('all')\nfname = '../pycmbs/examples/example_data/air.mon.mean.nc'\nx = Data(fname, 'air', read = True)\nxc = x.get_climatology(return_object = True)\nyc = xc.copy()\nyc.data = yc.data * np.random.random(yc.shape) * 10.\nPC = PatternCorrelation(xc, yc)\nPC.plot()\nplt.show()\n", "code_toks_joined": "<STRING> <NEWLINE> <STRING> <NEWLINE> from pycmbs . diagnostic import PatternCorrelation <NEWLINE> from pycmbs . data import Data <NEWLINE> import numpy as np <NEWLINE> import matplotlib . pyplot as plt <NEWLINE> plt . close ( <STRING> ) <NEWLINE> fname = <STRING> <NEWLINE> x = Data ( fname , <STRING> , read = True ) <NEWLINE> xc = x . get_climatology ( return_object = True ) <NEWLINE> yc = xc . copy ( ) <NEWLINE> yc . data = yc . data * np . random . random ( yc . shape ) * 10. <NEWLINE> PC = PatternCorrelation ( xc , yc ) <NEWLINE> PC . plot ( ) <NEWLINE> plt . show ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"This file is part of pyCMBS.\"\"\"", "\"\"\"development script for pattern correlation analysis\"\"\"", "'all'", "'../pycmbs/examples/example_data/air.mon.mean.nc'", "'air'"]}}], ["3b9abbe16c8a4765b64c2238b3363fff", {"code_string": "class GroupQuerySet(models.query.QuerySet):\n    def member(self, user, service = None, depth = None):\n        if depth is None:\n            depth = settings.GROUP_RECURSION_DEPTH\n        expr = Q(users = user, service = service)\n        kwarg = 'users'\n        for i in range(depth):\n            kwarg = 'parent_groups__%s' % kwarg\n            expr |= models.Q(**{kwarg: user, 'service': service})\n        return self.filter(expr).distinct()\n", "code_toks_joined": "class GroupQuerySet ( models . query . QuerySet ) : <NEWLINE> <INDENT> def member ( self , user , service = None , depth = None ) : <NEWLINE> <INDENT> if depth is None : <NEWLINE> <INDENT> depth = settings . GROUP_RECURSION_DEPTH <NEWLINE> <DEDENT> expr = Q ( users = user , service = service ) <NEWLINE> kwarg = <STRING> <NEWLINE> for i in range ( depth ) : <NEWLINE> <INDENT> kwarg = <STRING> % kwarg <NEWLINE> expr |= models . Q ( ** { kwarg : user , <STRING> : service } ) <NEWLINE> <DEDENT> return self . filter ( expr ) . distinct ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'users'", "'parent_groups__%s'", "'service'"]}}], ["490e6b67104cf07d9a923f62d66bf9ac", {"code_string": "def validate(tax_number):\n    \"\"\"Validate a tax number.\"\"\"\n    try:\n        verify_vat(tax_number)\n        return \"vat\"\n    except VatCannotIdentifyValidationError:\n        pass\n    return \"unknown\"\n", "code_toks_joined": "def validate ( tax_number ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> try : <NEWLINE> <INDENT> verify_vat ( tax_number ) <NEWLINE> return <STRING> <NEWLINE> <DEDENT> except VatCannotIdentifyValidationError : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> return <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Validate a tax number.\"\"\"", "\"vat\"", "\"unknown\""]}}], ["c80a06bd734149819e0dbdff2d7153ca", {"code_string": "import numpy as np\nfrom dswimg import *\nfrom dswimgproc import *\nr = np.random.random((50, 80))\nppnoise(r)\nppnoise(r * 100)\nh = (r[: , 1: ] + r[: , : - 1]) / 2\nppnoise(h)\nv = (r[: , 1: ] + r[: , : - 1]) / 2\nppnoise(v)\n", "code_toks_joined": "import numpy as np <NEWLINE> from dswimg import * <NEWLINE> from dswimgproc import * <NEWLINE> r = np . random . random ( ( 50 , 80 ) ) <NEWLINE> ppnoise ( r ) <NEWLINE> ppnoise ( r * 100 ) <NEWLINE> h = ( r [ : , 1 : ] + r [ : , : - 1 ] ) / 2 <NEWLINE> ppnoise ( h ) <NEWLINE> v = ( r [ : , 1 : ] + r [ : , : - 1 ] ) / 2 <NEWLINE> ppnoise ( v ) <NEWLINE>", "anonymize_dict": {}}], ["baf0919d6e2c87d51ec030038ddb1000", {"code_string": "def test_output_urls(self):\n    \"\"\"Ensure the tag correcly spits out the urls the bundle returns.\"\"\"\n    self.BundleClass.urls_to_fake = ['foo', 'bar']\n    assert self.render_template('\"file1\" \"file2\" \"file3\"') == 'foo;bar;'\n", "code_toks_joined": "def test_output_urls ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . BundleClass . urls_to_fake = [ <STRING> , <STRING> ] <NEWLINE> assert self . render_template ( <STRING> ) == <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Ensure the tag correcly spits out the urls the bundle returns.\"\"\"", "'foo'", "'bar'", "'\"file1\" \"file2\" \"file3\"'", "'foo;bar;'"]}}], ["644382560e6214af8f4279f724e86642", {"code_string": "def relerr(expected, actual):\n    \"\"\"Relative error between `expected` and `actual`: ``abs((a - e)/e)``.\"\"\"\n    return abs((actual - expected) / expected)\n", "code_toks_joined": "def relerr ( expected , actual ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return abs ( ( actual - expected ) / expected ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Relative error between `expected` and `actual`: ``abs((a - e)/e)``.\"\"\""]}}], ["f5b867dcf42f079614ada2249d74614d", {"code_string": "import cProfile\nimport pstats\nimport os.path\nfrom palm.linalg import ScipyMatrixExponential, ScipyMatrixExponential2, QitMatrixExponential, StubExponential\nfrom palm.blink_factory import SingleDarkBlinkFactory\nfrom palm.blink_parameter_set import SingleDarkParameterSet\nfrom palm.likelihood_judge import LikelihoodJudge\nfrom palm.backward_likelihood import BackwardPredictor\nfrom palm.blink_target_data import BlinkTargetData\nfrom palm.scipy_optimizer import ScipyOptimizer\nfrom palm.score_function import ScoreFunction\n", "code_toks_joined": "import cProfile <NEWLINE> import pstats <NEWLINE> import os . path <NEWLINE> from palm . linalg import ScipyMatrixExponential , ScipyMatrixExponential2 , QitMatrixExponential , StubExponential <NEWLINE> from palm . blink_factory import SingleDarkBlinkFactory <NEWLINE> from palm . blink_parameter_set import SingleDarkParameterSet <NEWLINE> from palm . likelihood_judge import LikelihoodJudge <NEWLINE> from palm . backward_likelihood import BackwardPredictor <NEWLINE> from palm . blink_target_data import BlinkTargetData <NEWLINE> from palm . scipy_optimizer import ScipyOptimizer <NEWLINE> from palm . score_function import ScoreFunction <NEWLINE>", "anonymize_dict": {}}], ["ff4ce7bcbbf49a39a83e1bf43188e10f", {"code_string": "def strip_tags(html):\n    stripper = MLStripper()\n    stripper.feed(html)\n    return stripper.get_data()\n", "code_toks_joined": "def strip_tags ( html ) : <NEWLINE> <INDENT> stripper = MLStripper ( ) <NEWLINE> stripper . feed ( html ) <NEWLINE> return stripper . get_data ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["718fd2dff48345110985460bdca909f9", {"code_string": "def model_to_dict(instance, exclude, include_not_editable):\n    data = {}\n    for f in instance_fields(instance):\n        if f.name in exclude:\n            continue\n        if not getattr(f, 'editable', False) and not include_not_editable:\n            continue\n        data[f.name] = f.value_from_object(instance)\n    return data\n", "code_toks_joined": "def model_to_dict ( instance , exclude , include_not_editable ) : <NEWLINE> <INDENT> data = { } <NEWLINE> for f in instance_fields ( instance ) : <NEWLINE> <INDENT> if f . name in exclude : <NEWLINE> <INDENT> continue <NEWLINE> <DEDENT> if not getattr ( f , <STRING> , False ) and not include_not_editable : <NEWLINE> <INDENT> continue <NEWLINE> <DEDENT> data [ f . name ] = f . value_from_object ( instance ) <NEWLINE> <DEDENT> return data <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'editable'"]}}], ["1ca0764c2fb13c1cb77266051f2424e8", {"code_string": "import sys\nimport re\nimport os\nimport zipfile\nimport zlib\nimport urllib\nimport shutil\nimport mechanize\nimport json\nimport argparse\n", "code_toks_joined": "import sys <NEWLINE> import re <NEWLINE> import os <NEWLINE> import zipfile <NEWLINE> import zlib <NEWLINE> import urllib <NEWLINE> import shutil <NEWLINE> import mechanize <NEWLINE> import json <NEWLINE> import argparse <NEWLINE>", "anonymize_dict": {}}], ["728d912dad6a7fc706b275e0112d81ec", {"code_string": "from flask_truss.factory import create_celery_app\ncelery_instance = create_celery_app()\n", "code_toks_joined": "from flask_truss . factory import create_celery_app <NEWLINE> celery_instance = create_celery_app ( ) <NEWLINE>", "anonymize_dict": {}}], ["6098662714a59a6aa403166efe614a15", {"code_string": "def _make_json_serializable(x):\n    if isinstance(x, np.ndarray):\n        return x.tolist()\n    elif isinstance(x, dict):\n        return{key: _make_json_serializable(value)\n            for key, value in x.items()}\n    elif isinstance(x, list):\n        return[_make_json_serializable(value) for value in x]\n    return x\n", "code_toks_joined": "def _make_json_serializable ( x ) : <NEWLINE> <INDENT> if isinstance ( x , np . ndarray ) : <NEWLINE> <INDENT> return x . tolist ( ) <NEWLINE> <DEDENT> elif isinstance ( x , dict ) : <NEWLINE> <INDENT> return { key : _make_json_serializable ( value ) <NEWLINE> <INDENT> for key , value in x . items ( ) } <NEWLINE> <DEDENT> <DEDENT> elif isinstance ( x , list ) : <NEWLINE> <INDENT> return [ _make_json_serializable ( value ) for value in x ] <NEWLINE> <DEDENT> return x <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["2aecb8b613c1007943852a974b18cc93", {"code_string": "def render_factcheck():\n    parsed_factcheck = parse_factcheck()\n    generate_views(['_factcheck', '_preview', '_share'],\n        parsed_factcheck)\n", "code_toks_joined": "def render_factcheck ( ) : <NEWLINE> <INDENT> parsed_factcheck = parse_factcheck ( ) <NEWLINE> generate_views ( [ <STRING> , <STRING> , <STRING> ] , <NEWLINE> <INDENT> parsed_factcheck ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'_factcheck'", "'_preview'", "'_share'"]}}], ["27e5721347df0ab35ea5f73c2333796e", {"code_string": "def get_mobility(e_field, temperature, is_electron):\n    if is_electron:\n        v_m = 1.53e9 * temperature **(- 0.87)\n        E_c = 1.01 * temperature ** 1.55\n        beta = 2.57e-2 * temperature ** 0.66\n    else:\n        v_m = 1.62e8 * temperature **(- 0.52)\n        E_c = 1.24 * temperature ** 1.68\n        beta = 0.46 * temperature ** 0.17\n    mu = v_m / E_c /(1. +(np.abs(e_field) / E_c) ** beta) **(1. / beta)\n    return mu\n", "code_toks_joined": "def get_mobility ( e_field , temperature , is_electron ) : <NEWLINE> <INDENT> if is_electron : <NEWLINE> <INDENT> v_m = 1.53e9 * temperature ** ( - 0.87 ) <NEWLINE> E_c = 1.01 * temperature ** 1.55 <NEWLINE> beta = 2.57e-2 * temperature ** 0.66 <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> v_m = 1.62e8 * temperature ** ( - 0.52 ) <NEWLINE> E_c = 1.24 * temperature ** 1.68 <NEWLINE> beta = 0.46 * temperature ** 0.17 <NEWLINE> <DEDENT> mu = v_m / E_c / ( 1. + ( np . abs ( e_field ) / E_c ) ** beta ) ** ( 1. / beta ) <NEWLINE> return mu <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["daa8e9f80dd8eb75ff728add4ed4679b", {"code_string": "\"\"\"Created on Sat May 07 01:02:28 2016\"\"\"\nfrom.Image import *\nfrom.NumericalGradient import *\nfrom.MNIST import *\n__all__ = ['Image', 'NumericalGradient', 'MNIST']\n", "code_toks_joined": "<STRING> <NEWLINE> from . Image import * <NEWLINE> from . NumericalGradient import * <NEWLINE> from . MNIST import * <NEWLINE> __all__ = [ <STRING> , <STRING> , <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Created on Sat May 07 01:02:28 2016\"\"\"", "'Image'", "'NumericalGradient'", "'MNIST'"]}}], ["526999f069e82dc6dfb065d4ea0a74cf", {"code_string": "def get_request_redis_id(acquisition_req):\n    \"\"\"Args:\"\"\"\n    return '{}:{}'.format(acquisition_req.orgUUID, acquisition_req.id)\n", "code_toks_joined": "def get_request_redis_id ( acquisition_req ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return <STRING> . format ( acquisition_req . orgUUID , acquisition_req . id ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Args:\"\"\"", "'{}:{}'"]}}], ["3c4e283ce4966a868997b7c606668479", {"code_string": "from collective.elephantvocabulary.vocabulary import VocabularyFactory\nfrom collective.elephantvocabulary.hidden import WrapperHidden\nfrom collective.elephantvocabulary.visible import WrapperVisible\nfrom collective.elephantvocabulary.base import WrapperBase\ndef wrap_vocabulary(vocab,\n    visible_terms = None,\n    visible_terms_from_registry = None,\n    hidden_terms = None,\n    hidden_terms_from_registry = None,\n    wrapper_class = WrapperBase):\n    return VocabularyFactory(\n    vocab,\n    visible_terms = visible_terms,\n    visible_terms_from_registry = visible_terms_from_registry,\n    hidden_terms = hidden_terms,\n    hidden_terms_from_registry = hidden_terms_from_registry,\n    wrapper_class = WrapperBase,\n    )\n__all__ = ['wrap_vocabulary', 'WrapperBase', 'WrapperVisible', 'WrapperHidden']\n", "code_toks_joined": "from collective . elephantvocabulary . vocabulary import VocabularyFactory <NEWLINE> from collective . elephantvocabulary . hidden import WrapperHidden <NEWLINE> from collective . elephantvocabulary . visible import WrapperVisible <NEWLINE> from collective . elephantvocabulary . base import WrapperBase <NEWLINE> def wrap_vocabulary ( vocab , <NEWLINE> <INDENT> visible_terms = None , <NEWLINE> visible_terms_from_registry = None , <NEWLINE> hidden_terms = None , <NEWLINE> hidden_terms_from_registry = None , <NEWLINE> wrapper_class = WrapperBase ) : <NEWLINE> return VocabularyFactory ( <NEWLINE> vocab , <NEWLINE> visible_terms = visible_terms , <NEWLINE> visible_terms_from_registry = visible_terms_from_registry , <NEWLINE> hidden_terms = hidden_terms , <NEWLINE> hidden_terms_from_registry = hidden_terms_from_registry , <NEWLINE> wrapper_class = WrapperBase , <NEWLINE> ) <NEWLINE> <DEDENT> __all__ = [ <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'wrap_vocabulary'", "'WrapperBase'", "'WrapperVisible'", "'WrapperHidden'"]}}], ["3564f031a9f5287ab34e65d31c6e816e", {"code_string": "def create_reduction_tree(oresult, parent):\n    ptask = DataProcessingTask()\n    ptask.host = 'localhost'\n    ptask.state = 0\n    ptask.parent = parent\n    ptask.creation_time = datetime.utcnow()\n    ptask.method = 'process%S' % oresult.label\n    for child in oresult.children:\n        create_reduction_tree(child, ptask)\n    return ptask\n", "code_toks_joined": "def create_reduction_tree ( oresult , parent ) : <NEWLINE> <INDENT> ptask = DataProcessingTask ( ) <NEWLINE> ptask . host = <STRING> <NEWLINE> ptask . state = 0 <NEWLINE> ptask . parent = parent <NEWLINE> ptask . creation_time = datetime . utcnow ( ) <NEWLINE> ptask . method = <STRING> % oresult . label <NEWLINE> for child in oresult . children : <NEWLINE> <INDENT> create_reduction_tree ( child , ptask ) <NEWLINE> <DEDENT> return ptask <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'localhost'", "'process%S'"]}}], ["cb3dae6fe5c1e53eef0172889a4eac50", {"code_string": "def to_latex(self, filepath = None):\n    t0 = time.time()\n    self.logfile.write_log(message1b)\n    doc = describe2latex(self.study_info, self.stats)\n    if filepath is None:\n        return doc\n    else:\n        with open(filepath, 'w') as myfile:\n            myfile.write(doc)\n        myfile.close()\n    self.logfile.write_log(message2 %(time.time() - t0))\n    self.logfile.write_log(message_close)\n", "code_toks_joined": "def to_latex ( self , filepath = None ) : <NEWLINE> <INDENT> t0 = time . time ( ) <NEWLINE> self . logfile . write_log ( message1b ) <NEWLINE> doc = describe2latex ( self . study_info , self . stats ) <NEWLINE> if filepath is None : <NEWLINE> <INDENT> return doc <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> with open ( filepath , <STRING> ) as myfile : <NEWLINE> <INDENT> myfile . write ( doc ) <NEWLINE> <DEDENT> myfile . close ( ) <NEWLINE> <DEDENT> self . logfile . write_log ( message2 % ( time . time ( ) - t0 ) ) <NEWLINE> self . logfile . write_log ( message_close ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'w'"]}}], ["8864925ff101e7f5ab4180c8eb904f9a", {"code_string": "def t1_new_full(in_val):\n    foo = T1()\n    foo.num = in_val\n    return pointer(foo)\n", "code_toks_joined": "def t1_new_full ( in_val ) : <NEWLINE> <INDENT> foo = T1 ( ) <NEWLINE> foo . num = in_val <NEWLINE> return pointer ( foo ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["8a4e381a112d38435112603b85fe6073", {"code_string": "import os\nimport sys\nif __name__ == '__main__':\n    filename = os.path.join(os.path.dirname(sys.executable),\n        'test_onefile_nestedlaunch0.exe')\n    try:\n        import subprocess\n    except ImportError:\n        if os.system(filename) != 0:\n            raise RuntimeError(\"os.system failed: %s\" % filename)\n    else:\n        subprocess.check_call([filename])\n", "code_toks_joined": "import os <NEWLINE> import sys <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> filename = os . path . join ( os . path . dirname ( sys . executable ) , <NEWLINE> <INDENT> <STRING> ) <NEWLINE> <DEDENT> try : <NEWLINE> <INDENT> import subprocess <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> if os . system ( filename ) != 0 : <NEWLINE> <INDENT> raise RuntimeError ( <STRING> % filename ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> subprocess . check_call ( [ filename ] ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'__main__'", "'test_onefile_nestedlaunch0.exe'", "\"os.system failed: %s\""]}}], ["b4b06c2407d18f2b47bc195c5ef2cd99", {"code_string": "class index:\n    def GET(self):\n        form = myform()\n        return \"<html><body><form name=\\\"main\\\" method=\\\"post\\\"> \" + form.render() + \"</form></body></html>\"\n    def POST(self):\n        form = myform()\n        if not form.validates():\n            return \"<html><body><form name=\\\"main\\\" method=\\\"post\\\"> \" + form.render() + \"</form></body></html>\"\n        else:\n            return \"<html><body>Gracias por sus datos \" + form['nombre'].value + \"</body></html>\";\n", "code_toks_joined": "class index : <NEWLINE> <INDENT> def GET ( self ) : <NEWLINE> <INDENT> form = myform ( ) <NEWLINE> return <STRING> + form . render ( ) + <STRING> <NEWLINE> <DEDENT> def POST ( self ) : <NEWLINE> <INDENT> form = myform ( ) <NEWLINE> if not form . validates ( ) : <NEWLINE> <INDENT> return <STRING> + form . render ( ) + <STRING> <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return <STRING> + form [ <STRING> ] . value + <STRING> ; <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"<html><body><form name=\\\"main\\\" method=\\\"post\\\"> \"", "\"</form></body></html>\"", "\"<html><body><form name=\\\"main\\\" method=\\\"post\\\"> \"", "\"</form></body></html>\"", "\"<html><body>Gracias por sus datos \"", "'nombre'", "\"</body></html>\""]}}], ["bf700cdd8bf91a7609b98418ecc933a0", {"code_string": "def getLastSecond(countBySecond):\n    lastSecond = 0\n    for second in countBySecond.keys():\n        if second > lastSecond:\n            lastSecond = second\n    return lastSecond\n", "code_toks_joined": "def getLastSecond ( countBySecond ) : <NEWLINE> <INDENT> lastSecond = 0 <NEWLINE> for second in countBySecond . keys ( ) : <NEWLINE> <INDENT> if second > lastSecond : <NEWLINE> <INDENT> lastSecond = second <NEWLINE> <DEDENT> <DEDENT> return lastSecond <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["44adfd9675768a82fc3f42906f3af322", {"code_string": "def from_CSV(files, usecols = None):\n    try:\n        return mm.util.load.from_CSV(files, usecols = usecols)\n    except:\n        return mm.util.load.from_ASCII(files, usecols = usecols)\n", "code_toks_joined": "def from_CSV ( files , usecols = None ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> return mm . util . load . from_CSV ( files , usecols = usecols ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> return mm . util . load . from_ASCII ( files , usecols = usecols ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["2cb38f73ac0a3fdfe0ccb6fcc711f0a9", {"code_string": "import sys\nfrom argparse import ArgumentParser\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom lib.graph import HypRG\n", "code_toks_joined": "import sys <NEWLINE> from argparse import ArgumentParser <NEWLINE> from collections import Counter <NEWLINE> import matplotlib . pyplot as plt <NEWLINE> from lib . graph import HypRG <NEWLINE>", "anonymize_dict": {}}], ["45400ee287df54feabebdc76f80bd276", {"code_string": "class MiembroViewSet(viewsets.ModelViewSet):\n    \"\"\"API endpoint that allows miembros to be viewed or edited.\"\"\"\n    queryset = Miembro.objects.all().order_by('-fecha_alta')\n    serializer_class = MiembroSerializer\n", "code_toks_joined": "class MiembroViewSet ( viewsets . ModelViewSet ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> queryset = Miembro . objects . all ( ) . order_by ( <STRING> ) <NEWLINE> serializer_class = MiembroSerializer <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"API endpoint that allows miembros to be viewed or edited.\"\"\"", "'-fecha_alta'"]}}], ["ec1da3420ef223dbfbbf2cd8ada09c82", {"code_string": "def DigitFibonacci():\n    fib1 = 0\n    fib2 = 1\n    temp = 0\n    found = False\n    fibCounter = 1\n    while(found == False):\n        fibStr = str(fib2)\n        fibCheck = len(fibStr)\n        if(fibCheck >= 1000):\n            found = True\n        else:\n            temp = fib2\n            fib2 = fib2 + fib1\n            fib1 = temp\n            fibCounter += 1\n    print(\"First 1k Digit Fib num = %d\" % fib2)\n    print(\"Fib index = %d\" % fibCounter)\n", "code_toks_joined": "def DigitFibonacci ( ) : <NEWLINE> <INDENT> fib1 = 0 <NEWLINE> fib2 = 1 <NEWLINE> temp = 0 <NEWLINE> found = False <NEWLINE> fibCounter = 1 <NEWLINE> while ( found == False ) : <NEWLINE> <INDENT> fibStr = str ( fib2 ) <NEWLINE> fibCheck = len ( fibStr ) <NEWLINE> if ( fibCheck >= 1000 ) : <NEWLINE> <INDENT> found = True <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> temp = fib2 <NEWLINE> fib2 = fib2 + fib1 <NEWLINE> fib1 = temp <NEWLINE> fibCounter += 1 <NEWLINE> <DEDENT> <DEDENT> print ( <STRING> % fib2 ) <NEWLINE> print ( <STRING> % fibCounter ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"First 1k Digit Fib num = %d\"", "\"Fib index = %d\""]}}], ["b494e64883027dd293c9e1fd2b156ff4", {"code_string": "import base64\nimport time\nfrom openerp.osv import orm, fields\nfrom openerp.tools.translate import _\nfrom openerp.tools import DEFAULT_SERVER_DATE_FORMAT\nfrom unidecode import unidecode\n", "code_toks_joined": "import base64 <NEWLINE> import time <NEWLINE> from openerp . osv import orm , fields <NEWLINE> from openerp . tools . translate import _ <NEWLINE> from openerp . tools import DEFAULT_SERVER_DATE_FORMAT <NEWLINE> from unidecode import unidecode <NEWLINE>", "anonymize_dict": {}}], ["06491a6c35889ee8d733fbf56c42d1c0", {"code_string": "def grades_sum(lst):\n    res = 0\n    for i in lst:\n        res += i\n    return res\n", "code_toks_joined": "def grades_sum ( lst ) : <NEWLINE> <INDENT> res = 0 <NEWLINE> for i in lst : <NEWLINE> <INDENT> res += i <NEWLINE> <DEDENT> return res <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["97b5e608ba363732cdd6ba4a1585f784", {"code_string": "def _compare2(a, b):\n    p = Turn._compare(a, b)\n    if p == 0:\n        alist = a.foes.all()\n        blist = b.foes.all()\n        i = len(alist) - 1\n        q = Turn._compare(alist[i], blist[i])\n        while q == 0 and i > 0:\n            i -= 1\n            q = Turn._compare(alist[i], blist[i])\n        return q\n    return p\n", "code_toks_joined": "def _compare2 ( a , b ) : <NEWLINE> <INDENT> p = Turn . _compare ( a , b ) <NEWLINE> if p == 0 : <NEWLINE> <INDENT> alist = a . foes . all ( ) <NEWLINE> blist = b . foes . all ( ) <NEWLINE> i = len ( alist ) - 1 <NEWLINE> q = Turn . _compare ( alist [ i ] , blist [ i ] ) <NEWLINE> while q == 0 and i > 0 : <NEWLINE> <INDENT> i -= 1 <NEWLINE> q = Turn . _compare ( alist [ i ] , blist [ i ] ) <NEWLINE> <DEDENT> return q <NEWLINE> <DEDENT> return p <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["8a737c198e25be0bb69a0f41596f007a", {"code_string": "def Zvalue_to_pvalue(Zvalue, mode = 'two-sided'):\n    \"\"\"Convert a Z-value to a p-value.\"\"\"\n    try:\n        mode = 2. if mode == 'two-sided' else 1.\n        pvalue = scipy.special.erfc(Zvalue / math.sqrt(2.)) / mode\n    except:\n        raise\n    return pvalue\n", "code_toks_joined": "def Zvalue_to_pvalue ( Zvalue , mode = <STRING> ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> try : <NEWLINE> <INDENT> mode = 2. if mode == <STRING> else 1. <NEWLINE> pvalue = scipy . special . erfc ( Zvalue / math . sqrt ( 2. ) ) / mode <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> raise <NEWLINE> <DEDENT> return pvalue <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'two-sided'", "\"\"\"Convert a Z-value to a p-value.\"\"\"", "'two-sided'"]}}], ["a7bca88560b30b521aa7dd952e819b65", {"code_string": "def mouseDoubleClickEvent(self, mouseEvent):\n    \"\"\"Executed when the mouse is double clicked on the widget.\"\"\"\n    pass\n", "code_toks_joined": "def mouseDoubleClickEvent ( self , mouseEvent ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Executed when the mouse is double clicked on the widget.\"\"\""]}}], ["52f2332a50553367b1963d4af3c6db88", {"code_string": "def DoCoProcessing(datadescription):\n    \"Callback to do co-processing for current timestep\"\n    global coprocessor\n    coprocessor.UpdateProducers(datadescription)\n    coprocessor.WriteData(datadescription);\n    coprocessor.WriteImages(datadescription, rescale_lookuptable = False)\n    coprocessor.DoLiveVisualization(datadescription, \"localhost\", 22222)\n", "code_toks_joined": "def DoCoProcessing ( datadescription ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> global coprocessor <NEWLINE> coprocessor . UpdateProducers ( datadescription ) <NEWLINE> coprocessor . WriteData ( datadescription ) ; <NEWLINE> coprocessor . WriteImages ( datadescription , rescale_lookuptable = False ) <NEWLINE> coprocessor . DoLiveVisualization ( datadescription , <STRING> , 22222 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Callback to do co-processing for current timestep\"", "\"localhost\""]}}], ["2fcbe640dcb6045e1c8de7abcbe9b728", {"code_string": "def finalize(self):\n    \"\"\"Finalize the job.\"\"\"\n    self._hisfile.close()\n    self._trajectory.close()\n", "code_toks_joined": "def finalize ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . _hisfile . close ( ) <NEWLINE> self . _trajectory . close ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Finalize the job.\"\"\""]}}], ["449fed76abea8f6aacba70ff0d3fe805", {"code_string": "def _addVersionString(self, versionkey, value):\n    self.log.warning(\"Package metadata has not been defined, however, the version is being used by the build configuration\")\n    self.version[versionkey] = value\n    self.versionkeys.append(versionkey)\n", "code_toks_joined": "def _addVersionString ( self , versionkey , value ) : <NEWLINE> <INDENT> self . log . warning ( <STRING> ) <NEWLINE> self . version [ versionkey ] = value <NEWLINE> self . versionkeys . append ( versionkey ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Package metadata has not been defined, however, the version is being used by the build configuration\""]}}], ["032af834afc1529addd48850ccc76bb4", {"code_string": "def make_shared(shape):\n    \"\"\"Returns a theano shared variable containing a tensor of the specified\"\"\"\n    return shared(np.zeros(shape))\n", "code_toks_joined": "def make_shared ( shape ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return shared ( np . zeros ( shape ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Returns a theano shared variable containing a tensor of the specified\"\"\""]}}], ["a97af435a1efa60d73862dfed74b6672", {"code_string": "def partition(self, s):\n    if not s:\n        return[]\n    mincut = [len(s)]\n    res = self.PalindromePart(s, 0, mincut)\n    return mincut[0]\n", "code_toks_joined": "def partition ( self , s ) : <NEWLINE> <INDENT> if not s : <NEWLINE> <INDENT> return [ ] <NEWLINE> <DEDENT> mincut = [ len ( s ) ] <NEWLINE> res = self . PalindromePart ( s , 0 , mincut ) <NEWLINE> return mincut [ 0 ] <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["2e6b40c72ffe38a63d69265ec734a589", {"code_string": "def jsonify_annual_water_use_volume(request):\n    result = get_annual_water_use_volume(request)\n    return HttpResponse(json.dumps(result), content_type = \"application/json\")\n", "code_toks_joined": "def jsonify_annual_water_use_volume ( request ) : <NEWLINE> <INDENT> result = get_annual_water_use_volume ( request ) <NEWLINE> return HttpResponse ( json . dumps ( result ) , content_type = <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"application/json\""]}}], ["03c92f298223149e1a8ff24deb3a0ee4", {"code_string": "def R2vec(self, i):\n    \"\"\"Return fraction of data variance which is explained by vector i.\"\"\"\n    d = self._model_vec(i) - self.data\n    return 1.0 - N.var(d[self._unmasked]) / self._unmasked_data_var\n", "code_toks_joined": "def R2vec ( self , i ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> d = self . _model_vec ( i ) - self . data <NEWLINE> return 1.0 - N . var ( d [ self . _unmasked ] ) / self . _unmasked_data_var <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Return fraction of data variance which is explained by vector i.\"\"\""]}}], ["8bdb4e76b10c543c73e48003227c1313", {"code_string": "def test_extend_with_tuple(self):\n    D1 = DistinctList([1, 2, 3, 4, 5, 6, 7, 8])\n    D1.extend((9, 10, 11, 12))\n    self.assertSequenceEqual(D1, DistinctList([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]), seq_type = DistinctList)\n", "code_toks_joined": "def test_extend_with_tuple ( self ) : <NEWLINE> <INDENT> D1 = DistinctList ( [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 ] ) <NEWLINE> D1 . extend ( ( 9 , 10 , 11 , 12 ) ) <NEWLINE> self . assertSequenceEqual ( D1 , DistinctList ( [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 ] ) , seq_type = DistinctList ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["1aa3d55fd1af4c515566454fb8cb072f", {"code_string": "from SpaceDock.config import _cfg\nfrom SpaceDock.celery import update_patreon\nimport celery\nimport redis\nimport time\nimport json\ndonation_cache = redis.Redis(host = _cfg('patreon-host'), port = _cfg('patreon-port'), db = _cfg('patreon-db'))\n", "code_toks_joined": "from SpaceDock . config import _cfg <NEWLINE> from SpaceDock . celery import update_patreon <NEWLINE> import celery <NEWLINE> import redis <NEWLINE> import time <NEWLINE> import json <NEWLINE> donation_cache = redis . Redis ( host = _cfg ( <STRING> ) , port = _cfg ( <STRING> ) , db = _cfg ( <STRING> ) ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'patreon-host'", "'patreon-port'", "'patreon-db'"]}}], ["89f6db14a91b879c595f816826bc7846", {"code_string": "def test_write_read_settings(self):\n    lyr1 = self.defaultLayerSettings()\n    lyr1dict = self.settingsDict(lyr1)\n    lyr1.writeToLayer(self.layer)\n    lyr2 = QgsPalLayerSettings()\n    lyr2.readFromLayer(self.layer)\n    lyr2dict = self.settingsDict(lyr1)\n    msg = '\\nLayer settings read not same as settings written'\n    self.assertDictEqual(lyr1dict, lyr2dict, msg)\n", "code_toks_joined": "def test_write_read_settings ( self ) : <NEWLINE> <INDENT> lyr1 = self . defaultLayerSettings ( ) <NEWLINE> lyr1dict = self . settingsDict ( lyr1 ) <NEWLINE> lyr1 . writeToLayer ( self . layer ) <NEWLINE> lyr2 = QgsPalLayerSettings ( ) <NEWLINE> lyr2 . readFromLayer ( self . layer ) <NEWLINE> lyr2dict = self . settingsDict ( lyr1 ) <NEWLINE> msg = <STRING> <NEWLINE> self . assertDictEqual ( lyr1dict , lyr2dict , msg ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'\\nLayer settings read not same as settings written'"]}}], ["4ab09f2daf87d9cfd6e3c31778925186", {"code_string": "def actualizar(self):\n    self.contador += 16\n    self.dx += self._incremento_aceleracion_x\n    self.dy += self._incremento_aceleracion_y\n    self.x += self.dx\n    self.y += self.dy\n    self.escala += self._incremento_escala\n    self.transparencia += self._incremento_transparencia\n    self.rotacion += self._incremento_rotacion\n    if self.contador > self.vida:\n        self.emisor.se_elimina_particula(self)\n        self.eliminar()\n", "code_toks_joined": "def actualizar ( self ) : <NEWLINE> <INDENT> self . contador += 16 <NEWLINE> self . dx += self . _incremento_aceleracion_x <NEWLINE> self . dy += self . _incremento_aceleracion_y <NEWLINE> self . x += self . dx <NEWLINE> self . y += self . dy <NEWLINE> self . escala += self . _incremento_escala <NEWLINE> self . transparencia += self . _incremento_transparencia <NEWLINE> self . rotacion += self . _incremento_rotacion <NEWLINE> if self . contador > self . vida : <NEWLINE> <INDENT> self . emisor . se_elimina_particula ( self ) <NEWLINE> self . eliminar ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["b905082feef4e592424a53c69fe0dd1d", {"code_string": "def sanitize_url(url):\n    valid_utf8 = True\n    try:\n        url.decode('utf-8')\n    except UnicodeDecodeError:\n        valid_utf8 = False\n        return url[: - 1]\n    return url\n", "code_toks_joined": "def sanitize_url ( url ) : <NEWLINE> <INDENT> valid_utf8 = True <NEWLINE> try : <NEWLINE> <INDENT> url . decode ( <STRING> ) <NEWLINE> <DEDENT> except UnicodeDecodeError : <NEWLINE> <INDENT> valid_utf8 = False <NEWLINE> return url [ : - 1 ] <NEWLINE> <DEDENT> return url <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'utf-8'"]}}], ["226986fce55864cdafda62c579847c76", {"code_string": "def init_config(self, app):\n    \"\"\"Initialize configuration.\"\"\"\n    if 'BASE_TEMPLATE' in app.config:\n        app.config.setdefault(\n            'UNICORN_BASE_TEMPLATE',\n            app.config['BASE_TEMPLATE'],\n        )\n    for k in dir(config):\n        if k.startswith('UNICORN_'):\n            app.config.setdefault(k, getattr(config, k))\n", "code_toks_joined": "def init_config ( self , app ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if <STRING> in app . config : <NEWLINE> <INDENT> app . config . setdefault ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> app . config [ <STRING> ] , <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> for k in dir ( config ) : <NEWLINE> <INDENT> if k . startswith ( <STRING> ) : <NEWLINE> <INDENT> app . config . setdefault ( k , getattr ( config , k ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Initialize configuration.\"\"\"", "'BASE_TEMPLATE'", "'UNICORN_BASE_TEMPLATE'", "'BASE_TEMPLATE'", "'UNICORN_'"]}}], ["29a166632e4dbd6b38ece5cf5694611c", {"code_string": "def visit_VARCHAR(self, type_):\n    if self.dialect._supports_char_length:\n        return \"VARCHAR(%(length)s CHAR)\" %{'length': type_.length}\n    else:\n        return \"VARCHAR(%(length)s)\" %{'length': type_.length}\n", "code_toks_joined": "def visit_VARCHAR ( self , type_ ) : <NEWLINE> <INDENT> if self . dialect . _supports_char_length : <NEWLINE> <INDENT> return <STRING> % { <STRING> : type_ . length } <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return <STRING> % { <STRING> : type_ . length } <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"VARCHAR(%(length)s CHAR)\"", "'length'", "\"VARCHAR(%(length)s)\"", "'length'"]}}], ["d07550eb7753430764758ca178a031a3", {"code_string": "from sys import version_info\nfrom setuptools import setup, find_packages\nbasename = \"telesto\"\nversion = \"0.1\"\npyversion = \"%s.%s\" %(version_info.major, version_info.minor)\nsetup(\n    name = basename,\n    version = version,\n    packages = find_packages(),\n    zip_safe = True,\n    author = \"Simon Marti, Dominic Langengger\",\n    author_email = \"simarti@ethz.ch, dominicl@ethz.ch\",\n    description = \"Protocol code generator for Telesto Messaging Passing System\",\n    keywords = \"telesto protocol code generator message passing system\",\n    install_requires = (\"jinja2\", )\n)\n", "code_toks_joined": "from sys import version_info <NEWLINE> from setuptools import setup , find_packages <NEWLINE> basename = <STRING> <NEWLINE> version = <STRING> <NEWLINE> pyversion = <STRING> % ( version_info . major , version_info . minor ) <NEWLINE> setup ( <NEWLINE> <INDENT> name = basename , <NEWLINE> version = version , <NEWLINE> packages = find_packages ( ) , <NEWLINE> zip_safe = True , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> keywords = <STRING> , <NEWLINE> install_requires = ( <STRING> , ) <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"telesto\"", "\"0.1\"", "\"%s.%s\"", "\"Simon Marti, Dominic Langengger\"", "\"simarti@ethz.ch, dominicl@ethz.ch\"", "\"Protocol code generator for Telesto Messaging Passing System\"", "\"telesto protocol code generator message passing system\"", "\"jinja2\""]}}], ["53f55c7f393977c23ee9218a7cc7862f", {"code_string": "from django.db import models\nfrom django.utils.translation import ugettext_lazy as _\nCOLOR_CHOICES = (('default', _('Default')),\n    ('primary', _('Primary')),\n    ('success', _('Success')),\n    ('info', _('Info')),\n    ('warning', _('Warning')),\n    ('danger', _('Danger')))\n", "code_toks_joined": "from django . db import models <NEWLINE> from django . utils . translation import ugettext_lazy as _ <NEWLINE> COLOR_CHOICES = ( ( <STRING> , _ ( <STRING> ) ) , <NEWLINE> <INDENT> ( <STRING> , _ ( <STRING> ) ) , <NEWLINE> ( <STRING> , _ ( <STRING> ) ) , <NEWLINE> ( <STRING> , _ ( <STRING> ) ) , <NEWLINE> ( <STRING> , _ ( <STRING> ) ) , <NEWLINE> ( <STRING> , _ ( <STRING> ) ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'default'", "'Default'", "'primary'", "'Primary'", "'success'", "'Success'", "'info'", "'Info'", "'warning'", "'Warning'", "'danger'", "'Danger'"]}}], ["9331695e36884087cebe26389a219eae", {"code_string": "def tout_decharger(self):\n    \"\"\"M\u00e9thode d\u00e9chargeant tous les modules\"\"\"\n    for module in self.modules:\n        self.decharger_module(module.type, module.nom)\n", "code_toks_joined": "def tout_decharger ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> for module in self . modules : <NEWLINE> <INDENT> self . decharger_module ( module . type , module . nom ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"M\u00e9thode d\u00e9chargeant tous les modules\"\"\""]}}], ["8c26d7c4d33cb41b09e92ada9d69e394", {"code_string": "def oid_repr(oid):\n    if isinstance(oid, StringType) and len(oid) == 8:\n        return '%16x' % U64(oid)\n    else:\n        return repr(oid)\n", "code_toks_joined": "def oid_repr ( oid ) : <NEWLINE> <INDENT> if isinstance ( oid , StringType ) and len ( oid ) == 8 : <NEWLINE> <INDENT> return <STRING> % U64 ( oid ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return repr ( oid ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'%16x'"]}}], ["85459b5d49cf913bf05f1e8246492c7c", {"code_string": "class L:\n    ModManager = None\n    InputManager = None\n    PlayerManager = None\n    GameLoopManager = None\n    MapManager = None\n    ModManager = None\n    UnitManager = None\n    CityManager = None\n    WidgetManager = None\n    TileMap = None\n    Screen = None\n    Grid = None\n    RootDirectory = None\n", "code_toks_joined": "class L : <NEWLINE> <INDENT> ModManager = None <NEWLINE> InputManager = None <NEWLINE> PlayerManager = None <NEWLINE> GameLoopManager = None <NEWLINE> MapManager = None <NEWLINE> ModManager = None <NEWLINE> UnitManager = None <NEWLINE> CityManager = None <NEWLINE> WidgetManager = None <NEWLINE> TileMap = None <NEWLINE> Screen = None <NEWLINE> Grid = None <NEWLINE> RootDirectory = None <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["419fb6648a429df26b8513c418a10436", {"code_string": "class GetCreditCardResult:\n    \"\"\"NOTE: This class is auto generated by the swagger code generator program.\"\"\"\n    def __init__(self):\n        self.swaggerTypes = {\n            'credit_card': 'CreditCardInfo'\n        }\n        self.credit_card = None\n", "code_toks_joined": "class GetCreditCardResult : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self ) : <NEWLINE> <INDENT> self . swaggerTypes = { <NEWLINE> <INDENT> <STRING> : <STRING> <NEWLINE> <DEDENT> } <NEWLINE> self . credit_card = None <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"NOTE: This class is auto generated by the swagger code generator program.\"\"\"", "'credit_card'", "'CreditCardInfo'"]}}], ["1e8909b124e9abaf08a24662bbaad36c", {"code_string": "def IsAllowed(self):\n    \"\"\"Returns ``True`` if the change is allowed (L{Veto} hasn't been called) or\"\"\"\n    return self.isAllowed\n", "code_toks_joined": "def IsAllowed ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . isAllowed <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Returns ``True`` if the change is allowed (L{Veto} hasn't been called) or\"\"\""]}}], ["7679e5f4db941da2ceea98e58e3ef8f1", {"code_string": "__author__ = 'fyu'\nfrom config import *\nfrom prepare import prepareDataStringFile as pd\nupdate_file_names = []\nfor per in pers:\n    update_file_name = data_dir + 'update' + str(per) + suffix\n    pd.prepareUpdateList(per, num_lines, update_file_name)\nprint('Update lists created.')\n", "code_toks_joined": "__author__ = <STRING> <NEWLINE> from config import * <NEWLINE> from prepare import prepareDataStringFile as pd <NEWLINE> update_file_names = [ ] <NEWLINE> for per in pers : <NEWLINE> <INDENT> update_file_name = data_dir + <STRING> + str ( per ) + suffix <NEWLINE> pd . prepareUpdateList ( per , num_lines , update_file_name ) <NEWLINE> <DEDENT> print ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'fyu'", "'update'", "'Update lists created.'"]}}], ["80e33d8787ae8b6f94ad185038e7570c", {"code_string": "def __init__(self):\n    \"\"\"Instance vars:\"\"\"\n    Algorithm.__init__(self)\n    self.name = \"Gauss Blur\"\n    self.parent = \"Preprocessing\"\n    self.kernelsize = IntegerSlider(\"kernelsize\", 1, 20, 1, 1)\n    self.sigmaX = FloatSlider(\"sigmaX\", 1.0, 100.0, 0.1, 1.0)\n    self.channel1 = CheckBox(\"channel1\", True)\n    self.channel2 = CheckBox(\"channel2\", True)\n    self.channel3 = CheckBox(\"channel3\", True)\n    self.integer_sliders.append(self.kernelsize)\n    self.float_sliders.append(self.sigmaX)\n", "code_toks_joined": "def __init__ ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> Algorithm . __init__ ( self ) <NEWLINE> self . name = <STRING> <NEWLINE> self . parent = <STRING> <NEWLINE> self . kernelsize = IntegerSlider ( <STRING> , 1 , 20 , 1 , 1 ) <NEWLINE> self . sigmaX = FloatSlider ( <STRING> , 1.0 , 100.0 , 0.1 , 1.0 ) <NEWLINE> self . channel1 = CheckBox ( <STRING> , True ) <NEWLINE> self . channel2 = CheckBox ( <STRING> , True ) <NEWLINE> self . channel3 = CheckBox ( <STRING> , True ) <NEWLINE> self . integer_sliders . append ( self . kernelsize ) <NEWLINE> self . float_sliders . append ( self . sigmaX ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Instance vars:\"\"\"", "\"Gauss Blur\"", "\"Preprocessing\"", "\"kernelsize\"", "\"sigmaX\"", "\"channel1\"", "\"channel2\"", "\"channel3\""]}}], ["9512d002a72a237e199e195f8a56eab2", {"code_string": "{'name': 'Balance on lines',\n    'summary': 'Display balance totals in move line view',\n    'version': '8.0.1.1.0',\n    'author': \"Camptocamp,Odoo Community Association (OCA)\",\n    'maintainter': 'Camptocamp',\n    'category': 'Accounting',\n    'depends': ['account'],\n    'description': \"\"\"Balance for a line\"\"\",\n    'website': 'http://www.camptocamp.com',\n    'data': ['account_move_line_view.xml'],\n    'tests': [],\n    'installable': True,\n    'auto_install': False,\n    'license': 'AGPL-3',\n    'application': False,\n    }\n", "code_toks_joined": "{ <STRING> : <STRING> , <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : [ <STRING> ] , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : [ <STRING> ] , <NEWLINE> <STRING> : [ ] , <NEWLINE> <STRING> : True , <NEWLINE> <STRING> : False , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : False , <NEWLINE> } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'name'", "'Balance on lines'", "'summary'", "'Display balance totals in move line view'", "'version'", "'8.0.1.1.0'", "'author'", "\"Camptocamp,Odoo Community Association (OCA)\"", "'maintainter'", "'Camptocamp'", "'category'", "'Accounting'", "'depends'", "'account'", "'description'", "\"\"\"Balance for a line\"\"\"", "'website'", "'http://www.camptocamp.com'", "'data'", "'account_move_line_view.xml'", "'tests'", "'installable'", "'auto_install'", "'license'", "'AGPL-3'", "'application'"]}}], ["8a3e51bab772f50f065899f43dad04b3", {"code_string": "from haystack.indexes import *\nfrom haystack import site\nfrom models import Contact\n", "code_toks_joined": "from haystack . indexes import * <NEWLINE> from haystack import site <NEWLINE> from models import Contact <NEWLINE>", "anonymize_dict": {}}], ["a225316069d057588ae761c32482ea45", {"code_string": "'''Name:\t\tProblem 2'''\nn1 = 1\nn2 = 2\ntot = n2\ni = 1\nwhile((n1 + n2) < 4000000):\n    sum = n1 + n2\n    n1 = n2\n    n2 = sum\n    if(i == 3):\n        i = 1\n        tot += sum\n    else:\n        i += 1\nprint(str(tot))\n", "code_toks_joined": "<STRING> <NEWLINE> n1 = 1 <NEWLINE> n2 = 2 <NEWLINE> tot = n2 <NEWLINE> i = 1 <NEWLINE> while ( ( n1 + n2 ) < 4000000 ) : <NEWLINE> <INDENT> sum = n1 + n2 <NEWLINE> n1 = n2 <NEWLINE> n2 = sum <NEWLINE> if ( i == 3 ) : <NEWLINE> <INDENT> i = 1 <NEWLINE> tot += sum <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> i += 1 <NEWLINE> <DEDENT> <DEDENT> print ( str ( tot ) ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Name:\t\tProblem 2'''"]}}], ["9cc0beef86616070ad3424ddae2a5481", {"code_string": "'''Created on Oct 22, 2014'''\nimport json\nfrom common import findFileInTheProject\nimport logging.config\nlogger = logging.getLogger(__name__)\nDEFAULT_LOG_FILENAME = 'logging.json'\n", "code_toks_joined": "<STRING> <NEWLINE> import json <NEWLINE> from common import findFileInTheProject <NEWLINE> import logging . config <NEWLINE> logger = logging . getLogger ( __name__ ) <NEWLINE> DEFAULT_LOG_FILENAME = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Created on Oct 22, 2014'''", "'logging.json'"]}}], ["80cb57156fb8cf197025ed4644e3ce33", {"code_string": "class ResponsiveImageSerializer(TaggitSerializer, serializers.ModelSerializer):\n    tags = TagListSerializerField()\n    class Meta(object):\n        model = ResponsiveImage\n        fields = (\n            'id', 'name', 'timestamp', 'description', 'thumb',\n            'original', 'wide', 'lg', 'md', 'sm', 'xs', 'tags',\n            'photographer'\n        )\n", "code_toks_joined": "class ResponsiveImageSerializer ( TaggitSerializer , serializers . ModelSerializer ) : <NEWLINE> <INDENT> tags = TagListSerializerField ( ) <NEWLINE> class Meta ( object ) : <NEWLINE> <INDENT> model = ResponsiveImage <NEWLINE> fields = ( <NEWLINE> <INDENT> <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <NEWLINE> <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <NEWLINE> <STRING> <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'id'", "'name'", "'timestamp'", "'description'", "'thumb'", "'original'", "'wide'", "'lg'", "'md'", "'sm'", "'xs'", "'tags'", "'photographer'"]}}], ["335e8b62589afeca1c9bd389c071f8ce", {"code_string": "import socket\nimport asyncio\nimport aiohttp\nimport re\n", "code_toks_joined": "import socket <NEWLINE> import asyncio <NEWLINE> import aiohttp <NEWLINE> import re <NEWLINE>", "anonymize_dict": {}}], ["13c8a18adae74e9109ecf42e23b4a123", {"code_string": "def update_requirements_file(filename):\n    with open(filename, 'r') as file:\n        content = file.read()\n        content = re.sub('^(.*?pygit2.*?)$', 'pygit2<={}'.format(libgit2_version), content, flags = re.MULTILINE)\n    with open(filename, 'w') as file:\n        file.write(content)\n", "code_toks_joined": "def update_requirements_file ( filename ) : <NEWLINE> <INDENT> with open ( filename , <STRING> ) as file : <NEWLINE> <INDENT> content = file . read ( ) <NEWLINE> content = re . sub ( <STRING> , <STRING> . format ( libgit2_version ) , content , flags = re . MULTILINE ) <NEWLINE> <DEDENT> with open ( filename , <STRING> ) as file : <NEWLINE> <INDENT> file . write ( content ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'r'", "'^(.*?pygit2.*?)$'", "'pygit2<={}'", "'w'"]}}], ["5cfc24659cab86d49b49a7ea9ccfcd3a", {"code_string": "class tee:\n    def __init__(self, * files):\n        self.files = files\n    def write(self, bytes):\n        for file in self.files:\n            file.write(bytes)\n", "code_toks_joined": "class tee : <NEWLINE> <INDENT> def __init__ ( self , * files ) : <NEWLINE> <INDENT> self . files = files <NEWLINE> <DEDENT> def write ( self , bytes ) : <NEWLINE> <INDENT> for file in self . files : <NEWLINE> <INDENT> file . write ( bytes ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["446f922c990a8f7b071275091504f73d", {"code_string": "def test_version(self):\n    expected_resp = json.dumps({\n        u'APIName': u'api',\n        u'APIVersion': u'1.1.12.0-beta-201210081020',\n        u'status_code': 200,\n        u'status_message': u'API Version Lookup',\n        u'status_time': u'2010-10-22T17:42:59.556Z'}, sort_keys = True)\n    mb = MessageBusAPIClient(self.api_key)\n    mb.__dict__[\n        '_MessageBusBase__connection'] = self._setup_mock_connection('GET', '/version', '', 200,\n            expected_resp)\n    received_resp = json.dumps(mb.api_version(), sort_keys = True)\n    self._validate_results(expected_resp, received_resp)\n    self.mocker.UnsetStubs()\n", "code_toks_joined": "def test_version ( self ) : <NEWLINE> <INDENT> expected_resp = json . dumps ( { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : 200 , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> } , sort_keys = True ) <NEWLINE> <DEDENT> mb = MessageBusAPIClient ( self . api_key ) <NEWLINE> mb . __dict__ [ <NEWLINE> <INDENT> <STRING> ] = self . _setup_mock_connection ( <STRING> , <STRING> , <STRING> , 200 , <NEWLINE> <INDENT> expected_resp ) <NEWLINE> <DEDENT> <DEDENT> received_resp = json . dumps ( mb . api_version ( ) , sort_keys = True ) <NEWLINE> self . _validate_results ( expected_resp , received_resp ) <NEWLINE> self . mocker . UnsetStubs ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["u'APIName'", "u'api'", "u'APIVersion'", "u'1.1.12.0-beta-201210081020'", "u'status_code'", "u'status_message'", "u'API Version Lookup'", "u'status_time'", "u'2010-10-22T17:42:59.556Z'", "'_MessageBusBase__connection'", "'GET'", "'/version'", "''"]}}], ["50af2531bfcd465fbbabf7bde4d659e2", {"code_string": "def cwh_to_chw(m):\n    '''Reorder 3-dim array from C x W x H to C x H x W'''\n    if m.ndim == 3:\n        m = m.transpose((0, 2, 1))\n    else:\n        raise AttributeError(\"No. of dimensions (%d) not supported.\" % m.ndim)\n    return m\n", "code_toks_joined": "def cwh_to_chw ( m ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if m . ndim == 3 : <NEWLINE> <INDENT> m = m . transpose ( ( 0 , 2 , 1 ) ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> raise AttributeError ( <STRING> % m . ndim ) <NEWLINE> <DEDENT> return m <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Reorder 3-dim array from C x W x H to C x H x W'''", "\"No. of dimensions (%d) not supported.\""]}}], ["c167e5021baa12f88925fdc33c42c812", {"code_string": "def add_test_dimensions(cls):\n    super(TestStringQueries, cls).add_test_dimensions()\n    cls.TestMatrix.add_dimension(\n        create_exec_option_dimension(disable_codegen_options = [False, True]))\n    cls.TestMatrix.add_constraint(lambda v: v.get_value('table_format').file_format in['text'] and\n        v.get_value('table_format').compression_codec in['none'])\n", "code_toks_joined": "def add_test_dimensions ( cls ) : <NEWLINE> <INDENT> super ( TestStringQueries , cls ) . add_test_dimensions ( ) <NEWLINE> cls . TestMatrix . add_dimension ( <NEWLINE> <INDENT> create_exec_option_dimension ( disable_codegen_options = [ False , True ] ) ) <NEWLINE> <DEDENT> cls . TestMatrix . add_constraint ( lambda v : v . get_value ( <STRING> ) . file_format in [ <STRING> ] and <NEWLINE> <INDENT> v . get_value ( <STRING> ) . compression_codec in [ <STRING> ] ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'table_format'", "'text'", "'table_format'", "'none'"]}}], ["cc3fa3d3dd6bcd33a817a7e3a3c727be", {"code_string": "from.ListAndSearch import ListAndSearch\nfrom.Encode import Encode\nfrom.Decode import Decode\n", "code_toks_joined": "from . ListAndSearch import ListAndSearch <NEWLINE> from . Encode import Encode <NEWLINE> from . Decode import Decode <NEWLINE>", "anonymize_dict": {}}], ["b1dae542ee51d196ef1ca6ac6fde5a38", {"code_string": "def u2opener(self):\n    \"\"\"Create a urllib opener.\"\"\"\n    if self.urlopener is None or self.proxy != self.options.proxy:\n        openers = self.u2handlers()\n        openers.insert(0, self.build_ssl_opener())\n        self.urlopener = u2.build_opener(* openers)\n    return self.urlopener\n", "code_toks_joined": "def u2opener ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if self . urlopener is None or self . proxy != self . options . proxy : <NEWLINE> <INDENT> openers = self . u2handlers ( ) <NEWLINE> openers . insert ( 0 , self . build_ssl_opener ( ) ) <NEWLINE> self . urlopener = u2 . build_opener ( * openers ) <NEWLINE> <DEDENT> return self . urlopener <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Create a urllib opener.\"\"\""]}}], ["69218467d9d3d7aeccdaa69faeee48f0", {"code_string": "def poll_stat_namer(event):\n    if not isinstance(event, int):\n        raise TypeError(\"`event' must be int, but it is `{}'\".format(event))\n    devided = poll_stat_devider(event)\n    names = set()\n    for i in POLL_CONSTS.keys():\n        for j in devided:\n            if POLL_CONSTS[i] == j:\n                names.add(i)\n    return list(names)\n", "code_toks_joined": "def poll_stat_namer ( event ) : <NEWLINE> <INDENT> if not isinstance ( event , int ) : <NEWLINE> <INDENT> raise TypeError ( <STRING> . format ( event ) ) <NEWLINE> <DEDENT> devided = poll_stat_devider ( event ) <NEWLINE> names = set ( ) <NEWLINE> for i in POLL_CONSTS . keys ( ) : <NEWLINE> <INDENT> for j in devided : <NEWLINE> <INDENT> if POLL_CONSTS [ i ] == j : <NEWLINE> <INDENT> names . add ( i ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> return list ( names ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"`event' must be int, but it is `{}'\""]}}], ["71a363950afb355606292f2a7769c5bf", {"code_string": "def build_rsync_manifest(self):\n    manifest_path = os.path.normpath(os.path.join(OUTPUT_DIRECTORY, 'rsync_manifest.txt'))\n    with open(manifest_path, 'w', encoding = 'utf8') as f:\n        for each in self.static:\n            new_path = each.replace(RSYNC_STRIP, \"\").replace(\"\\\\\", \"/\")\n            f.write(new_path + \"\\n\")\n        for each in self.compressed:\n            new_path = each.replace(RSYNC_STRIP, \"\").replace(\"\\\\\", \"/\")\n            f.write(new_path + \"\\n\")\n", "code_toks_joined": "def build_rsync_manifest ( self ) : <NEWLINE> <INDENT> manifest_path = os . path . normpath ( os . path . join ( OUTPUT_DIRECTORY , <STRING> ) ) <NEWLINE> with open ( manifest_path , <STRING> , encoding = <STRING> ) as f : <NEWLINE> <INDENT> for each in self . static : <NEWLINE> <INDENT> new_path = each . replace ( RSYNC_STRIP , <STRING> ) . replace ( <STRING> , <STRING> ) <NEWLINE> f . write ( new_path + <STRING> ) <NEWLINE> <DEDENT> for each in self . compressed : <NEWLINE> <INDENT> new_path = each . replace ( RSYNC_STRIP , <STRING> ) . replace ( <STRING> , <STRING> ) <NEWLINE> f . write ( new_path + <STRING> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'rsync_manifest.txt'", "'w'", "'utf8'", "\"\"", "\"\\\\\"", "\"/\"", "\"\\n\"", "\"\"", "\"\\\\\"", "\"/\"", "\"\\n\""]}}], ["1149ee590000f8a0fbf16ea10d04d16d", {"code_string": "def suite():\n    \"\"\"Define suite\"\"\"\n    test_suite = trytond.tests.test_tryton.suite()\n    test_suite.addTests(\n        unittest.TestLoader().loadTestsFromTestCase(TestSerialization)\n    )\n    return test_suite\n", "code_toks_joined": "def suite ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> test_suite = trytond . tests . test_tryton . suite ( ) <NEWLINE> test_suite . addTests ( <NEWLINE> <INDENT> unittest . TestLoader ( ) . loadTestsFromTestCase ( TestSerialization ) <NEWLINE> <DEDENT> ) <NEWLINE> return test_suite <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Define suite\"\"\""]}}], ["38ee1fea61882c618dcb3431b511e9d1", {"code_string": "\"\"\"convert adjacency lists to edge lists\"\"\"\nimport sys\nimport CGAT.Experiment as E\n", "code_toks_joined": "<STRING> <NEWLINE> import sys <NEWLINE> import CGAT . Experiment as E <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"convert adjacency lists to edge lists\"\"\""]}}], ["f24c58996356469a04c409af53fa7317", {"code_string": "\"\"\"pagination for sqlalchemy\"\"\"\nfrom flask import current_app, request, url_for\nfrom.utils import merge_dict\n", "code_toks_joined": "<STRING> <NEWLINE> from flask import current_app , request , url_for <NEWLINE> from . utils import merge_dict <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"pagination for sqlalchemy\"\"\""]}}], ["e1888f42704ef4bc2535f162ed3fc055", {"code_string": "class DateTimeConstraint(BaseConstraint):\n    \"\"\"Class representing constraints on a DateTime field type.\"\"\"\n    name_type = \"datetime\"\n    constraints = [\"pkey\"]\n    def __init__(self, base_type, pkey = False):\n        self.base_type = base_type\n        self.pkey = pkey\n    def control(self, value):\n        \"\"\"Return whether the value is correct for these constraints.\"\"\"\n        return True\n", "code_toks_joined": "class DateTimeConstraint ( BaseConstraint ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> name_type = <STRING> <NEWLINE> constraints = [ <STRING> ] <NEWLINE> def __init__ ( self , base_type , pkey = False ) : <NEWLINE> <INDENT> self . base_type = base_type <NEWLINE> self . pkey = pkey <NEWLINE> <DEDENT> def control ( self , value ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return True <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Class representing constraints on a DateTime field type.\"\"\"", "\"datetime\"", "\"pkey\"", "\"\"\"Return whether the value is correct for these constraints.\"\"\""]}}], ["4bd40efc07d528664ea726b84ad2859d", {"code_string": "def list_resource_group(self):\n    self.log('List items')\n    try:\n        response = self.storage_client.storage_accounts.list_by_resource_group(self.resource_group)\n    except Exception as exc:\n        self.fail(\"Error listing for resource group {0} - {1}\".format(self.resource_group, str(exc)))\n    results = []\n    for item in response:\n        if self.has_tags(item.tags, self.tags):\n            results.append(self.serialize_obj(item, AZURE_OBJECT_CLASS))\n    return results\n", "code_toks_joined": "def list_resource_group ( self ) : <NEWLINE> <INDENT> self . log ( <STRING> ) <NEWLINE> try : <NEWLINE> <INDENT> response = self . storage_client . storage_accounts . list_by_resource_group ( self . resource_group ) <NEWLINE> <DEDENT> except Exception as exc : <NEWLINE> <INDENT> self . fail ( <STRING> . format ( self . resource_group , str ( exc ) ) ) <NEWLINE> <DEDENT> results = [ ] <NEWLINE> for item in response : <NEWLINE> <INDENT> if self . has_tags ( item . tags , self . tags ) : <NEWLINE> <INDENT> results . append ( self . serialize_obj ( item , AZURE_OBJECT_CLASS ) ) <NEWLINE> <DEDENT> <DEDENT> return results <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'List items'", "\"Error listing for resource group {0} - {1}\""]}}], ["656936e847afe101b8ae2890d3aba7f0", {"code_string": "appcode = \"x4ga\"\nappdesc = \"X4 Gestione Aziendale\"\nfrom _branch import branch\nVERSION_BRANCH = branch\nfrom _version import apptype, appType, appinfo\nVERSION_MAJOR = 1\nVERSION_MINOR = 5\nVERSION_RELEASE = 46\nVERSION_TAG = \"\"\nVERSION_TYPE = apptype\nVERSION_TYPEXT = appType\nVERSION_INFO = appinfo\n__min_compat_ver__ = '1.5.44'\nVERSION = (VERSION_MAJOR, VERSION_MINOR, VERSION_RELEASE, VERSION_TAG)\nVERSION_STRING = \"%s.%s.%s\" %(VERSION_MAJOR,\n    VERSION_MINOR,\n    str(VERSION_RELEASE).zfill(2))\n__version_exe__ = VERSION_STRING\nif VERSION_TAG:\n    VERSION_STRING += \" %s\" % VERSION_TAG\n__version__ = VERSION_STRING\n", "code_toks_joined": "appcode = <STRING> <NEWLINE> appdesc = <STRING> <NEWLINE> from _branch import branch <NEWLINE> VERSION_BRANCH = branch <NEWLINE> from _version import apptype , appType , appinfo <NEWLINE> VERSION_MAJOR = 1 <NEWLINE> VERSION_MINOR = 5 <NEWLINE> VERSION_RELEASE = 46 <NEWLINE> VERSION_TAG = <STRING> <NEWLINE> VERSION_TYPE = apptype <NEWLINE> VERSION_TYPEXT = appType <NEWLINE> VERSION_INFO = appinfo <NEWLINE> __min_compat_ver__ = <STRING> <NEWLINE> VERSION = ( VERSION_MAJOR , VERSION_MINOR , VERSION_RELEASE , VERSION_TAG ) <NEWLINE> VERSION_STRING = <STRING> % ( VERSION_MAJOR , <NEWLINE> <INDENT> VERSION_MINOR , <NEWLINE> str ( VERSION_RELEASE ) . zfill ( 2 ) ) <NEWLINE> <DEDENT> __version_exe__ = VERSION_STRING <NEWLINE> if VERSION_TAG : <NEWLINE> <INDENT> VERSION_STRING += <STRING> % VERSION_TAG <NEWLINE> <DEDENT> __version__ = VERSION_STRING <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"x4ga\"", "\"X4 Gestione Aziendale\"", "\"\"", "'1.5.44'", "\"%s.%s.%s\"", "\" %s\""]}}], ["b99edd0412e7adc800678a86a71af798", {"code_string": "def application(chip):\n    keyboard_test = Component(\n    r\"\"\"int ps2 = input(\"ps2\");\"\"\", inline = True)\n    keyboard_test(\n        chip,\n        inputs = {\n            \"rs232_rx\": chip.inputs[\"input_rs232_rx\"],\n            \"ps2\": chip.inputs[\"input_ps2\"],\n        },\n        outputs = {\n            \"rs232_tx\": chip.outputs[\"output_rs232_tx\"],\n        },\n        parameters = {}\n        )\n", "code_toks_joined": "def application ( chip ) : <NEWLINE> <INDENT> keyboard_test = Component ( <NEWLINE> <STRING> , inline = True ) <NEWLINE> keyboard_test ( <NEWLINE> <INDENT> chip , <NEWLINE> inputs = { <NEWLINE> <INDENT> <STRING> : chip . inputs [ <STRING> ] , <NEWLINE> <STRING> : chip . inputs [ <STRING> ] , <NEWLINE> <DEDENT> } , <NEWLINE> outputs = { <NEWLINE> <INDENT> <STRING> : chip . outputs [ <STRING> ] , <NEWLINE> <DEDENT> } , <NEWLINE> parameters = { } <NEWLINE> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["r\"\"\"int ps2 = input(\"ps2\");\"\"\"", "\"rs232_rx\"", "\"input_rs232_rx\"", "\"ps2\"", "\"input_ps2\"", "\"rs232_tx\"", "\"output_rs232_tx\""]}}], ["0b2c2a9f90ea08a4017dd7e4b2a06df0", {"code_string": "def reload_settings(** kwargs):\n    if kwargs['setting'] == 'KNOWLEDGEBASE':\n        settings.update(kwargs['value'])\n", "code_toks_joined": "def reload_settings ( ** kwargs ) : <NEWLINE> <INDENT> if kwargs [ <STRING> ] == <STRING> : <NEWLINE> <INDENT> settings . update ( kwargs [ <STRING> ] ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'setting'", "'KNOWLEDGEBASE'", "'value'"]}}], ["377e5ed9404999750c40bfd1b77dc497", {"code_string": "class MockSeries(learn.Series):\n    \"\"\"A mock series for use in testing.\"\"\"\n    def __init__(self, cachekey, mock_tensor):\n        super(MockSeries, self).__init__()\n        self._cachekey = cachekey\n        self._mock_tensor = mock_tensor\n    def build(self, cache):\n        return self._mock_tensor\n    def __repr__(self):\n        return self._cachekey\n", "code_toks_joined": "class MockSeries ( learn . Series ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , cachekey , mock_tensor ) : <NEWLINE> <INDENT> super ( MockSeries , self ) . __init__ ( ) <NEWLINE> self . _cachekey = cachekey <NEWLINE> self . _mock_tensor = mock_tensor <NEWLINE> <DEDENT> def build ( self , cache ) : <NEWLINE> <INDENT> return self . _mock_tensor <NEWLINE> <DEDENT> def __repr__ ( self ) : <NEWLINE> <INDENT> return self . _cachekey <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"A mock series for use in testing.\"\"\""]}}], ["2685be46ecbcc81f31c703a27e09222c", {"code_string": "from.udp import UdpDiscoveryMedium\nfrom.memory import MemoryDiscoveryMedium\n__all__ = [UdpDiscoveryMedium, MemoryDiscoveryMedium]\n", "code_toks_joined": "from . udp import UdpDiscoveryMedium <NEWLINE> from . memory import MemoryDiscoveryMedium <NEWLINE> __all__ = [ UdpDiscoveryMedium , MemoryDiscoveryMedium ] <NEWLINE>", "anonymize_dict": {}}], ["4cdc21230d47d5966705ec35b1353222", {"code_string": "import logging\nimport os\nCONFIG_PATH = '/genconf/config.yaml'\nSSH_KEY_PATH = '/genconf/ssh_key'\nIP_DETECT_PATH = '/genconf/ip-detect'\nREXRAY_CONFIG_PATH = '/genconf/rexray.yaml'\nSERVE_DIR = '/genconf/serve'\nSTATE_DIR = '/genconf/state'\nGENCONF_DIR = '/genconf'\nlog = logging.getLogger(__name__)\n", "code_toks_joined": "import logging <NEWLINE> import os <NEWLINE> CONFIG_PATH = <STRING> <NEWLINE> SSH_KEY_PATH = <STRING> <NEWLINE> IP_DETECT_PATH = <STRING> <NEWLINE> REXRAY_CONFIG_PATH = <STRING> <NEWLINE> SERVE_DIR = <STRING> <NEWLINE> STATE_DIR = <STRING> <NEWLINE> GENCONF_DIR = <STRING> <NEWLINE> log = logging . getLogger ( __name__ ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'/genconf/config.yaml'", "'/genconf/ssh_key'", "'/genconf/ip-detect'", "'/genconf/rexray.yaml'", "'/genconf/serve'", "'/genconf/state'", "'/genconf'"]}}], ["557449df72f6f36a7a5755f62cd41541", {"code_string": "\"\"\"pycounter\"\"\"\nfrom __future__ import absolute_import\nfrom pycounter import exceptions, report, sushi\nfrom pycounter.version import __version__\n__all__ = ['__version__', 'report', 'sushi', 'exceptions']\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import absolute_import <NEWLINE> from pycounter import exceptions , report , sushi <NEWLINE> from pycounter . version import __version__ <NEWLINE> __all__ = [ <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"pycounter\"\"\"", "'__version__'", "'report'", "'sushi'", "'exceptions'"]}}], ["301e68213ba77c431cc9bd61f3737dbf", {"code_string": "import argparse\nimport os\nfrom cbc.parsers import CBCConfigParser, ExtendedInterpolation\nRECIPE_TYPES = ['python',\n    'make',\n    'gnu',\n    'scons',\n    'cmake']\n", "code_toks_joined": "import argparse <NEWLINE> import os <NEWLINE> from cbc . parsers import CBCConfigParser , ExtendedInterpolation <NEWLINE> RECIPE_TYPES = [ <STRING> , <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'python'", "'make'", "'gnu'", "'scons'", "'cmake'"]}}], ["47a0e0c0902b15dfa638ec5bb3c12102", {"code_string": "def _set_discount(self):\n    discount = 0.0\n    if self.price_unit:\n        total_discount_perc = self.total_discount / 100.0\n        list_discount_perc = self.list_discount / 100.0\n        discount = 1.0 -((1.0 - total_discount_perc) /(1.0 - list_discount_perc))\n    self.discount = discount * 100.0\n", "code_toks_joined": "def _set_discount ( self ) : <NEWLINE> <INDENT> discount = 0.0 <NEWLINE> if self . price_unit : <NEWLINE> <INDENT> total_discount_perc = self . total_discount / 100.0 <NEWLINE> list_discount_perc = self . list_discount / 100.0 <NEWLINE> discount = 1.0 - ( ( 1.0 - total_discount_perc ) / ( 1.0 - list_discount_perc ) ) <NEWLINE> <DEDENT> self . discount = discount * 100.0 <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["636ed0134981a668f00b0ebefa5cb3c7", {"code_string": "def send_message(message):\n    \"\"\"Send a message to one of the connected clients.\"\"\"\n    if message[\"sender_id\"] in INDEX:\n        INDEX[message[\"sender_id\"]].sendMessage(\n            message[\"result\"].encode('utf8'), False)\n    else:\n        LOGGER.warning(\"There is no client with the UID %s!\",\n            message[\"sender_id\"])\n", "code_toks_joined": "def send_message ( message ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if message [ <STRING> ] in INDEX : <NEWLINE> <INDENT> INDEX [ message [ <STRING> ] ] . sendMessage ( <NEWLINE> <INDENT> message [ <STRING> ] . encode ( <STRING> ) , False ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> LOGGER . warning ( <STRING> , <NEWLINE> <INDENT> message [ <STRING> ] ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Send a message to one of the connected clients.\"\"\"", "\"sender_id\"", "\"sender_id\"", "\"result\"", "'utf8'", "\"There is no client with the UID %s!\"", "\"sender_id\""]}}], ["e28d1923fcc8aad3c51c2292fb33a88e", {"code_string": "\"\"\"container property\"\"\"\nfrom __future__ import unicode_literals\nimport regex as re\nfrom rebulk import Rebulk\nfrom..common.validators import seps_surround\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import unicode_literals <NEWLINE> import regex as re <NEWLINE> from rebulk import Rebulk <NEWLINE> from . . common . validators import seps_surround <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"container property\"\"\""]}}], ["45e08184eecb42e24c7650fafc12bca1", {"code_string": "def fetch_files(self):\n    folder = UPLOAD_FOLDER\n    allfiles = [f for f in listdir(folder) if isfile(join(folder, f)) if not f.startswith('.')]\n    if allfiles:\n        return allfiles\n", "code_toks_joined": "def fetch_files ( self ) : <NEWLINE> <INDENT> folder = UPLOAD_FOLDER <NEWLINE> allfiles = [ f for f in listdir ( folder ) if isfile ( join ( folder , f ) ) if not f . startswith ( <STRING> ) ] <NEWLINE> if allfiles : <NEWLINE> <INDENT> return allfiles <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'.'"]}}], ["458baa3f6f60839a87a6b8a30161a531", {"code_string": "import testlib\nimport pybitcoin\nimport json\nimport os\nimport sys\nimport virtualchain\nwallets = [\n    testlib.Wallet(\"5JesPiN68qt44Hc2nT8qmyZ1JDwHebfoh9KQ52Lazb1m1LaKNj9\", 100000000000),\n    testlib.Wallet(\"5KHqsiU9qa77frZb6hQy9ocV7Sus9RWJcQGYYBJJBb2Efj1o77e\", 100000000000),\n    testlib.Wallet(\"5Kg5kJbQHvk1B64rJniEmgbD83FpZpbw2RjdAZEzTefs9ihN3Bz\", 100000000000),\n    testlib.Wallet(\"5JuVsoS9NauksSkqEjbUZxWwgGDQbMwPsEfoRBSpLpgDX1RtLX7\", 100000000000),\n    testlib.Wallet(\"5KEpiSRr1BrT8vRD7LKGCEmudokTh1iMHbiThMQpLdwBwhDJB1T\", 100000000000)\n]\nconsensus = \"17ac43c1d8549c3181b200f1bf97eb7d\"\nworking_dir = None\n", "code_toks_joined": "import testlib <NEWLINE> import pybitcoin <NEWLINE> import json <NEWLINE> import os <NEWLINE> import sys <NEWLINE> import virtualchain <NEWLINE> wallets = [ <NEWLINE> <INDENT> testlib . Wallet ( <STRING> , 100000000000 ) , <NEWLINE> testlib . Wallet ( <STRING> , 100000000000 ) , <NEWLINE> testlib . Wallet ( <STRING> , 100000000000 ) , <NEWLINE> testlib . Wallet ( <STRING> , 100000000000 ) , <NEWLINE> testlib . Wallet ( <STRING> , 100000000000 ) <NEWLINE> <DEDENT> ] <NEWLINE> consensus = <STRING> <NEWLINE> working_dir = None <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"5JesPiN68qt44Hc2nT8qmyZ1JDwHebfoh9KQ52Lazb1m1LaKNj9\"", "\"5KHqsiU9qa77frZb6hQy9ocV7Sus9RWJcQGYYBJJBb2Efj1o77e\"", "\"5Kg5kJbQHvk1B64rJniEmgbD83FpZpbw2RjdAZEzTefs9ihN3Bz\"", "\"5JuVsoS9NauksSkqEjbUZxWwgGDQbMwPsEfoRBSpLpgDX1RtLX7\"", "\"5KEpiSRr1BrT8vRD7LKGCEmudokTh1iMHbiThMQpLdwBwhDJB1T\"", "\"17ac43c1d8549c3181b200f1bf97eb7d\""]}}], ["e16bb90b496d342c8f26dab1d2f574cb", {"code_string": "def test_execute(self):\n    result = self.task_ep.execute(task_name = self.task_cls_name,\n        task_uuid = self.task_uuid,\n        arguments = self.task_args,\n        progress_callback = None)\n    self.assertEqual(result, self.task_result)\n", "code_toks_joined": "def test_execute ( self ) : <NEWLINE> <INDENT> result = self . task_ep . execute ( task_name = self . task_cls_name , <NEWLINE> <INDENT> task_uuid = self . task_uuid , <NEWLINE> arguments = self . task_args , <NEWLINE> progress_callback = None ) <NEWLINE> <DEDENT> self . assertEqual ( result , self . task_result ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ee78cce377231d34324ec3a96983caf5", {"code_string": "from rtc_handle import *\nfrom BasicDataType_idl import *\nimport time\nimport commands\nenv = RtmEnv(sys.argv, [\"localhost:9898\"])\nlist0 = env.name_space[\"localhost:9898\"].list_obj()\nenv.name_space['localhost:9898'].rtc_handles.keys()\nns = env.name_space['localhost:9898']\ntime.sleep(2)\ncompo1 = ns.rtc_handles[\"ConsoleIn0.rtc\"]\ncompo0 = ns.rtc_handles[\"ConsoleOut0.rtc\"]\nseqin0 = ns.rtc_handles[\"SequenceInComponent0.rtc\"]\nec = compo0.rtc_ref.get_owned_contexts()\n", "code_toks_joined": "from rtc_handle import * <NEWLINE> from BasicDataType_idl import * <NEWLINE> import time <NEWLINE> import commands <NEWLINE> env = RtmEnv ( sys . argv , [ <STRING> ] ) <NEWLINE> list0 = env . name_space [ <STRING> ] . list_obj ( ) <NEWLINE> env . name_space [ <STRING> ] . rtc_handles . keys ( ) <NEWLINE> ns = env . name_space [ <STRING> ] <NEWLINE> time . sleep ( 2 ) <NEWLINE> compo1 = ns . rtc_handles [ <STRING> ] <NEWLINE> compo0 = ns . rtc_handles [ <STRING> ] <NEWLINE> seqin0 = ns . rtc_handles [ <STRING> ] <NEWLINE> ec = compo0 . rtc_ref . get_owned_contexts ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"localhost:9898\"", "\"localhost:9898\"", "'localhost:9898'", "'localhost:9898'", "\"ConsoleIn0.rtc\"", "\"ConsoleOut0.rtc\"", "\"SequenceInComponent0.rtc\""]}}], ["0597955915f7e47249a1a6bc92252b01", {"code_string": "DOCUMENTATION = '''---'''\nimport json\nimport requests\nimport sys\nimport time\nfrom ansible.module_utils.basic import AnsibleModule\nAPI_BASE = 'https://cloud.skytap.com/'\nAPI_HEADERS = {'accept': 'application/json', 'content-type': 'application/json'}\n", "code_toks_joined": "DOCUMENTATION = <STRING> <NEWLINE> import json <NEWLINE> import requests <NEWLINE> import sys <NEWLINE> import time <NEWLINE> from ansible . module_utils . basic import AnsibleModule <NEWLINE> API_BASE = <STRING> <NEWLINE> API_HEADERS = { <STRING> : <STRING> , <STRING> : <STRING> } <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''---'''", "'https://cloud.skytap.com/'", "'accept'", "'application/json'", "'content-type'", "'application/json'"]}}], ["1308c75d6d290843604954f84be5c270", {"code_string": "import json\nfrom Tribler.Core.exceptions import TriblerException\nfrom Tribler.Test.twisted_thread import deferred\nfrom base_api_test import AbstractApiTest\n", "code_toks_joined": "import json <NEWLINE> from Tribler . Core . exceptions import TriblerException <NEWLINE> from Tribler . Test . twisted_thread import deferred <NEWLINE> from base_api_test import AbstractApiTest <NEWLINE>", "anonymize_dict": {}}], ["b89690c038838ee251f9c3b3d38c344f", {"code_string": "def migrate_users(index):\n    logger.info(\"Migrating users to index: {}\".format(index))\n    n_migr = 0\n    n_iter = 0\n    for user in User.find():\n        if user.is_active:\n            search.update_user(user, index = index)\n            n_migr += 1\n        n_iter += 1\n    logger.info('Users iterated: {0}\\nUsers migrated: {1}'.format(n_iter, n_migr))\n", "code_toks_joined": "def migrate_users ( index ) : <NEWLINE> <INDENT> logger . info ( <STRING> . format ( index ) ) <NEWLINE> n_migr = 0 <NEWLINE> n_iter = 0 <NEWLINE> for user in User . find ( ) : <NEWLINE> <INDENT> if user . is_active : <NEWLINE> <INDENT> search . update_user ( user , index = index ) <NEWLINE> n_migr += 1 <NEWLINE> <DEDENT> n_iter += 1 <NEWLINE> <DEDENT> logger . info ( <STRING> . format ( n_iter , n_migr ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Migrating users to index: {}\"", "'Users iterated: {0}\\nUsers migrated: {1}'"]}}], ["49e65e0de12d0f120e282dbfb020d140", {"code_string": "class Users(AbstractUser):\n    profile_pic = models.CharField(max_length = 30, null = True)\n    last_activity = models.DateTimeField(null = True, blank = True)\n    class Meta(AbstractUser.Meta):\n        swappable = 'user_profiles'\n", "code_toks_joined": "class Users ( AbstractUser ) : <NEWLINE> <INDENT> profile_pic = models . CharField ( max_length = 30 , null = True ) <NEWLINE> last_activity = models . DateTimeField ( null = True , blank = True ) <NEWLINE> class Meta ( AbstractUser . Meta ) : <NEWLINE> <INDENT> swappable = <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'user_profiles'"]}}], ["d3398985fb830bc8e68cff51a6888506", {"code_string": "\"\"\"A Django management command to bundle our media.\"\"\"\nfrom django.core.management.base import NoArgsCommand\nfrom media_bundler.conf import bundler_settings\nfrom media_bundler import bundler\nfrom media_bundler import versioning\n", "code_toks_joined": "<STRING> <NEWLINE> from django . core . management . base import NoArgsCommand <NEWLINE> from media_bundler . conf import bundler_settings <NEWLINE> from media_bundler import bundler <NEWLINE> from media_bundler import versioning <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"A Django management command to bundle our media.\"\"\""]}}], ["a14299a151a0b1918b4984aa5b41eb92", {"code_string": "def __init__(self):\n    self.name = \"NYSE\"\n    self.description = \"New York Stock Exchange\"\n    self.benchmark = \"NYA\"\n    self.country = \"US\"\n    self.currency = \"$\"\n    self.f_penny_threshold = 5.0\n    self.suffix = \"\"\n    now = dt.datetime.now()\n    year = now.year\n    self.all_symbols_list = \"NYSE_Active_%d\" % year\n    self.ls_indexes = ['NYA', '^GSPC', '^DJI', 'OEX', 'MID']\n    super(NYSEExchange, self).__init__()\n", "code_toks_joined": "def __init__ ( self ) : <NEWLINE> <INDENT> self . name = <STRING> <NEWLINE> self . description = <STRING> <NEWLINE> self . benchmark = <STRING> <NEWLINE> self . country = <STRING> <NEWLINE> self . currency = <STRING> <NEWLINE> self . f_penny_threshold = 5.0 <NEWLINE> self . suffix = <STRING> <NEWLINE> now = dt . datetime . now ( ) <NEWLINE> year = now . year <NEWLINE> self . all_symbols_list = <STRING> % year <NEWLINE> self . ls_indexes = [ <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE> super ( NYSEExchange , self ) . __init__ ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"NYSE\"", "\"New York Stock Exchange\"", "\"NYA\"", "\"US\"", "\"$\"", "\"\"", "\"NYSE_Active_%d\"", "'NYA'", "'^GSPC'", "'^DJI'", "'OEX'", "'MID'"]}}], ["dc92fea8f19ad39e5aef74ff9ec83832", {"code_string": "import copy\nimport re\nimport sys\nfrom SilverCity import ScintillaConstants\nimport logging\nMAX_REASONABLE_LIMIT = 10000\nWHITESPACE = '\\t\\n\\x0b\\x0c\\r '\nws_re = re.compile(\"^[\" + WHITESPACE + \"\\\\\\\\\" + \"]*$\")\ntrailing_spaces_re = re.compile(\"\\n([ \\t]*)$\")\ntrim_ws_re2 = re.compile(r'[\\r\\n\\t]')\ntrim_ws_re3 = re.compile(r' {2,}')\n", "code_toks_joined": "import copy <NEWLINE> import re <NEWLINE> import sys <NEWLINE> from SilverCity import ScintillaConstants <NEWLINE> import logging <NEWLINE> MAX_REASONABLE_LIMIT = 10000 <NEWLINE> WHITESPACE = <STRING> <NEWLINE> ws_re = re . compile ( <STRING> + WHITESPACE + <STRING> + <STRING> ) <NEWLINE> trailing_spaces_re = re . compile ( <STRING> ) <NEWLINE> trim_ws_re2 = re . compile ( <STRING> ) <NEWLINE> trim_ws_re3 = re . compile ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'\\t\\n\\x0b\\x0c\\r '", "\"^[\"", "\"\\\\\\\\\"", "\"]*$\"", "\"\\n([ \\t]*)$\"", "r'[\\r\\n\\t]'", "r' {2,}'"]}}], ["3efa68e418616beb891ff56f9d8f3629", {"code_string": "def get_delivery_backend_class(delivery_str = None):\n    return str_to_class(delivery_str, 'INVITATION_DELIVERY_BACKEND',\n        'invitation.backends.EmailDeliveryBackend')\n", "code_toks_joined": "def get_delivery_backend_class ( delivery_str = None ) : <NEWLINE> <INDENT> return str_to_class ( delivery_str , <STRING> , <NEWLINE> <INDENT> <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'INVITATION_DELIVERY_BACKEND'", "'invitation.backends.EmailDeliveryBackend'"]}}], ["b13e0dd7d93eed502ea3856055cfd33c", {"code_string": "def _update_registration_date_end(self, registration):\n    super(WizEventDeleteAssistant, self)._update_registration_date_end(\n        registration)\n    reg_date_end = str2datetime(registration.date_end)\n    wiz_from_date = _convert_to_utc_date(\n        self.from_date, time = self.start_time, tz = self.env.user.tz)\n    if wiz_from_date != reg_date_end:\n        registration.date_end = wiz_from_date\n", "code_toks_joined": "def _update_registration_date_end ( self , registration ) : <NEWLINE> <INDENT> super ( WizEventDeleteAssistant , self ) . _update_registration_date_end ( <NEWLINE> <INDENT> registration ) <NEWLINE> <DEDENT> reg_date_end = str2datetime ( registration . date_end ) <NEWLINE> wiz_from_date = _convert_to_utc_date ( <NEWLINE> <INDENT> self . from_date , time = self . start_time , tz = self . env . user . tz ) <NEWLINE> <DEDENT> if wiz_from_date != reg_date_end : <NEWLINE> <INDENT> registration . date_end = wiz_from_date <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["cc88228cc2d11b3bcd237c60b81e6ffc", {"code_string": "import os\nimport datetime\ncurrent_dir = os.path.abspath(os.path.dirname(__file__))\npicture = current_dir + \"/data/colibri.jpeg\"\ntoday = str(datetime.date.today())\n", "code_toks_joined": "import os <NEWLINE> import datetime <NEWLINE> current_dir = os . path . abspath ( os . path . dirname ( __file__ ) ) <NEWLINE> picture = current_dir + <STRING> <NEWLINE> today = str ( datetime . date . today ( ) ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"/data/colibri.jpeg\""]}}], ["851b747bcfc6b6e6cbfd01dcf481ad00", {"code_string": "class NewCSVForm(Form):\n    file_upload = FileField(validators = [DataRequired()])\n    replace_or_merge = SelectField('Would you like to replace all of your current items on the system with this upload or merge this upload with the items on the system?', choices = [('replace', 'Replace'), ('merge', 'Merge')], validators = [DataRequired()])\n    submit = SubmitField('Submit Upload')\n", "code_toks_joined": "class NewCSVForm ( Form ) : <NEWLINE> <INDENT> file_upload = FileField ( validators = [ DataRequired ( ) ] ) <NEWLINE> replace_or_merge = SelectField ( <STRING> , choices = [ ( <STRING> , <STRING> ) , ( <STRING> , <STRING> ) ] , validators = [ DataRequired ( ) ] ) <NEWLINE> submit = SubmitField ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Would you like to replace all of your current items on the system with this upload or merge this upload with the items on the system?'", "'replace'", "'Replace'", "'merge'", "'Merge'", "'Submit Upload'"]}}], ["79defdbd67191c5f7ee3324be7790293", {"code_string": "from django import forms\nimport Image\nfrom models import Post\nfrom django.utils.translation import ugettext_lazy as _\n", "code_toks_joined": "from django import forms <NEWLINE> import Image <NEWLINE> from models import Post <NEWLINE> from django . utils . translation import ugettext_lazy as _ <NEWLINE>", "anonymize_dict": {}}], ["8e673cf8bf0ed2fdc280122e45981b8f", {"code_string": "def __receive_mode__(self):\n    while True:\n        beacon = self.receive()\n        if beacon:\n            print(beacon)\n", "code_toks_joined": "def __receive_mode__ ( self ) : <NEWLINE> <INDENT> while True : <NEWLINE> <INDENT> beacon = self . receive ( ) <NEWLINE> if beacon : <NEWLINE> <INDENT> print ( beacon ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["10490524af96cd3dd58340f98194ca75", {"code_string": "def database_forwards(self, app_label, schema_editor, from_state, to_state):\n    old_apps = from_state.render()\n    new_apps = to_state.render()\n    old_model = old_apps.get_model(app_label, self.name)\n    new_model = new_apps.get_model(app_label, self.name)\n    if self.allowed_to_migrate(schema_editor.connection.alias, new_model):\n        schema_editor.alter_db_table(\n            new_model,\n            old_model._meta.db_table,\n            new_model._meta.db_table,\n        )\n", "code_toks_joined": "def database_forwards ( self , app_label , schema_editor , from_state , to_state ) : <NEWLINE> <INDENT> old_apps = from_state . render ( ) <NEWLINE> new_apps = to_state . render ( ) <NEWLINE> old_model = old_apps . get_model ( app_label , self . name ) <NEWLINE> new_model = new_apps . get_model ( app_label , self . name ) <NEWLINE> if self . allowed_to_migrate ( schema_editor . connection . alias , new_model ) : <NEWLINE> <INDENT> schema_editor . alter_db_table ( <NEWLINE> <INDENT> new_model , <NEWLINE> old_model . _meta . db_table , <NEWLINE> new_model . _meta . db_table , <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["146cde1aa7f73031e0fc76b71b7d4113", {"code_string": "class TestPickleFix(GPflowTestCase):\n    \"\"\"Make sure a kernel with a fixed parameter can be computed after pickling\"\"\"\n    def test(self):\n        with self.test_session():\n            k = gpflow.kernels.PeriodicKernel(1)\n            k.period.fixed = True\n            k = pickle.loads(pickle.dumps(k))\n            x = np.linspace(0, 1, 100).reshape([- 1, 1])\n            k.compute_K(x, x)\n", "code_toks_joined": "class TestPickleFix ( GPflowTestCase ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def test ( self ) : <NEWLINE> <INDENT> with self . test_session ( ) : <NEWLINE> <INDENT> k = gpflow . kernels . PeriodicKernel ( 1 ) <NEWLINE> k . period . fixed = True <NEWLINE> k = pickle . loads ( pickle . dumps ( k ) ) <NEWLINE> x = np . linspace ( 0 , 1 , 100 ) . reshape ( [ - 1 , 1 ] ) <NEWLINE> k . compute_K ( x , x ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Make sure a kernel with a fixed parameter can be computed after pickling\"\"\""]}}], ["7683eda5ffea9b521531e71c2a0ee1e3", {"code_string": "from flask import Blueprint, request, redirect, render_template, url_for\nfrom flask.views import MethodView\nfrom flask.ext.mongoengine.wtf import model_form\nfrom watchmen.models import Event, History\nevents = Blueprint('events', __name__, template_folder = 'templates')\n", "code_toks_joined": "from flask import Blueprint , request , redirect , render_template , url_for <NEWLINE> from flask . views import MethodView <NEWLINE> from flask . ext . mongoengine . wtf import model_form <NEWLINE> from watchmen . models import Event , History <NEWLINE> events = Blueprint ( <STRING> , __name__ , template_folder = <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'events'", "'templates'"]}}], ["0f0b01bdb6ad4bd072f5a8c68b79af40", {"code_string": "class converter(object):\n    \"\"\"Create custom config value converters.\"\"\"\n    def __init__(self, callback, descr):\n        self.callback = callback\n        self.descr = descr\n    def describe(self):\n        return self.descr\n    def convert(self, val):\n        return self.callback(val)\n", "code_toks_joined": "class converter ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , callback , descr ) : <NEWLINE> <INDENT> self . callback = callback <NEWLINE> self . descr = descr <NEWLINE> <DEDENT> def describe ( self ) : <NEWLINE> <INDENT> return self . descr <NEWLINE> <DEDENT> def convert ( self , val ) : <NEWLINE> <INDENT> return self . callback ( val ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Create custom config value converters.\"\"\""]}}], ["e4f92d1bcf7cd6d7864d037111c03ae6", {"code_string": "\"\"\"Auto-generated class for CreateUserBankAccountReqBody\"\"\"\nfrom.BankAccount import BankAccount\nfrom.import client_support\n", "code_toks_joined": "<STRING> <NEWLINE> from . BankAccount import BankAccount <NEWLINE> from . import client_support <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Auto-generated class for CreateUserBankAccountReqBody\"\"\""]}}], ["d10f1200ca86b622927071e5be46adc4", {"code_string": "class Content(Box):\n    def __init__(self):\n        super(Content, self).__init__()\n", "code_toks_joined": "class Content ( Box ) : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> super ( Content , self ) . __init__ ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["2b24ecbf1c5ed196133d8880d3dc631e", {"code_string": "def __init__(self, uri, uid):\n    client = pymongo.MongoClient(uri)\n    self.database = client[uid]\n", "code_toks_joined": "def __init__ ( self , uri , uid ) : <NEWLINE> <INDENT> client = pymongo . MongoClient ( uri ) <NEWLINE> self . database = client [ uid ] <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["aef6ed33bda34f79818f692082b50066", {"code_string": "import os\nimport imp\nimport sys\n", "code_toks_joined": "import os <NEWLINE> import imp <NEWLINE> import sys <NEWLINE>", "anonymize_dict": {}}], ["bfa6554e29d7da40ad1e572d91bdad30", {"code_string": "def _get_x_y_from_header(hdr):\n    \"\"\"Calculated the X and Y arrays given windsyn binary header.\"\"\"\n    X = {'data': np.arange(0., hdr['Imax'] * hdr['Sx'], hdr['Sx']),\n        'units': 'km',\n        'long_name': 'East-West Distance'}\n    Y = {'data': np.arange(0., hdr['Jmax'] * hdr['Sy'], hdr['Sy']),\n        'units': 'km',\n        'long_name': 'North-South Distance'}\n    return X, Y\n", "code_toks_joined": "def _get_x_y_from_header ( hdr ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> X = { <STRING> : np . arange ( 0. , hdr [ <STRING> ] * hdr [ <STRING> ] , hdr [ <STRING> ] ) , <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> } <NEWLINE> <DEDENT> Y = { <STRING> : np . arange ( 0. , hdr [ <STRING> ] * hdr [ <STRING> ] , hdr [ <STRING> ] ) , <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> } <NEWLINE> <DEDENT> return X , Y <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Calculated the X and Y arrays given windsyn binary header.\"\"\"", "'data'", "'Imax'", "'Sx'", "'Sx'", "'units'", "'km'", "'long_name'", "'East-West Distance'", "'data'", "'Jmax'", "'Sy'", "'Sy'", "'units'", "'km'", "'long_name'", "'North-South Distance'"]}}], ["a215133b7db3d735a88b3b3fec677118", {"code_string": "def throwError(message):\n    print('{}'.format(message))\n    sys.exit(1)\n", "code_toks_joined": "def throwError ( message ) : <NEWLINE> <INDENT> print ( <STRING> . format ( message ) ) <NEWLINE> sys . exit ( 1 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'{}'"]}}], ["ae33ac1b9ff138e674a21fa224e769f7", {"code_string": "def checkFileExits(self, path):\n    \"\"\"purpose:\"\"\"\n    if os.path.exists(path):\n        return True\n    else:\n        return False\n", "code_toks_joined": "def checkFileExits ( self , path ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if os . path . exists ( path ) : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"purpose:\"\"\""]}}], ["3e5c324c59238ac5e8d9bd38a4461fcd", {"code_string": "class CDS(Document):\n    hostname = StringField(required = True, unique = True)\n    display_name = StringField(required = False)\n    client_hostname = StringField(required = False)\n    description = StringField(required = False)\n    created_at = DateTimeField(required = True, default = datetime.utcnow())\n    sync_schedule = StringField(required = False)\n    cluster_id = StringField(required = True)\n    meta = {'collection': 'cds'}\n    last_sync = DateTimeField(required = False)\n", "code_toks_joined": "class CDS ( Document ) : <NEWLINE> <INDENT> hostname = StringField ( required = True , unique = True ) <NEWLINE> display_name = StringField ( required = False ) <NEWLINE> client_hostname = StringField ( required = False ) <NEWLINE> description = StringField ( required = False ) <NEWLINE> created_at = DateTimeField ( required = True , default = datetime . utcnow ( ) ) <NEWLINE> sync_schedule = StringField ( required = False ) <NEWLINE> cluster_id = StringField ( required = True ) <NEWLINE> meta = { <STRING> : <STRING> } <NEWLINE> last_sync = DateTimeField ( required = False ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'collection'", "'cds'"]}}], ["1b2514b3d5357e513036a3e519d1de14", {"code_string": "def dumps(content, pretty = False):\n    \"\"\"format an HTML response\"\"\"\n    if pretty and \"<html><\" in content and \"<body><\" in content:\n        tags = ['<' + e for e in content.split('<') if e != \"\"]\n        content = ''.join(prettify_xml(tags))\n    if not content.lstrip().startswith(\"<!DOCTYPE\"):\n        content = DOCTYPE + content\n    return '{}{}'.format(pretty * '\\n', content)\n", "code_toks_joined": "def dumps ( content , pretty = False ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if pretty and <STRING> in content and <STRING> in content : <NEWLINE> <INDENT> tags = [ <STRING> + e for e in content . split ( <STRING> ) if e != <STRING> ] <NEWLINE> content = <STRING> . join ( prettify_xml ( tags ) ) <NEWLINE> <DEDENT> if not content . lstrip ( ) . startswith ( <STRING> ) : <NEWLINE> <INDENT> content = DOCTYPE + content <NEWLINE> <DEDENT> return <STRING> . format ( pretty * <STRING> , content ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"format an HTML response\"\"\"", "\"<html><\"", "\"<body><\"", "'<'", "'<'", "\"\"", "''", "\"<!DOCTYPE\"", "'{}{}'", "'\\n'"]}}], ["1fc624a4e46fa1c02eb06a15a7233172", {"code_string": "def get_headers(self):\n    \"\"\"Return prepared header for HTTP call\"\"\"\n    headers = self.BASIC_HEADERS\n    if self.session is None:\n        self.init_session()\n    headers[\"Cookie\"] = \"session={0}\".format(self.session)\n    return headers\n", "code_toks_joined": "def get_headers ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> headers = self . BASIC_HEADERS <NEWLINE> if self . session is None : <NEWLINE> <INDENT> self . init_session ( ) <NEWLINE> <DEDENT> headers [ <STRING> ] = <STRING> . format ( self . session ) <NEWLINE> return headers <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Return prepared header for HTTP call\"\"\"", "\"Cookie\"", "\"session={0}\""]}}], ["c22e90753f6aa34e57392779f8474bf2", {"code_string": "def test_najdi():\n    herni_pole = 20 *('-')\n    symbol_hrace = 'o'\n    assert najdi_symboly(herni_pole, symbol_hrace) == list()\n    assert najdi_symboly('--o-o-o-o', symbol_hrace) ==[2, 4, 6, 8]\n", "code_toks_joined": "def test_najdi ( ) : <NEWLINE> <INDENT> herni_pole = 20 * ( <STRING> ) <NEWLINE> symbol_hrace = <STRING> <NEWLINE> assert najdi_symboly ( herni_pole , symbol_hrace ) == list ( ) <NEWLINE> assert najdi_symboly ( <STRING> , symbol_hrace ) == [ 2 , 4 , 6 , 8 ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'-'", "'o'", "'--o-o-o-o'"]}}], ["02831262a2532f4c8743d56cd2d6da63", {"code_string": "from glob import glob\nfrom setuptools import setup\nsetup(\n    name = \"diy-lsi\",\n    version = \"0.1\",\n    author = \"Narayan Desai\",\n    author_email = \"narayan.desai+lsi@gmail.com\",\n    description = (\"Tools for managing lsi disk arrays on illumos\"),\n    license = \"BSD\",\n    keywords = \"LSI Illumos\",\n    url = \"https://github.com/narayandesai/diy-lsi\",\n    packages = ['diylsi'],\n    scripts = glob('tools/*'),\n    long_description = open('README.md').read(),\n    classifiers = [\n        \"Development Status :: 3 - Alpha\",\n        \"Topic :: Utilities\",\n        \"License :: OSI Approved :: BSD License\",\n    ],\n)\n", "code_toks_joined": "from glob import glob <NEWLINE> from setuptools import setup <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> description = ( <STRING> ) , <NEWLINE> license = <STRING> , <NEWLINE> keywords = <STRING> , <NEWLINE> url = <STRING> , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> scripts = glob ( <STRING> ) , <NEWLINE> long_description = open ( <STRING> ) . read ( ) , <NEWLINE> classifiers = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <DEDENT> ] , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"diy-lsi\"", "\"0.1\"", "\"Narayan Desai\"", "\"narayan.desai+lsi@gmail.com\"", "\"Tools for managing lsi disk arrays on illumos\"", "\"BSD\"", "\"LSI Illumos\"", "\"https://github.com/narayandesai/diy-lsi\"", "'diylsi'", "'tools/*'", "'README.md'", "\"Development Status :: 3 - Alpha\"", "\"Topic :: Utilities\"", "\"License :: OSI Approved :: BSD License\""]}}], ["f877d11bab7af37ca2929b509ed7f32a", {"code_string": "default_app_config = 'wechat_sdk.context.framework.django.apps.ContextConfig'\ntry:\n    from wechat_sdk.context.framework.django.models import Context as DatabaseContext\n    from wechat_sdk.context.framework.django.backends.db import ContextStore as DatabaseContextStore\nexcept ImportError:\n    pass\n", "code_toks_joined": "default_app_config = <STRING> <NEWLINE> try : <NEWLINE> <INDENT> from wechat_sdk . context . framework . django . models import Context as DatabaseContext <NEWLINE> from wechat_sdk . context . framework . django . backends . db import ContextStore as DatabaseContextStore <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'wechat_sdk.context.framework.django.apps.ContextConfig'"]}}], ["87082da453ae05e6bca4a80d5caef165", {"code_string": "from PySide.QtCore import *\nfrom PySide.QtGui import *\nfrom Settings import Settings\nimport pdb\nimport types\n", "code_toks_joined": "from PySide . QtCore import * <NEWLINE> from PySide . QtGui import * <NEWLINE> from Settings import Settings <NEWLINE> import pdb <NEWLINE> import types <NEWLINE>", "anonymize_dict": {}}], ["ee28ce6285763912fb4fc30a0be77b64", {"code_string": "def make_instance_obj(self, obj):\n    return{\n        'data': obj.nodes.all(),\n        'self': obj\n    }\n", "code_toks_joined": "def make_instance_obj ( self , obj ) : <NEWLINE> <INDENT> return { <NEWLINE> <INDENT> <STRING> : obj . nodes . all ( ) , <NEWLINE> <STRING> : obj <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'data'", "'self'"]}}], ["e004b0b0a73065bcf8b53e2bfd07d204", {"code_string": "from scrapy.spiders import Spider\nfrom projects.bixiawenxue.bixiawenxue.items import ChapterItem\nfrom helper.textUtil import removeTagsAndWhiteSpaces\nfrom pymongo.mongo_client import MongoClient\n", "code_toks_joined": "from scrapy . spiders import Spider <NEWLINE> from projects . bixiawenxue . bixiawenxue . items import ChapterItem <NEWLINE> from helper . textUtil import removeTagsAndWhiteSpaces <NEWLINE> from pymongo . mongo_client import MongoClient <NEWLINE>", "anonymize_dict": {}}], ["cb83e81e15ff0f2996c7dc8b72066d58", {"code_string": "import requests\nimport base64\nimport copy\nfrom sjcl import SJCL\n", "code_toks_joined": "import requests <NEWLINE> import base64 <NEWLINE> import copy <NEWLINE> from sjcl import SJCL <NEWLINE>", "anonymize_dict": {}}], ["974c1eabeea60337e50b463069d4c167", {"code_string": "def _command_handler(self, url, command):\n    self.req_urls.append(url)\n    self.req_commands.append(command)\n", "code_toks_joined": "def _command_handler ( self , url , command ) : <NEWLINE> <INDENT> self . req_urls . append ( url ) <NEWLINE> self . req_commands . append ( command ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ddd3a675b8300002b4f3d72eb3e2a047", {"code_string": "def delete(self, trans, ** kwd):\n    idnum = kwd[self.tagged_item_id]\n    item = self._get_item_from_id(trans, idnum)\n    if item is not None:\n        return self.delete_item_annotation(trans.sa_session, trans.get_user(), item)\n", "code_toks_joined": "def delete ( self , trans , ** kwd ) : <NEWLINE> <INDENT> idnum = kwd [ self . tagged_item_id ] <NEWLINE> item = self . _get_item_from_id ( trans , idnum ) <NEWLINE> if item is not None : <NEWLINE> <INDENT> return self . delete_item_annotation ( trans . sa_session , trans . get_user ( ) , item ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["e9e63e8633457bb334c89f2d7eb2f75e", {"code_string": "from __future__ import unicode_literals\nfrom django.db import models, migrations\nfrom django.apps import apps\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> from django . db import models , migrations <NEWLINE> from django . apps import apps <NEWLINE>", "anonymize_dict": {}}], ["c06b9638327c5598acb88ce8283cb760", {"code_string": "from otz.Timestream import CalibrationTimestream, CapturedTimestream\nfrom otz.Calibration import Calibration\nfrom otz.Beam import Beam, Bead\n", "code_toks_joined": "from otz . Timestream import CalibrationTimestream , CapturedTimestream <NEWLINE> from otz . Calibration import Calibration <NEWLINE> from otz . Beam import Beam , Bead <NEWLINE>", "anonymize_dict": {}}], ["877dd5e9ce9fd32344aa8a909c719757", {"code_string": "class Piece:\n    \"\"\"Common abstract base class for pieces\"\"\"\n    __metaclass__ = ABCMeta\n    colors = ['green', 'cyan', 'magenta', 'blue', 'yellow']\n    def __init__(self, name, label, player):\n        self.name = name\n        self.label = label\n        self.color = None\n        self.player_num = player\n    def __str__(self):\n        return self.name\n    def __lt__(self, other):\n        return self.name < other.name\n    @ abstractmethod\n    def moves(self, x, y, board):\n        pass\n", "code_toks_joined": "class Piece : <NEWLINE> <INDENT> <STRING> <NEWLINE> __metaclass__ = ABCMeta <NEWLINE> colors = [ <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE> def __init__ ( self , name , label , player ) : <NEWLINE> <INDENT> self . name = name <NEWLINE> self . label = label <NEWLINE> self . color = None <NEWLINE> self . player_num = player <NEWLINE> <DEDENT> def __str__ ( self ) : <NEWLINE> <INDENT> return self . name <NEWLINE> <DEDENT> def __lt__ ( self , other ) : <NEWLINE> <INDENT> return self . name < other . name <NEWLINE> <DEDENT> @ abstractmethod <NEWLINE> def moves ( self , x , y , board ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Common abstract base class for pieces\"\"\"", "'green'", "'cyan'", "'magenta'", "'blue'", "'yellow'"]}}], ["dc1b0fc52af16cb84dd25ef68b9b0160", {"code_string": "\"\"\"Number theory module (primes, etc)\"\"\"\nfrom.generate import nextprime, prevprime, prime, primepi, primerange, randprime, Sieve, sieve, primorial, cycle_length\nfrom.primetest import isprime\nfrom.factor_ import divisors, factorint, multiplicity, perfect_power, pollard_pm1, pollard_rho, primefactors, totient, trailing, divisor_count, divisor_sigma\nfrom.partitions_ import npartitions\nfrom.residue_ntheory import is_primitive_root, is_quad_residue, legendre_symbol, jacobi_symbol, n_order, sqrt_mod, quadratic_residues, primitive_root, nthroot_mod, is_nthpow_residue, sqrt_mod_iter, mobius\nfrom.multinomial import binomial_coefficients, binomial_coefficients_list, multinomial_coefficients\nfrom.continued_fraction import continued_fraction_periodic, continued_fraction_iterator, continued_fraction_reduce, continued_fraction_convergents\nfrom.egyptian_fraction import egyptian_fraction\n", "code_toks_joined": "<STRING> <NEWLINE> from . generate import nextprime , prevprime , prime , primepi , primerange , randprime , Sieve , sieve , primorial , cycle_length <NEWLINE> from . primetest import isprime <NEWLINE> from . factor_ import divisors , factorint , multiplicity , perfect_power , pollard_pm1 , pollard_rho , primefactors , totient , trailing , divisor_count , divisor_sigma <NEWLINE> from . partitions_ import npartitions <NEWLINE> from . residue_ntheory import is_primitive_root , is_quad_residue , legendre_symbol , jacobi_symbol , n_order , sqrt_mod , quadratic_residues , primitive_root , nthroot_mod , is_nthpow_residue , sqrt_mod_iter , mobius <NEWLINE> from . multinomial import binomial_coefficients , binomial_coefficients_list , multinomial_coefficients <NEWLINE> from . continued_fraction import continued_fraction_periodic , continued_fraction_iterator , continued_fraction_reduce , continued_fraction_convergents <NEWLINE> from . egyptian_fraction import egyptian_fraction <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Number theory module (primes, etc)\"\"\""]}}], ["86f5b0e0d3e2b2183e3d0c5116684aba", {"code_string": "import sys\nimport json\nimport time\nimport ibmiotf.application\nfrom ibmiotf import APIException\nimport requests\nimport signal\nimport argparse\nimport logging\nfrom logging.handlers import RotatingFileHandler\n", "code_toks_joined": "import sys <NEWLINE> import json <NEWLINE> import time <NEWLINE> import ibmiotf . application <NEWLINE> from ibmiotf import APIException <NEWLINE> import requests <NEWLINE> import signal <NEWLINE> import argparse <NEWLINE> import logging <NEWLINE> from logging . handlers import RotatingFileHandler <NEWLINE>", "anonymize_dict": {}}], ["85726be857602284fc03a7db12f22bc7", {"code_string": "from distutils.core import setup\nfrom setuptools import find_packages\nsetup(\n    name = 'django-reversion-compare-auditlog',\n    version = '0.0.1',\n    author = u'Azamat Tokhtaev',\n    author_email = 'krik123@gmail.com',\n    url = 'https://github.com/ITAttractor/django-reversion-compare-auditlog',\n    license = 'BSD License',\n    description = 'Uses django-reversion-compare to show a standalone table where user can see all the changes to the objects',\n    long_description = open('README.md').read(),\n    zip_safe = False,\n    packages = find_packages(),\n    setup_requires = ['django-reversion', 'django-reversion-compare'],\n    install_requires = ['django-reversion', 'django-reversion-compare']\n)\n", "code_toks_joined": "from distutils . core import setup <NEWLINE> from setuptools import find_packages <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> url = <STRING> , <NEWLINE> license = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> long_description = open ( <STRING> ) . read ( ) , <NEWLINE> zip_safe = False , <NEWLINE> packages = find_packages ( ) , <NEWLINE> setup_requires = [ <STRING> , <STRING> ] , <NEWLINE> install_requires = [ <STRING> , <STRING> ] <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'django-reversion-compare-auditlog'", "'0.0.1'", "u'Azamat Tokhtaev'", "'krik123@gmail.com'", "'https://github.com/ITAttractor/django-reversion-compare-auditlog'", "'BSD License'", "'Uses django-reversion-compare to show a standalone table where user can see all the changes to the objects'", "'README.md'", "'django-reversion'", "'django-reversion-compare'", "'django-reversion'", "'django-reversion-compare'"]}}], ["715b00a8de88c8d617cf33a771f1adbf", {"code_string": "class LoginForm(BaseForm):\n    username = TextField(\n        'username',\n        validators = [DataRequired()]\n    )\n    password = PasswordField(\n        'password',\n        validators = [DataRequired()]\n    )\n", "code_toks_joined": "class LoginForm ( BaseForm ) : <NEWLINE> <INDENT> username = TextField ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> validators = [ DataRequired ( ) ] <NEWLINE> <DEDENT> ) <NEWLINE> password = PasswordField ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> validators = [ DataRequired ( ) ] <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'username'", "'password'"]}}], ["71b233e1292c348803adf67c8f8f1098", {"code_string": "from django.contrib.gis.db import models\nfrom lizard_security.manager import FilteredGeoManager\nfrom lizard_security.models import DataSet\nfrom lizard_measure.models import(\n    WaterBody,\n    Measure,\n)\nfrom lizard_area.models import Area\nfrom lizard_workspace.models import(\n    LayerWorkspace,\n    LayerCollage,\n)\nfrom lizard_history.utils import get_simple_history\nimport copy\nfrom django.contrib.contenttypes.models import ContentType\nfrom django.contrib.contenttypes import generic\nfrom django.core.urlresolvers import reverse\nfrom django.utils.translation import ugettext as _\n", "code_toks_joined": "from django . contrib . gis . db import models <NEWLINE> from lizard_security . manager import FilteredGeoManager <NEWLINE> from lizard_security . models import DataSet <NEWLINE> from lizard_measure . models import ( <NEWLINE> <INDENT> WaterBody , <NEWLINE> Measure , <NEWLINE> <DEDENT> ) <NEWLINE> from lizard_area . models import Area <NEWLINE> from lizard_workspace . models import ( <NEWLINE> <INDENT> LayerWorkspace , <NEWLINE> LayerCollage , <NEWLINE> <DEDENT> ) <NEWLINE> from lizard_history . utils import get_simple_history <NEWLINE> import copy <NEWLINE> from django . contrib . contenttypes . models import ContentType <NEWLINE> from django . contrib . contenttypes import generic <NEWLINE> from django . core . urlresolvers import reverse <NEWLINE> from django . utils . translation import ugettext as _ <NEWLINE>", "anonymize_dict": {}}], ["c2c8ae300a39445d7b2a22fb4a326c4f", {"code_string": "class OutlineCodeItemsResponse(object):\n    \"\"\"NOTE: This class is auto generated by the swagger code generator program.\"\"\"\n    def __init__(self):\n        \"\"\"Attributes:\"\"\"\n        self.swaggerTypes = {\n            'OutlineCodes': 'OutlineCodeItems',\n            'Code': 'str',\n            'Status': 'str'\n        }\n        self.attributeMap = {\n            'OutlineCodes': 'OutlineCodes', 'Code': 'Code', 'Status': 'Status'}\n        self.OutlineCodes = None\n        self.Code = None\n        self.Status = None\n", "code_toks_joined": "class OutlineCodeItemsResponse ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . swaggerTypes = { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> <NEWLINE> <DEDENT> } <NEWLINE> self . attributeMap = { <NEWLINE> <INDENT> <STRING> : <STRING> , <STRING> : <STRING> , <STRING> : <STRING> } <NEWLINE> <DEDENT> self . OutlineCodes = None <NEWLINE> self . Code = None <NEWLINE> self . Status = None <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"NOTE: This class is auto generated by the swagger code generator program.\"\"\"", "\"\"\"Attributes:\"\"\"", "'OutlineCodes'", "'OutlineCodeItems'", "'Code'", "'str'", "'Status'", "'str'", "'OutlineCodes'", "'OutlineCodes'", "'Code'", "'Code'", "'Status'", "'Status'"]}}], ["edb6fdcf959f2316bff7a86abe61cc31", {"code_string": "\"\"\"Export Observation data from a network notary database.\"\"\"\nfrom __future__ import print_function\nimport time\nimport argparse\nfrom notary_db import ndb\nimport notary_common\nDEFAULT_OUTFILE = \"-\"\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import print_function <NEWLINE> import time <NEWLINE> import argparse <NEWLINE> from notary_db import ndb <NEWLINE> import notary_common <NEWLINE> DEFAULT_OUTFILE = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Export Observation data from a network notary database.\"\"\"", "\"-\""]}}], ["3c9cb24fd90dc483d6818641fad1e12f", {"code_string": "class iCalentador(object):\n    def __init__(self):\n        logging.info('Invernadero Calentador')\n        self.calentador = mraa.Gpio(3)\n        self.estado = 0\n    def iCalentadorPrender(self, estado):\n        self.calentador.dir(mraa.DIR_OUT)\n        self.calentador.write(estado)\n    def iCalentadorEstado(self):\n        return self.calentador.read()\n", "code_toks_joined": "class iCalentador ( object ) : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> logging . info ( <STRING> ) <NEWLINE> self . calentador = mraa . Gpio ( 3 ) <NEWLINE> self . estado = 0 <NEWLINE> <DEDENT> def iCalentadorPrender ( self , estado ) : <NEWLINE> <INDENT> self . calentador . dir ( mraa . DIR_OUT ) <NEWLINE> self . calentador . write ( estado ) <NEWLINE> <DEDENT> def iCalentadorEstado ( self ) : <NEWLINE> <INDENT> return self . calentador . read ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Invernadero Calentador'"]}}], ["02ef02f9073a4410f29958b8e5ee5e1d", {"code_string": "import skills._kick\nimport behavior\nimport constants\nimport robocup\nimport enum\nimport main\nimport role_assignment\n", "code_toks_joined": "import skills . _kick <NEWLINE> import behavior <NEWLINE> import constants <NEWLINE> import robocup <NEWLINE> import enum <NEWLINE> import main <NEWLINE> import role_assignment <NEWLINE>", "anonymize_dict": {}}], ["c223d74b6c558d93712ad9d879234ea8", {"code_string": "def selectOption(self, selector):\n    self.client.nowait('browser.selectOption', (selector, ))\n    return self\n", "code_toks_joined": "def selectOption ( self , selector ) : <NEWLINE> <INDENT> self . client . nowait ( <STRING> , ( selector , ) ) <NEWLINE> return self <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'browser.selectOption'"]}}], ["ee3e39ed89833a978aa41f9421150892", {"code_string": "import urllib\nimport requests\nimport soundcloud\nimport hashconversions\n", "code_toks_joined": "import urllib <NEWLINE> import requests <NEWLINE> import soundcloud <NEWLINE> import hashconversions <NEWLINE>", "anonymize_dict": {}}], ["69507fdc2c594258f79f7307f35e21eb", {"code_string": "class LeftRightHandWordsTest(unittest.TestCase):\n    def test_search(self):\n        res = search([\n            \"qwert\",\n            \"rararararararara\",\n            \"asd\",\n            \"asdlkj\",\n            \"iosakbrknerlk\",\n            \"mmmmmm\",\n            \"llllllllllllllllllll\",\n            \"laskdj\",\n            \"llll\",\n            \"qqqqqqqqqqqqqqqqqqqq\",\n            \"p\"])\n        smallest_left, smallest_right, largest_left, largest_right = res\n        self.assertEquals(\"asd\", smallest_left)\n        self.assertEquals(\"p\", smallest_right)\n        self.assertEquals(\"qqqqqqqqqqqqqqqqqqqq\", largest_left)\n        self.assertEquals(\"llllllllllllllllllll\", largest_right)\n", "code_toks_joined": "class LeftRightHandWordsTest ( unittest . TestCase ) : <NEWLINE> <INDENT> def test_search ( self ) : <NEWLINE> <INDENT> res = search ( [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> ] ) <NEWLINE> <DEDENT> smallest_left , smallest_right , largest_left , largest_right = res <NEWLINE> self . assertEquals ( <STRING> , smallest_left ) <NEWLINE> self . assertEquals ( <STRING> , smallest_right ) <NEWLINE> self . assertEquals ( <STRING> , largest_left ) <NEWLINE> self . assertEquals ( <STRING> , largest_right ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"qwert\"", "\"rararararararara\"", "\"asd\"", "\"asdlkj\"", "\"iosakbrknerlk\"", "\"mmmmmm\"", "\"llllllllllllllllllll\"", "\"laskdj\"", "\"llll\"", "\"qqqqqqqqqqqqqqqqqqqq\"", "\"p\"", "\"asd\"", "\"p\"", "\"qqqqqqqqqqqqqqqqqqqq\"", "\"llllllllllllllllllll\""]}}], ["80e5c0e8a6090cca502c33b87f8ac10e", {"code_string": "def format_directive(module, package = None):\n    \"\"\"Create the automodule directive and add the options.\"\"\"\n    directive = '.. automodule:: %s\\n' % makename(package, module)\n    for option in OPTIONS:\n        directive += '    :%s:\\n' % option\n    return directive\n", "code_toks_joined": "def format_directive ( module , package = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> directive = <STRING> % makename ( package , module ) <NEWLINE> for option in OPTIONS : <NEWLINE> <INDENT> directive += <STRING> % option <NEWLINE> <DEDENT> return directive <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Create the automodule directive and add the options.\"\"\"", "'.. automodule:: %s\\n'", "'    :%s:\\n'"]}}], ["e4d0134834cc36ad2b64201b9dd128ed", {"code_string": "\"\"\"package that contains several classes used in the tracking of the mouse\"\"\"\nfrom.parameters import PARAMETERS_DEFAULT, set_base_folder, scale_parameters\nfrom.data_handler import DataHandler\nfrom.pass1 import FirstPass\nfrom.pass2 import SecondPass\nfrom.pass3 import ThirdPass\nfrom.pass4 import FourthPass\n", "code_toks_joined": "<STRING> <NEWLINE> from . parameters import PARAMETERS_DEFAULT , set_base_folder , scale_parameters <NEWLINE> from . data_handler import DataHandler <NEWLINE> from . pass1 import FirstPass <NEWLINE> from . pass2 import SecondPass <NEWLINE> from . pass3 import ThirdPass <NEWLINE> from . pass4 import FourthPass <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"package that contains several classes used in the tracking of the mouse\"\"\""]}}], ["387dc5364c655b4674f7fb2967917815", {"code_string": "def start(urls):\n    logger.debug('.....')\n    logger.debug(urls)\n    for url in urls:\n        logger.debug('url looping...')\n        Task(url, None)\n        Thread(target = Task(url, None).run())\n", "code_toks_joined": "def start ( urls ) : <NEWLINE> <INDENT> logger . debug ( <STRING> ) <NEWLINE> logger . debug ( urls ) <NEWLINE> for url in urls : <NEWLINE> <INDENT> logger . debug ( <STRING> ) <NEWLINE> Task ( url , None ) <NEWLINE> Thread ( target = Task ( url , None ) . run ( ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'.....'", "'url looping...'"]}}], ["f0d3cbb798370b19276800645af15f66", {"code_string": "class About(Resource):\n    def get(self, app_id = None):\n        if app_id:\n            return api_util.attach_meta(utils.get_app_info_object(app_id),\n                meta_success), 200\n        message = ('Welcome to the next.discovery system.\\n '\n            'Available apps {}'.format(', '.join(utils.get_supported_apps())))\n        return api_util.attach_meta({},\n            meta_success,\n            message = message)\n", "code_toks_joined": "class About ( Resource ) : <NEWLINE> <INDENT> def get ( self , app_id = None ) : <NEWLINE> <INDENT> if app_id : <NEWLINE> <INDENT> return api_util . attach_meta ( utils . get_app_info_object ( app_id ) , <NEWLINE> <INDENT> meta_success ) , 200 <NEWLINE> <DEDENT> <DEDENT> message = ( <STRING> <NEWLINE> <INDENT> <STRING> . format ( <STRING> . join ( utils . get_supported_apps ( ) ) ) ) <NEWLINE> <DEDENT> return api_util . attach_meta ( { } , <NEWLINE> <INDENT> meta_success , <NEWLINE> message = message ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Welcome to the next.discovery system.\\n '", "'Available apps {}'", "', '"]}}], ["4166877dd4288867968bda39f2146b59", {"code_string": "from.import summary\nfrom.import summary_seq\nfrom.import summary_address_person\nfrom.import summary_address_event\nfrom.import summary_address_document\nfrom.import summary_address_lab_test_request\nfrom.import summary_person_event\nfrom.import summary_person_document\nfrom.import summary_person_lab_test_request\n", "code_toks_joined": "from . import summary <NEWLINE> from . import summary_seq <NEWLINE> from . import summary_address_person <NEWLINE> from . import summary_address_event <NEWLINE> from . import summary_address_document <NEWLINE> from . import summary_address_lab_test_request <NEWLINE> from . import summary_person_event <NEWLINE> from . import summary_person_document <NEWLINE> from . import summary_person_lab_test_request <NEWLINE>", "anonymize_dict": {}}], ["1a02fbfe1010bc99b33c2575777192d5", {"code_string": "def is_strict_mode():\n    '''Determine if the tests are being run on a strict mode cluster.'''\n    return os.environ.get('SECURITY', '') == 'strict'\n", "code_toks_joined": "def is_strict_mode ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return os . environ . get ( <STRING> , <STRING> ) == <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Determine if the tests are being run on a strict mode cluster.'''", "'SECURITY'", "''", "'strict'"]}}], ["0d3268e234387763b0aecff5bba01427", {"code_string": "from twisted.protocols import basic\nfrom twisted.python import log\nfrom PyChat import command as cmd\nCLIENT_PREFIX = cmd.CLIENT_PREFIX\n", "code_toks_joined": "from twisted . protocols import basic <NEWLINE> from twisted . python import log <NEWLINE> from PyChat import command as cmd <NEWLINE> CLIENT_PREFIX = cmd . CLIENT_PREFIX <NEWLINE>", "anonymize_dict": {}}], ["8021dc22770a064fed722b75228e28fc", {"code_string": "def listClasses(module = None):\n    if module:\n        __import__(module)\n        pkg = sys.modules[module]\n        print(\"Available Interfaces:\")\n        for k, v in sorted(list(pkg.__dict__.items())):\n            if inspect.isclass(v) and issubclass(v, Interface):\n                print(\"\\t%s\" % k)\n", "code_toks_joined": "def listClasses ( module = None ) : <NEWLINE> <INDENT> if module : <NEWLINE> <INDENT> __import__ ( module ) <NEWLINE> pkg = sys . modules [ module ] <NEWLINE> print ( <STRING> ) <NEWLINE> for k , v in sorted ( list ( pkg . __dict__ . items ( ) ) ) : <NEWLINE> <INDENT> if inspect . isclass ( v ) and issubclass ( v , Interface ) : <NEWLINE> <INDENT> print ( <STRING> % k ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Available Interfaces:\"", "\"\\t%s\""]}}], ["ae50b226dc941601bc4c33dac1db2d1e", {"code_string": "from.models import(load_fmm_model,\n    RetinotopyModel, RetinotopyMeshModel, RegisteredRetinotopyModel,\n    SchiraModel)\nfrom.retinotopy import(empirical_retinotopy_data, predicted_retinotopy_data, retinotopy_data,\n    extract_retinotopy_argument,\n    register_retinotopy, retinotopy_anchors, retinotopy_model,\n    predict_retinotopy, register_retinotopy_initialize,\n    mesh_retinotopy, as_retinotopy, retinotopic_field_sign,\n    clean_retinotopy, predict_pRF_radius)\nfrom.cmag import(neighborhood_cortical_magnification, path_cortical_magnification,\n    isoangular_path)\n", "code_toks_joined": "from . models import ( load_fmm_model , <NEWLINE> <INDENT> RetinotopyModel , RetinotopyMeshModel , RegisteredRetinotopyModel , <NEWLINE> SchiraModel ) <NEWLINE> <DEDENT> from . retinotopy import ( empirical_retinotopy_data , predicted_retinotopy_data , retinotopy_data , <NEWLINE> <INDENT> extract_retinotopy_argument , <NEWLINE> register_retinotopy , retinotopy_anchors , retinotopy_model , <NEWLINE> predict_retinotopy , register_retinotopy_initialize , <NEWLINE> mesh_retinotopy , as_retinotopy , retinotopic_field_sign , <NEWLINE> clean_retinotopy , predict_pRF_radius ) <NEWLINE> <DEDENT> from . cmag import ( neighborhood_cortical_magnification , path_cortical_magnification , <NEWLINE> <INDENT> isoangular_path ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["4e0e7ac7b21628073dca06079c39ed15", {"code_string": "def _register_psutil_metrics(self, stats, names_to_metric_types):\n    \"\"\"Saves sample metrics from psutil\"\"\"\n    base_metric = 'datadog.agent.collector.{0}.{1}'\n    for k, v in stats.iteritems():\n        metric_type = names_to_metric_types[k]\n        if isinstance(v, dict):\n            for _k, _v in v.iteritems():\n                full_metric_name = base_metric.format(k, _k)\n                self._send_single_metric(full_metric_name, _v, metric_type)\n        else:\n            full_metric_name = 'datadog.agent.collector.{0}'.format(k)\n            self._send_single_metric(full_metric_name, v, metric_type)\n", "code_toks_joined": "def _register_psutil_metrics ( self , stats , names_to_metric_types ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> base_metric = <STRING> <NEWLINE> for k , v in stats . iteritems ( ) : <NEWLINE> <INDENT> metric_type = names_to_metric_types [ k ] <NEWLINE> if isinstance ( v , dict ) : <NEWLINE> <INDENT> for _k , _v in v . iteritems ( ) : <NEWLINE> <INDENT> full_metric_name = base_metric . format ( k , _k ) <NEWLINE> self . _send_single_metric ( full_metric_name , _v , metric_type ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> full_metric_name = <STRING> . format ( k ) <NEWLINE> self . _send_single_metric ( full_metric_name , v , metric_type ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Saves sample metrics from psutil\"\"\"", "'datadog.agent.collector.{0}.{1}'", "'datadog.agent.collector.{0}'"]}}], ["f69aab44f35e8e50f9fb783a0537b345", {"code_string": "import os\nimport urllib.request\nimport shutil\nfrom bs4 import BeautifulSoup\nURL = '----------------Link Disabled----------------'\nheaders = {'User-Agent': 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7', }\n", "code_toks_joined": "import os <NEWLINE> import urllib . request <NEWLINE> import shutil <NEWLINE> from bs4 import BeautifulSoup <NEWLINE> URL = <STRING> <NEWLINE> headers = { <STRING> : <STRING> , } <NEWLINE>", "anonymize_dict": {"<STRING>": ["'----------------Link Disabled----------------'", "'User-Agent'", "'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'"]}}], ["d6a821a597ae658535a0c61b2953210d", {"code_string": "import sys\nimport optparse\nimport inspect\nimport time\nimport imaplib\nimport re\n", "code_toks_joined": "import sys <NEWLINE> import optparse <NEWLINE> import inspect <NEWLINE> import time <NEWLINE> import imaplib <NEWLINE> import re <NEWLINE>", "anonymize_dict": {}}], ["55d9060c30376b4bda0a8d56fc3404a9", {"code_string": "def test(var):\n    x = var\n    try: x\n    except NameError:\n        return False\n    else:\n        return True\n", "code_toks_joined": "def test ( var ) : <NEWLINE> <INDENT> x = var <NEWLINE> try : x <NEWLINE> except NameError : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["88e8ef4b379136bf42fa0afecab5b42d", {"code_string": "def getAFBC_vof(x, flag):\n    if flag == boundaryTags['top']:\n        return None\n    elif flag == boundaryTags['left']:\n        return None\n    elif flag == boundaryTags['right']:\n        return None\n    else:\n        return lambda x, t: 0.0\n", "code_toks_joined": "def getAFBC_vof ( x , flag ) : <NEWLINE> <INDENT> if flag == boundaryTags [ <STRING> ] : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> elif flag == boundaryTags [ <STRING> ] : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> elif flag == boundaryTags [ <STRING> ] : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return lambda x , t : 0.0 <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'top'", "'left'", "'right'"]}}], ["0784d51057dd2f1637b180d3c46d29ce", {"code_string": "def construct_int(value):\n    \"\"\"Contructs an integer value from a string or a comma separated list\"\"\"\n    if value == '' or value is None:\n        return 0\n    print(value)\n    index = value.find(',')\n    if index is - 1:\n        return int(value)\n    else:\n        return int(value[: index] + value[index + 1: ])\n", "code_toks_joined": "def construct_int ( value ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if value == <STRING> or value is None : <NEWLINE> <INDENT> return 0 <NEWLINE> <DEDENT> print ( value ) <NEWLINE> index = value . find ( <STRING> ) <NEWLINE> if index is - 1 : <NEWLINE> <INDENT> return int ( value ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return int ( value [ : index ] + value [ index + 1 : ] ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Contructs an integer value from a string or a comma separated list\"\"\"", "''", "','"]}}], ["49b6cba3989809d7fb7abda971ad078a", {"code_string": "def to_json(self):\n    \"\"\"Converts data from this report part to JSON format. This includes all\"\"\"\n    return json.dumps(self, cls = ReportJSONEncoder)\n", "code_toks_joined": "def to_json ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return json . dumps ( self , cls = ReportJSONEncoder ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Converts data from this report part to JSON format. This includes all\"\"\""]}}], ["3662d6600c9d66ae4a2385b9701e51b8", {"code_string": "from __future__ import(absolute_import, unicode_literals, division,\n    print_function)\nfrom..attributes import TimeAttribute\nfrom.utils import DEFAULT_OBSTIME\nfrom.baseradec import _base_radec_docstring, BaseRADecFrame\n", "code_toks_joined": "from __future__ import ( absolute_import , unicode_literals , division , <NEWLINE> <INDENT> print_function ) <NEWLINE> <DEDENT> from . . attributes import TimeAttribute <NEWLINE> from . utils import DEFAULT_OBSTIME <NEWLINE> from . baseradec import _base_radec_docstring , BaseRADecFrame <NEWLINE>", "anonymize_dict": {}}], ["5af8df94398365c78e63470eecce7e95", {"code_string": "revision = '16'\ndown_revision = '15'\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\nimport re\n", "code_toks_joined": "revision = <STRING> <NEWLINE> down_revision = <STRING> <NEWLINE> from alembic import op <NEWLINE> import sqlalchemy as sa <NEWLINE> from sqlalchemy . ext . declarative import declarative_base <NEWLINE> from sqlalchemy . orm import sessionmaker <NEWLINE> import re <NEWLINE>", "anonymize_dict": {"<STRING>": ["'16'", "'15'"]}}], ["7c749e4e3f2907d98af0adc28c0d46a1", {"code_string": "def test_alias_cleanup(self):\n    \"\"\"Check that the name is cleaned up as we'd expect\"\"\"\n    tests = [\n        ('   Mr. Foo  ', 'Mr. Foo'),\n        ('Mr. Foo,', 'Mr. Foo'),\n        ('Mr.Foo,', 'Mr. Foo'),\n        ('Mr.   Foo,', 'Mr. Foo'),\n        ('(Mr. Foo)', 'Mr. Foo'),\n        ('[Mr. Foo]', 'Mr. Foo'),\n        ('Mr A.N. Other', 'Mr. A. N. Other'),\n    ]\n    for dirty, clean in tests:\n        self.assertEqual(Alias.clean_up_name(dirty), clean)\n", "code_toks_joined": "def test_alias_cleanup ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> tests = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> for dirty , clean in tests : <NEWLINE> <INDENT> self . assertEqual ( Alias . clean_up_name ( dirty ) , clean ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Check that the name is cleaned up as we'd expect\"\"\"", "'   Mr. Foo  '", "'Mr. Foo'", "'Mr. Foo,'", "'Mr. Foo'", "'Mr.Foo,'", "'Mr. Foo'", "'Mr.   Foo,'", "'Mr. Foo'", "'(Mr. Foo)'", "'Mr. Foo'", "'[Mr. Foo]'", "'Mr. Foo'", "'Mr A.N. Other'", "'Mr. A. N. Other'"]}}], ["d2f55103dd8636af8c7e07ccb377184c", {"code_string": "class WPTagTest(WPTestCase):\n    def test_get_absolute_url_works(self):\n        tag = WPTagFactory()\n        self.assertTrue(tag.get_absolute_url())\n", "code_toks_joined": "class WPTagTest ( WPTestCase ) : <NEWLINE> <INDENT> def test_get_absolute_url_works ( self ) : <NEWLINE> <INDENT> tag = WPTagFactory ( ) <NEWLINE> self . assertTrue ( tag . get_absolute_url ( ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["fcf198c47e1624070ae0a69901566375", {"code_string": "class TestCIPlugInInterface(TestCase):\n    def testMethods(self):\n        self.assertResultIsBOOL(TestCIPluginInterfaceHelper.load_)\n    def no_testProtocol(self):\n        p = objc.protocolNamed('CIPlugInRegistration')\n        self.assertIsInstancE(p, objc.formal_protocol)\n", "code_toks_joined": "class TestCIPlugInInterface ( TestCase ) : <NEWLINE> <INDENT> def testMethods ( self ) : <NEWLINE> <INDENT> self . assertResultIsBOOL ( TestCIPluginInterfaceHelper . load_ ) <NEWLINE> <DEDENT> def no_testProtocol ( self ) : <NEWLINE> <INDENT> p = objc . protocolNamed ( <STRING> ) <NEWLINE> self . assertIsInstancE ( p , objc . formal_protocol ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'CIPlugInRegistration'"]}}], ["1f05aa1199ec1811289df8589ff67ae4", {"code_string": "class Anthill:\n    \"\"\"docstring for Anthill\"\"\"\n    def __init__(self, arg):\n        self.arg = arg\n", "code_toks_joined": "class Anthill : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , arg ) : <NEWLINE> <INDENT> self . arg = arg <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"docstring for Anthill\"\"\""]}}], ["bd6ce8af010e2d657df14fa8f34c08c9", {"code_string": "def create_slots(self, cursor):\n    from queries import create_slots\n    print(\"Creating slot table\")\n    cursor.execute(create_slots)\n    self.connection.commit()\n", "code_toks_joined": "def create_slots ( self , cursor ) : <NEWLINE> <INDENT> from queries import create_slots <NEWLINE> print ( <STRING> ) <NEWLINE> cursor . execute ( create_slots ) <NEWLINE> self . connection . commit ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Creating slot table\""]}}], ["c750163445244219b382ddfda9215e83", {"code_string": "def register_goals():\n    Goal.register('sq-depmap', 'Generates a visualization of the dependency graph of the target arguments using graphviz dot.')\n    task(name = 'sq-depmap', action = SquareDepmap).install('sq-depmap')\n", "code_toks_joined": "def register_goals ( ) : <NEWLINE> <INDENT> Goal . register ( <STRING> , <STRING> ) <NEWLINE> task ( name = <STRING> , action = SquareDepmap ) . install ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'sq-depmap'", "'Generates a visualization of the dependency graph of the target arguments using graphviz dot.'", "'sq-depmap'", "'sq-depmap'"]}}], ["ae479dc9a055662d9200693272c1a189", {"code_string": "import datetime\nimport hashlib\nimport os\nimport unicodedata\nfrom django.db import models\nfrom django.contrib.auth.models import User\nfrom crashstats.base.utils import get_now\n", "code_toks_joined": "import datetime <NEWLINE> import hashlib <NEWLINE> import os <NEWLINE> import unicodedata <NEWLINE> from django . db import models <NEWLINE> from django . contrib . auth . models import User <NEWLINE> from crashstats . base . utils import get_now <NEWLINE>", "anonymize_dict": {}}], ["74572af6a86b0d96699b669f5f3725d3", {"code_string": "\"\"\"The setup and build script for the pyrant library.\"\"\"\nfrom setuptools import setup\nsetup(\n    name = \"pyrant\",\n    version = \"0.0.2\",\n    url = 'http://code.google.com/p/pyrant/',\n    license = 'Apache License 2.0',\n    description = 'A python wrapper around Tyrant Implamentation',\n    author = 'Martin Conte Mac Donell',\n    author_email = 'Reflejo@gmail.com',\n    packages = ['pyrant'],\n    install_requires = ['setuptools'],\n    include_package_data = True,\n    classifiers = [\n        'Intended Audience :: Developers',\n        'Development Status :: 4 - Beta',\n        'Programming Language :: Python',\n        'Intended Audience :: Developers',\n        'License :: OSI Approved :: Apache Software License',\n        'Topic :: Software Development :: Libraries :: Python Modules',\n        'Topic :: Database :: Front-Ends',\n    ],\n)\n", "code_toks_joined": "<STRING> <NEWLINE> from setuptools import setup <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> url = <STRING> , <NEWLINE> license = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> install_requires = [ <STRING> ] , <NEWLINE> include_package_data = True , <NEWLINE> classifiers = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <DEDENT> ] , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"The setup and build script for the pyrant library.\"\"\"", "\"pyrant\"", "\"0.0.2\"", "'http://code.google.com/p/pyrant/'", "'Apache License 2.0'", "'A python wrapper around Tyrant Implamentation'", "'Martin Conte Mac Donell'", "'Reflejo@gmail.com'", "'pyrant'", "'setuptools'", "'Intended Audience :: Developers'", "'Development Status :: 4 - Beta'", "'Programming Language :: Python'", "'Intended Audience :: Developers'", "'License :: OSI Approved :: Apache Software License'", "'Topic :: Software Development :: Libraries :: Python Modules'", "'Topic :: Database :: Front-Ends'"]}}], ["f23fe8581ce2606dc8362718ca7f74cb", {"code_string": "from ooop import OOOP\no = OOOP(dbname = \"testv6\")\npartners = o.ResPartner.all()\nfor partner in partners:\n    print(\"id: %d, name: %s\" %(partner._ref, partner.name))\n", "code_toks_joined": "from ooop import OOOP <NEWLINE> o = OOOP ( dbname = <STRING> ) <NEWLINE> partners = o . ResPartner . all ( ) <NEWLINE> for partner in partners : <NEWLINE> <INDENT> print ( <STRING> % ( partner . _ref , partner . name ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"testv6\"", "\"id: %d, name: %s\""]}}], ["54a12f552645c1db43e5451ad357fff9", {"code_string": "class URLTest(unittest.TestCase):\n    def test_valid_url(self):\n        url = \"http://mkdocs.org\"\n        option = config_options.URL()\n        value = option.validate(url)\n        self.assertEqual(value, url)\n    def test_invalid_url(self):\n        option = config_options.URL()\n        self.assertRaises(config_options.ValidationError,\n            option.validate, \"www.mkdocs.org\")\n    def test_invalid(self):\n        option = config_options.URL()\n        self.assertRaises(config_options.ValidationError,\n            option.validate, 1)\n", "code_toks_joined": "class URLTest ( unittest . TestCase ) : <NEWLINE> <INDENT> def test_valid_url ( self ) : <NEWLINE> <INDENT> url = <STRING> <NEWLINE> option = config_options . URL ( ) <NEWLINE> value = option . validate ( url ) <NEWLINE> self . assertEqual ( value , url ) <NEWLINE> <DEDENT> def test_invalid_url ( self ) : <NEWLINE> <INDENT> option = config_options . URL ( ) <NEWLINE> self . assertRaises ( config_options . ValidationError , <NEWLINE> <INDENT> option . validate , <STRING> ) <NEWLINE> <DEDENT> <DEDENT> def test_invalid ( self ) : <NEWLINE> <INDENT> option = config_options . URL ( ) <NEWLINE> self . assertRaises ( config_options . ValidationError , <NEWLINE> <INDENT> option . validate , 1 ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"http://mkdocs.org\"", "\"www.mkdocs.org\""]}}], ["dcea7489566aff13a75277cbf5ce1be0", {"code_string": "\"\"\"This sample will show the user the properties of a\"\"\"\nimport arcrest\nif __name__ == \"__main__\":\n    url = \"https://<tile site>/arcgis/rest/admin\"\n    username = \"<agol username>\"\n    password = \"<agol password>\"\n    sh = arcrest.AGOLTokenSecurityHandler(username, password)\n    agolServices = arcrest.hostedservice.Services(url, securityHandler = sh)\n    for service in agolServices.services:\n        if isinstance(service, arcrest.hostedservice.AdminMapService):\n            print(service.id)\n            print(service.urlService)\n            print(service.name)\n", "code_toks_joined": "<STRING> <NEWLINE> import arcrest <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> url = <STRING> <NEWLINE> username = <STRING> <NEWLINE> password = <STRING> <NEWLINE> sh = arcrest . AGOLTokenSecurityHandler ( username , password ) <NEWLINE> agolServices = arcrest . hostedservice . Services ( url , securityHandler = sh ) <NEWLINE> for service in agolServices . services : <NEWLINE> <INDENT> if isinstance ( service , arcrest . hostedservice . AdminMapService ) : <NEWLINE> <INDENT> print ( service . id ) <NEWLINE> print ( service . urlService ) <NEWLINE> print ( service . name ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"This sample will show the user the properties of a\"\"\"", "\"__main__\"", "\"https://<tile site>/arcgis/rest/admin\"", "\"<agol username>\"", "\"<agol password>\""]}}], ["9d29eecc2943207ad141c12eff68b838", {"code_string": "def has_user_profile(u):\n    try:\n        u.get_profile()\n    except UserProfile.DoesNotExist:\n        return False\n    else:\n        return True\n", "code_toks_joined": "def has_user_profile ( u ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> u . get_profile ( ) <NEWLINE> <DEDENT> except UserProfile . DoesNotExist : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["47007efdbc102c1dd2d2d75503cab600", {"code_string": "def getDirs(software_folders):\n    try:\n        software_folders +=[folder for folder in os.listdir(\n            dir) if os.path.isdir(folder)]\n    except IOError as e:\n        print(\"I/O error({0}): {1}\".format(e.errno, e.strerror))\n    except OSError as e:\n        print(\"OS error({0}): {1}\".format(e.errno, e.strerror))\n        print(\"sure the dir is right?\")\n    except:\n        print(\"Unexpected error:\", sys.exc_info()[0])\n        raise\n", "code_toks_joined": "def getDirs ( software_folders ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> software_folders += [ folder for folder in os . listdir ( <NEWLINE> <INDENT> dir ) if os . path . isdir ( folder ) ] <NEWLINE> <DEDENT> <DEDENT> except IOError as e : <NEWLINE> <INDENT> print ( <STRING> . format ( e . errno , e . strerror ) ) <NEWLINE> <DEDENT> except OSError as e : <NEWLINE> <INDENT> print ( <STRING> . format ( e . errno , e . strerror ) ) <NEWLINE> print ( <STRING> ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> print ( <STRING> , sys . exc_info ( ) [ 0 ] ) <NEWLINE> raise <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"I/O error({0}): {1}\"", "\"OS error({0}): {1}\"", "\"sure the dir is right?\"", "\"Unexpected error:\""]}}], ["a1c51004eb9c37aab86212b3cc730477", {"code_string": "file_for_reading = open('somefile.txt', 'r')\nfile_for_writing = open('somefile.txt', 'w')\nfile_for_appending = open('somefile.txt', 'a')\nfile_for_writing.close()\ncount = 0\nwith open('somefile.txt', 'r') as f:\n    for line in f:\n        if re.match(\"^#\", line):\n            count += 1\n    print(\"with block end\")\n", "code_toks_joined": "file_for_reading = open ( <STRING> , <STRING> ) <NEWLINE> file_for_writing = open ( <STRING> , <STRING> ) <NEWLINE> file_for_appending = open ( <STRING> , <STRING> ) <NEWLINE> file_for_writing . close ( ) <NEWLINE> count = 0 <NEWLINE> with open ( <STRING> , <STRING> ) as f : <NEWLINE> <INDENT> for line in f : <NEWLINE> <INDENT> if re . match ( <STRING> , line ) : <NEWLINE> <INDENT> count += 1 <NEWLINE> <DEDENT> <DEDENT> print ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'somefile.txt'", "'r'", "'somefile.txt'", "'w'", "'somefile.txt'", "'a'", "'somefile.txt'", "'r'", "\"^#\"", "\"with block end\""]}}], ["846b92d6a56a4677cc5e722766751c6c", {"code_string": "import logging\nfrom django.conf import settings\nfrom django.core.mail.message import EmailMultiAlternatives\nfrom django.template.loader import get_template\nfrom django.urls import reverse\nfrom django.utils.translation import ugettext_lazy as _\nfrom opaque_keys.edx.keys import CourseKey\nfrom course_discovery.apps.publisher.models import CourseRun\nfrom course_discovery.apps.publisher.utils import is_email_notification_enabled\nlog = logging.getLogger(__name__)\n", "code_toks_joined": "import logging <NEWLINE> from django . conf import settings <NEWLINE> from django . core . mail . message import EmailMultiAlternatives <NEWLINE> from django . template . loader import get_template <NEWLINE> from django . urls import reverse <NEWLINE> from django . utils . translation import ugettext_lazy as _ <NEWLINE> from opaque_keys . edx . keys import CourseKey <NEWLINE> from course_discovery . apps . publisher . models import CourseRun <NEWLINE> from course_discovery . apps . publisher . utils import is_email_notification_enabled <NEWLINE> log = logging . getLogger ( __name__ ) <NEWLINE>", "anonymize_dict": {}}], ["568e6d242b239dc865634f16181275be", {"code_string": "def get_data(self):\n    links = self.generate_link()\n    pool = Pool(8)\n    pool.map(self.sub_get, links)\n", "code_toks_joined": "def get_data ( self ) : <NEWLINE> <INDENT> links = self . generate_link ( ) <NEWLINE> pool = Pool ( 8 ) <NEWLINE> pool . map ( self . sub_get , links ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["98815cbb56f2dd14fcade892ae33b756", {"code_string": "from distutils.core import setup\nimport py2exe\nimport gio\nsetup(\n    name = 'ValOpciones',\n    description = 'Herramienta para valuar Opciones de Compra y Venta',\n    version = '1.0',\n    windows = [\n        {\n            'script': 'interfaz.py',\n            'icon_resources': [(1, \"escudo.ico\")],\n        }\n        ],\n    options = {\n        'py2exe': {\n            'packages': 'encodings',\n            'includes': 'cairo, pango, pangocairo, atk, gobject, gio',\n        }\n        },\n        data_files = [\n            'escudo.png',\n            'libreria.py',\n            'libreria.pyc'\n            ]\n            )\n", "code_toks_joined": "from distutils . core import setup <NEWLINE> import py2exe <NEWLINE> import gio <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> windows = [ <NEWLINE> <INDENT> { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : [ ( 1 , <STRING> ) ] , <NEWLINE> <DEDENT> } <NEWLINE> ] , <NEWLINE> <DEDENT> options = { <NEWLINE> <INDENT> <STRING> : { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <DEDENT> } <NEWLINE> } , <NEWLINE> data_files = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> <NEWLINE> ] <NEWLINE> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'ValOpciones'", "'Herramienta para valuar Opciones de Compra y Venta'", "'1.0'", "'script'", "'interfaz.py'", "'icon_resources'", "\"escudo.ico\"", "'py2exe'", "'packages'", "'encodings'", "'includes'", "'cairo, pango, pangocairo, atk, gobject, gio'", "'escudo.png'", "'libreria.py'", "'libreria.pyc'"]}}], ["19301f32f64daddd9bcfbb869e4713c1", {"code_string": "def ListDirectoryAbsolute(directory):\n    \"\"\"Yields all files in the given directory. The paths are absolute.\"\"\"\n    return(os.path.join(directory, path)\n        for path in tf.gfile.ListDirectory(directory))\n", "code_toks_joined": "def ListDirectoryAbsolute ( directory ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return ( os . path . join ( directory , path ) <NEWLINE> <INDENT> for path in tf . gfile . ListDirectory ( directory ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Yields all files in the given directory. The paths are absolute.\"\"\""]}}], ["249931b0e478ac4d03f6c03ab32afaca", {"code_string": "from distutils.core import setup\nsetup(name = 'flac_compare',\n    version = '0.4.0',\n    author = 'Magnus Runesson',\n    author_email = 'magru@linuxalert.org',\n    url = 'http://www.linuxalert.org/project/flac-utils/',\n    description = 'Compare two flac files',\n    long_description = \"\"\"Compare two flac files using the metadata in the\"\"\",\n    requires = ['mutagen(>=1.19)'],\n    packages = ['flac_compare'],\n    py_modules = ['flac_compare'],\n    package_dir = {'flac_compare': 'src/'},\n    license = 'GPL'\n    )\n", "code_toks_joined": "from distutils . core import setup <NEWLINE> setup ( name = <STRING> , <NEWLINE> <INDENT> version = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> url = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> long_description = <STRING> , <NEWLINE> requires = [ <STRING> ] , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> py_modules = [ <STRING> ] , <NEWLINE> package_dir = { <STRING> : <STRING> } , <NEWLINE> license = <STRING> <NEWLINE> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'flac_compare'", "'0.4.0'", "'Magnus Runesson'", "'magru@linuxalert.org'", "'http://www.linuxalert.org/project/flac-utils/'", "'Compare two flac files'", "\"\"\"Compare two flac files using the metadata in the\"\"\"", "'mutagen(>=1.19)'", "'flac_compare'", "'flac_compare'", "'flac_compare'", "'src/'", "'GPL'"]}}], ["866979d4278981129e781e984f30a659", {"code_string": "def OrEvent(* events):\n    '''Parameters'''\n    or_event = threading.Event()\n    def changed():\n        '''Set ``or_event`` if any of the specified events have been set.'''\n        bools = [event_i.is_set() for event_i in events]\n        if any(bools):\n            or_event.set()\n        else:\n            or_event.clear()\n    for event_i in events:\n        orify(event_i, changed)\n    changed()\n    return or_event\n", "code_toks_joined": "def OrEvent ( * events ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> or_event = threading . Event ( ) <NEWLINE> def changed ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> bools = [ event_i . is_set ( ) for event_i in events ] <NEWLINE> if any ( bools ) : <NEWLINE> <INDENT> or_event . set ( ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> or_event . clear ( ) <NEWLINE> <DEDENT> <DEDENT> for event_i in events : <NEWLINE> <INDENT> orify ( event_i , changed ) <NEWLINE> <DEDENT> changed ( ) <NEWLINE> return or_event <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Parameters'''", "'''Set ``or_event`` if any of the specified events have been set.'''"]}}], ["2d6bbf7d1cf4b69fe7d77da9a4c0ba94", {"code_string": "def test_name_returns_custom_name_when_given(self):\n    f = File(io.StringIO('...'), 'file.txt')\n    self.assertEqual(f.name, 'file.txt')\n", "code_toks_joined": "def test_name_returns_custom_name_when_given ( self ) : <NEWLINE> <INDENT> f = File ( io . StringIO ( <STRING> ) , <STRING> ) <NEWLINE> self . assertEqual ( f . name , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'...'", "'file.txt'", "'file.txt'"]}}], ["bc78292ae1660e67c0a1431fd7b12a5a", {"code_string": "class TestMobileSpecAppFunctions(unittest.TestCase):\n    def test_launch(self):\n        comm.setUp()\n        app_name = \"mobilespec\"\n        pkg_name = \"org.apache.\" + app_name.lower()\n        if not comm.check_app_installed(pkg_name, self):\n            comm.app_install(app_name, pkg_name, self)\n        comm.app_launch(app_name, pkg_name, self)\n", "code_toks_joined": "class TestMobileSpecAppFunctions ( unittest . TestCase ) : <NEWLINE> <INDENT> def test_launch ( self ) : <NEWLINE> <INDENT> comm . setUp ( ) <NEWLINE> app_name = <STRING> <NEWLINE> pkg_name = <STRING> + app_name . lower ( ) <NEWLINE> if not comm . check_app_installed ( pkg_name , self ) : <NEWLINE> <INDENT> comm . app_install ( app_name , pkg_name , self ) <NEWLINE> <DEDENT> comm . app_launch ( app_name , pkg_name , self ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"mobilespec\"", "\"org.apache.\""]}}], ["2dbd6586d40c1c8b562f6c0cfe16646f", {"code_string": "import matplotlib.pyplot as plt\nimport numpy as np\nfig = plt.figure()\nent = (np.loadtxt('t-fixed-2.0.DAT')).T\nplt.xlabel('$t \\Delta$')\nplt.ylabel('$\\sigma(t)$', rotation = 'horizontal')\nplt.plot(ent[0], ent[1], 'y-')\nplt.grid(True)\nplt.show()\n", "code_toks_joined": "import matplotlib . pyplot as plt <NEWLINE> import numpy as np <NEWLINE> fig = plt . figure ( ) <NEWLINE> ent = ( np . loadtxt ( <STRING> ) ) . T <NEWLINE> plt . xlabel ( <STRING> ) <NEWLINE> plt . ylabel ( <STRING> , rotation = <STRING> ) <NEWLINE> plt . plot ( ent [ 0 ] , ent [ 1 ] , <STRING> ) <NEWLINE> plt . grid ( True ) <NEWLINE> plt . show ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'t-fixed-2.0.DAT'", "'$t \\Delta$'", "'$\\sigma(t)$'", "'horizontal'", "'y-'"]}}], ["3f8489fecbca56b38cde599a76c1250e", {"code_string": "def headerData(self, col, orientation = Qt.Horizontal, role = Qt.DisplayRole):\n    \"\"\"Sets the data for the given role and section in the header with the specified orientation to the value supplied.\"\"\"\n    if role != Qt.DisplayRole:\n        return None\n    if orientation == Qt.Horizontal:\n        if col == 0:\n            return \"ASSET\"\n        elif col == 1:\n            return \"ID\"\n        elif col == 2:\n            return \"VERSION #\"\n", "code_toks_joined": "def headerData ( self , col , orientation = Qt . Horizontal , role = Qt . DisplayRole ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if role != Qt . DisplayRole : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> if orientation == Qt . Horizontal : <NEWLINE> <INDENT> if col == 0 : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> elif col == 1 : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> elif col == 2 : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Sets the data for the given role and section in the header with the specified orientation to the value supplied.\"\"\"", "\"ASSET\"", "\"ID\"", "\"VERSION #\""]}}], ["5aa6168fad6bf14bf5bc3e3bbcd3a818", {"code_string": "class Sample(object):\n    def __init__(self, the_id, filename, size, size_in_bytes, upload_date_utc, upload_status):\n        \"\"\"Initialize a new Sample instance with the provided arguments.\"\"\"\n        self.id = the_id\n        self.filename = filename\n        self.human_readable_size = size\n        self.size_in_bytes = size_in_bytes,\n        self.upload_date = upload_date_utc\n        self.upload_status = upload_status\n    @ property\n    def localized_upload_date(self):\n        \"\"\"Get the upload date of this sample, localized to the local timezone.  Useful for\"\"\"\n        return localize_utc_datetime_to_local_timezone(self.upload_date)\n", "code_toks_joined": "class Sample ( object ) : <NEWLINE> <INDENT> def __init__ ( self , the_id , filename , size , size_in_bytes , upload_date_utc , upload_status ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . id = the_id <NEWLINE> self . filename = filename <NEWLINE> self . human_readable_size = size <NEWLINE> self . size_in_bytes = size_in_bytes , <NEWLINE> self . upload_date = upload_date_utc <NEWLINE> self . upload_status = upload_status <NEWLINE> <DEDENT> @ property <NEWLINE> def localized_upload_date ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return localize_utc_datetime_to_local_timezone ( self . upload_date ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Initialize a new Sample instance with the provided arguments.\"\"\"", "\"\"\"Get the upload date of this sample, localized to the local timezone.  Useful for\"\"\""]}}], ["47faae64349c3edd9bd5b6b68184f9db", {"code_string": "import pecan\nfrom webtest import TestApp\nfrom peacock import model\n", "code_toks_joined": "import pecan <NEWLINE> from webtest import TestApp <NEWLINE> from peacock import model <NEWLINE>", "anonymize_dict": {}}], ["053416b4c203ce7f57136dcf718c13e2", {"code_string": "from flask import abort\nfrom flask.ext.sqlalchemy import Pagination\nfrom sqlalchemy import func\nfrom sqlalchemy.orm import aliased\nfrom sqlalchemy.sql import and_\nfrom MonkeyBook.extensions import db\nfrom MonkeyBook.models.monkey import Monkey, monkey_friends, best_friends\n", "code_toks_joined": "from flask import abort <NEWLINE> from flask . ext . sqlalchemy import Pagination <NEWLINE> from sqlalchemy import func <NEWLINE> from sqlalchemy . orm import aliased <NEWLINE> from sqlalchemy . sql import and_ <NEWLINE> from MonkeyBook . extensions import db <NEWLINE> from MonkeyBook . models . monkey import Monkey , monkey_friends , best_friends <NEWLINE>", "anonymize_dict": {}}], ["a67d8edf5574fad699d38b0af8ba1537", {"code_string": "from nose.tools import(\n    eq_,\n    ok_,\n)\nfrom..mapping import(\n    Mapping,\n    MappingProperty,\n    object_property,\n)\nfrom..schema import JSONSchema\nfrom..types import(\n    Integer,\n    String,\n)\n", "code_toks_joined": "from nose . tools import ( <NEWLINE> <INDENT> eq_ , <NEWLINE> ok_ , <NEWLINE> <DEDENT> ) <NEWLINE> from . . mapping import ( <NEWLINE> <INDENT> Mapping , <NEWLINE> MappingProperty , <NEWLINE> object_property , <NEWLINE> <DEDENT> ) <NEWLINE> from . . schema import JSONSchema <NEWLINE> from . . types import ( <NEWLINE> <INDENT> Integer , <NEWLINE> String , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {}}], ["1e8934122a9d07777d379caa53e48f04", {"code_string": "\"\"\"***************************************************************************\"\"\"\n__author__ = 'Alexander Bruy'\n__date__ = 'October 2014'\n__copyright__ = '(C) 2014, Alexander Bruy'\n__revision__ = '$Format:%H$'\nimport os\nfrom PyQt4 import uic\nfrom PyQt4.QtCore import QUrl\nfrom PyQt4.QtGui import QDesktopServices\npluginPath = os.path.split(os.path.dirname(__file__))[0]\nWIDGET, BASE = uic.loadUiType(\n    os.path.join(pluginPath, 'ui', 'DlgMessage.ui'))\n", "code_toks_joined": "<STRING> <NEWLINE> __author__ = <STRING> <NEWLINE> __date__ = <STRING> <NEWLINE> __copyright__ = <STRING> <NEWLINE> __revision__ = <STRING> <NEWLINE> import os <NEWLINE> from PyQt4 import uic <NEWLINE> from PyQt4 . QtCore import QUrl <NEWLINE> from PyQt4 . QtGui import QDesktopServices <NEWLINE> pluginPath = os . path . split ( os . path . dirname ( __file__ ) ) [ 0 ] <NEWLINE> WIDGET , BASE = uic . loadUiType ( <NEWLINE> <INDENT> os . path . join ( pluginPath , <STRING> , <STRING> ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"***************************************************************************\"\"\"", "'Alexander Bruy'", "'October 2014'", "'(C) 2014, Alexander Bruy'", "'$Format:%H$'", "'ui'", "'DlgMessage.ui'"]}}], ["1ff803ac026a0c245395d2f53ca78540", {"code_string": "from django.conf.urls import url\nfrom django.contrib import admin\nfrom actors.views import ActorsView\nurlpatterns = [\n    url(r'^admin/', admin.site.urls),\n    url(r'^', ActorsView.as_view(), name = \"actors\"),\n]\n", "code_toks_joined": "from django . conf . urls import url <NEWLINE> from django . contrib import admin <NEWLINE> from actors . views import ActorsView <NEWLINE> urlpatterns = [ <NEWLINE> <INDENT> url ( <STRING> , admin . site . urls ) , <NEWLINE> url ( <STRING> , ActorsView . as_view ( ) , name = <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["r'^admin/'", "r'^'", "\"actors\""]}}], ["7c041514e54c0d77c639b56c3bcf3639", {"code_string": "def handle_departure(event):\n    aircraft = event.sender\n    aircraft.depart()\n    aircraft.controller.calibrate()\n", "code_toks_joined": "def handle_departure ( event ) : <NEWLINE> <INDENT> aircraft = event . sender <NEWLINE> aircraft . depart ( ) <NEWLINE> aircraft . controller . calibrate ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["5617c7bf48458cb9fe5247b43702a85a", {"code_string": "def forwards(self, orm):\n    db.add_column('lizard_levee_imagemap', 'auto_offset_z', self.gf('django.db.models.fields.FloatField')(default = 2.0), keep_default = False)\n    db.add_column('lizard_levee_imagemap', 'auto_scale_z', self.gf('django.db.models.fields.FloatField')(default = 100.0), keep_default = False)\n", "code_toks_joined": "def forwards ( self , orm ) : <NEWLINE> <INDENT> db . add_column ( <STRING> , <STRING> , self . gf ( <STRING> ) ( default = 2.0 ) , keep_default = False ) <NEWLINE> db . add_column ( <STRING> , <STRING> , self . gf ( <STRING> ) ( default = 100.0 ) , keep_default = False ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'lizard_levee_imagemap'", "'auto_offset_z'", "'django.db.models.fields.FloatField'", "'lizard_levee_imagemap'", "'auto_scale_z'", "'django.db.models.fields.FloatField'"]}}], ["edcd29e01bc5e959becf0700e3c25a22", {"code_string": "def enable_default_plugins():\n    \"\"\"Enable new plugins that have been added between versions\"\"\"\n    global config\n    changed = False\n    for module_path in DEFAULT_PLUGINS:\n        if module_path not in config['INSTALLED_APPS']:\n            config['INSTALLED_APPS'].append(module_path)\n            logger.warning(\n                (\n                    \"Default plugin {mod} not found in configuration. To re-disable it, run:\\n\"\n                    \"   $ kolibri plugin {mod} disable\"\n                ).format(mod = module_path)\n            )\n            changed = True\n    if changed:\n        save()\n", "code_toks_joined": "def enable_default_plugins ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> global config <NEWLINE> changed = False <NEWLINE> for module_path in DEFAULT_PLUGINS : <NEWLINE> <INDENT> if module_path not in config [ <STRING> ] : <NEWLINE> <INDENT> config [ <STRING> ] . append ( module_path ) <NEWLINE> logger . warning ( <NEWLINE> <INDENT> ( <NEWLINE> <INDENT> <STRING> <NEWLINE> <STRING> <NEWLINE> <DEDENT> ) . format ( mod = module_path ) <NEWLINE> <DEDENT> ) <NEWLINE> changed = True <NEWLINE> <DEDENT> <DEDENT> if changed : <NEWLINE> <INDENT> save ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Enable new plugins that have been added between versions\"\"\"", "'INSTALLED_APPS'", "'INSTALLED_APPS'", "\"Default plugin {mod} not found in configuration. To re-disable it, run:\\n\"", "\"   $ kolibri plugin {mod} disable\""]}}], ["d149af0e070d13e16dcc8dd2735d06e3", {"code_string": "\"\"\"A script to get information from MrTijn's new server so I (MrMadsenMalmo) can display it\"\"\"\n__author__ = \"MrMadsenMalmo - Fredrik A. Madsen-Malmo & Tijndagamer\"\nimport os\nimport time\nimport re\nimport datetime\n", "code_toks_joined": "<STRING> <NEWLINE> __author__ = <STRING> <NEWLINE> import os <NEWLINE> import time <NEWLINE> import re <NEWLINE> import datetime <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"A script to get information from MrTijn's new server so I (MrMadsenMalmo) can display it\"\"\"", "\"MrMadsenMalmo - Fredrik A. Madsen-Malmo & Tijndagamer\""]}}], ["e6dfb3df6815182fda93f0b0d6bba7f2", {"code_string": "\"\"\"Author: Rajat Gupta\"\"\"\nimport uuid\nfrom beacons import app\nif __name__ == '__main__':\n    app.secret_key = str(uuid.uuid4())\n    app.run(debug = True)\n", "code_toks_joined": "<STRING> <NEWLINE> import uuid <NEWLINE> from beacons import app <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> app . secret_key = str ( uuid . uuid4 ( ) ) <NEWLINE> app . run ( debug = True ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Author: Rajat Gupta\"\"\"", "'__main__'"]}}], ["1325d80d7021912b17eee4b01ae70cba", {"code_string": "class GUIThread(Thread):\n    def run(self):\n        print('Creating Window')\n        self.gtkWindow = GUI()\n        print('Created Window')\n        Gtk.main()\n    def join(self):\n        Gtk.main_quit()\n", "code_toks_joined": "class GUIThread ( Thread ) : <NEWLINE> <INDENT> def run ( self ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> self . gtkWindow = GUI ( ) <NEWLINE> print ( <STRING> ) <NEWLINE> Gtk . main ( ) <NEWLINE> <DEDENT> def join ( self ) : <NEWLINE> <INDENT> Gtk . main_quit ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Creating Window'", "'Created Window'"]}}], ["fa4097ce3a14fced3bd75d0db5090f30", {"code_string": "from django.core.management.base import BaseCommand, CommandError\nfrom apps.models.models import Initiative\n\"\"\"A manage.py command to migrate cities from a CSV file\"\"\"\n", "code_toks_joined": "from django . core . management . base import BaseCommand , CommandError <NEWLINE> from apps . models . models import Initiative <NEWLINE> <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"A manage.py command to migrate cities from a CSV file\"\"\""]}}], ["142482d718edabc1a413d4319e24dd13", {"code_string": "def solve(self, n_iter = 0, eps = 1.0e-16):\n    \"\"\"Solves the equation given an error precision -- eps.  If\"\"\"\n    err = self.timeStep()\n    count = 1\n    while err > eps:\n        if n_iter and count >= n_iter:\n            return err\n        err = self.timeStep()\n        count = count + 1\n    return count\n", "code_toks_joined": "def solve ( self , n_iter = 0 , eps = 1.0e-16 ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> err = self . timeStep ( ) <NEWLINE> count = 1 <NEWLINE> while err > eps : <NEWLINE> <INDENT> if n_iter and count >= n_iter : <NEWLINE> <INDENT> return err <NEWLINE> <DEDENT> err = self . timeStep ( ) <NEWLINE> count = count + 1 <NEWLINE> <DEDENT> return count <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Solves the equation given an error precision -- eps.  If\"\"\""]}}], ["9fd289cf594fe67287ab432ceb509dcb", {"code_string": "class ChaincodeSupportStub(object):\n    \"\"\"Interface that provides support to chaincode execution. ChaincodeContext\"\"\"\n    def __init__(self, channel):\n        \"\"\"Constructor.\"\"\"\n        self.Register = channel.stream_stream(\n            '/protos.ChaincodeSupport/Register',\n            request_serializer = ChaincodeMessage.SerializeToString,\n            response_deserializer = ChaincodeMessage.FromString,\n            )\n", "code_toks_joined": "class ChaincodeSupportStub ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , channel ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . Register = channel . stream_stream ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> request_serializer = ChaincodeMessage . SerializeToString , <NEWLINE> response_deserializer = ChaincodeMessage . FromString , <NEWLINE> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Interface that provides support to chaincode execution. ChaincodeContext\"\"\"", "\"\"\"Constructor.\"\"\"", "'/protos.ChaincodeSupport/Register'"]}}], ["95ccd82bc106119a6e8ec4b9ebe68690", {"code_string": "class Migration(SchemaMigration):\n    def forwards(self, orm):\n        safe_add_column(\n            u'auth_user', 'is_fake',\n            self.gf('django.db.models.fields.BooleanField')(default = False), keep_default = False)\n    def backwards(self, orm):\n        db.delete_column('auth_user', 'is_fake')\n    complete_apps = ['askbot']\n", "code_toks_joined": "class Migration ( SchemaMigration ) : <NEWLINE> <INDENT> def forwards ( self , orm ) : <NEWLINE> <INDENT> safe_add_column ( <NEWLINE> <INDENT> <STRING> , <STRING> , <NEWLINE> self . gf ( <STRING> ) ( default = False ) , keep_default = False ) <NEWLINE> <DEDENT> <DEDENT> def backwards ( self , orm ) : <NEWLINE> <INDENT> db . delete_column ( <STRING> , <STRING> ) <NEWLINE> <DEDENT> complete_apps = [ <STRING> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["u'auth_user'", "'is_fake'", "'django.db.models.fields.BooleanField'", "'auth_user'", "'is_fake'", "'askbot'"]}}], ["0c55da8ab09ba6dff2757c3c6661c2b8", {"code_string": "def kill(self, session, name):\n    \"\"\"Kills the given component instance\"\"\"\n    try:\n        self._ipopo.kill(name)\n        session.write_line(\"Component '{0}' killed.\", name)\n    except ValueError as ex:\n        session.write_line(\"Invalid parameter: {0}\", ex)\n        return False\n", "code_toks_joined": "def kill ( self , session , name ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> try : <NEWLINE> <INDENT> self . _ipopo . kill ( name ) <NEWLINE> session . write_line ( <STRING> , name ) <NEWLINE> <DEDENT> except ValueError as ex : <NEWLINE> <INDENT> session . write_line ( <STRING> , ex ) <NEWLINE> return False <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Kills the given component instance\"\"\"", "\"Component '{0}' killed.\"", "\"Invalid parameter: {0}\""]}}], ["9d4f9ce1e6407e0b4ba7a4bce3a89e6a", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('base', '0011_satellite_manual_tle'),\n    ]\n    operations = [\n        migrations.AlterField(\n            model_name = 'station',\n            name = 'antenna',\n            field = models.ManyToManyField(blank = True, help_text = b'If you want to add a new Antenna contact <a href=\"https://community.satnogs.org/\" target=\"_blank\">SatNOGS Team</a>', to = 'base.Antenna'),\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . AlterField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . ManyToManyField ( blank = True , help_text = <STRING> , to = <STRING> ) , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'base'", "'0011_satellite_manual_tle'", "'station'", "'antenna'", "b'If you want to add a new Antenna contact <a href=\"https://community.satnogs.org/\" target=\"_blank\">SatNOGS Team</a>'", "'base.Antenna'"]}}], ["4ac830ce8634044a33a4d7f82e77c4ec", {"code_string": "def requires_admin(f):\n    @ wraps(f)\n    def decorated_function(* args, ** kwargs):\n        if 'user' not in g or g.user is None or not g.user.is_admin():\n            flash(gettext(u'You don\\'t have privilege to view this page.'))\n            return redirect(url_for('page_not_found'))\n        return f(* args, ** kwargs)\n    return decorated_function\n", "code_toks_joined": "def requires_admin ( f ) : <NEWLINE> <INDENT> @ wraps ( f ) <NEWLINE> def decorated_function ( * args , ** kwargs ) : <NEWLINE> <INDENT> if <STRING> not in g or g . user is None or not g . user . is_admin ( ) : <NEWLINE> <INDENT> flash ( gettext ( <STRING> ) ) <NEWLINE> return redirect ( url_for ( <STRING> ) ) <NEWLINE> <DEDENT> return f ( * args , ** kwargs ) <NEWLINE> <DEDENT> return decorated_function <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'user'", "u'You don\\'t have privilege to view this page.'", "'page_not_found'"]}}], ["dca3e58d2603bb5b0e7e4e756d8f77e3", {"code_string": "class QuickbooksToken(models.Model):\n    user = models.ForeignKey(settings.AUTH_USER_MODEL, related_name = 'quickbooks_tokens')\n    access_token = models.CharField(max_length = 255)\n    access_token_secret = models.CharField(max_length = 255)\n    realm_id = models.CharField(max_length = 64)\n    data_source = models.CharField(max_length = 10)\n    def __str__(self):\n        return '%s - %d' %(str(self.user), self.id)\n", "code_toks_joined": "class QuickbooksToken ( models . Model ) : <NEWLINE> <INDENT> user = models . ForeignKey ( settings . AUTH_USER_MODEL , related_name = <STRING> ) <NEWLINE> access_token = models . CharField ( max_length = 255 ) <NEWLINE> access_token_secret = models . CharField ( max_length = 255 ) <NEWLINE> realm_id = models . CharField ( max_length = 64 ) <NEWLINE> data_source = models . CharField ( max_length = 10 ) <NEWLINE> def __str__ ( self ) : <NEWLINE> <INDENT> return <STRING> % ( str ( self . user ) , self . id ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'quickbooks_tokens'", "'%s - %d'"]}}], ["dffcf9b91be70d28aa268f15cce2f20a", {"code_string": "def GetGccVersion(env):\n    \"\"\"Gets the gcc version of the target toolchain.\"\"\"\n    if not env.Bit('host_linux'):\n        return(None, None, None)\n    if env.Bit('cross_compile'):\n        gcc_command = env['CXX']\n    else:\n        gcc_command = 'gcc'\n    version_string = _OutputFromShellCommand(\n        '%s --version | head -n 1 |'\n        r'sed \"s/.*\\([0-9]\\+\\.[0-9]\\+\\.[0-9]\\+\\).*/\\1/g\"' % gcc_command)\n    return tuple([int(x or '0') for x in version_string.split('.')])\n", "code_toks_joined": "def GetGccVersion ( env ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if not env . Bit ( <STRING> ) : <NEWLINE> <INDENT> return ( None , None , None ) <NEWLINE> <DEDENT> if env . Bit ( <STRING> ) : <NEWLINE> <INDENT> gcc_command = env [ <STRING> ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> gcc_command = <STRING> <NEWLINE> <DEDENT> version_string = _OutputFromShellCommand ( <NEWLINE> <INDENT> <STRING> <NEWLINE> <STRING> % gcc_command ) <NEWLINE> <DEDENT> return tuple ( [ int ( x or <STRING> ) for x in version_string . split ( <STRING> ) ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Gets the gcc version of the target toolchain.\"\"\"", "'host_linux'", "'cross_compile'", "'CXX'", "'gcc'", "'%s --version | head -n 1 |'", "r'sed \"s/.*\\([0-9]\\+\\.[0-9]\\+\\.[0-9]\\+\\).*/\\1/g\"'", "'0'", "'.'"]}}], ["ddd6842490df138fca71ab366d5eb40a", {"code_string": "from bpcs_steg_decode import decode\nfrom bpcs_steg_encode import encode\nfrom bpcs_steg_capacity import capacity\nfrom bpcs_steg_test import test_all\n__version__ = '0.0.2'\n", "code_toks_joined": "from bpcs_steg_decode import decode <NEWLINE> from bpcs_steg_encode import encode <NEWLINE> from bpcs_steg_capacity import capacity <NEWLINE> from bpcs_steg_test import test_all <NEWLINE> __version__ = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'0.0.2'"]}}], ["989e374367468869cb0c3e8c97eccf71", {"code_string": "class OverrideBackendTestCase(TestCase):\n    @ patch('requests.post')\n    def test_runcmd(self, mock_post):\n        ret = notify('message', 'title', {\n            'backends': ['foobar'],\n            'foobar': {\n                'backend': 'pushover',\n                'user_key': 't0k3n',\n            }\n        })\n        self.assertEqual(ret, 0)\n", "code_toks_joined": "class OverrideBackendTestCase ( TestCase ) : <NEWLINE> <INDENT> @ patch ( <STRING> ) <NEWLINE> def test_runcmd ( self , mock_post ) : <NEWLINE> <INDENT> ret = notify ( <STRING> , <STRING> , { <NEWLINE> <INDENT> <STRING> : [ <STRING> ] , <NEWLINE> <STRING> : { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT> } ) <NEWLINE> self . assertEqual ( ret , 0 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'requests.post'", "'message'", "'title'", "'backends'", "'foobar'", "'foobar'", "'backend'", "'pushover'", "'user_key'", "'t0k3n'"]}}], ["3eafc86cb22d24e3dc0dd7aa6868532d", {"code_string": "class MultiplexTransport(BaseTransportMixin):\n    name = 'multiplex'\n    def __init__(self, conn_info):\n        self.conn_info = conn_info\n    def get_conn_info(self):\n        return self.conn_info\n", "code_toks_joined": "class MultiplexTransport ( BaseTransportMixin ) : <NEWLINE> <INDENT> name = <STRING> <NEWLINE> def __init__ ( self , conn_info ) : <NEWLINE> <INDENT> self . conn_info = conn_info <NEWLINE> <DEDENT> def get_conn_info ( self ) : <NEWLINE> <INDENT> return self . conn_info <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'multiplex'"]}}], ["18739a51e2eb1b9e8d41c4aba4b8b06f", {"code_string": "import sys\nfrom time import sleep\nsys.path.append('./')\n", "code_toks_joined": "import sys <NEWLINE> from time import sleep <NEWLINE> sys . path . append ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'./'"]}}], ["ac0123bffacf94bbb5b65afef7db1a42", {"code_string": "def test_pheno_objects_shh_2():\n    \"\"\"Equivalent to above, using convenience method\"\"\"\n    objs = get_objects_for_subject(subject = HUMAN_SHH,\n        object_category = 'phenotype')\n    print(objs)\n    assert HOLOPROSENCEPHALY in objs\n    assert len(objs) > 50\n", "code_toks_joined": "def test_pheno_objects_shh_2 ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> objs = get_objects_for_subject ( subject = HUMAN_SHH , <NEWLINE> <INDENT> object_category = <STRING> ) <NEWLINE> <DEDENT> print ( objs ) <NEWLINE> assert HOLOPROSENCEPHALY in objs <NEWLINE> assert len ( objs ) > 50 <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Equivalent to above, using convenience method\"\"\"", "'phenotype'"]}}], ["b550d375d8aa929de5869eb880afc505", {"code_string": "def line_matrix(line):\n    v0 = line[0: 2, 0]\n    v1 = line[0: 2, 1]\n    v = v1 - v0\n    length = norm(v)\n    angle = math.atan2(get_y(v), get_x(v))\n    shift_to_v0 = shift_matrix(get_x(v0), get_y(v0))\n    shift_to_center = shift_matrix(0, - 0.5)\n    scale_to_line = scale_matrix(length, c2)\n    rotate_to_line = rotate_matrix(angle)\n    return shift_to_v0 * shift_to_center * rotate_to_line * scale_to_line\n", "code_toks_joined": "def line_matrix ( line ) : <NEWLINE> <INDENT> v0 = line [ 0 : 2 , 0 ] <NEWLINE> v1 = line [ 0 : 2 , 1 ] <NEWLINE> v = v1 - v0 <NEWLINE> length = norm ( v ) <NEWLINE> angle = math . atan2 ( get_y ( v ) , get_x ( v ) ) <NEWLINE> shift_to_v0 = shift_matrix ( get_x ( v0 ) , get_y ( v0 ) ) <NEWLINE> shift_to_center = shift_matrix ( 0 , - 0.5 ) <NEWLINE> scale_to_line = scale_matrix ( length , c2 ) <NEWLINE> rotate_to_line = rotate_matrix ( angle ) <NEWLINE> return shift_to_v0 * shift_to_center * rotate_to_line * scale_to_line <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["d7af7601e50cfac932f7c50c5efed2fe", {"code_string": "def setUp(self):\n    super(TestSecurityGroupsClient, self).setUp()\n    fake_auth = fake_auth_provider.FakeAuthProvider()\n    self.client = security_groups_client.SecurityGroupsClient(\n        fake_auth, 'compute', 'regionOne')\n", "code_toks_joined": "def setUp ( self ) : <NEWLINE> <INDENT> super ( TestSecurityGroupsClient , self ) . setUp ( ) <NEWLINE> fake_auth = fake_auth_provider . FakeAuthProvider ( ) <NEWLINE> self . client = security_groups_client . SecurityGroupsClient ( <NEWLINE> <INDENT> fake_auth , <STRING> , <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'compute'", "'regionOne'"]}}], ["67a5c04178a787e5354c70d66084560e", {"code_string": "class Location(TimeStampedModel):\n    address = models.TextField()\n    def __unicode__(self):\n        return self.address\n", "code_toks_joined": "class Location ( TimeStampedModel ) : <NEWLINE> <INDENT> address = models . TextField ( ) <NEWLINE> def __unicode__ ( self ) : <NEWLINE> <INDENT> return self . address <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["d71382e67a3e45ea2f4879a285e7ec01", {"code_string": "from django.contrib import admin\nfrom answrs.models import UserProfile, Category, Question, Answer\nadmin.site.register(UserProfile)\nadmin.site.register(Category)\nadmin.site.register(Question)\nadmin.site.register(Answer)\n", "code_toks_joined": "from django . contrib import admin <NEWLINE> from answrs . models import UserProfile , Category , Question , Answer <NEWLINE> admin . site . register ( UserProfile ) <NEWLINE> admin . site . register ( Category ) <NEWLINE> admin . site . register ( Question ) <NEWLINE> admin . site . register ( Answer ) <NEWLINE>", "anonymize_dict": {}}], ["4c410fdf2b109c1b69363b2cb7b17a1c", {"code_string": "from setuptools import setup\nlong_description = \"\"\"sphinx-javalink\"\"\"\nsetup(\n    name = 'sphinx-javalink',\n    version = '0.11.1',\n    description = 'Link to Javadoc APIs from Sphinx documentation',\n    long_description = long_description,\n    url = 'https://github.com/bluekeyes/sphinx-javalink',\n    author = 'Billy Keyes',\n    author_email = 'bluekeyes@gmail.com',\n    license = 'MIT',\n    classifiers = [\n        'Development Status :: 4 - Beta',\n        'Intended Audience :: Developers',\n        'Topic :: Documentation',\n        'Topic :: Software Development :: Documentation',\n        'Framework :: Sphinx :: Extension',\n        'License :: OSI Approved :: MIT License',\n        'Programming Language :: Java',\n        'Programming Language :: Python :: 2',\n        'Programming Language :: Python :: 2.7'\n    ],\n    keywords = 'javadoc java sphinx documentation',\n    packages = ['javalink'],\n    install_requires = ['sphinx >=1.2', 'javatools >=1.3']\n)\n", "code_toks_joined": "from setuptools import setup <NEWLINE> long_description = <STRING> <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> long_description = long_description , <NEWLINE> url = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> license = <STRING> , <NEWLINE> classifiers = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> <NEWLINE> <DEDENT> ] , <NEWLINE> keywords = <STRING> , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> install_requires = [ <STRING> , <STRING> ] <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"sphinx-javalink\"\"\"", "'sphinx-javalink'", "'0.11.1'", "'Link to Javadoc APIs from Sphinx documentation'", "'https://github.com/bluekeyes/sphinx-javalink'", "'Billy Keyes'", "'bluekeyes@gmail.com'", "'MIT'", "'Development Status :: 4 - Beta'", "'Intended Audience :: Developers'", "'Topic :: Documentation'", "'Topic :: Software Development :: Documentation'", "'Framework :: Sphinx :: Extension'", "'License :: OSI Approved :: MIT License'", "'Programming Language :: Java'", "'Programming Language :: Python :: 2'", "'Programming Language :: Python :: 2.7'", "'javadoc java sphinx documentation'", "'javalink'", "'sphinx >=1.2'", "'javatools >=1.3'"]}}], ["518ffb3d236117b4afde2ecda12f4182", {"code_string": "from isat.rules import *\nfrom isat.tools import isat_filename\nfrom game import GameState\nfrom os.path import exists\nimport unittest\n", "code_toks_joined": "from isat . rules import * <NEWLINE> from isat . tools import isat_filename <NEWLINE> from game import GameState <NEWLINE> from os . path import exists <NEWLINE> import unittest <NEWLINE>", "anonymize_dict": {}}], ["30e77405fc608965300ff7174665988f", {"code_string": "def testPeek(self):\n    \"\"\"Test peeking in the cache\"\"\"\n    self.cache.Clear()\n    self.cache.PutItem(\"hello\")\n    self.cache.PutItem(\"hello1\")\n    self.cache.PutItem(\"hello2\")\n    self.assertEquals(self.cache.PeekNext(), \"hello2\")\n    self.assertEquals(self.cache.PeekPrev(), \"hello\")\n", "code_toks_joined": "def testPeek ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . cache . Clear ( ) <NEWLINE> self . cache . PutItem ( <STRING> ) <NEWLINE> self . cache . PutItem ( <STRING> ) <NEWLINE> self . cache . PutItem ( <STRING> ) <NEWLINE> self . assertEquals ( self . cache . PeekNext ( ) , <STRING> ) <NEWLINE> self . assertEquals ( self . cache . PeekPrev ( ) , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test peeking in the cache\"\"\"", "\"hello\"", "\"hello1\"", "\"hello2\"", "\"hello2\"", "\"hello\""]}}], ["cfdb9df550ae98882d10e577247ad6fe", {"code_string": "class CompressTestCase(unittest.TestCase):\n    def test_regular(self):\n        self.assertEquals('a3b2c1a4', compress('aaabbcaaaa'))\n    def test_singles(self):\n        self.assertEquals('a1k1o1s1', compress('akos'))\n    def test_single_letter(self):\n        self.assertEquals('a10', compress('aaaaaaaaaa'))\n    def test_empty(self):\n        self.assertEquals('', compress(''))\n", "code_toks_joined": "class CompressTestCase ( unittest . TestCase ) : <NEWLINE> <INDENT> def test_regular ( self ) : <NEWLINE> <INDENT> self . assertEquals ( <STRING> , compress ( <STRING> ) ) <NEWLINE> <DEDENT> def test_singles ( self ) : <NEWLINE> <INDENT> self . assertEquals ( <STRING> , compress ( <STRING> ) ) <NEWLINE> <DEDENT> def test_single_letter ( self ) : <NEWLINE> <INDENT> self . assertEquals ( <STRING> , compress ( <STRING> ) ) <NEWLINE> <DEDENT> def test_empty ( self ) : <NEWLINE> <INDENT> self . assertEquals ( <STRING> , compress ( <STRING> ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'a3b2c1a4'", "'aaabbcaaaa'", "'a1k1o1s1'", "'akos'", "'a10'", "'aaaaaaaaaa'", "''", "''"]}}], ["e280b0e843efadbe862fb9475c8a969a", {"code_string": "def __components_items_changed(self, event):\n    \"\"\" Make sure components that are added can be used with constraints.\"\"\"\n    for item in event.removed:\n        item.on_trait_change(self._component_size_hint_changed,\n            'layout_size_hint', remove = True)\n        del self._component_map[item.id]\n    self._check_and_add_components(event.added)\n", "code_toks_joined": "def __components_items_changed ( self , event ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> for item in event . removed : <NEWLINE> <INDENT> item . on_trait_change ( self . _component_size_hint_changed , <NEWLINE> <INDENT> <STRING> , remove = True ) <NEWLINE> <DEDENT> del self . _component_map [ item . id ] <NEWLINE> <DEDENT> self . _check_and_add_components ( event . added ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Make sure components that are added can be used with constraints.\"\"\"", "'layout_size_hint'"]}}], ["682077be89cc00fa6943f13a8ced33a9", {"code_string": "import unittest\nimport mock\nfrom pollicino import geocoder, exceptions\n", "code_toks_joined": "import unittest <NEWLINE> import mock <NEWLINE> from pollicino import geocoder , exceptions <NEWLINE>", "anonymize_dict": {}}], ["8f0c6fd7348ee8429cd3f5c0c865c12f", {"code_string": "from dal import autocomplete\nimport dal_queryset_sequence\nimport dal_select2_queryset_sequence\nfrom django import forms\nfrom django.forms.widgets import HiddenInput\nfrom django.forms import ModelForm\nfrom mezzanine.core.models import Orderable\n", "code_toks_joined": "from dal import autocomplete <NEWLINE> import dal_queryset_sequence <NEWLINE> import dal_select2_queryset_sequence <NEWLINE> from django import forms <NEWLINE> from django . forms . widgets import HiddenInput <NEWLINE> from django . forms import ModelForm <NEWLINE> from mezzanine . core . models import Orderable <NEWLINE>", "anonymize_dict": {}}], ["aed31d0ff84c8f831b4e80f1c3b25136", {"code_string": "class TestSystemInjector(TestSystem):\n    def __init__(self, name, system):\n        self.injected = False\n        self.name = name\n        self.system = system\n    def step(self, dt):\n        TestSystem.step(self, dt)\n        if not self.injected:\n            setattr(self.world.systems, self.name, self.system)\n            self.injected = True\n", "code_toks_joined": "class TestSystemInjector ( TestSystem ) : <NEWLINE> <INDENT> def __init__ ( self , name , system ) : <NEWLINE> <INDENT> self . injected = False <NEWLINE> self . name = name <NEWLINE> self . system = system <NEWLINE> <DEDENT> def step ( self , dt ) : <NEWLINE> <INDENT> TestSystem . step ( self , dt ) <NEWLINE> if not self . injected : <NEWLINE> <INDENT> setattr ( self . world . systems , self . name , self . system ) <NEWLINE> self . injected = True <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["4e75678991a527efe52ce788405c9912", {"code_string": "\"\"\"c-ares based hostname resolver.\"\"\"\nfrom __future__ import absolute_import\nimport os\nimport sys\nfrom _socket import getservbyname, getaddrinfo, gaierror, error\nfrom gevent.hub import Waiter, get_hub, string_types, text_type, integer_types, reraise, PY3\nfrom gevent.socket import AF_UNSPEC, AF_INET, AF_INET6, SOCK_STREAM, SOCK_DGRAM, SOCK_RAW, AI_NUMERICHOST, EAI_SERVICE, AI_PASSIVE\nfrom gevent.ares import channel, InvalidIP\n__all__ = ['Resolver']\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import absolute_import <NEWLINE> import os <NEWLINE> import sys <NEWLINE> from _socket import getservbyname , getaddrinfo , gaierror , error <NEWLINE> from gevent . hub import Waiter , get_hub , string_types , text_type , integer_types , reraise , PY3 <NEWLINE> from gevent . socket import AF_UNSPEC , AF_INET , AF_INET6 , SOCK_STREAM , SOCK_DGRAM , SOCK_RAW , AI_NUMERICHOST , EAI_SERVICE , AI_PASSIVE <NEWLINE> from gevent . ares import channel , InvalidIP <NEWLINE> __all__ = [ <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"c-ares based hostname resolver.\"\"\"", "'Resolver'"]}}], ["5a282e17f95ca47653ccccdef27974fc", {"code_string": "def table(self, name, database = None):\n    \"\"\"Create a table expression that references a particular table in the\"\"\"\n    alch_table = self._get_sqla_table(name)\n    node = SQLiteTable(alch_table, self)\n    return self._table_expr_klass(node)\n", "code_toks_joined": "def table ( self , name , database = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> alch_table = self . _get_sqla_table ( name ) <NEWLINE> node = SQLiteTable ( alch_table , self ) <NEWLINE> return self . _table_expr_klass ( node ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Create a table expression that references a particular table in the\"\"\""]}}], ["5dcfc1981965de1b9e4d01e864e7857d", {"code_string": "import re\niterations = 40\nwith open(\"../input/10.txt\") as fileobj:\n    puzzle = fileobj.readline().strip()\nprint(puzzle)\nfor x in range(40):\n    newpuzzle = ''\n    for y in re.finditer(r\"([0-9])\\1*\", puzzle):\n        newpuzzle += str(len(y.group(0))) + y.group(0)[0]\n    puzzle = newpuzzle\nprint(len(puzzle))\n", "code_toks_joined": "import re <NEWLINE> iterations = 40 <NEWLINE> with open ( <STRING> ) as fileobj : <NEWLINE> <INDENT> puzzle = fileobj . readline ( ) . strip ( ) <NEWLINE> <DEDENT> print ( puzzle ) <NEWLINE> for x in range ( 40 ) : <NEWLINE> <INDENT> newpuzzle = <STRING> <NEWLINE> for y in re . finditer ( <STRING> , puzzle ) : <NEWLINE> <INDENT> newpuzzle += str ( len ( y . group ( 0 ) ) ) + y . group ( 0 ) [ 0 ] <NEWLINE> <DEDENT> puzzle = newpuzzle <NEWLINE> <DEDENT> print ( len ( puzzle ) ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"../input/10.txt\"", "''", "r\"([0-9])\\1*\""]}}], ["5213602e5605a95153908e341651b25d", {"code_string": "class TokenTests(common.IdentityTests):\n    def test_token_issue(self):\n        raw_output = self.openstack('token issue')\n        items = self.parse_show(raw_output)\n        self.assert_show_fields(items, self.TOKEN_FIELDS)\n", "code_toks_joined": "class TokenTests ( common . IdentityTests ) : <NEWLINE> <INDENT> def test_token_issue ( self ) : <NEWLINE> <INDENT> raw_output = self . openstack ( <STRING> ) <NEWLINE> items = self . parse_show ( raw_output ) <NEWLINE> self . assert_show_fields ( items , self . TOKEN_FIELDS ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'token issue'"]}}], ["27b1309ef266fc1a020f03f183237fec", {"code_string": "def register():\n    Pool.register(\n        Configuration,\n        ConfigurationSequence,\n        Type,\n        Package,\n        Move,\n        ShipmentOut,\n        ShipmentInReturn,\n        module = 'stock_package', type_ = 'model')\n    Pool.register(\n        PackageLabel,\n        module = 'stock_package', type_ = 'report')\n", "code_toks_joined": "def register ( ) : <NEWLINE> <INDENT> Pool . register ( <NEWLINE> <INDENT> Configuration , <NEWLINE> ConfigurationSequence , <NEWLINE> Type , <NEWLINE> Package , <NEWLINE> Move , <NEWLINE> ShipmentOut , <NEWLINE> ShipmentInReturn , <NEWLINE> module = <STRING> , type_ = <STRING> ) <NEWLINE> <DEDENT> Pool . register ( <NEWLINE> <INDENT> PackageLabel , <NEWLINE> module = <STRING> , type_ = <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'stock_package'", "'model'", "'stock_package'", "'report'"]}}], ["ac07e3a5d4dae4d8a88404f081bb19d3", {"code_string": "\"\"\"Generic mesh visualization tools.\"\"\"\nimport os\ntry:\n    import pygimli as pg\n    from pygimli.mplviewer import drawMesh, drawModel, drawField\n    from pygimli.mplviewer import drawSensors, showLater\n    from pygimli.mplviewer import createColorbar, drawStreams, addCoverageAlpha\nexcept ImportError as e:\n    print(e)\n    import traceback\n    import sys\n    traceback.print_exc(file = sys.stdout)\n    raise Exception('''ERROR: cannot import the library 'pygimli'.''')\nimport matplotlib.pyplot as plt\nimport numpy as np\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> try : <NEWLINE> <INDENT> import pygimli as pg <NEWLINE> from pygimli . mplviewer import drawMesh , drawModel , drawField <NEWLINE> from pygimli . mplviewer import drawSensors , showLater <NEWLINE> from pygimli . mplviewer import createColorbar , drawStreams , addCoverageAlpha <NEWLINE> <DEDENT> except ImportError as e : <NEWLINE> <INDENT> print ( e ) <NEWLINE> import traceback <NEWLINE> import sys <NEWLINE> traceback . print_exc ( file = sys . stdout ) <NEWLINE> raise Exception ( <STRING> ) <NEWLINE> <DEDENT> import matplotlib . pyplot as plt <NEWLINE> import numpy as np <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Generic mesh visualization tools.\"\"\"", "'''ERROR: cannot import the library 'pygimli'.'''"]}}], ["ba8cbd2695b7b02a8aed0ddc422aea7c", {"code_string": "import logging\nlogger = logging.getLogger('libpymux')\n_logfile = open('/tmp/pymux-log', 'w')\nlogging.basicConfig(stream = _logfile, level = logging.INFO)\n", "code_toks_joined": "import logging <NEWLINE> logger = logging . getLogger ( <STRING> ) <NEWLINE> _logfile = open ( <STRING> , <STRING> ) <NEWLINE> logging . basicConfig ( stream = _logfile , level = logging . INFO ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'libpymux'", "'/tmp/pymux-log'", "'w'"]}}], ["52d990b5fdfa7680ba4680475df1eb44", {"code_string": "def initialize_app():\n    instance_path = os.path.abspath(os.path.dirname(__file__) + '/../..')\n    template_folder = os.path.join(instance_path, 'app/views')\n    static_folder = os.path.join(instance_path, 'app/static')\n    app = Flask('app', static_folder = static_folder, template_folder = template_folder, instance_path = instance_path)\n    initialize_config(app)\n    initialize_db(app)\n    initialize_routes(app)\n    return app\n", "code_toks_joined": "def initialize_app ( ) : <NEWLINE> <INDENT> instance_path = os . path . abspath ( os . path . dirname ( __file__ ) + <STRING> ) <NEWLINE> template_folder = os . path . join ( instance_path , <STRING> ) <NEWLINE> static_folder = os . path . join ( instance_path , <STRING> ) <NEWLINE> app = Flask ( <STRING> , static_folder = static_folder , template_folder = template_folder , instance_path = instance_path ) <NEWLINE> initialize_config ( app ) <NEWLINE> initialize_db ( app ) <NEWLINE> initialize_routes ( app ) <NEWLINE> return app <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/../..'", "'app/views'", "'app/static'", "'app'"]}}], ["9dc99671073f29b43eaf736a85690c6a", {"code_string": "class PymagingException(Exception): pass\nclass FormatNotSupported(PymagingException): pass\nclass InvalidColor(PymagingException): pass\n", "code_toks_joined": "class PymagingException ( Exception ) : pass <NEWLINE> class FormatNotSupported ( PymagingException ) : pass <NEWLINE> class InvalidColor ( PymagingException ) : pass <NEWLINE>", "anonymize_dict": {}}], ["6f86c4ad02d305bd458b5cd44e9a2d38", {"code_string": "def __check_logged(self):\n    if self.__connected and not self.__logged_in:\n        logger.warn(\"Client %s didn't log in 60 seconds, dropping\", self.cid())\n        self.transport.abortConnection()\n        self.__connected = False\n", "code_toks_joined": "def __check_logged ( self ) : <NEWLINE> <INDENT> if self . __connected and not self . __logged_in : <NEWLINE> <INDENT> logger . warn ( <STRING> , self . cid ( ) ) <NEWLINE> self . transport . abortConnection ( ) <NEWLINE> self . __connected = False <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Client %s didn't log in 60 seconds, dropping\""]}}], ["6253dd1ed12df3dbf0b137c2f622e4d0", {"code_string": "def try_parse_number(number_value, cls = float, default = 0):\n    \"\"\"rudimentary number parsing.\"\"\"\n    if isinstance(number_value, int) or isinstance(number_value, long) or isinstance(number_value, float):\n        return number_value\n    try:\n        return int_or_float(cls(number_value))\n    except:\n        if default is None:\n            return default\n        return cls(default)\n", "code_toks_joined": "def try_parse_number ( number_value , cls = float , default = 0 ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if isinstance ( number_value , int ) or isinstance ( number_value , long ) or isinstance ( number_value , float ) : <NEWLINE> <INDENT> return number_value <NEWLINE> <DEDENT> try : <NEWLINE> <INDENT> return int_or_float ( cls ( number_value ) ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> if default is None : <NEWLINE> <INDENT> return default <NEWLINE> <DEDENT> return cls ( default ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"rudimentary number parsing.\"\"\""]}}], ["98d8e79d7a5289fe5899f6aaea58d1ca", {"code_string": "class BasketVoucherForm(forms.Form):\n    code = forms.CharField(max_length = 128, label = _('Code'))\n    def __init__(self, * args, ** kwargs):\n        super(BasketVoucherForm, self).__init__(* args, ** kwargs)\n    def clean_code(self):\n        return self.cleaned_data['code'].strip().upper()\n", "code_toks_joined": "class BasketVoucherForm ( forms . Form ) : <NEWLINE> <INDENT> code = forms . CharField ( max_length = 128 , label = _ ( <STRING> ) ) <NEWLINE> def __init__ ( self , * args , ** kwargs ) : <NEWLINE> <INDENT> super ( BasketVoucherForm , self ) . __init__ ( * args , ** kwargs ) <NEWLINE> <DEDENT> def clean_code ( self ) : <NEWLINE> <INDENT> return self . cleaned_data [ <STRING> ] . strip ( ) . upper ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Code'", "'code'"]}}], ["768903bb7b704caea705eb9aaf79f356", {"code_string": "from config import API_URL, CONNECT_TIME_OUT\nfrom tornado.httpclient import HTTPRequest, HTTPClient, HTTPError\nimport urllib\n", "code_toks_joined": "from config import API_URL , CONNECT_TIME_OUT <NEWLINE> from tornado . httpclient import HTTPRequest , HTTPClient , HTTPError <NEWLINE> import urllib <NEWLINE>", "anonymize_dict": {}}], ["321eae88dfb2c3c1369a63ca5af907ee", {"code_string": "def parse_args():\n    \"\"\"Parse commandline arguments.\"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument('url', help = 'The URL to open')\n    parser.add_argument('--plugins', '-p', help = 'Enable plugins',\n        default = False, action = 'store_true')\n    if QWebEngineView is not None:\n        parser.add_argument('--webengine', help = 'Use QtWebEngine',\n            default = False, action = 'store_true')\n    return parser.parse_known_args()[0]\n", "code_toks_joined": "def parse_args ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> parser = argparse . ArgumentParser ( ) <NEWLINE> parser . add_argument ( <STRING> , help = <STRING> ) <NEWLINE> parser . add_argument ( <STRING> , <STRING> , help = <STRING> , <NEWLINE> <INDENT> default = False , action = <STRING> ) <NEWLINE> <DEDENT> if QWebEngineView is not None : <NEWLINE> <INDENT> parser . add_argument ( <STRING> , help = <STRING> , <NEWLINE> <INDENT> default = False , action = <STRING> ) <NEWLINE> <DEDENT> <DEDENT> return parser . parse_known_args ( ) [ 0 ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Parse commandline arguments.\"\"\"", "'url'", "'The URL to open'", "'--plugins'", "'-p'", "'Enable plugins'", "'store_true'", "'--webengine'", "'Use QtWebEngine'", "'store_true'"]}}], ["96a8688e3c3957d6f18797ab5dffac19", {"code_string": "class ReceiveData(State):\n    def run(self, _input):\n        if _input == \">\":\n            self.context.append_received_data()\n            self.context.reception_complete()\n            self.context.currentState = WaitForStart(self.context)\n        elif _input == \",\":\n            self.context.append_received_data()\n        else:\n            self.context.receive_data(_input)\n", "code_toks_joined": "class ReceiveData ( State ) : <NEWLINE> <INDENT> def run ( self , _input ) : <NEWLINE> <INDENT> if _input == <STRING> : <NEWLINE> <INDENT> self . context . append_received_data ( ) <NEWLINE> self . context . reception_complete ( ) <NEWLINE> self . context . currentState = WaitForStart ( self . context ) <NEWLINE> <DEDENT> elif _input == <STRING> : <NEWLINE> <INDENT> self . context . append_received_data ( ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . context . receive_data ( _input ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\">\"", "\",\""]}}], ["adcb34c6d1968a76a0b30b8dc8fc3db9", {"code_string": "def run_ssh_cmd(self, cmd):\n    \"\"\"Open SSH session with credentials from config file and execute command passed to the method.\"\"\"\n    ssh = paramiko.SSHClient()\n    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n    ssh.load_system_host_keys()\n    ssh.connect(hostname = self.labconfig['host'],\n        username = self.labconfig['sshuser'],\n        password = self.labconfig['sshpassword'])\n    stdin, stdout, stderr = ssh.exec_command(cmd)\n    res = stdout.readlines()\n    print(\"STDOUT:\\n %s\" % res)\n    ssh.close()\n    return res\n", "code_toks_joined": "def run_ssh_cmd ( self , cmd ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> ssh = paramiko . SSHClient ( ) <NEWLINE> ssh . set_missing_host_key_policy ( paramiko . AutoAddPolicy ( ) ) <NEWLINE> ssh . load_system_host_keys ( ) <NEWLINE> ssh . connect ( hostname = self . labconfig [ <STRING> ] , <NEWLINE> <INDENT> username = self . labconfig [ <STRING> ] , <NEWLINE> password = self . labconfig [ <STRING> ] ) <NEWLINE> <DEDENT> stdin , stdout , stderr = ssh . exec_command ( cmd ) <NEWLINE> res = stdout . readlines ( ) <NEWLINE> print ( <STRING> % res ) <NEWLINE> ssh . close ( ) <NEWLINE> return res <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Open SSH session with credentials from config file and execute command passed to the method.\"\"\"", "'host'", "'sshuser'", "'sshpassword'", "\"STDOUT:\\n %s\""]}}], ["34ccfcee2b108b4071db7fc12d6aa6e2", {"code_string": "def setUp(self):\n    super(TestAccountApi, self).setUp()\n    self.request_factory = RequestFactory()\n    self.table = \"student_languageproficiency\"\n    self.user = UserFactory.create(password = self.password)\n    self.default_request = self.request_factory.get(\"/api/user/v1/accounts/\")\n    self.default_request.user = self.user\n    self.different_user = UserFactory.create(password = self.password)\n    self.staff_user = UserFactory(is_staff = True, password = self.password)\n    self.reset_tracker()\n", "code_toks_joined": "def setUp ( self ) : <NEWLINE> <INDENT> super ( TestAccountApi , self ) . setUp ( ) <NEWLINE> self . request_factory = RequestFactory ( ) <NEWLINE> self . table = <STRING> <NEWLINE> self . user = UserFactory . create ( password = self . password ) <NEWLINE> self . default_request = self . request_factory . get ( <STRING> ) <NEWLINE> self . default_request . user = self . user <NEWLINE> self . different_user = UserFactory . create ( password = self . password ) <NEWLINE> self . staff_user = UserFactory ( is_staff = True , password = self . password ) <NEWLINE> self . reset_tracker ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"student_languageproficiency\"", "\"/api/user/v1/accounts/\""]}}], ["03bd4e849e208ea46eefa2c9d529fb1c", {"code_string": "'''Mrknow TV Add-on'''\nimport urlparse, base64, urllib\nimport re, time, datetime\nimport json, sys\nfrom resources.lib.lib import control\nfrom resources.lib.lib import client\nfrom resources.lib.lib import client2\nHOST = 'XBMC'\nheaders = {'User-Agent': HOST, 'ContentType': 'application/x-www-form-urlencoded'}\n", "code_toks_joined": "<STRING> <NEWLINE> import urlparse , base64 , urllib <NEWLINE> import re , time , datetime <NEWLINE> import json , sys <NEWLINE> from resources . lib . lib import control <NEWLINE> from resources . lib . lib import client <NEWLINE> from resources . lib . lib import client2 <NEWLINE> HOST = <STRING> <NEWLINE> headers = { <STRING> : HOST , <STRING> : <STRING> } <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Mrknow TV Add-on'''", "'XBMC'", "'User-Agent'", "'ContentType'", "'application/x-www-form-urlencoded'"]}}], ["e9488f1cef91884165115015f3af55d4", {"code_string": "class GroupSerializer(serializers.HyperlinkedModelSerializer):\n    \"\"\"DRf serializer for the `django.contrib.auth.Group` model\"\"\"\n    class Meta:\n        model = Group\n        fields = ('url', 'id', 'name', )\n", "code_toks_joined": "class GroupSerializer ( serializers . HyperlinkedModelSerializer ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> class Meta : <NEWLINE> <INDENT> model = Group <NEWLINE> fields = ( <STRING> , <STRING> , <STRING> , ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"DRf serializer for the `django.contrib.auth.Group` model\"\"\"", "'url'", "'id'", "'name'"]}}], ["d16f6a8cf015cc9c99cf485fbdd5f839", {"code_string": "def pagesize(request):\n    \"\"\"Return pagesize of given request.\"\"\"\n    return pagination.from_request(request)[0]\n", "code_toks_joined": "def pagesize ( request ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return pagination . from_request ( request ) [ 0 ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Return pagesize of given request.\"\"\""]}}], ["cc40697c08313cbe0f5c6a1da7508222", {"code_string": "class LoginForm(Form):\n    provider = HiddenField('provider', validators = [validators.Required()])\n    remember_me = BooleanField('remember_me', default = False)\n", "code_toks_joined": "class LoginForm ( Form ) : <NEWLINE> <INDENT> provider = HiddenField ( <STRING> , validators = [ validators . Required ( ) ] ) <NEWLINE> remember_me = BooleanField ( <STRING> , default = False ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'provider'", "'remember_me'"]}}], ["808607055b141c1789092b1df50dbac9", {"code_string": "def __init__(self, dimIn, dimOut, actionList, features):\n    \"\"\" Initialize the BoltzmannExploration Actor.\"\"\"\n    Actor.__init__(self, dimIn, dimOut)\n    self._actionList = actionList\n    self._features = features\n    self._dimPar = features.size()\n    self._parameters = 0.05 * np.random.randn()\n", "code_toks_joined": "def __init__ ( self , dimIn , dimOut , actionList , features ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> Actor . __init__ ( self , dimIn , dimOut ) <NEWLINE> self . _actionList = actionList <NEWLINE> self . _features = features <NEWLINE> self . _dimPar = features . size ( ) <NEWLINE> self . _parameters = 0.05 * np . random . randn ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Initialize the BoltzmannExploration Actor.\"\"\""]}}], ["34017ba545f7a2bf33884b1963578d64", {"code_string": "\"\"\"http://www.pythonchallenge.com/pc/hex/lake.html\"\"\"\n__author__ = \"\u5b50\u98a8\"\n__copyright__ = \"Copyright 2015, Sun All rights reserved\"\n__version__ = \"1.0.0\"\nimport get_challenge\nimport wave\nwavs = [wave.open(get_challenge.download('butter', 'fly', 'http://www.pythonchallenge.com/pc/hex/lake%d.wav' % i)) for i in range(1, 26)]\n", "code_toks_joined": "<STRING> <NEWLINE> __author__ = <STRING> <NEWLINE> __copyright__ = <STRING> <NEWLINE> __version__ = <STRING> <NEWLINE> import get_challenge <NEWLINE> import wave <NEWLINE> wavs = [ wave . open ( get_challenge . download ( <STRING> , <STRING> , <STRING> % i ) ) for i in range ( 1 , 26 ) ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"http://www.pythonchallenge.com/pc/hex/lake.html\"\"\"", "\"\u5b50\u98a8\"", "\"Copyright 2015, Sun All rights reserved\"", "\"1.0.0\"", "'butter'", "'fly'", "'http://www.pythonchallenge.com/pc/hex/lake%d.wav'"]}}], ["c906e4a59010448d77c728025d5ac832", {"code_string": "def get_verb_by_iri(self, verb_iri):\n    for verb, iri in self.VERB_IRI_MAPPER.items():\n        if iri == verb_iri:\n            return verb\n", "code_toks_joined": "def get_verb_by_iri ( self , verb_iri ) : <NEWLINE> <INDENT> for verb , iri in self . VERB_IRI_MAPPER . items ( ) : <NEWLINE> <INDENT> if iri == verb_iri : <NEWLINE> <INDENT> return verb <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["e7607d0bcf1437b873ef51bece8c80e7", {"code_string": "import os\nimport sys\nimport tornado.web\nimport tornado.httpserver\nimport tornado.ioloop\nimport tornado.websocket\nimport json\nunnamed = []\nconnected = {}\n", "code_toks_joined": "import os <NEWLINE> import sys <NEWLINE> import tornado . web <NEWLINE> import tornado . httpserver <NEWLINE> import tornado . ioloop <NEWLINE> import tornado . websocket <NEWLINE> import json <NEWLINE> unnamed = [ ] <NEWLINE> connected = { } <NEWLINE>", "anonymize_dict": {}}], ["194e30c42e3e36c43d19e3106dfa4548", {"code_string": "def fixed_ellipse(th, a, b):\n    '''returns c=2 ellipse in polar coordinates'''\n    xcomp = ((abs(np.cos(th)) ** 2.0) / a ** 2.0)\n    ycomp = ((abs(np.sin(th)) ** 2.0) / b ** 2.0)\n    gell = ((xcomp + ycomp)) **(- 1. / 2.0)\n    return gell\n", "code_toks_joined": "def fixed_ellipse ( th , a , b ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> xcomp = ( ( abs ( np . cos ( th ) ) ** 2.0 ) / a ** 2.0 ) <NEWLINE> ycomp = ( ( abs ( np . sin ( th ) ) ** 2.0 ) / b ** 2.0 ) <NEWLINE> gell = ( ( xcomp + ycomp ) ) ** ( - 1. / 2.0 ) <NEWLINE> return gell <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''returns c=2 ellipse in polar coordinates'''"]}}], ["e792dcdb183e39379fea8c40f626f4e5", {"code_string": "def _get_compressor(self, algorithm):\n    try:\n        if algorithm.lower() in('none', 'off', 'no'):\n            return None\n        elif algorithm.lower() in('zlib', 'gzip'):\n            import zlib as compressor\n            return compressor\n        elif algorithm.lower() in('bz2', 'bzip2'):\n            import bz2 as compressor\n            return compressor\n    except ImportError:\n        pass\n    err = _('unsupported compression algorithm: %s') % algorithm\n    raise ValueError(unicode(err))\n", "code_toks_joined": "def _get_compressor ( self , algorithm ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> if algorithm . lower ( ) in ( <STRING> , <STRING> , <STRING> ) : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> elif algorithm . lower ( ) in ( <STRING> , <STRING> ) : <NEWLINE> <INDENT> import zlib as compressor <NEWLINE> return compressor <NEWLINE> <DEDENT> elif algorithm . lower ( ) in ( <STRING> , <STRING> ) : <NEWLINE> <INDENT> import bz2 as compressor <NEWLINE> return compressor <NEWLINE> <DEDENT> <DEDENT> except ImportError : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> err = _ ( <STRING> ) % algorithm <NEWLINE> raise ValueError ( unicode ( err ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'none'", "'off'", "'no'", "'zlib'", "'gzip'", "'bz2'", "'bzip2'", "'unsupported compression algorithm: %s'"]}}], ["d43e7426f8680ff485b5bdd80c915f8f", {"code_string": "from lingpyd import *\nfrom lingpyd.plugins.burmish import ipa2tokens\nimport os\nfrom lingpyd.settings import rcParams\nrcParams['sca'] = Model('sca')\n", "code_toks_joined": "from lingpyd import * <NEWLINE> from lingpyd . plugins . burmish import ipa2tokens <NEWLINE> import os <NEWLINE> from lingpyd . settings import rcParams <NEWLINE> rcParams [ <STRING> ] = Model ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'sca'", "'sca'"]}}], ["72af53410fac69775aa0f2cea91f1ac5", {"code_string": "def load_ipython_extension(ip):\n    transformer = XalcInputTransformer()\n    ip.input_transformer_manager.logical_line_transforms.append(transformer)\n    formatter = ip.display_formatter.formatters['text/plain']\n    formatter.for_type(int, XalcFormatter().format_int)\n", "code_toks_joined": "def load_ipython_extension ( ip ) : <NEWLINE> <INDENT> transformer = XalcInputTransformer ( ) <NEWLINE> ip . input_transformer_manager . logical_line_transforms . append ( transformer ) <NEWLINE> formatter = ip . display_formatter . formatters [ <STRING> ] <NEWLINE> formatter . for_type ( int , XalcFormatter ( ) . format_int ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'text/plain'"]}}], ["0e07d9e19aa72b7c398655de046f6166", {"code_string": "class graphiteapiTest(TestCase):\n    def setUp(self):\n        pass\n    def tearDown(self):\n        pass\n", "code_toks_joined": "class graphiteapiTest ( TestCase ) : <NEWLINE> <INDENT> def setUp ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def tearDown ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["5517908d50610a8fdf8d10e77b745d90", {"code_string": "class DeNoronha(DstTzInfo):\n    '''Brazil/DeNoronha timezone definition. See datetime.tzinfo for details'''\n    zone = 'Brazil/DeNoronha'\n", "code_toks_joined": "class DeNoronha ( DstTzInfo ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> zone = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Brazil/DeNoronha timezone definition. See datetime.tzinfo for details'''", "'Brazil/DeNoronha'"]}}], ["a2e9695dc525109eb19c2fc575e35c4d", {"code_string": "def get_cap_state(keyboard):\n    result = False\n    if 'KEY_LEFTSHIFT' in mapFirstElement(keyboard.active_keys(verbose = True)) or 'KEY_RIGHTSHIFT' in mapFirstElement(keyboard.active_keys(verbose = True)):\n        result = not result\n    if 'LED_CAPSL' in mapFirstElement(keyboard.leds(verbose = True)):\n        result = not result\n    return result\n", "code_toks_joined": "def get_cap_state ( keyboard ) : <NEWLINE> <INDENT> result = False <NEWLINE> if <STRING> in mapFirstElement ( keyboard . active_keys ( verbose = True ) ) or <STRING> in mapFirstElement ( keyboard . active_keys ( verbose = True ) ) : <NEWLINE> <INDENT> result = not result <NEWLINE> <DEDENT> if <STRING> in mapFirstElement ( keyboard . leds ( verbose = True ) ) : <NEWLINE> <INDENT> result = not result <NEWLINE> <DEDENT> return result <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'KEY_LEFTSHIFT'", "'KEY_RIGHTSHIFT'", "'LED_CAPSL'"]}}], ["672c54034423fe87f2e73c38e41fde50", {"code_string": "from NotifierClass import Notifier\nimport twitter\nimport re\n", "code_toks_joined": "from NotifierClass import Notifier <NEWLINE> import twitter <NEWLINE> import re <NEWLINE>", "anonymize_dict": {}}], ["f248b350debb3f5da552287f4b03446c", {"code_string": "def get_auth_header(signature, timestamp, client, api_key = None):\n    header = [\n        ('sentry_timestamp', timestamp),\n        ('sentry_signature', signature),\n        ('sentry_client', client),\n    ]\n    if api_key:\n        header.append(('sentry_key', api_key))\n    return 'Sentry %s' % ', '.join('%s=%s' %(k, v) for k, v in header)\n", "code_toks_joined": "def get_auth_header ( signature , timestamp , client , api_key = None ) : <NEWLINE> <INDENT> header = [ <NEWLINE> <INDENT> ( <STRING> , timestamp ) , <NEWLINE> ( <STRING> , signature ) , <NEWLINE> ( <STRING> , client ) , <NEWLINE> <DEDENT> ] <NEWLINE> if api_key : <NEWLINE> <INDENT> header . append ( ( <STRING> , api_key ) ) <NEWLINE> <DEDENT> return <STRING> % <STRING> . join ( <STRING> % ( k , v ) for k , v in header ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'sentry_timestamp'", "'sentry_signature'", "'sentry_client'", "'sentry_key'", "'Sentry %s'", "', '", "'%s=%s'"]}}], ["083a26bae672df4660e1237d8c796390", {"code_string": "class PlaceBase:\n    \"\"\"Base class for place-aware objects.\"\"\"\n    def __init__(self, source = None):\n        \"\"\"Initialize a PlaceBase.\"\"\"\n        if source:\n            self.place = source.place\n        else:\n            self.place = \"\"\n    def set_place_handle(self, place_handle):\n        \"\"\"Set the database handle for :class:`~.place.Place` associated with the\"\"\"\n        self.place = place_handle\n    def get_place_handle(self):\n        \"\"\"Return the database handle of the :class:`~.place.Place` associated\"\"\"\n        return self.place\n", "code_toks_joined": "class PlaceBase : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , source = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if source : <NEWLINE> <INDENT> self . place = source . place <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . place = <STRING> <NEWLINE> <DEDENT> <DEDENT> def set_place_handle ( self , place_handle ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . place = place_handle <NEWLINE> <DEDENT> def get_place_handle ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . place <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Base class for place-aware objects.\"\"\"", "\"\"\"Initialize a PlaceBase.\"\"\"", "\"\"", "\"\"\"Set the database handle for :class:`~.place.Place` associated with the\"\"\"", "\"\"\"Return the database handle of the :class:`~.place.Place` associated\"\"\""]}}], ["a970606d1b22c4ccc0f4f5740b904a29", {"code_string": "def invalidate_cms_page_cache():\n    '''Invalidates the CMS PAGE CACHE.'''\n    version = _get_cache_version()\n    _set_cache_version(version + 1)\n", "code_toks_joined": "def invalidate_cms_page_cache ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> version = _get_cache_version ( ) <NEWLINE> _set_cache_version ( version + 1 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Invalidates the CMS PAGE CACHE.'''"]}}], ["0ced36d74a8b9cd5c5cfc01718ddd93e", {"code_string": "import os\nimport tempfile\nimport unittest\nimport logging\nfrom pyidf import ValidationLevel\nimport pyidf\nfrom pyidf.idf import IDF\nfrom pyidf.detailed_ground_heat_transfer import GroundHeatTransferBasementComBldg\nlog = logging.getLogger(__name__)\n", "code_toks_joined": "import os <NEWLINE> import tempfile <NEWLINE> import unittest <NEWLINE> import logging <NEWLINE> from pyidf import ValidationLevel <NEWLINE> import pyidf <NEWLINE> from pyidf . idf import IDF <NEWLINE> from pyidf . detailed_ground_heat_transfer import GroundHeatTransferBasementComBldg <NEWLINE> log = logging . getLogger ( __name__ ) <NEWLINE>", "anonymize_dict": {}}], ["ab4953907b3f386a7f7c3f483e45b968", {"code_string": "def make_rectangle(p1, p2, color, bottom = 0.0, top = 1.0):\n    verts = [\n        (p1, bottom),\n        (p1, top),\n        (p2, top),\n        (p2, bottom),\n        (0.0, 0.0)\n    ]\n    codes = [\n        Path.MOVETO,\n        Path.LINETO,\n        Path.LINETO,\n        Path.LINETO,\n        Path.CLOSEPOLY\n    ]\n    path = Path(verts, codes)\n    return patches.PathPatch(path, facecolor = color, lw = 0)\n", "code_toks_joined": "def make_rectangle ( p1 , p2 , color , bottom = 0.0 , top = 1.0 ) : <NEWLINE> <INDENT> verts = [ <NEWLINE> <INDENT> ( p1 , bottom ) , <NEWLINE> ( p1 , top ) , <NEWLINE> ( p2 , top ) , <NEWLINE> ( p2 , bottom ) , <NEWLINE> ( 0.0 , 0.0 ) <NEWLINE> <DEDENT> ] <NEWLINE> codes = [ <NEWLINE> <INDENT> Path . MOVETO , <NEWLINE> Path . LINETO , <NEWLINE> Path . LINETO , <NEWLINE> Path . LINETO , <NEWLINE> Path . CLOSEPOLY <NEWLINE> <DEDENT> ] <NEWLINE> path = Path ( verts , codes ) <NEWLINE> return patches . PathPatch ( path , facecolor = color , lw = 0 ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ea33920aa3b43282b36ff80a7ed37374", {"code_string": "class PizzaViewSet(viewsets.ModelViewSet):\n    \"\"\"API endpoint that allows users to be viewed or edited.\"\"\"\n    queryset = Pizza.objects.all()\n    serializer_class = PizzaSerializer\n", "code_toks_joined": "class PizzaViewSet ( viewsets . ModelViewSet ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> queryset = Pizza . objects . all ( ) <NEWLINE> serializer_class = PizzaSerializer <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"API endpoint that allows users to be viewed or edited.\"\"\""]}}], ["95785e1a271219a77f133317e328e1d1", {"code_string": "def setUp(self):\n    super(FilemapIntegrationTest, self).setUp()\n    project_tree = FileSystemProjectTree(os.path.abspath(self.PATH_PREFIX), ['BUILD', '.*'])\n    scan_set = set()\n    for root, dirs, files in project_tree.walk(''):\n        scan_set.update({os.path.join(root, f) for f in files})\n    self.assertEquals(scan_set, self.TEST_EXCLUDE_FILES)\n", "code_toks_joined": "def setUp ( self ) : <NEWLINE> <INDENT> super ( FilemapIntegrationTest , self ) . setUp ( ) <NEWLINE> project_tree = FileSystemProjectTree ( os . path . abspath ( self . PATH_PREFIX ) , [ <STRING> , <STRING> ] ) <NEWLINE> scan_set = set ( ) <NEWLINE> for root , dirs , files in project_tree . walk ( <STRING> ) : <NEWLINE> <INDENT> scan_set . update ( { os . path . join ( root , f ) for f in files } ) <NEWLINE> <DEDENT> self . assertEquals ( scan_set , self . TEST_EXCLUDE_FILES ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'BUILD'", "'.*'", "''"]}}], ["664c24b4e909ac1fafc14377e1f6573c", {"code_string": "import numpy\nimport theano\nimport theano.tensor as T\nfrom hidden import HiddenLayer\n", "code_toks_joined": "import numpy <NEWLINE> import theano <NEWLINE> import theano . tensor as T <NEWLINE> from hidden import HiddenLayer <NEWLINE>", "anonymize_dict": {}}], ["749a2263ef663ae2a164a39e170c7bba", {"code_string": "def sum_of_n(n):\n    last = 0\n    is_positive = n > 0\n    result = [0]\n    for a in xrange(1, abs(n) + 1):\n        last += a\n        result.append(last if is_positive else last * - 1)\n    return result\n", "code_toks_joined": "def sum_of_n ( n ) : <NEWLINE> <INDENT> last = 0 <NEWLINE> is_positive = n > 0 <NEWLINE> result = [ 0 ] <NEWLINE> for a in xrange ( 1 , abs ( n ) + 1 ) : <NEWLINE> <INDENT> last += a <NEWLINE> result . append ( last if is_positive else last * - 1 ) <NEWLINE> <DEDENT> return result <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["482dcb5f5fc055e7a0061cb72ce19641", {"code_string": "class FibonacciHandler:\n    \"\"\"Fibonacci endpoint handler.  Will expect a parameter to be present\"\"\"\n    def GET(self):\n        \"\"\"Implementation of the GET handler interface.\"\"\"\n        try:\n            desired_sequence = int(web.input().desired_sequence)\n            fibonacci = Fibonacci(desired_sequence)\n            return fibonacci.calculate()\n        except:\n            raise web.HTTPError('400 Bad Request', {})\n", "code_toks_joined": "class FibonacciHandler : <NEWLINE> <INDENT> <STRING> <NEWLINE> def GET ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> try : <NEWLINE> <INDENT> desired_sequence = int ( web . input ( ) . desired_sequence ) <NEWLINE> fibonacci = Fibonacci ( desired_sequence ) <NEWLINE> return fibonacci . calculate ( ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> raise web . HTTPError ( <STRING> , { } ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Fibonacci endpoint handler.  Will expect a parameter to be present\"\"\"", "\"\"\"Implementation of the GET handler interface.\"\"\"", "'400 Bad Request'"]}}], ["83bb4a1a224095bfd310564934761fed", {"code_string": "import contextlib\nimport six\nfrom shuup.apps.provides import get_provide_objects\nfrom shuup.utils.importing import cached_load, load\n_registry = []\n", "code_toks_joined": "import contextlib <NEWLINE> import six <NEWLINE> from shuup . apps . provides import get_provide_objects <NEWLINE> from shuup . utils . importing import cached_load , load <NEWLINE> _registry = [ ] <NEWLINE>", "anonymize_dict": {}}], ["021c17661889ddbcee56f6c07c96cb13", {"code_string": "def test_request_shortcut(self):\n    from pyrake.http import Request, FormRequest\n    self.assertIs(pyrake.Request, Request)\n    self.assertIs(pyrake.FormRequest, FormRequest)\n", "code_toks_joined": "def test_request_shortcut ( self ) : <NEWLINE> <INDENT> from pyrake . http import Request , FormRequest <NEWLINE> self . assertIs ( pyrake . Request , Request ) <NEWLINE> self . assertIs ( pyrake . FormRequest , FormRequest ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["9bc9290652c3e1674fcd08f71ee2f65f", {"code_string": "class BaseMiddleware(object):\n    def __init__(self, get_response):\n        self.get_response = get_response\n    def __call__(self, request):\n        return self.get_response(request)\n", "code_toks_joined": "class BaseMiddleware ( object ) : <NEWLINE> <INDENT> def __init__ ( self , get_response ) : <NEWLINE> <INDENT> self . get_response = get_response <NEWLINE> <DEDENT> def __call__ ( self , request ) : <NEWLINE> <INDENT> return self . get_response ( request ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["e99b3323616879333412275b54117014", {"code_string": "class SplashHandler(BaseHandler):\n    def get(self):\n        self.render(\"splash.html\")\n", "code_toks_joined": "class SplashHandler ( BaseHandler ) : <NEWLINE> <INDENT> def get ( self ) : <NEWLINE> <INDENT> self . render ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"splash.html\""]}}], ["61ad0aae323fffe2118273c2bf33a266", {"code_string": "class TestDriver(notifier._Driver):\n    \"Store notifications in memory for test verification.\"\n    def notify(self, ctxt, message, priority, retry):\n        NOTIFICATIONS.append((ctxt, message, priority, retry))\n", "code_toks_joined": "class TestDriver ( notifier . _Driver ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def notify ( self , ctxt , message , priority , retry ) : <NEWLINE> <INDENT> NOTIFICATIONS . append ( ( ctxt , message , priority , retry ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Store notifications in memory for test verification.\""]}}], ["94b7ae8a0951d27498e0dda0901a9db0", {"code_string": "import redis\nfrom smithers import conf\nif conf.REDIS_UNIX_SOCKET_PATH:\n    client = redis.StrictRedis(unix_socket_path = conf.REDIS_UNIX_SOCKET_PATH)\nelse:\n    client = redis.StrictRedis(host = conf.REDIS_HOST, port = conf.REDIS_PORT)\n", "code_toks_joined": "import redis <NEWLINE> from smithers import conf <NEWLINE> if conf . REDIS_UNIX_SOCKET_PATH : <NEWLINE> <INDENT> client = redis . StrictRedis ( unix_socket_path = conf . REDIS_UNIX_SOCKET_PATH ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> client = redis . StrictRedis ( host = conf . REDIS_HOST , port = conf . REDIS_PORT ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["bce82a1bfbb12424a66f3a2df03e933d", {"code_string": "def test_requires(self):\n    y2 = Y2()\n    x = X()\n    self.assertEqual(y2.requires(), x)\n    self.assertEqual(y2.n, 42)\n", "code_toks_joined": "def test_requires ( self ) : <NEWLINE> <INDENT> y2 = Y2 ( ) <NEWLINE> x = X ( ) <NEWLINE> self . assertEqual ( y2 . requires ( ) , x ) <NEWLINE> self . assertEqual ( y2 . n , 42 ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["2c5393be27f7c0f02d7f3ae514e18544", {"code_string": "__license__ = \"\"\"Copyright 2010-2012 elfCLOUD / elfcloud.fi \u2013 SCIS Secure Cloud Infrastructure Services\"\"\"\nimport http.cookiejar\nimport urllib.request, urllib.error, urllib.parse\nimport json\nfrom.exceptions import ECUnknownException, ECDataItemException\nimport elfcloud.exceptions as exceptions\n", "code_toks_joined": "__license__ = <STRING> <NEWLINE> import http . cookiejar <NEWLINE> import urllib . request , urllib . error , urllib . parse <NEWLINE> import json <NEWLINE> from . exceptions import ECUnknownException , ECDataItemException <NEWLINE> import elfcloud . exceptions as exceptions <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Copyright 2010-2012 elfCLOUD / elfcloud.fi \u2013 SCIS Secure Cloud Infrastructure Services\"\"\""]}}], ["15fe5ca45032e1a7c62026f6abb41577", {"code_string": "try: paraview.simple\nexcept: from paraview.simple import *\nparaview.simple._DisableFirstRenderCameraReset()\nImageExtractComponents()\n", "code_toks_joined": "try : paraview . simple <NEWLINE> except : from paraview . simple import * <NEWLINE> paraview . simple . _DisableFirstRenderCameraReset ( ) <NEWLINE> ImageExtractComponents ( ) <NEWLINE>", "anonymize_dict": {}}], ["ebac532edc738cbf0fe76e56a38e6f74", {"code_string": "class Options(usage.Options, strcred.AuthOptionMixin):\n    supportedInterfaces = (credentials.IUsernamePassword, )\n    optFlags = [\n        [\"xyzzy\", \"x\", \"Magic flag\"],\n        ]\n    optParameters = [\n        [\"endpoint\", \"e\", None, \"The endpoint listen on (default 'tcp:10389').\"],\n        [\"instance-config\", \"c\", None, \"Instance configuration overrides settings from other configs.\"],\n        ]\n    def __init__(self):\n        usage.Options.__init__(self)\n", "code_toks_joined": "class Options ( usage . Options , strcred . AuthOptionMixin ) : <NEWLINE> <INDENT> supportedInterfaces = ( credentials . IUsernamePassword , ) <NEWLINE> optFlags = [ <NEWLINE> <INDENT> [ <STRING> , <STRING> , <STRING> ] , <NEWLINE> ] <NEWLINE> <DEDENT> optParameters = [ <NEWLINE> <INDENT> [ <STRING> , <STRING> , None , <STRING> ] , <NEWLINE> [ <STRING> , <STRING> , None , <STRING> ] , <NEWLINE> ] <NEWLINE> <DEDENT> def __init__ ( self ) : <NEWLINE> <INDENT> usage . Options . __init__ ( self ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"xyzzy\"", "\"x\"", "\"Magic flag\"", "\"endpoint\"", "\"e\"", "\"The endpoint listen on (default 'tcp:10389').\"", "\"instance-config\"", "\"c\"", "\"Instance configuration overrides settings from other configs.\""]}}], ["f1879c15b064086befe54a87b600fae1", {"code_string": "class EmbeddedCollections(document.BaseDocument):\n    field_list = fields.ListField('s')\n    field_dict = fields.DictField('i')\n    field_id = fields.ObjectIdField(field_name = '_id', null = True)\n", "code_toks_joined": "class EmbeddedCollections ( document . BaseDocument ) : <NEWLINE> <INDENT> field_list = fields . ListField ( <STRING> ) <NEWLINE> field_dict = fields . DictField ( <STRING> ) <NEWLINE> field_id = fields . ObjectIdField ( field_name = <STRING> , null = True ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'s'", "'i'", "'_id'"]}}], ["97e599d6b4c1df19e3aa027166b3b3da", {"code_string": "'''Created on Dec 26, 2012'''\nfrom buildbot.steps.shell import ShellCommand\nimport os\nfrom twisted.python import log\nimport ast, json\n", "code_toks_joined": "<STRING> <NEWLINE> from buildbot . steps . shell import ShellCommand <NEWLINE> import os <NEWLINE> from twisted . python import log <NEWLINE> import ast , json <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Created on Dec 26, 2012'''"]}}], ["59e2c13c1df56439e73da0c9e77fff49", {"code_string": "import os\nimport requests\nimport json\nfrom settings import API_GW_BASE_URL, SERVICE_MOVIE_RESOURCE, SERVICE_POLITICS_RESOURCE, SERVICE_MOVIE_NAME, SERVICE_POLITICS_NAME\nmovies_info = {\n    'img_file': 'movies.png', 'name': 'Micro Movie', 'text': 'lorem lorem',\n    'tag': 'Movie'\n}\npolitics_info = {\n    'img_file': 'politics.png', 'name': 'Micro Politics',\n    'text': 'lorem lorem', 'tag': 'Politics'\n}\nweather_info = {\n    'img_file': 'weather.png', 'name': 'Micro Weather',\n    'text': 'lorem lorem', 'tag': 'Weather'\n}\nservices_info = [\n    movies_info,\n    politics_info,\n    weather_info\n]\n'''\"\"\"'''\n", "code_toks_joined": "import os <NEWLINE> import requests <NEWLINE> import json <NEWLINE> from settings import API_GW_BASE_URL , SERVICE_MOVIE_RESOURCE , SERVICE_POLITICS_RESOURCE , SERVICE_MOVIE_NAME , SERVICE_POLITICS_NAME <NEWLINE> movies_info = { <NEWLINE> <INDENT> <STRING> : <STRING> , <STRING> : <STRING> , <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> <NEWLINE> <DEDENT> } <NEWLINE> politics_info = { <NEWLINE> <INDENT> <STRING> : <STRING> , <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <STRING> : <STRING> <NEWLINE> <DEDENT> } <NEWLINE> weather_info = { <NEWLINE> <INDENT> <STRING> : <STRING> , <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <STRING> : <STRING> <NEWLINE> <DEDENT> } <NEWLINE> services_info = [ <NEWLINE> <INDENT> movies_info , <NEWLINE> politics_info , <NEWLINE> weather_info <NEWLINE> <DEDENT> ] <NEWLINE> <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'img_file'", "'movies.png'", "'name'", "'Micro Movie'", "'text'", "'lorem lorem'", "'tag'", "'Movie'", "'img_file'", "'politics.png'", "'name'", "'Micro Politics'", "'text'", "'lorem lorem'", "'tag'", "'Politics'", "'img_file'", "'weather.png'", "'name'", "'Micro Weather'", "'text'", "'lorem lorem'", "'tag'", "'Weather'", "'''\"\"\"'''"]}}], ["5633bc389234474dddfdd9eedae0b1ca", {"code_string": "def encode_frame(self, frame):\n    if frame.extended:\n        cmd = 'T'\n        can_id = '{:08x}'.format(frame.id)\n    else:\n        cmd = 't'\n        can_id = '{:03x}'.format(frame.id)\n    length = '{:x}'.format(frame.data_length)\n    data = ''\n    for b in frame.data:\n        data += '{:02x}'.format(b)\n    return cmd + can_id + length + data\n", "code_toks_joined": "def encode_frame ( self , frame ) : <NEWLINE> <INDENT> if frame . extended : <NEWLINE> <INDENT> cmd = <STRING> <NEWLINE> can_id = <STRING> . format ( frame . id ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> cmd = <STRING> <NEWLINE> can_id = <STRING> . format ( frame . id ) <NEWLINE> <DEDENT> length = <STRING> . format ( frame . data_length ) <NEWLINE> data = <STRING> <NEWLINE> for b in frame . data : <NEWLINE> <INDENT> data += <STRING> . format ( b ) <NEWLINE> <DEDENT> return cmd + can_id + length + data <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'T'", "'{:08x}'", "'t'", "'{:03x}'", "'{:x}'", "''", "'{:02x}'"]}}], ["fc3203c6c92c8b51c46881f878860adb", {"code_string": "import optparse\nimport random\nimport sys\n", "code_toks_joined": "import optparse <NEWLINE> import random <NEWLINE> import sys <NEWLINE>", "anonymize_dict": {}}], ["bfd70432b3d1289c631f004b54c332a2", {"code_string": "from config import CONFIG_FILE\nfrom ifcb.util import get_config\nimport re\nCONFIG_SCHEMA = [\n('stitch', 'bool'),\n('use_memcached', 'bool'),\n('memcached_servers', 'list'),\n('url_base', 'str'),\n('data_ttl', 'int'),\n('data_namespace', 'str'),\n('feed', 'str'),\n('fs_roots', 'list'),\n('mod_roots', 'list'),\n('blob_roots', 'list'),\n('psql_connect', 'str')\n]\n", "code_toks_joined": "from config import CONFIG_FILE <NEWLINE> from ifcb . util import get_config <NEWLINE> import re <NEWLINE> CONFIG_SCHEMA = [ <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) , <NEWLINE> ( <STRING> , <STRING> ) <NEWLINE> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'stitch'", "'bool'", "'use_memcached'", "'bool'", "'memcached_servers'", "'list'", "'url_base'", "'str'", "'data_ttl'", "'int'", "'data_namespace'", "'str'", "'feed'", "'str'", "'fs_roots'", "'list'", "'mod_roots'", "'list'", "'blob_roots'", "'list'", "'psql_connect'", "'str'"]}}], ["39f0b46ce81bdd083a5c1ed12a9b194e", {"code_string": "def distribution(x, label):\n    fig = plt.figure()\n    ax1 = fig.add_subplot(2, 1, 1)\n    ax1.set_title(label + '_hist')\n    ax1.hist(x, bins = 100, histtype = 'step')\n    ax2 = fig.add_subplot(2, 1, 2)\n    ax2.set_title(label + '_cumulative_normalized')\n    ax2.hist(x, bins = 100, cumulative = True, normed = True, histtype = 'step')\n    plt.savefig(label)\n", "code_toks_joined": "def distribution ( x , label ) : <NEWLINE> <INDENT> fig = plt . figure ( ) <NEWLINE> ax1 = fig . add_subplot ( 2 , 1 , 1 ) <NEWLINE> ax1 . set_title ( label + <STRING> ) <NEWLINE> ax1 . hist ( x , bins = 100 , histtype = <STRING> ) <NEWLINE> ax2 = fig . add_subplot ( 2 , 1 , 2 ) <NEWLINE> ax2 . set_title ( label + <STRING> ) <NEWLINE> ax2 . hist ( x , bins = 100 , cumulative = True , normed = True , histtype = <STRING> ) <NEWLINE> plt . savefig ( label ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'_hist'", "'step'", "'_cumulative_normalized'", "'step'"]}}], ["a4b13895830f960d45ffa623c5cb2147", {"code_string": "\"\"\"tekuilaget.py\"\"\"\nfrom nzbget import ScanScript\nimport tekuila.teksavvy\nimport tekuila.startca\nimport xmlrpclib\nfrom sys import exit\n", "code_toks_joined": "<STRING> <NEWLINE> from nzbget import ScanScript <NEWLINE> import tekuila . teksavvy <NEWLINE> import tekuila . startca <NEWLINE> import xmlrpclib <NEWLINE> from sys import exit <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"tekuilaget.py\"\"\""]}}], ["3addfbc30b6c08f61dcfe449d13dbca3", {"code_string": "def __activate_cb(self, * args):\n    try:\n        self.__manager.match()\n    except AttributeError:\n        from Manager import Manager\n        self.__manager = Manager(self.__editor)\n        self.__manager.match()\n    return False\n", "code_toks_joined": "def __activate_cb ( self , * args ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> self . __manager . match ( ) <NEWLINE> <DEDENT> except AttributeError : <NEWLINE> <INDENT> from Manager import Manager <NEWLINE> self . __manager = Manager ( self . __editor ) <NEWLINE> self . __manager . match ( ) <NEWLINE> <DEDENT> return False <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["23932d6fb567f29feb99a904f6eb46bc", {"code_string": "def find_existing_toc(container):\n    toc = container.opf_xpath('//opf:spine/@toc')\n    if toc:\n        toc = container.manifest_id_map.get(toc[0], None)\n    if not toc:\n        ncx = guess_type('a.ncx')\n        toc = container.manifest_type_map.get(ncx, [None])[0]\n    if not toc:\n        return None\n    return toc\n", "code_toks_joined": "def find_existing_toc ( container ) : <NEWLINE> <INDENT> toc = container . opf_xpath ( <STRING> ) <NEWLINE> if toc : <NEWLINE> <INDENT> toc = container . manifest_id_map . get ( toc [ 0 ] , None ) <NEWLINE> <DEDENT> if not toc : <NEWLINE> <INDENT> ncx = guess_type ( <STRING> ) <NEWLINE> toc = container . manifest_type_map . get ( ncx , [ None ] ) [ 0 ] <NEWLINE> <DEDENT> if not toc : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> return toc <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'//opf:spine/@toc'", "'a.ncx'"]}}], ["b8846bbddeab54b8eb6bcdc3ff09f2c6", {"code_string": "def test_load_balancer(self):\n    body = {\"name\": \"test_name\", \"description\": \"test_description\",\n        \"vip_subnet_id\": uuidutils.generate_uuid()}\n    lb = wsme_json.fromjson(self._type, body)\n    self.assertTrue(lb.admin_state_up)\n", "code_toks_joined": "def test_load_balancer ( self ) : <NEWLINE> <INDENT> body = { <STRING> : <STRING> , <STRING> : <STRING> , <NEWLINE> <INDENT> <STRING> : uuidutils . generate_uuid ( ) } <NEWLINE> <DEDENT> lb = wsme_json . fromjson ( self . _type , body ) <NEWLINE> self . assertTrue ( lb . admin_state_up ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"name\"", "\"test_name\"", "\"description\"", "\"test_description\"", "\"vip_subnet_id\""]}}], ["fd373be5140381ee137087b41a89d377", {"code_string": "def dodetectplatform(visualstudio):\n    global toolset\n    if \"Microsoft Visual Studio 10.0\" in visualstudio:\n        toolset = \"v100\"\n    elif \"Microsoft Visual Studio 11.0\" in visualstudio:\n        toolset = \"v110\"\n    elif \"Microsoft Visual Studio 12.0\" in visualstudio:\n        toolset = \"v120\"\n    elif \"Microsoft Visual Studio 14.0\" in visualstudio:\n        toolset = \"v140\"\n    else:\n        print(\"PlatformToolset for \\\"\" + visualstudio + \"\\\" not supported\")\n        toolset = \"\"\n", "code_toks_joined": "def dodetectplatform ( visualstudio ) : <NEWLINE> <INDENT> global toolset <NEWLINE> if <STRING> in visualstudio : <NEWLINE> <INDENT> toolset = <STRING> <NEWLINE> <DEDENT> elif <STRING> in visualstudio : <NEWLINE> <INDENT> toolset = <STRING> <NEWLINE> <DEDENT> elif <STRING> in visualstudio : <NEWLINE> <INDENT> toolset = <STRING> <NEWLINE> <DEDENT> elif <STRING> in visualstudio : <NEWLINE> <INDENT> toolset = <STRING> <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> print ( <STRING> + visualstudio + <STRING> ) <NEWLINE> toolset = <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Microsoft Visual Studio 10.0\"", "\"v100\"", "\"Microsoft Visual Studio 11.0\"", "\"v110\"", "\"Microsoft Visual Studio 12.0\"", "\"v120\"", "\"Microsoft Visual Studio 14.0\"", "\"v140\"", "\"PlatformToolset for \\\"\"", "\"\\\" not supported\"", "\"\""]}}], ["74d3270c639453406fcdffd48a062bda", {"code_string": "class TaxAgencyTests(unittest.TestCase):\n    def test_unicode(self):\n        deposit = TaxAgency()\n        deposit.DisplayName = \"test\"\n        self.assertEquals(unicode(deposit), \"test\")\n", "code_toks_joined": "class TaxAgencyTests ( unittest . TestCase ) : <NEWLINE> <INDENT> def test_unicode ( self ) : <NEWLINE> <INDENT> deposit = TaxAgency ( ) <NEWLINE> deposit . DisplayName = <STRING> <NEWLINE> self . assertEquals ( unicode ( deposit ) , <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"test\"", "\"test\""]}}], ["1698592d03450a0c89b926db331cc898", {"code_string": "def isimage(filename):\n    \"\"\"true if the filename's extension is in the content-type lookup\"\"\"\n    filename = filename.lower()\n    return filename[filename.rfind(\".\") + 1: ] in ext2conttype\n", "code_toks_joined": "def isimage ( filename ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> filename = filename . lower ( ) <NEWLINE> return filename [ filename . rfind ( <STRING> ) + 1 : ] in ext2conttype <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"true if the filename's extension is in the content-type lookup\"\"\"", "\".\""]}}], ["b091742601edb164cfc244b82097957a", {"code_string": "def test_log_exception(self):\n    \"\"\"Catch any exception and log it.\"\"\"\n    mock_logger = Mock()\n    @ log_exceptions(mock_logger)\n    def raise_exception():\n        \"\"\"Raise an exception.\"\"\"\n        raise Exception(u\"Bad exception.\")\n    self.assertRaises(Exception, raise_exception)\n    self.assertTrue(mock_logger.exception.called)\n", "code_toks_joined": "def test_log_exception ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> mock_logger = Mock ( ) <NEWLINE> @ log_exceptions ( mock_logger ) <NEWLINE> def raise_exception ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> raise Exception ( <STRING> ) <NEWLINE> <DEDENT> self . assertRaises ( Exception , raise_exception ) <NEWLINE> self . assertTrue ( mock_logger . exception . called ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Catch any exception and log it.\"\"\"", "\"\"\"Raise an exception.\"\"\"", "u\"Bad exception.\""]}}], ["8b503ba2b071f5089a02c4c1ec40c605", {"code_string": "class TestUtils(unittest.TestCase):\n    def test_reldir(self):\n        assert goatd.utils.reldir('test/thing.py', 'dir') == 'test/dir'\n", "code_toks_joined": "class TestUtils ( unittest . TestCase ) : <NEWLINE> <INDENT> def test_reldir ( self ) : <NEWLINE> <INDENT> assert goatd . utils . reldir ( <STRING> , <STRING> ) == <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'test/thing.py'", "'dir'", "'test/dir'"]}}], ["17827e349b7cc6b5f96cf0ab161daaa8", {"code_string": "def step(self):\n    \"\"\"Perform a single parsing operation.  If a reduction is\"\"\"\n    return self.reduce() or self.shift()\n", "code_toks_joined": "def step ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . reduce ( ) or self . shift ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Perform a single parsing operation.  If a reduction is\"\"\""]}}], ["7d24b72d7f0b499722c5eec3abd7c496", {"code_string": "def check(mf):\n    \"\"\"In python2.5 modules in the email package were renamed to be\"\"\"\n    m = mf.findNode('email')\n    if m is None or m.filename is None:\n        return None\n    return dict(\n        packages = ['email'],\n    )\n", "code_toks_joined": "def check ( mf ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> m = mf . findNode ( <STRING> ) <NEWLINE> if m is None or m . filename is None : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> return dict ( <NEWLINE> <INDENT> packages = [ <STRING> ] , <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"In python2.5 modules in the email package were renamed to be\"\"\"", "'email'", "'email'"]}}], ["e2fb4a82b9b66deba22cda4a8cc687e8", {"code_string": "def hello(a):\n    print(a)\n    x = input(\"\")\n    print(x)\n", "code_toks_joined": "def hello ( a ) : <NEWLINE> <INDENT> print ( a ) <NEWLINE> x = input ( <STRING> ) <NEWLINE> print ( x ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\""]}}], ["5ea040bf90b656c0961cf01fed0b00c3", {"code_string": "def test_username_max_length(self):\n    response = self.client.post(self.list_url, {\n        'username': 'a' * 31,\n        'find_unique_username': 1,\n        'email': 'test@example.com',\n    })\n    assert_equal(response.status_code, status.HTTP_400_BAD_REQUEST)\n", "code_toks_joined": "def test_username_max_length ( self ) : <NEWLINE> <INDENT> response = self . client . post ( self . list_url , { <NEWLINE> <INDENT> <STRING> : <STRING> * 31 , <NEWLINE> <STRING> : 1 , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <DEDENT> } ) <NEWLINE> assert_equal ( response . status_code , status . HTTP_400_BAD_REQUEST ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'username'", "'a'", "'find_unique_username'", "'email'", "'test@example.com'"]}}], ["3ca05cc440b972e5c0b865ee8d8b5ab4", {"code_string": "class ValueAction(eg.ActionWithStringParameter):\n    \"\"\"Base class for all actions with adjustable argument\"\"\"\n    def __call__(self, data):\n        self.plugin.serial.write(self.cmd + str(data) + chr(13))\n", "code_toks_joined": "class ValueAction ( eg . ActionWithStringParameter ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __call__ ( self , data ) : <NEWLINE> <INDENT> self . plugin . serial . write ( self . cmd + str ( data ) + chr ( 13 ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Base class for all actions with adjustable argument\"\"\""]}}], ["6e8f1f43b3aa82215217f1e2a2dd82d2", {"code_string": "def gga2ddm(gga):\n    \"\"\"Convert from GGA coordinate to degree decimal minutes.\"\"\"\n    try:\n        gga = str(gga)\n        dot_index = gga.index(\".\")\n        degrees = gga[: dot_index - 2]\n        decimal_minutes = gga[dot_index - 2: ]\n    except ValueError:\n        degrees = gga[: - 2]\n        decimal_minutes = gga[- 2: ]\n    return(degrees, decimal_minutes)\n", "code_toks_joined": "def gga2ddm ( gga ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> try : <NEWLINE> <INDENT> gga = str ( gga ) <NEWLINE> dot_index = gga . index ( <STRING> ) <NEWLINE> degrees = gga [ : dot_index - 2 ] <NEWLINE> decimal_minutes = gga [ dot_index - 2 : ] <NEWLINE> <DEDENT> except ValueError : <NEWLINE> <INDENT> degrees = gga [ : - 2 ] <NEWLINE> decimal_minutes = gga [ - 2 : ] <NEWLINE> <DEDENT> return ( degrees , decimal_minutes ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Convert from GGA coordinate to degree decimal minutes.\"\"\"", "\".\""]}}], ["982da62cba5fbea2d8d9574dcc246488", {"code_string": "def __init__(self, appKey, push):\n    self.batchId = str(uuid.uuid1())\n    self.APPKEY = appKey\n    self.push = push\n    self.seqId = 0\n    self.innerMsgList = list()\n    self.lastPostData = None\n", "code_toks_joined": "def __init__ ( self , appKey , push ) : <NEWLINE> <INDENT> self . batchId = str ( uuid . uuid1 ( ) ) <NEWLINE> self . APPKEY = appKey <NEWLINE> self . push = push <NEWLINE> self . seqId = 0 <NEWLINE> self . innerMsgList = list ( ) <NEWLINE> self . lastPostData = None <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["cb21bda1d7c268422548640a63fd5c16", {"code_string": "import os\nimport string\nimport tempfile\nimport time\nimport datetime\nimport unittest\nimport subprocess\nfrom exportable.columns import IntColumn, DateTimeColumn, TextColumn, FloatColumn\nfrom exportable.exporters import SPSSExporter\nfrom exportable.exporters.spss import write_table\nfrom exportable.table import ListTable\n", "code_toks_joined": "import os <NEWLINE> import string <NEWLINE> import tempfile <NEWLINE> import time <NEWLINE> import datetime <NEWLINE> import unittest <NEWLINE> import subprocess <NEWLINE> from exportable . columns import IntColumn , DateTimeColumn , TextColumn , FloatColumn <NEWLINE> from exportable . exporters import SPSSExporter <NEWLINE> from exportable . exporters . spss import write_table <NEWLINE> from exportable . table import ListTable <NEWLINE>", "anonymize_dict": {}}], ["7f21f426ff9cd06c666bc2dca0832e27", {"code_string": "import sys\nimport string\nCHAR_MAP = dict(zip(\n    string.ascii_lowercase,\n    string.ascii_lowercase[13: 26] + string.ascii_lowercase[0: 13]\n    )\n)\n", "code_toks_joined": "import sys <NEWLINE> import string <NEWLINE> CHAR_MAP = dict ( zip ( <NEWLINE> <INDENT> string . ascii_lowercase , <NEWLINE> string . ascii_lowercase [ 13 : 26 ] + string . ascii_lowercase [ 0 : 13 ] <NEWLINE> ) <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {}}], ["6ba52a9786d0c0050354246fac149df4", {"code_string": "def spider_ended(spider):\n    db_conn.close()\n    db_cursor.close()\n    print(\"close database\")\n", "code_toks_joined": "def spider_ended ( spider ) : <NEWLINE> <INDENT> db_conn . close ( ) <NEWLINE> db_cursor . close ( ) <NEWLINE> print ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"close database\""]}}], ["c73c78c43952278f37f9d0826f11afb7", {"code_string": "def main():\n    list_1 = evenele(list_a)\n    list_b = ranlist()\n    list_2 = evenele(list_b)\n    print(list_1)\n    print(list_2)\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> list_1 = evenele ( list_a ) <NEWLINE> list_b = ranlist ( ) <NEWLINE> list_2 = evenele ( list_b ) <NEWLINE> print ( list_1 ) <NEWLINE> print ( list_2 ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["0ffb021d9195b4c5812248b526477696", {"code_string": "class Pointer(object):\n    def __init__(self, d):\n        self.d = d\n        self.indices = []\n    @ property\n    def r(self):\n        self.indices.append(1)\n        return self\n    @ property\n    def l(self):\n        self.indices.append(0)\n        return self\n    @ property\n    def E(self):\n        d = self.d\n        for i in self.indices:\n            d = d[i]\n        return d\n", "code_toks_joined": "class Pointer ( object ) : <NEWLINE> <INDENT> def __init__ ( self , d ) : <NEWLINE> <INDENT> self . d = d <NEWLINE> self . indices = [ ] <NEWLINE> <DEDENT> @ property <NEWLINE> def r ( self ) : <NEWLINE> <INDENT> self . indices . append ( 1 ) <NEWLINE> return self <NEWLINE> <DEDENT> @ property <NEWLINE> def l ( self ) : <NEWLINE> <INDENT> self . indices . append ( 0 ) <NEWLINE> return self <NEWLINE> <DEDENT> @ property <NEWLINE> def E ( self ) : <NEWLINE> <INDENT> d = self . d <NEWLINE> for i in self . indices : <NEWLINE> <INDENT> d = d [ i ] <NEWLINE> <DEDENT> return d <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["850c1f7ec8003047dad09d9433c76904", {"code_string": "def test_notificationStore(self):\n    n = self.ns.get_notifications()\n    self.assertIsNone(n)\n    self.ns.save_notification(self.u.guid, self.m.handle, 'NOTICE',\n        '0000-00-00 00:00:00', '')\n    n = self.ns.get_notifications()\n    self.assertIsNotNone(n)\n    self.ns.delete_notfication(self.u.guid, '0000-00-00 00:00:00')\n    n = self.ns.get_notifications()\n    self.assertIsNone(n)\n", "code_toks_joined": "def test_notificationStore ( self ) : <NEWLINE> <INDENT> n = self . ns . get_notifications ( ) <NEWLINE> self . assertIsNone ( n ) <NEWLINE> self . ns . save_notification ( self . u . guid , self . m . handle , <STRING> , <NEWLINE> <INDENT> <STRING> , <STRING> ) <NEWLINE> <DEDENT> n = self . ns . get_notifications ( ) <NEWLINE> self . assertIsNotNone ( n ) <NEWLINE> self . ns . delete_notfication ( self . u . guid , <STRING> ) <NEWLINE> n = self . ns . get_notifications ( ) <NEWLINE> self . assertIsNone ( n ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'NOTICE'", "'0000-00-00 00:00:00'", "''", "'0000-00-00 00:00:00'"]}}], ["c84aa355f3effa900204583608460a87", {"code_string": "def set_list_write(filename, entries):\n    \"\"\"Write a list of values to a file. One per line.\"\"\"\n    values = set(entries)\n    with open(filename, 'tw', encoding = 'utf-8') as f:\n        f.writelines(values)\n        os.fchmod(f.fileno(), 0o644)\n", "code_toks_joined": "def set_list_write ( filename , entries ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> values = set ( entries ) <NEWLINE> with open ( filename , <STRING> , encoding = <STRING> ) as f : <NEWLINE> <INDENT> f . writelines ( values ) <NEWLINE> os . fchmod ( f . fileno ( ) , 0o644 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Write a list of values to a file. One per line.\"\"\"", "'tw'", "'utf-8'"]}}], ["997e5be19f45e25eaba1b4f3d053a447", {"code_string": "from django.conf.urls import patterns, url\nfrom sites import views\nurlpatterns = patterns('',\n    url(r'^search$', views.SearchView.as_view()),\n    url(r'^stat$', views.StatView.as_view()),\n    url(r'^wordcloud$', views.WordCloudView.as_view()),\n)\n", "code_toks_joined": "from django . conf . urls import patterns , url <NEWLINE> from sites import views <NEWLINE> urlpatterns = patterns ( <STRING> , <NEWLINE> <INDENT> url ( <STRING> , views . SearchView . as_view ( ) ) , <NEWLINE> url ( <STRING> , views . StatView . as_view ( ) ) , <NEWLINE> url ( <STRING> , views . WordCloudView . as_view ( ) ) , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["''", "r'^search$'", "r'^stat$'", "r'^wordcloud$'"]}}], ["1ba7c14193630889c9b16e4ddb0e666d", {"code_string": "import logging\nfrom tasklib.actions import action\nfrom tasklib import exceptions\nfrom tasklib import utils\nlog = logging.getLogger(__name__)\n", "code_toks_joined": "import logging <NEWLINE> from tasklib . actions import action <NEWLINE> from tasklib import exceptions <NEWLINE> from tasklib import utils <NEWLINE> log = logging . getLogger ( __name__ ) <NEWLINE>", "anonymize_dict": {}}], ["7fcba20bff8f21b0d7463e2f9830eb3c", {"code_string": "class TForm(autocomplete.FutureModelForm):\n    test = autocomplete.QuerySetSequenceModelField(\n        queryset = autocomplete.QuerySetSequence(\n            Group.objects.all(),\n            TModel.objects.all(),\n        ),\n        required = False,\n        widget = autocomplete.QuerySetSequenceSelect2('select2_gfk'),\n    )\n    class Meta:\n        model = TModel\n        fields = ('name', )\n", "code_toks_joined": "class TForm ( autocomplete . FutureModelForm ) : <NEWLINE> <INDENT> test = autocomplete . QuerySetSequenceModelField ( <NEWLINE> <INDENT> queryset = autocomplete . QuerySetSequence ( <NEWLINE> <INDENT> Group . objects . all ( ) , <NEWLINE> TModel . objects . all ( ) , <NEWLINE> <DEDENT> ) , <NEWLINE> required = False , <NEWLINE> widget = autocomplete . QuerySetSequenceSelect2 ( <STRING> ) , <NEWLINE> <DEDENT> ) <NEWLINE> class Meta : <NEWLINE> <INDENT> model = TModel <NEWLINE> fields = ( <STRING> , ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'select2_gfk'", "'name'"]}}], ["c2a89119821c272177aeaa1815e1807d", {"code_string": "class CountryGrid(object):\n    \"\"\"Wraps a Nominatim country_osm_grid table.\"\"\"\n    def __init__(self, meta, name = 'country_osm_grid'):\n        self.data = Table(name, meta,\n            Column('country_code', String),\n            Column('area', Float),\n            Column('geom', Geometry)\n            )\n    def column_cc(self):\n        return self.data.c.country_code\n    def column_geom(self):\n        return self.data.c.geom\n", "code_toks_joined": "class CountryGrid ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , meta , name = <STRING> ) : <NEWLINE> <INDENT> self . data = Table ( name , meta , <NEWLINE> <INDENT> Column ( <STRING> , String ) , <NEWLINE> Column ( <STRING> , Float ) , <NEWLINE> Column ( <STRING> , Geometry ) <NEWLINE> ) <NEWLINE> <DEDENT> <DEDENT> def column_cc ( self ) : <NEWLINE> <INDENT> return self . data . c . country_code <NEWLINE> <DEDENT> def column_geom ( self ) : <NEWLINE> <INDENT> return self . data . c . geom <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Wraps a Nominatim country_osm_grid table.\"\"\"", "'country_osm_grid'", "'country_code'", "'area'", "'geom'"]}}], ["fedf78a627c72d4c56096b3c9c121a96", {"code_string": "def extract_features(document):\n    document_words = set(document)\n    features = {}\n    for word in word_features:\n        features['contains(%s %s)' %(word)] = (word in document_words)\n    return features\n", "code_toks_joined": "def extract_features ( document ) : <NEWLINE> <INDENT> document_words = set ( document ) <NEWLINE> features = { } <NEWLINE> for word in word_features : <NEWLINE> <INDENT> features [ <STRING> % ( word ) ] = ( word in document_words ) <NEWLINE> <DEDENT> return features <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'contains(%s %s)'"]}}], ["43d7178f8a5d1d04f90a6f736cda4fa7", {"code_string": "def _get_measurement_kwargs(self):\n    r = Command._get_measurement_kwargs(self)\n    r[\"packets\"] = self.arguments.packets\n    r[\"packet_interval\"] = self.arguments.packet_interval\n    r[\"size\"] = self.arguments.size\n    return r\n", "code_toks_joined": "def _get_measurement_kwargs ( self ) : <NEWLINE> <INDENT> r = Command . _get_measurement_kwargs ( self ) <NEWLINE> r [ <STRING> ] = self . arguments . packets <NEWLINE> r [ <STRING> ] = self . arguments . packet_interval <NEWLINE> r [ <STRING> ] = self . arguments . size <NEWLINE> return r <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"packets\"", "\"packet_interval\"", "\"size\""]}}], ["26c9ec2f8730608069c34d631612e93b", {"code_string": "def test_lt(self):\n    assert Location(1, 1) < Location(1, 2)\n    assert Location(1, 1) < Location(2, 1)\n    assert not(Location(1, 1) < Location(1, 1))\n    assert not(Location(2, 1) < Location(1, 1))\n    assert not(Location(1, 2) < Location(1, 1))\n", "code_toks_joined": "def test_lt ( self ) : <NEWLINE> <INDENT> assert Location ( 1 , 1 ) < Location ( 1 , 2 ) <NEWLINE> assert Location ( 1 , 1 ) < Location ( 2 , 1 ) <NEWLINE> assert not ( Location ( 1 , 1 ) < Location ( 1 , 1 ) ) <NEWLINE> assert not ( Location ( 2 , 1 ) < Location ( 1 , 1 ) ) <NEWLINE> assert not ( Location ( 1 , 2 ) < Location ( 1 , 1 ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["675f8c0d1019dbbc4c83c67462669a8b", {"code_string": "\"\"\"Class to perform under-sampling based on the instance hardness\"\"\"\nfrom __future__ import print_function\nfrom __future__ import division\nimport numpy as np\nfrom collections import Counter\nfrom sklearn.cross_validation import StratifiedKFold\nfrom..base import SamplerMixin\nESTIMATOR_KIND = ('knn', 'decision-tree', 'random-forest', 'adaboost',\n    'gradient-boosting', 'linear-svm')\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import print_function <NEWLINE> from __future__ import division <NEWLINE> import numpy as np <NEWLINE> from collections import Counter <NEWLINE> from sklearn . cross_validation import StratifiedKFold <NEWLINE> from . . base import SamplerMixin <NEWLINE> ESTIMATOR_KIND = ( <STRING> , <STRING> , <STRING> , <STRING> , <NEWLINE> <INDENT> <STRING> , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Class to perform under-sampling based on the instance hardness\"\"\"", "'knn'", "'decision-tree'", "'random-forest'", "'adaboost'", "'gradient-boosting'", "'linear-svm'"]}}], ["cf030acee5672a890ffb4fa1e407af18", {"code_string": "class DataSample(models.Model):\n    \"\"\"One sample of a given metric representing a daily summary.\"\"\"\n    metric = models.ForeignKey(Metric)\n    utc_timestamp = models.DateTimeField(default = datetime.datetime.utcnow)\n    value = models.BigIntegerField()\n    class Meta:\n        ordering = ['-utc_timestamp']\n        get_latest_by = 'utc_timestamp'\n        verbose_name_plural = 'data sample'\n", "code_toks_joined": "class DataSample ( models . Model ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> metric = models . ForeignKey ( Metric ) <NEWLINE> utc_timestamp = models . DateTimeField ( default = datetime . datetime . utcnow ) <NEWLINE> value = models . BigIntegerField ( ) <NEWLINE> class Meta : <NEWLINE> <INDENT> ordering = [ <STRING> ] <NEWLINE> get_latest_by = <STRING> <NEWLINE> verbose_name_plural = <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"One sample of a given metric representing a daily summary.\"\"\"", "'-utc_timestamp'", "'utc_timestamp'", "'data sample'"]}}], ["194c1f6586eac0da1b100dc31a304de5", {"code_string": "def send_data(json_data):\n    \"\"\"Send the data to InfluxDB\"\"\"\n    db_client = influxdb.InfluxDBClient('5.196.8.140',\n        8086,\n        'ISEN',\n        'ISEN29',\n        'thermostat')\n    db_client.write_points(json_data)\n", "code_toks_joined": "def send_data ( json_data ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> db_client = influxdb . InfluxDBClient ( <STRING> , <NEWLINE> <INDENT> 8086 , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> ) <NEWLINE> <DEDENT> db_client . write_points ( json_data ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Send the data to InfluxDB\"\"\"", "'5.196.8.140'", "'ISEN'", "'ISEN29'", "'thermostat'"]}}], ["cefc77ba8f8efa4ac3a1e422d6245796", {"code_string": "class SVMClassifier(AbstractZnormClassifier):\n    \"\"\"Classifier which uses one-vs-one support vector machines\"\"\"\n    def __init__(self, C = 1, ** kwargs):\n        super(SVMClassifier, self).__init__(\"SVM\", C = C, ** kwargs)\n        self._svm = SVC(C = C, ** kwargs)\n    def _train(self, X, Y):\n        self._svm.fit(X, Y)\n    def _classify(self, test_X):\n        return self._svm.predict(test_X)\n", "code_toks_joined": "class SVMClassifier ( AbstractZnormClassifier ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , C = 1 , ** kwargs ) : <NEWLINE> <INDENT> super ( SVMClassifier , self ) . __init__ ( <STRING> , C = C , ** kwargs ) <NEWLINE> self . _svm = SVC ( C = C , ** kwargs ) <NEWLINE> <DEDENT> def _train ( self , X , Y ) : <NEWLINE> <INDENT> self . _svm . fit ( X , Y ) <NEWLINE> <DEDENT> def _classify ( self , test_X ) : <NEWLINE> <INDENT> return self . _svm . predict ( test_X ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Classifier which uses one-vs-one support vector machines\"\"\"", "\"SVM\""]}}], ["6e50fb8c62ab0d24a8894f2a4656cf9b", {"code_string": "def test(n, k):\n    sol = Solution()\n    print(\"input: %d %d\" %(n, k))\n    print(\"output: %s\" %(sol.getPermutation(n, k)))\n", "code_toks_joined": "def test ( n , k ) : <NEWLINE> <INDENT> sol = Solution ( ) <NEWLINE> print ( <STRING> % ( n , k ) ) <NEWLINE> print ( <STRING> % ( sol . getPermutation ( n , k ) ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"input: %d %d\"", "\"output: %s\""]}}], ["67562783fe8b6b84097b97093b2f06ab", {"code_string": "def gediVolatility(strike, forward, expiry, atmVol, skew, kurt):\n    moneyness = math.log(strike / forward) / math.sqrt(expiry)\n    s = math.atan(moneyness)\n    return atmVol + s * skew + kurt *(s ** 2)\n", "code_toks_joined": "def gediVolatility ( strike , forward , expiry , atmVol , skew , kurt ) : <NEWLINE> <INDENT> moneyness = math . log ( strike / forward ) / math . sqrt ( expiry ) <NEWLINE> s = math . atan ( moneyness ) <NEWLINE> return atmVol + s * skew + kurt * ( s ** 2 ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ad638b041187a5fa2a72bd9827a44f93", {"code_string": "from __future__ import absolute_import, unicode_literals\nfrom base import GAETestCase\nfrom pswdclient.model import SignSecret\nfrom pswdclient.manager import FindOrCreateSecrets, RenewSecrets, RevokeSecrets\n", "code_toks_joined": "from __future__ import absolute_import , unicode_literals <NEWLINE> from base import GAETestCase <NEWLINE> from pswdclient . model import SignSecret <NEWLINE> from pswdclient . manager import FindOrCreateSecrets , RenewSecrets , RevokeSecrets <NEWLINE>", "anonymize_dict": {}}], ["d08f0764be8c989030f0c57b5706aa35", {"code_string": "g = (x ** 2 for x in range(6))\n'''this is same as:'''\nprint(g)\nfor x in g:\n    print(x)\n", "code_toks_joined": "g = ( x ** 2 for x in range ( 6 ) ) <NEWLINE> <STRING> <NEWLINE> print ( g ) <NEWLINE> for x in g : <NEWLINE> <INDENT> print ( x ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''this is same as:'''"]}}], ["4f79e261d1efba561171cd1e2f1cb9d0", {"code_string": "def rm(self, grp):\n    \"\"\" Remove a group or dataset.\"\"\"\n    grp = self._get_item(grp)\n    del self[grp.name]\n", "code_toks_joined": "def rm ( self , grp ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> grp = self . _get_item ( grp ) <NEWLINE> del self [ grp . name ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Remove a group or dataset.\"\"\""]}}], ["a2940aa507878290416fa7ca97b36706", {"code_string": "from sys import argv\nscript, user_name, location = argv\nprompt = '$ '\nprint(\"Hi, %s! I'm the %s script.\" %(user_name, script))\nprint(\"I'd like to ask you a few questions.\")\nprint(\"Do you like me, %s?\" % user_name)\nlikes = raw_input(prompt)\nprint(\"Where do you live, %s?\" % user_name)\nlives = raw_input(prompt)\nprint(\"What kind of computer do you have?\")\ncomputer = raw_input(prompt)\nif location != lives:\n    print(\"You are not at home\")\nprint(\"\"\"You said %s about liking me. I like you anyway because i'm a friendly\"\"\" %(likes, lives, computer))\n", "code_toks_joined": "from sys import argv <NEWLINE> script , user_name , location = argv <NEWLINE> prompt = <STRING> <NEWLINE> print ( <STRING> % ( user_name , script ) ) <NEWLINE> print ( <STRING> ) <NEWLINE> print ( <STRING> % user_name ) <NEWLINE> likes = raw_input ( prompt ) <NEWLINE> print ( <STRING> % user_name ) <NEWLINE> lives = raw_input ( prompt ) <NEWLINE> print ( <STRING> ) <NEWLINE> computer = raw_input ( prompt ) <NEWLINE> if location != lives : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> print ( <STRING> % ( likes , lives , computer ) ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'$ '", "\"Hi, %s! I'm the %s script.\"", "\"I'd like to ask you a few questions.\"", "\"Do you like me, %s?\"", "\"Where do you live, %s?\"", "\"What kind of computer do you have?\"", "\"You are not at home\"", "\"\"\"You said %s about liking me. I like you anyway because i'm a friendly\"\"\""]}}], ["cdb8f9d6116ff3bd617b87e8de7337af", {"code_string": "def summary_scope(name, family = None, default_name = None, values = None):\n    \"\"\"Enters a scope used for the summary and yields both the name and tag.\"\"\"\n    name = clean_tag(name)\n    family = clean_tag(family)\n    scope_base_name = name if family is None else '{}/{}'.format(family, name)\n    with ops.name_scope(scope_base_name, default_name, values = values) as scope:\n        if family is None:\n            tag = scope.rstrip('/')\n        else:\n            tag = '{}/{}'.format(family, scope.rstrip('/'))\n        yield(tag, scope)\n", "code_toks_joined": "def summary_scope ( name , family = None , default_name = None , values = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> name = clean_tag ( name ) <NEWLINE> family = clean_tag ( family ) <NEWLINE> scope_base_name = name if family is None else <STRING> . format ( family , name ) <NEWLINE> with ops . name_scope ( scope_base_name , default_name , values = values ) as scope : <NEWLINE> <INDENT> if family is None : <NEWLINE> <INDENT> tag = scope . rstrip ( <STRING> ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> tag = <STRING> . format ( family , scope . rstrip ( <STRING> ) ) <NEWLINE> <DEDENT> yield ( tag , scope ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Enters a scope used for the summary and yields both the name and tag.\"\"\"", "'{}/{}'", "'/'", "'{}/{}'", "'/'"]}}], ["e93f608c713ae4ea123d89043a910692", {"code_string": "import logging\nimport random\nimport threading\nfrom tornado import gen, ioloop\nfrom zoonado import Zoonado\nlog = logging.getLogger()\nmonitor_ioloop = None\n", "code_toks_joined": "import logging <NEWLINE> import random <NEWLINE> import threading <NEWLINE> from tornado import gen , ioloop <NEWLINE> from zoonado import Zoonado <NEWLINE> log = logging . getLogger ( ) <NEWLINE> monitor_ioloop = None <NEWLINE>", "anonymize_dict": {}}], ["adfb2be60f9a8e5e0186b648f2e44028", {"code_string": "def deallocvmss():\n    '''Stop deallocate on a VM scale set'''\n    global refresh_thread_running\n    current_vmss.dealloc()\n    statusmsg(current_vmss.status)\n    refresh_thread_running = True\n", "code_toks_joined": "def deallocvmss ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> global refresh_thread_running <NEWLINE> current_vmss . dealloc ( ) <NEWLINE> statusmsg ( current_vmss . status ) <NEWLINE> refresh_thread_running = True <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Stop deallocate on a VM scale set'''"]}}], ["b768e86d3835ceb16a27c9ab5b31ea55", {"code_string": "class SearchMembers(BaseApi):\n    \"\"\"Manage campaign reports for your MailChimp account. All Reports endpoints\"\"\"\n    def __init__(self, * args, ** kwargs):\n        \"\"\"Initialize the endpoint\"\"\"\n        super(SearchMembers, self).__init__(* args, ** kwargs)\n        self.endpoint = 'search-members'\n        self.list_id = None\n    def get(self, ** queryparams):\n        \"\"\"Search for list members. This search can be restricted to a specific\"\"\"\n        if 'list_id' in queryparams:\n            self.list_id = queryparams['list_id']\n        else:\n            self.list_id = None\n        return self._mc_client._get(url = self._build_path(), ** queryparams)\n", "code_toks_joined": "class SearchMembers ( BaseApi ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , * args , ** kwargs ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> super ( SearchMembers , self ) . __init__ ( * args , ** kwargs ) <NEWLINE> self . endpoint = <STRING> <NEWLINE> self . list_id = None <NEWLINE> <DEDENT> def get ( self , ** queryparams ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if <STRING> in queryparams : <NEWLINE> <INDENT> self . list_id = queryparams [ <STRING> ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . list_id = None <NEWLINE> <DEDENT> return self . _mc_client . _get ( url = self . _build_path ( ) , ** queryparams ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Manage campaign reports for your MailChimp account. All Reports endpoints\"\"\"", "\"\"\"Initialize the endpoint\"\"\"", "'search-members'", "\"\"\"Search for list members. This search can be restricted to a specific\"\"\"", "'list_id'", "'list_id'"]}}], ["58366b70c0c3d6404147907181d98cad", {"code_string": "class DataSource:\n    def __init__(self, params):\n        self.params = params\n        self.data = None\n    def connect(self):\n        raise NotImplementedError\n    def __iter__(self):\n        return self.data\n", "code_toks_joined": "class DataSource : <NEWLINE> <INDENT> def __init__ ( self , params ) : <NEWLINE> <INDENT> self . params = params <NEWLINE> self . data = None <NEWLINE> <DEDENT> def connect ( self ) : <NEWLINE> <INDENT> raise NotImplementedError <NEWLINE> <DEDENT> def __iter__ ( self ) : <NEWLINE> <INDENT> return self . data <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["f86df0e3fc00516eb82e6210a2cd3aad", {"code_string": "from dateutil.relativedelta import relativedelta\nfrom time import sleep\nfrom django.conf import settings\nfrom django.core.mail import send_mail\nfrom django.core.management.base import BaseCommand\nfrom django.template.loader import render_to_string\nfrom django.utils import timezone\nfrom ... models import Win, Notification\n", "code_toks_joined": "from dateutil . relativedelta import relativedelta <NEWLINE> from time import sleep <NEWLINE> from django . conf import settings <NEWLINE> from django . core . mail import send_mail <NEWLINE> from django . core . management . base import BaseCommand <NEWLINE> from django . template . loader import render_to_string <NEWLINE> from django . utils import timezone <NEWLINE> from ... models import Win , Notification <NEWLINE>", "anonymize_dict": {}}], ["9102bebcc7812d92268c6bec5cfd0370", {"code_string": "\"\"\"login URL Configuration\"\"\"\nfrom django.conf.urls import include, url\nfrom django.contrib import admin\nfrom django.conf import settings\nfrom django.conf.urls.static import static\nurlpatterns = [\n    url(r'^', include('home.urls')),\n    url(r'^account/', include('social_django.urls', namespace = 'social_django')),\n    url(r'^account/', include('django.contrib.auth.urls', namespace = 'auth')),\n    url(r'^admin/', include(admin.site.urls)),\n]\n", "code_toks_joined": "<STRING> <NEWLINE> from django . conf . urls import include , url <NEWLINE> from django . contrib import admin <NEWLINE> from django . conf import settings <NEWLINE> from django . conf . urls . static import static <NEWLINE> urlpatterns = [ <NEWLINE> <INDENT> url ( <STRING> , include ( <STRING> ) ) , <NEWLINE> url ( <STRING> , include ( <STRING> , namespace = <STRING> ) ) , <NEWLINE> url ( <STRING> , include ( <STRING> , namespace = <STRING> ) ) , <NEWLINE> url ( <STRING> , include ( admin . site . urls ) ) , <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"login URL Configuration\"\"\"", "r'^'", "'home.urls'", "r'^account/'", "'social_django.urls'", "'social_django'", "r'^account/'", "'django.contrib.auth.urls'", "'auth'", "r'^admin/'"]}}], ["858463aa6256748bc41fdf587d0b4135", {"code_string": "def recursiveReverseString(stringInput, stringTracker):\n    \"\"\"Tail recursive function to reverse a string. Loses efficiency to repeated function calls and allocation of strings\"\"\"\n    if len(stringInput) > 0:\n        stringTracker += stringInput[- 1]\n        return recursiveReverseString(stringInput[: - 1], stringTracker)\n    else:\n        return stringTracker\n", "code_toks_joined": "def recursiveReverseString ( stringInput , stringTracker ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if len ( stringInput ) > 0 : <NEWLINE> <INDENT> stringTracker += stringInput [ - 1 ] <NEWLINE> return recursiveReverseString ( stringInput [ : - 1 ] , stringTracker ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return stringTracker <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Tail recursive function to reverse a string. Loses efficiency to repeated function calls and allocation of strings\"\"\""]}}], ["9a113cf9055b3519955670e6401c06f3", {"code_string": "__all__ = [\"generic\"]\nfrom types import ClassType, InstanceType\nclasstypes = type, ClassType\n", "code_toks_joined": "__all__ = [ <STRING> ] <NEWLINE> from types import ClassType , InstanceType <NEWLINE> classtypes = type , ClassType <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"generic\""]}}], ["d97ef73497cd4335e0fdddad5a8ef701", {"code_string": "def can_edit_session(user, session):\n    \"\"\"Checks if a given user can modify the specified session.\"\"\"\n    if user.is_anonymous():\n        return False\n    if user.is_superuser or user.is_staff:\n        return True\n    speaker = user.speaker_profile\n    if not speaker:\n        return False\n    if session.speaker == speaker:\n        return True\n    return speaker in session.additional_speakers.all()\n", "code_toks_joined": "def can_edit_session ( user , session ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if user . is_anonymous ( ) : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> if user . is_superuser or user . is_staff : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> speaker = user . speaker_profile <NEWLINE> if not speaker : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> if session . speaker == speaker : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> return speaker in session . additional_speakers . all ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Checks if a given user can modify the specified session.\"\"\""]}}], ["6ced23e4b12c98581eace1348674a371", {"code_string": "def index(request):\n    context = {'somthin': 1}\n    return render(request, 'goat/index.html', context)\n", "code_toks_joined": "def index ( request ) : <NEWLINE> <INDENT> context = { <STRING> : 1 } <NEWLINE> return render ( request , <STRING> , context ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'somthin'", "'goat/index.html'"]}}], ["e0616cc2eabf9369966fee20d1ce12f2", {"code_string": "def get_mount_point(pathname):\n    pathname = os.path.normcase(os.path.realpath(pathname))\n    parent_device = path_device = os.stat(pathname).st_dev\n    while parent_device == path_device:\n        mount_point = pathname\n        pathname = os.path.dirname(pathname)\n        if pathname == mount_point: break\n        parent_device = os.stat(pathname).st_dev\n    return mount_point\n", "code_toks_joined": "def get_mount_point ( pathname ) : <NEWLINE> <INDENT> pathname = os . path . normcase ( os . path . realpath ( pathname ) ) <NEWLINE> parent_device = path_device = os . stat ( pathname ) . st_dev <NEWLINE> while parent_device == path_device : <NEWLINE> <INDENT> mount_point = pathname <NEWLINE> pathname = os . path . dirname ( pathname ) <NEWLINE> if pathname == mount_point : break <NEWLINE> parent_device = os . stat ( pathname ) . st_dev <NEWLINE> <DEDENT> return mount_point <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["1b5247791a9dd03429923a4ceae140c0", {"code_string": "def setUp(self):\n    self.settings = get_appsettings('configs/development.virtuoso.ini', name = 'main')\n    self.request = testing.DummyRequest()\n    self.request.session['upload_directory'] = os.path.join(os.path.dirname(__file__), \"..\", \"test-data\")\n    self.temp_directory = tempfile.mkdtemp()\n    self.it = InterfaceTPS(self.settings, self.request)\n    self.it.empty()\n    self.it.load_test1()\n", "code_toks_joined": "def setUp ( self ) : <NEWLINE> <INDENT> self . settings = get_appsettings ( <STRING> , name = <STRING> ) <NEWLINE> self . request = testing . DummyRequest ( ) <NEWLINE> self . request . session [ <STRING> ] = os . path . join ( os . path . dirname ( __file__ ) , <STRING> , <STRING> ) <NEWLINE> self . temp_directory = tempfile . mkdtemp ( ) <NEWLINE> self . it = InterfaceTPS ( self . settings , self . request ) <NEWLINE> self . it . empty ( ) <NEWLINE> self . it . load_test1 ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'configs/development.virtuoso.ini'", "'main'", "'upload_directory'", "\"..\"", "\"test-data\""]}}], ["3e307d4c4c9fbf80f1253f9826f29c1e", {"code_string": "import os\nimport re\nimport pickle\n", "code_toks_joined": "import os <NEWLINE> import re <NEWLINE> import pickle <NEWLINE>", "anonymize_dict": {}}], ["272079a1ce9ec90faa4f3054608b7751", {"code_string": "def cb():\n    from.Netconfig import Netconfig\n    return Netconfig()\n", "code_toks_joined": "def cb ( ) : <NEWLINE> <INDENT> from . Netconfig import Netconfig <NEWLINE> return Netconfig ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["bc181a8a8730b8faea39c61633a86688", {"code_string": "from __future__ import absolute_import\nimport logging\nfrom logging.handlers import SysLogHandler\nfrom conf.appconfig import LOG_FORMAT, LOG_DATE, LOG_ROOT_LEVEL, TOTEM_ENV, LOG_IDENTIFIER\n", "code_toks_joined": "from __future__ import absolute_import <NEWLINE> import logging <NEWLINE> from logging . handlers import SysLogHandler <NEWLINE> from conf . appconfig import LOG_FORMAT , LOG_DATE , LOG_ROOT_LEVEL , TOTEM_ENV , LOG_IDENTIFIER <NEWLINE>", "anonymize_dict": {}}], ["98329dd17b5117253c4ab17e1ac095c5", {"code_string": "def splitByDeletions(self):\n    \"\"\"This method will split the object based on the deletion headers.\"\"\"\n    splitObjects = []\n    isFirstIteration = True\n    obj = None\n    for tag, chunk in self.chunk_pairs:\n        isNewObject = (tag.isHeaderTag and tag.isDeleted)\n        if isNewObject or isFirstIteration:\n            obj = YaffsObject(self.object_id)\n            splitObjects.append(obj)\n            isFirstIteration = False\n        obj.chunk_pairs.append((tag, chunk))\n    if len(splitObjects) > 1 or len(splitObjects) == 0:\n        pass\n    return splitObjects\n", "code_toks_joined": "def splitByDeletions ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> splitObjects = [ ] <NEWLINE> isFirstIteration = True <NEWLINE> obj = None <NEWLINE> for tag , chunk in self . chunk_pairs : <NEWLINE> <INDENT> isNewObject = ( tag . isHeaderTag and tag . isDeleted ) <NEWLINE> if isNewObject or isFirstIteration : <NEWLINE> <INDENT> obj = YaffsObject ( self . object_id ) <NEWLINE> splitObjects . append ( obj ) <NEWLINE> isFirstIteration = False <NEWLINE> <DEDENT> obj . chunk_pairs . append ( ( tag , chunk ) ) <NEWLINE> <DEDENT> if len ( splitObjects ) > 1 or len ( splitObjects ) == 0 : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> return splitObjects <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"This method will split the object based on the deletion headers.\"\"\""]}}], ["8972eea90eccb821c218f9bfe24ef7f3", {"code_string": "from django.contrib import admin\nfrom fpr import models\nadmin.site.register(models.Format)\nadmin.site.register(models.FormatGroup)\nadmin.site.register(models.FormatVersion)\nadmin.site.register(models.IDCommand)\nadmin.site.register(models.IDRule)\nadmin.site.register(models.IDTool)\nadmin.site.register(models.FPRule)\nadmin.site.register(models.FPCommand)\nadmin.site.register(models.FPTool)\n", "code_toks_joined": "from django . contrib import admin <NEWLINE> from fpr import models <NEWLINE> admin . site . register ( models . Format ) <NEWLINE> admin . site . register ( models . FormatGroup ) <NEWLINE> admin . site . register ( models . FormatVersion ) <NEWLINE> admin . site . register ( models . IDCommand ) <NEWLINE> admin . site . register ( models . IDRule ) <NEWLINE> admin . site . register ( models . IDTool ) <NEWLINE> admin . site . register ( models . FPRule ) <NEWLINE> admin . site . register ( models . FPCommand ) <NEWLINE> admin . site . register ( models . FPTool ) <NEWLINE>", "anonymize_dict": {}}], ["0489cdd0ba04538298fb9b177575fd3d", {"code_string": "class DiffsetAction(AbstractAction):\n    def __init__(self, documentNumber, fiscalYears):\n        self.documentNumber = documentNumber\n        self.fiscalYears = set(fiscalYears)\n", "code_toks_joined": "class DiffsetAction ( AbstractAction ) : <NEWLINE> <INDENT> def __init__ ( self , documentNumber , fiscalYears ) : <NEWLINE> <INDENT> self . documentNumber = documentNumber <NEWLINE> self . fiscalYears = set ( fiscalYears ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["05756b30975441a7193d6146ec72e607", {"code_string": "from layer import NeuralLayer\nfrom recurrent import RecurrentLayer, RecurrentNetwork\n", "code_toks_joined": "from layer import NeuralLayer <NEWLINE> from recurrent import RecurrentLayer , RecurrentNetwork <NEWLINE>", "anonymize_dict": {}}], ["4b52eb9745a4e0d65f5bebba3bec72f5", {"code_string": "class AnnealingCountStopper(BasicStopper):\n    \"\"\"Stops training when the learning rate has been decreased\"\"\"\n    def __init__(self, training_options, * args, ** kwargs):\n        \"\"\"Creates a learning rate stopping criterion with given\"\"\"\n        super().__init__(training_options, * args, ** kwargs)\n        self.min_epochs = training_options['min_epochs']\n        self._annealing_left = training_options['max_annealing_count']\n    def improvement_ceased(self):\n        \"\"\"Called when the performance of the model ceases to improve\"\"\"\n        self._annealing_left -= 1\n    def start_new_minibatch(self):\n        \"\"\"Decides whether training should continue after the current\"\"\"\n        if self.trainer.epoch_number <= self.min_epochs:\n            return True\n        return self._annealing_left >= 0\n", "code_toks_joined": "class AnnealingCountStopper ( BasicStopper ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , training_options , * args , ** kwargs ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> super ( ) . __init__ ( training_options , * args , ** kwargs ) <NEWLINE> self . min_epochs = training_options [ <STRING> ] <NEWLINE> self . _annealing_left = training_options [ <STRING> ] <NEWLINE> <DEDENT> def improvement_ceased ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . _annealing_left -= 1 <NEWLINE> <DEDENT> def start_new_minibatch ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if self . trainer . epoch_number <= self . min_epochs : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> return self . _annealing_left >= 0 <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Stops training when the learning rate has been decreased\"\"\"", "\"\"\"Creates a learning rate stopping criterion with given\"\"\"", "'min_epochs'", "'max_annealing_count'", "\"\"\"Called when the performance of the model ceases to improve\"\"\"", "\"\"\"Decides whether training should continue after the current\"\"\""]}}], ["219b349548dc49f38e8ed2dc46d9a82c", {"code_string": "def timeout():\n    print('\\nTest Finished\\n')\n    loop.quit()\n", "code_toks_joined": "def timeout ( ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> loop . quit ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'\\nTest Finished\\n'"]}}], ["608a5361406b697055ca744878cf9fde", {"code_string": "from __future__ import absolute_import, division, print_function\nimport hashlib\nfrom os import remove, makedirs\nfrom os.path import exists, isdir\nfrom functools import partial\nfrom warnings import warn\nfrom types import FunctionType\nfrom._decorator import experimental, deprecated\n", "code_toks_joined": "from __future__ import absolute_import , division , print_function <NEWLINE> import hashlib <NEWLINE> from os import remove , makedirs <NEWLINE> from os . path import exists , isdir <NEWLINE> from functools import partial <NEWLINE> from warnings import warn <NEWLINE> from types import FunctionType <NEWLINE> from . _decorator import experimental , deprecated <NEWLINE>", "anonymize_dict": {}}], ["a3a3bb711856437f49beb90db23c8ba1", {"code_string": "class Quote(Group):\n    def __str__(self):\n        if not self.end:\n            if[x for x in self if isinstance(x, Whitespace)]:\n                self.start = '(%s' % self.start\n                self.end = ')'\n        return '%s%s%s' %(\n            self.start, ''.join(unicode(x) for x in self), self.end)\n", "code_toks_joined": "class Quote ( Group ) : <NEWLINE> <INDENT> def __str__ ( self ) : <NEWLINE> <INDENT> if not self . end : <NEWLINE> <INDENT> if [ x for x in self if isinstance ( x , Whitespace ) ] : <NEWLINE> <INDENT> self . start = <STRING> % self . start <NEWLINE> self . end = <STRING> <NEWLINE> <DEDENT> <DEDENT> return <STRING> % ( <NEWLINE> <INDENT> self . start , <STRING> . join ( unicode ( x ) for x in self ) , self . end ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'(%s'", "')'", "'%s%s%s'", "''"]}}], ["60832218bf11739c7e9dc8afda352603", {"code_string": "def consume(self, amount = 1):\n    \"\"\"Consume quota.\"\"\"\n    while self.quota < amount:\n        delta = self.quota_manager.consume(self.bucket, self.batch_size,\n            consume_some = True)\n        if not delta:\n            return False\n        self.quota += delta\n    self.quota -= amount\n    return True\n", "code_toks_joined": "def consume ( self , amount = 1 ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> while self . quota < amount : <NEWLINE> <INDENT> delta = self . quota_manager . consume ( self . bucket , self . batch_size , <NEWLINE> <INDENT> consume_some = True ) <NEWLINE> <DEDENT> if not delta : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> self . quota += delta <NEWLINE> <DEDENT> self . quota -= amount <NEWLINE> return True <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Consume quota.\"\"\""]}}], ["d2f6145d872a78ffce8a07cade7c08c3", {"code_string": "def streem(items, map = SIMPLE_MAP, reduce = None, starting_level = 0, mandatory_levels = [], mandatory_levels_all = False):\n    return(reduce or _REDUCE_DEFAULT)(NodeIterator(\n        SourceData(items, map, reduce, starting_level, mandatory_levels, mandatory_levels_all)))\n", "code_toks_joined": "def streem ( items , map = SIMPLE_MAP , reduce = None , starting_level = 0 , mandatory_levels = [ ] , mandatory_levels_all = False ) : <NEWLINE> <INDENT> return ( reduce or _REDUCE_DEFAULT ) ( NodeIterator ( <NEWLINE> <INDENT> SourceData ( items , map , reduce , starting_level , mandatory_levels , mandatory_levels_all ) ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["f5130a159379c5e80310a742600cfe54", {"code_string": "def resolve_windows(self, window):\n    if not window:\n        return[]\n    res = [window]\n    res.extend(window.get_children())\n    return res\n", "code_toks_joined": "def resolve_windows ( self , window ) : <NEWLINE> <INDENT> if not window : <NEWLINE> <INDENT> return [ ] <NEWLINE> <DEDENT> res = [ window ] <NEWLINE> res . extend ( window . get_children ( ) ) <NEWLINE> return res <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["5a6cfc49acab0bdbfd9994f8783de9db", {"code_string": "import smtplib\nfrom email.MIMEMultipart import MIMEMultipart\nfrom email.MIMEBase import MIMEBase\nfrom email.MIMEText import MIMEText\nfrom email.Utils import COMMASPACE, formatdate\nfrom email import Encoders\nimport os, datetime\n", "code_toks_joined": "import smtplib <NEWLINE> from email . MIMEMultipart import MIMEMultipart <NEWLINE> from email . MIMEBase import MIMEBase <NEWLINE> from email . MIMEText import MIMEText <NEWLINE> from email . Utils import COMMASPACE , formatdate <NEWLINE> from email import Encoders <NEWLINE> import os , datetime <NEWLINE>", "anonymize_dict": {}}], ["96c32a1c0c58d00464d1f9bab6970af9", {"code_string": "def get_next_sequence_number(name):\n    connection = pymongo.MongoClient(\"mongodb://localhost\")\n    db = connection.test\n    counters = db.counters\n    try:\n        counter = counters.find_one_and_update(filter = {'type': name},\n            update = {'$inc': {'value': - 1}},\n            upsert = True,\n            return_document = pymongo.ReturnDocument.AFTER)\n    except Exception as e:\n        print(\"Exception: \", type(e), e)\n    counter_value = counter['value']\n    return counter_value\n", "code_toks_joined": "def get_next_sequence_number ( name ) : <NEWLINE> <INDENT> connection = pymongo . MongoClient ( <STRING> ) <NEWLINE> db = connection . test <NEWLINE> counters = db . counters <NEWLINE> try : <NEWLINE> <INDENT> counter = counters . find_one_and_update ( filter = { <STRING> : name } , <NEWLINE> <INDENT> update = { <STRING> : { <STRING> : - 1 } } , <NEWLINE> upsert = True , <NEWLINE> return_document = pymongo . ReturnDocument . AFTER ) <NEWLINE> <DEDENT> <DEDENT> except Exception as e : <NEWLINE> <INDENT> print ( <STRING> , type ( e ) , e ) <NEWLINE> <DEDENT> counter_value = counter [ <STRING> ] <NEWLINE> return counter_value <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"mongodb://localhost\"", "'type'", "'$inc'", "'value'", "\"Exception: \"", "'value'"]}}], ["db3dc293f2cc2907bbf4b3d1190f4201", {"code_string": "class TestCopyFromPy(unittest.TestCase):\n    def test_bool(self):\n        a = nd.empty('var * bool')\n        a[...] = [True, False, 1, 0, 'true', 'false', 'on', 'off']\n        self.assertEqual(nd.as_py(a), [True, False] * 4)\n", "code_toks_joined": "class TestCopyFromPy ( unittest . TestCase ) : <NEWLINE> <INDENT> def test_bool ( self ) : <NEWLINE> <INDENT> a = nd . empty ( <STRING> ) <NEWLINE> a [ ... ] = [ True , False , 1 , 0 , <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE> self . assertEqual ( nd . as_py ( a ) , [ True , False ] * 4 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'var * bool'", "'true'", "'false'", "'on'", "'off'"]}}], ["83dbb7fa641b3f5e5862fbf0bb8c0935", {"code_string": "def object_to_form(self):\n    self.extracolumns()\n    return SQLObjectWithFormGlue.object_to_form(self)\n", "code_toks_joined": "def object_to_form ( self ) : <NEWLINE> <INDENT> self . extracolumns ( ) <NEWLINE> return SQLObjectWithFormGlue . object_to_form ( self ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["4d2dc9e8dae519322db26826ab492832", {"code_string": "def journal_writer(filename, queue):\n    with open(filename, 'a') as f:\n        slave = queue.get()\n        while slave:\n            print(slave)\n            slave = queue.get()\n", "code_toks_joined": "def journal_writer ( filename , queue ) : <NEWLINE> <INDENT> with open ( filename , <STRING> ) as f : <NEWLINE> <INDENT> slave = queue . get ( ) <NEWLINE> while slave : <NEWLINE> <INDENT> print ( slave ) <NEWLINE> slave = queue . get ( ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'a'"]}}], ["3f8d115ed6f24d3713f9fb7333565785", {"code_string": "def formed_page_num(self, page_index):\n    \"\"\" Method to form part of the url where the page num is included.\"\"\"\n    return \"&start=%i\" %(page_index * 100)\n", "code_toks_joined": "def formed_page_num ( self , page_index ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return <STRING> % ( page_index * 100 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Method to form part of the url where the page num is included.\"\"\"", "\"&start=%i\""]}}], ["4f6ce5f2b209b26a723b7fec9f6db825", {"code_string": "def test_CRLF_headers_only(self, httpbin):\n    r = http('--headers', 'GET', httpbin.url + '/get')\n    body = self._validate_crlf(r)\n    assert not body, 'Garbage after headers: %r' % r\n", "code_toks_joined": "def test_CRLF_headers_only ( self , httpbin ) : <NEWLINE> <INDENT> r = http ( <STRING> , <STRING> , httpbin . url + <STRING> ) <NEWLINE> body = self . _validate_crlf ( r ) <NEWLINE> assert not body , <STRING> % r <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'--headers'", "'GET'", "'/get'", "'Garbage after headers: %r'"]}}], ["9c63f712a6cfcbc596d1c490e623e2e7", {"code_string": "def match(text):\n    \"\"\"Parse calendar entry\"\"\"\n    return MATCHER.match(text)\n", "code_toks_joined": "def match ( text ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return MATCHER . match ( text ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Parse calendar entry\"\"\""]}}], ["567a8323d415761e9a256799cdd38b93", {"code_string": "class InterfaceMeta(type):\n    def __new__(cls, name, parents, dct):\n        if 'class_id' not in dct:\n            dct['class_id'] = name.lower()\n        if 'file' in dct:\n            filename = dct['file']\n            dct['file'] = open(filename, 'w')\n        return super(InterfaceMeta, cls).__new__(cls, name, parents, dct)\n", "code_toks_joined": "class InterfaceMeta ( type ) : <NEWLINE> <INDENT> def __new__ ( cls , name , parents , dct ) : <NEWLINE> <INDENT> if <STRING> not in dct : <NEWLINE> <INDENT> dct [ <STRING> ] = name . lower ( ) <NEWLINE> <DEDENT> if <STRING> in dct : <NEWLINE> <INDENT> filename = dct [ <STRING> ] <NEWLINE> dct [ <STRING> ] = open ( filename , <STRING> ) <NEWLINE> <DEDENT> return super ( InterfaceMeta , cls ) . __new__ ( cls , name , parents , dct ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'class_id'", "'class_id'", "'file'", "'file'", "'file'", "'w'"]}}], ["80576783735e845bcfe3fb3588f7f0ee", {"code_string": "def scanSent():\n    print('Scanning Sent')\n    sent = r.get_sent(limit = MAXPOSTS)\n    listo = []\n    for item in sent:\n        iid = item.fullname\n        cur.execute('SELECT * FROM oldposts WHERE id=?', [iid])\n        if not cur.fetchone():\n            if ITEMTYPE in iid:\n                print('\\tOut ' + iid)\n                listo.append(item)\n            cur.execute('INSERT INTO oldposts VALUES(?)', [iid])\n    sql.commit()\n    return listo\n", "code_toks_joined": "def scanSent ( ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> sent = r . get_sent ( limit = MAXPOSTS ) <NEWLINE> listo = [ ] <NEWLINE> for item in sent : <NEWLINE> <INDENT> iid = item . fullname <NEWLINE> cur . execute ( <STRING> , [ iid ] ) <NEWLINE> if not cur . fetchone ( ) : <NEWLINE> <INDENT> if ITEMTYPE in iid : <NEWLINE> <INDENT> print ( <STRING> + iid ) <NEWLINE> listo . append ( item ) <NEWLINE> <DEDENT> cur . execute ( <STRING> , [ iid ] ) <NEWLINE> <DEDENT> <DEDENT> sql . commit ( ) <NEWLINE> return listo <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Scanning Sent'", "'SELECT * FROM oldposts WHERE id=?'", "'\\tOut '", "'INSERT INTO oldposts VALUES(?)'"]}}], ["ee660544b38bfea24c6d8d617f91386b", {"code_string": "'''Created on Sep 2, 2010'''\n'''Fibonacci series in Python: the sum of two elements defines the next'''\n'''Imports fibonacci module from com.irdeto.python.module package.'''\nfrom com.irdeto.sample.python.module import fibonacci\n'''It's simple and readable. The for loop will iterate over the result according'''\nfib_result = fibonacci.fib(1000)\n", "code_toks_joined": "<STRING> <NEWLINE> <STRING> <NEWLINE> <STRING> <NEWLINE> from com . irdeto . sample . python . module import fibonacci <NEWLINE> <STRING> <NEWLINE> fib_result = fibonacci . fib ( 1000 ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Created on Sep 2, 2010'''", "'''Fibonacci series in Python: the sum of two elements defines the next'''", "'''Imports fibonacci module from com.irdeto.python.module package.'''", "'''It's simple and readable. The for loop will iterate over the result according'''"]}}], ["44da3c75a4ff3c64731b5752b3525e87", {"code_string": "from __future__ import unicode_literals\nfrom django.db import migrations, models\nimport utils\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> from django . db import migrations , models <NEWLINE> import utils <NEWLINE>", "anonymize_dict": {}}], ["27311f9495a38ab8bc1cbb2d4ca987d8", {"code_string": "def downgrade(migrate_engine):\n    meta = MetaData()\n    meta.bind = migrate_engine\n    tables = [define_metadef_objects_table(meta),\n        define_metadef_properties_table(meta),\n        define_metadef_namespace_resource_types_table(meta),\n        define_metadef_resource_types_table(meta),\n        define_metadef_namespaces_table(meta)]\n    drop_tables(tables)\n", "code_toks_joined": "def downgrade ( migrate_engine ) : <NEWLINE> <INDENT> meta = MetaData ( ) <NEWLINE> meta . bind = migrate_engine <NEWLINE> tables = [ define_metadef_objects_table ( meta ) , <NEWLINE> <INDENT> define_metadef_properties_table ( meta ) , <NEWLINE> define_metadef_namespace_resource_types_table ( meta ) , <NEWLINE> define_metadef_resource_types_table ( meta ) , <NEWLINE> define_metadef_namespaces_table ( meta ) ] <NEWLINE> <DEDENT> drop_tables ( tables ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["9677187a23e6a8a3837204a62905b3e6", {"code_string": "def __init__(self, game):\n    \"\"\" Pass filenames of 2 images that animation will alternate. \"\"\"\n    Object.__init__(self, game)\n    self.image = pygame.image.load(\"img/mother1.png\").convert()\n    self.image2 = pygame.image.load(\"img/mother1b.png\").convert()\n    self.imageHit = pygame.image.load(\"img/explosionb.png\").convert()\n    self.rect = self.image.get_rect()\n    self.SetAppearing()\n", "code_toks_joined": "def __init__ ( self , game ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> Object . __init__ ( self , game ) <NEWLINE> self . image = pygame . image . load ( <STRING> ) . convert ( ) <NEWLINE> self . image2 = pygame . image . load ( <STRING> ) . convert ( ) <NEWLINE> self . imageHit = pygame . image . load ( <STRING> ) . convert ( ) <NEWLINE> self . rect = self . image . get_rect ( ) <NEWLINE> self . SetAppearing ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Pass filenames of 2 images that animation will alternate. \"\"\"", "\"img/mother1.png\"", "\"img/mother1b.png\"", "\"img/explosionb.png\""]}}], ["bbf717e79eefb43b5b568ded00262f1e", {"code_string": "def get_ensemble_ncl(_name, _n_models, fast = True):\n    ensemble = get_ensembleNCL_model(name = _name, classification = True, classes_labels = classes_labels,\n        n_input = n_features, n_output = n_output,\n        n_ensemble_models = _n_models, n_neurons_models = n_neurons,\n        fn_activation1 = fn_activation, fn_activation2 = fn_activation,\n        update = update_fn, name_update = name_update,\n        lamb = 0.3, params_update = {'learning_rate': 0.03}\n        )\n    ensemble.compile(fast = fast)\n    return ensemble\n", "code_toks_joined": "def get_ensemble_ncl ( _name , _n_models , fast = True ) : <NEWLINE> <INDENT> ensemble = get_ensembleNCL_model ( name = _name , classification = True , classes_labels = classes_labels , <NEWLINE> <INDENT> n_input = n_features , n_output = n_output , <NEWLINE> n_ensemble_models = _n_models , n_neurons_models = n_neurons , <NEWLINE> fn_activation1 = fn_activation , fn_activation2 = fn_activation , <NEWLINE> update = update_fn , name_update = name_update , <NEWLINE> lamb = 0.3 , params_update = { <STRING> : 0.03 } <NEWLINE> ) <NEWLINE> <DEDENT> ensemble . compile ( fast = fast ) <NEWLINE> return ensemble <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'learning_rate'"]}}], ["9ac37856ac5729aac23cb788a6d18909", {"code_string": "\"\"\"kaptan.handlers.json_handler\"\"\"\nfrom __future__ import print_function, unicode_literals\nimport json\nfrom.import BaseHandler\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import print_function , unicode_literals <NEWLINE> import json <NEWLINE> from . import BaseHandler <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"kaptan.handlers.json_handler\"\"\""]}}], ["8884b7c701218aaaaf71bd978908b4b6", {"code_string": "class AccountVoucher(orm.Model):\n    _inherit = 'account.voucher'\n    _columns = {\n        'product_categ_id': fields.related('partner_id',\n            'product_categ_id', type = 'many2one', store = True,\n            relation = 'product.category', string = u'\u4f9b\u8d27\u7c7b\u578b')\n        }\n", "code_toks_joined": "class AccountVoucher ( orm . Model ) : <NEWLINE> <INDENT> _inherit = <STRING> <NEWLINE> _columns = { <NEWLINE> <INDENT> <STRING> : fields . related ( <STRING> , <NEWLINE> <INDENT> <STRING> , type = <STRING> , store = True , <NEWLINE> relation = <STRING> , string = <STRING> ) <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'account.voucher'", "'product_categ_id'", "'partner_id'", "'product_categ_id'", "'many2one'", "'product.category'", "u'\u4f9b\u8d27\u7c7b\u578b'"]}}], ["cdeaedf005a3a08f0f82eb820a7848d1", {"code_string": "def request(self, url, * args, ** kwargs):\n    url += '?access_token=' + self.access_token\n    self.location(self.absurl(url, base = True), * args, ** kwargs)\n    return json.loads(self.response.content)\n", "code_toks_joined": "def request ( self , url , * args , ** kwargs ) : <NEWLINE> <INDENT> url += <STRING> + self . access_token <NEWLINE> self . location ( self . absurl ( url , base = True ) , * args , ** kwargs ) <NEWLINE> return json . loads ( self . response . content ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'?access_token='"]}}], ["e2f685c40df8db54266578a3d085b251", {"code_string": "from __future__ import unicode_literals\nfrom sure.old import AssertionHelper\nthat = AssertionHelper\n__all__ = ['that']\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> from sure . old import AssertionHelper <NEWLINE> that = AssertionHelper <NEWLINE> __all__ = [ <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'that'"]}}], ["44bc71ea70deb88146eb66e9fa30d7e6", {"code_string": "def previousTI(self):\n    \"\"\":return:  :class:`~ts2.scenery.abstract.TrackItem`  connected to this one from which to measure the\"\"\"\n    return self._previousTI\n", "code_toks_joined": "def previousTI ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . _previousTI <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\":return:  :class:`~ts2.scenery.abstract.TrackItem`  connected to this one from which to measure the\"\"\""]}}], ["e3e065e097b637058d71b7e790f48404", {"code_string": "def get_feed(self, url = None):\n    \"\"\"Returns a feedgenerator.DefaultFeed object, fully populated, for\"\"\"\n    if url:\n        bits = url.split('/')\n    else:\n        bits = []\n    try:\n        obj = self.get_object(bits)\n    except ObjectDoesNotExist:\n        raise FeedDoesNotExist\n    return super(Feed, self).get_feed(obj, self.request)\n", "code_toks_joined": "def get_feed ( self , url = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if url : <NEWLINE> <INDENT> bits = url . split ( <STRING> ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> bits = [ ] <NEWLINE> <DEDENT> try : <NEWLINE> <INDENT> obj = self . get_object ( bits ) <NEWLINE> <DEDENT> except ObjectDoesNotExist : <NEWLINE> <INDENT> raise FeedDoesNotExist <NEWLINE> <DEDENT> return super ( Feed , self ) . get_feed ( obj , self . request ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Returns a feedgenerator.DefaultFeed object, fully populated, for\"\"\"", "'/'"]}}], ["d78c231db87da36692e55e5c979c020a", {"code_string": "import sys\nfrom distutils import unixccompiler\nfrom distutils import ccompiler\n", "code_toks_joined": "import sys <NEWLINE> from distutils import unixccompiler <NEWLINE> from distutils import ccompiler <NEWLINE>", "anonymize_dict": {}}], ["98ba8ff55ad7b0f22bf1405ffeb1bd82", {"code_string": "def interpret_warning(line):\n    \"\"\"Decode the message from gcc.  The messages we care about have a filename, and a warning\"\"\"\n    line = line.rstrip('\\n')\n    m = warning_re.match(line)\n    if m and m.group(2) not in allowed_warnings:\n        print(\"error, forbidden warning:\", m.group(2))\n", "code_toks_joined": "def interpret_warning ( line ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> line = line . rstrip ( <STRING> ) <NEWLINE> m = warning_re . match ( line ) <NEWLINE> if m and m . group ( 2 ) not in allowed_warnings : <NEWLINE> <INDENT> print ( <STRING> , m . group ( 2 ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Decode the message from gcc.  The messages we care about have a filename, and a warning\"\"\"", "'\\n'", "\"error, forbidden warning:\""]}}], ["c1ccd5ae82079e7bb26d2e806908e78c", {"code_string": "from mongcore.connectors import *\nfrom mongseafood.models import *\nfrom mongcore.imports import *\nimport time\nimport datetime\nfrom django.utils.timezone import get_current_timezone, make_aware\n", "code_toks_joined": "from mongcore . connectors import * <NEWLINE> from mongseafood . models import * <NEWLINE> from mongcore . imports import * <NEWLINE> import time <NEWLINE> import datetime <NEWLINE> from django . utils . timezone import get_current_timezone , make_aware <NEWLINE>", "anonymize_dict": {}}], ["d4f54e6927a4af2b10307829a36f5f48", {"code_string": "\"\"\"Command-line utility for querying ROS services, along with library\"\"\"\nfrom __future__ import print_function\nNAME = 'rosservice'\nimport os\nimport sys\nimport socket\ntry:\n    from cStringIO import StringIO\nexcept ImportError:\n    from io import StringIO\nimport genpy\nimport roslib.message\nimport rospy\nimport rosmsg\nimport rosgraph\nimport rosgraph.names\nimport rosgraph.network\nfrom optparse import OptionParser\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import print_function <NEWLINE> NAME = <STRING> <NEWLINE> import os <NEWLINE> import sys <NEWLINE> import socket <NEWLINE> try : <NEWLINE> <INDENT> from cStringIO import StringIO <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> from io import StringIO <NEWLINE> <DEDENT> import genpy <NEWLINE> import roslib . message <NEWLINE> import rospy <NEWLINE> import rosmsg <NEWLINE> import rosgraph <NEWLINE> import rosgraph . names <NEWLINE> import rosgraph . network <NEWLINE> from optparse import OptionParser <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Command-line utility for querying ROS services, along with library\"\"\"", "'rosservice'"]}}], ["45bde08f533c70765c0fc501f93255b7", {"code_string": "from django.conf.urls import patterns, include, url\nfrom django.contrib import admin\nfrom shelf.views import MainPageView\nfrom contact.views import MessageAddView\nurlpatterns = patterns('',\n    url(r'^admin/', include(admin.site.urls)),\n    url(r'^shelf/', include('shelf.urls', namespace = 'shelf')),\n    url(r'^contact/$', MessageAddView.as_view()),\n    url(r'^$', MainPageView.as_view(), name = 'main-page'),\n    url(r'^accounts/', include('allauth.urls')),\n)\n", "code_toks_joined": "from django . conf . urls import patterns , include , url <NEWLINE> from django . contrib import admin <NEWLINE> from shelf . views import MainPageView <NEWLINE> from contact . views import MessageAddView <NEWLINE> urlpatterns = patterns ( <STRING> , <NEWLINE> <INDENT> url ( <STRING> , include ( admin . site . urls ) ) , <NEWLINE> url ( <STRING> , include ( <STRING> , namespace = <STRING> ) ) , <NEWLINE> url ( <STRING> , MessageAddView . as_view ( ) ) , <NEWLINE> url ( <STRING> , MainPageView . as_view ( ) , name = <STRING> ) , <NEWLINE> url ( <STRING> , include ( <STRING> ) ) , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["''", "r'^admin/'", "r'^shelf/'", "'shelf.urls'", "'shelf'", "r'^contact/$'", "r'^$'", "'main-page'", "r'^accounts/'", "'allauth.urls'"]}}], ["cfc2c1c4f4f1acbd359a0738f4fbc8c8", {"code_string": "def OR(x1, x2):\n    x = np.array([x1, x2])\n    w = np.array([0.5, 0.5])\n    b = - 0.3\n    tmp = np.sum(w * x) + b\n    if tmp <= 0:\n        return 0\n    else:\n        return 1\n", "code_toks_joined": "def OR ( x1 , x2 ) : <NEWLINE> <INDENT> x = np . array ( [ x1 , x2 ] ) <NEWLINE> w = np . array ( [ 0.5 , 0.5 ] ) <NEWLINE> b = - 0.3 <NEWLINE> tmp = np . sum ( w * x ) + b <NEWLINE> if tmp <= 0 : <NEWLINE> <INDENT> return 0 <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return 1 <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["68806bc64e3cbdcc06b8fdff5b445dc7", {"code_string": "from __future__ import print_function\n\"\"\"A Python script for power cycling a virtual machine. Demonstrates the use\"\"\"\nimport atexit\nimport argparse\nfrom six import PY2\nimport sys\nimport textwrap\nfrom pyvmomi_tools import cli\nfrom pyVim import connect\nfrom pyVmomi import vim\nfrom pyvmomi_tools.extensions.credstore import VICredStore, NoCredentialsFileFound, HostNotFoundException\nif PY2:\n    input = raw_input\n", "code_toks_joined": "from __future__ import print_function <NEWLINE> <STRING> <NEWLINE> import atexit <NEWLINE> import argparse <NEWLINE> from six import PY2 <NEWLINE> import sys <NEWLINE> import textwrap <NEWLINE> from pyvmomi_tools import cli <NEWLINE> from pyVim import connect <NEWLINE> from pyVmomi import vim <NEWLINE> from pyvmomi_tools . extensions . credstore import VICredStore , NoCredentialsFileFound , HostNotFoundException <NEWLINE> if PY2 : <NEWLINE> <INDENT> input = raw_input <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"A Python script for power cycling a virtual machine. Demonstrates the use\"\"\""]}}], ["5f8697035144dd308abe9015219ee653", {"code_string": "from __future__ import absolute_import, unicode_literals\nfrom.production import *\nDEBUG = False\nTEMPLATE_DEBUG = False\nEMAIL_BACKEND = 'django.core.mail.backends.console.EmailBackend'\ntry:\n    from.local import *\nexcept ImportError:\n    pass\n", "code_toks_joined": "from __future__ import absolute_import , unicode_literals <NEWLINE> from . production import * <NEWLINE> DEBUG = False <NEWLINE> TEMPLATE_DEBUG = False <NEWLINE> EMAIL_BACKEND = <STRING> <NEWLINE> try : <NEWLINE> <INDENT> from . local import * <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'django.core.mail.backends.console.EmailBackend'"]}}], ["199611621b675a74419b1edcfc504f5a", {"code_string": "from subprocess import call\nfrom random import randint\nfrom time import sleep\nfrom threading import Thread\nthreadlist = []\nzip_codes = open('zipcodes.txt', 'r')\nfor line in zip_codes:\n    print(line.strip())\n", "code_toks_joined": "from subprocess import call <NEWLINE> from random import randint <NEWLINE> from time import sleep <NEWLINE> from threading import Thread <NEWLINE> threadlist = [ ] <NEWLINE> zip_codes = open ( <STRING> , <STRING> ) <NEWLINE> for line in zip_codes : <NEWLINE> <INDENT> print ( line . strip ( ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'zipcodes.txt'", "'r'"]}}], ["5c576bd9d75f381b07d2d63a065fe4f4", {"code_string": "def test_negative_create_with_empty_layout(self):\n    \"\"\"Create a new partition table with empty layout\"\"\"\n    name = gen_string('utf8')\n    with Session(self.browser) as session:\n        make_partitiontable(\n            session, name = name, template_path = '', os_family = 'Red Hat')\n        self.assertIsNotNone(self.partitiontable.wait_until_element\n            (common_locators['haserror']))\n        self.assertIsNone(self.partitiontable.search(name))\n", "code_toks_joined": "def test_negative_create_with_empty_layout ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> name = gen_string ( <STRING> ) <NEWLINE> with Session ( self . browser ) as session : <NEWLINE> <INDENT> make_partitiontable ( <NEWLINE> <INDENT> session , name = name , template_path = <STRING> , os_family = <STRING> ) <NEWLINE> <DEDENT> self . assertIsNotNone ( self . partitiontable . wait_until_element <NEWLINE> <INDENT> ( common_locators [ <STRING> ] ) ) <NEWLINE> <DEDENT> self . assertIsNone ( self . partitiontable . search ( name ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Create a new partition table with empty layout\"\"\"", "'utf8'", "''", "'Red Hat'", "'haserror'"]}}], ["f871ba87b77cee46fdc3ce20b76fc929", {"code_string": "def test_source_validation(self):\n    with pytest.raises(ValidationError) as execinfo:\n        GoodFactory()\n        message = u'Goods must either originate from a shop or an event.'\n        assert message in execinfo.execonly()\n", "code_toks_joined": "def test_source_validation ( self ) : <NEWLINE> <INDENT> with pytest . raises ( ValidationError ) as execinfo : <NEWLINE> <INDENT> GoodFactory ( ) <NEWLINE> message = <STRING> <NEWLINE> assert message in execinfo . execonly ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["u'Goods must either originate from a shop or an event.'"]}}], ["c2438260b0685a2e7e837a9c73a48b3e", {"code_string": "from __future__ import unicode_literals\nfrom.models import batch_backends\nfrom..core.models import base_decorator\nbatch_backend = batch_backends['us-east-1']\nmock_batch = base_decorator(batch_backends)\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> from . models import batch_backends <NEWLINE> from . . core . models import base_decorator <NEWLINE> batch_backend = batch_backends [ <STRING> ] <NEWLINE> mock_batch = base_decorator ( batch_backends ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'us-east-1'"]}}], ["e48ce63445a4ca24c71e3e2ff91d42fe", {"code_string": "def ecologyGBM_random_noise():\n    ecology_train = h2o.import_file(path = pyunit_utils.locate(\"smalldata/gbm_test/ecology_model.csv\"))\n    gbm_h2o = H2OGradientBoostingEstimator(pred_noise_bandwidth = 0.5)\n    gbm_h2o.train(x = list(range(2, ecology_train.ncol)), y = \"Angaus\", training_frame = ecology_train)\n    print(gbm_h2o)\n", "code_toks_joined": "def ecologyGBM_random_noise ( ) : <NEWLINE> <INDENT> ecology_train = h2o . import_file ( path = pyunit_utils . locate ( <STRING> ) ) <NEWLINE> gbm_h2o = H2OGradientBoostingEstimator ( pred_noise_bandwidth = 0.5 ) <NEWLINE> gbm_h2o . train ( x = list ( range ( 2 , ecology_train . ncol ) ) , y = <STRING> , training_frame = ecology_train ) <NEWLINE> print ( gbm_h2o ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"smalldata/gbm_test/ecology_model.csv\"", "\"Angaus\""]}}], ["dbd2b51c4b08b06a25936bb55eb1a111", {"code_string": "\"\"\"Platform specific network status.\"\"\"\nimport sys\nNetworkManagerState = None\n", "code_toks_joined": "<STRING> <NEWLINE> import sys <NEWLINE> NetworkManagerState = None <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Platform specific network status.\"\"\""]}}], ["78ef976d526a7d9bc8b0d5bfbab0ae3f", {"code_string": "def property_attributes(interface, method):\n    extended_attributes = method.extended_attributes\n    property_attributes_list = []\n    if 'NotEnumerable' in extended_attributes:\n        property_attributes_list.append('v8::DontEnum')\n    if is_unforgeable(interface, method):\n        property_attributes_list.append('v8::ReadOnly')\n        property_attributes_list.append('v8::DontDelete')\n    return property_attributes_list\n", "code_toks_joined": "def property_attributes ( interface , method ) : <NEWLINE> <INDENT> extended_attributes = method . extended_attributes <NEWLINE> property_attributes_list = [ ] <NEWLINE> if <STRING> in extended_attributes : <NEWLINE> <INDENT> property_attributes_list . append ( <STRING> ) <NEWLINE> <DEDENT> if is_unforgeable ( interface , method ) : <NEWLINE> <INDENT> property_attributes_list . append ( <STRING> ) <NEWLINE> property_attributes_list . append ( <STRING> ) <NEWLINE> <DEDENT> return property_attributes_list <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'NotEnumerable'", "'v8::DontEnum'", "'v8::ReadOnly'", "'v8::DontDelete'"]}}], ["ac29892eb0b4d1267102acd04c621354", {"code_string": "\"\"\"The EMUS package is a collection of scripts and tools based on the\"\"\"\n__author__ = \"Erik Henning Thiede\"\n__license__ = \"GPL\"\n__maintainer__ = \"Erik Henning Thiede\"\n__email__ = \"thiede@uchicago.edu\"\nimport autocorrelation\nimport avar\nimport emus\nimport linalg\nimport usutils\n", "code_toks_joined": "<STRING> <NEWLINE> __author__ = <STRING> <NEWLINE> __license__ = <STRING> <NEWLINE> __maintainer__ = <STRING> <NEWLINE> __email__ = <STRING> <NEWLINE> import autocorrelation <NEWLINE> import avar <NEWLINE> import emus <NEWLINE> import linalg <NEWLINE> import usutils <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"The EMUS package is a collection of scripts and tools based on the\"\"\"", "\"Erik Henning Thiede\"", "\"GPL\"", "\"Erik Henning Thiede\"", "\"thiede@uchicago.edu\""]}}], ["3493cd43524acb249afe6c1968d67aaf", {"code_string": "import random\nprint(random.randint(1, 18))\n", "code_toks_joined": "import random <NEWLINE> print ( random . randint ( 1 , 18 ) ) <NEWLINE>", "anonymize_dict": {}}], ["78c7ae3ebf717f6f582ca476c6ddcb06", {"code_string": "def setUp(self):\n    \"\"\" Setting up a test. \"\"\"\n    self.__dirs_to_remove = []\n", "code_toks_joined": "def setUp ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . __dirs_to_remove = [ ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Setting up a test. \"\"\""]}}], ["b334182e04b51b426dfd8044dbe51d25", {"code_string": "import glob\nimport os\nimport pygame\nimport time\npygame.init()\nwhite = (255, 255, 255)\nblack = (0, 0, 0)\n", "code_toks_joined": "import glob <NEWLINE> import os <NEWLINE> import pygame <NEWLINE> import time <NEWLINE> pygame . init ( ) <NEWLINE> white = ( 255 , 255 , 255 ) <NEWLINE> black = ( 0 , 0 , 0 ) <NEWLINE>", "anonymize_dict": {}}], ["6965b1eb0626b9f0e25b7e85830b586d", {"code_string": "class Solution(object):\n    def combinationSum4(self, nums, target):\n        \"\"\":type nums: List[int]\"\"\"\n        if target <= 0:\n            return 0\n        nums.sort()\n        dp = [0] *(target + 1)\n        dp[0] = 1\n        for t in xrange(1, target + 1):\n            for n in nums:\n                if n > t: break\n                dp[t] += dp[t - n]\n        return dp[target]\n", "code_toks_joined": "class Solution ( object ) : <NEWLINE> <INDENT> def combinationSum4 ( self , nums , target ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if target <= 0 : <NEWLINE> <INDENT> return 0 <NEWLINE> <DEDENT> nums . sort ( ) <NEWLINE> dp = [ 0 ] * ( target + 1 ) <NEWLINE> dp [ 0 ] = 1 <NEWLINE> for t in xrange ( 1 , target + 1 ) : <NEWLINE> <INDENT> for n in nums : <NEWLINE> <INDENT> if n > t : break <NEWLINE> dp [ t ] += dp [ t - n ] <NEWLINE> <DEDENT> <DEDENT> return dp [ target ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\":type nums: List[int]\"\"\""]}}], ["e63382c65dd5fd50e621b85ec87dd7dc", {"code_string": "class PystanError(Exception):\n    \"\"\"Base class for exceptions in this module.\"\"\"\n    pass\n", "code_toks_joined": "class PystanError ( Exception ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Base class for exceptions in this module.\"\"\""]}}], ["8c7947b9f07434c1aded6e8738c594ef", {"code_string": "def dispose(self):\n    self._username = None\n    self._password = None\n    self._org_url = None\n    self._proxy_url = None\n    self._proxy_port = None\n    self._token_url = None\n    self._securityHandler = None\n    self._valid = None\n    self._message = None\n    del self._username\n    del self._password\n    del self._org_url\n    del self._proxy_url\n    del self._proxy_port\n    del self._token_url\n    del self._securityHandler\n    del self._valid\n    del self._message\n", "code_toks_joined": "def dispose ( self ) : <NEWLINE> <INDENT> self . _username = None <NEWLINE> self . _password = None <NEWLINE> self . _org_url = None <NEWLINE> self . _proxy_url = None <NEWLINE> self . _proxy_port = None <NEWLINE> self . _token_url = None <NEWLINE> self . _securityHandler = None <NEWLINE> self . _valid = None <NEWLINE> self . _message = None <NEWLINE> del self . _username <NEWLINE> del self . _password <NEWLINE> del self . _org_url <NEWLINE> del self . _proxy_url <NEWLINE> del self . _proxy_port <NEWLINE> del self . _token_url <NEWLINE> del self . _securityHandler <NEWLINE> del self . _valid <NEWLINE> del self . _message <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["dae3c20004252b41781de44dd55b8e7f", {"code_string": "import mock\nfrom kombu import Connection, Exchange, Queue\nfrom st2common.transport import consumers\nfrom st2common.transport import utils as transport_utils\nfrom st2tests.base import DbTestCase\nfrom tests.unit.base import FakeModelDB\nFAKE_XCHG = Exchange('st2.tests', type = 'topic')\nFAKE_WORK_Q = Queue('st2.tests.unit', FAKE_XCHG)\n", "code_toks_joined": "import mock <NEWLINE> from kombu import Connection , Exchange , Queue <NEWLINE> from st2common . transport import consumers <NEWLINE> from st2common . transport import utils as transport_utils <NEWLINE> from st2tests . base import DbTestCase <NEWLINE> from tests . unit . base import FakeModelDB <NEWLINE> FAKE_XCHG = Exchange ( <STRING> , type = <STRING> ) <NEWLINE> FAKE_WORK_Q = Queue ( <STRING> , FAKE_XCHG ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'st2.tests'", "'topic'", "'st2.tests.unit'"]}}], ["2146989a78b3fd4c5706c21bd34f4b17", {"code_string": "import theano\nimport theano.tensor as T\nimport numpy as np\nfrom learn_theano.utils.download_all_datasets import get_dataset\nimport cPickle\nimport pickle\nimport time\n", "code_toks_joined": "import theano <NEWLINE> import theano . tensor as T <NEWLINE> import numpy as np <NEWLINE> from learn_theano . utils . download_all_datasets import get_dataset <NEWLINE> import cPickle <NEWLINE> import pickle <NEWLINE> import time <NEWLINE>", "anonymize_dict": {}}], ["4e886c857a28b5ae86a53a5919789d81", {"code_string": "def test_room(self):\n    \"\"\" Test that single room works well\"\"\"\n    rv = self.app.get(\"/api/rooms/Mango\")\n    assert b'Mango' in rv.data\n", "code_toks_joined": "def test_room ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> rv = self . app . get ( <STRING> ) <NEWLINE> assert <STRING> in rv . data <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Test that single room works well\"\"\"", "\"/api/rooms/Mango\"", "b'Mango'"]}}], ["be3d1edabec148da44014270ef32b2cc", {"code_string": "class Point(object):\n    \"\"\"docstring for Point\"\"\"\n    __slots__ = ('x', 'y', 'z', 'w')\n    def __init__(self, x = 0.0, y = 0.0, z = 0.0, w = 1.0):\n        super(Point, self).__init__()\n        self.x = x\n        self.y = y\n        self.z = z\n        self.w = w\n", "code_toks_joined": "class Point ( object ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> __slots__ = ( <STRING> , <STRING> , <STRING> , <STRING> ) <NEWLINE> def __init__ ( self , x = 0.0 , y = 0.0 , z = 0.0 , w = 1.0 ) : <NEWLINE> <INDENT> super ( Point , self ) . __init__ ( ) <NEWLINE> self . x = x <NEWLINE> self . y = y <NEWLINE> self . z = z <NEWLINE> self . w = w <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"docstring for Point\"\"\"", "'x'", "'y'", "'z'", "'w'"]}}], ["e0e55edfdf58e2fecae74d562a240254", {"code_string": "from neutron.plugins.ml2 import driver_api as api\nfrom neutron_lib import constants as p_constants\nfrom oslo_log import log\nfrom networking_powervm.plugins.ibm.agent.powervm import constants as pconst\nfrom networking_powervm.plugins.ml2.drivers import mech_pvm_base\nLOG = log.getLogger(__name__)\n", "code_toks_joined": "from neutron . plugins . ml2 import driver_api as api <NEWLINE> from neutron_lib import constants as p_constants <NEWLINE> from oslo_log import log <NEWLINE> from networking_powervm . plugins . ibm . agent . powervm import constants as pconst <NEWLINE> from networking_powervm . plugins . ml2 . drivers import mech_pvm_base <NEWLINE> LOG = log . getLogger ( __name__ ) <NEWLINE>", "anonymize_dict": {}}], ["f3ce2e5fb18ab473a8034b0ce51aee75", {"code_string": "class PrepareOut(cr.Plugin, cr.Plugin.Type):\n    \"\"\"Base class for output directory preparation plugins.\"\"\"\n    def UpdateContext(self):\n        \"\"\"Update the context if needed.\"\"\"\n    def Prepare(self):\n        \"\"\"All PrepareOut plugins must override this method to do their work.\"\"\"\n        raise NotImplementedError('Must be overridden.')\n", "code_toks_joined": "class PrepareOut ( cr . Plugin , cr . Plugin . Type ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def UpdateContext ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> <DEDENT> def Prepare ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> raise NotImplementedError ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Base class for output directory preparation plugins.\"\"\"", "\"\"\"Update the context if needed.\"\"\"", "\"\"\"All PrepareOut plugins must override this method to do their work.\"\"\"", "'Must be overridden.'"]}}], ["7a6bca34f54cd5051bac7fa2b00f0fd2", {"code_string": "\"\"\"Copyright 2013 Steven Diamond\"\"\"\nimport abc\nimport cvxpy\nimport cvxpy.interface as intf\nimport cvxopt\n", "code_toks_joined": "<STRING> <NEWLINE> import abc <NEWLINE> import cvxpy <NEWLINE> import cvxpy . interface as intf <NEWLINE> import cvxopt <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Copyright 2013 Steven Diamond\"\"\""]}}], ["f9921e82dec66a5ee32cbe70934ce084", {"code_string": "\"\"\"test root features\"\"\"\nimport unittest\nfrom daeso.pair import Pair\nfrom daeso_nl.graph.alpinograph import AlpinoGraph\nfrom daeso_nl.ga.feats import *\nfrom daeso_nl.ga.feats.root import(ff_roots_share_infix,\n    ff_roots_share_prefix,\n    ff_roots_share_suffix,\n    ff_roots_subsumption)\n", "code_toks_joined": "<STRING> <NEWLINE> import unittest <NEWLINE> from daeso . pair import Pair <NEWLINE> from daeso_nl . graph . alpinograph import AlpinoGraph <NEWLINE> from daeso_nl . ga . feats import * <NEWLINE> from daeso_nl . ga . feats . root import ( ff_roots_share_infix , <NEWLINE> <INDENT> ff_roots_share_prefix , <NEWLINE> ff_roots_share_suffix , <NEWLINE> ff_roots_subsumption ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"test root features\"\"\""]}}], ["5c6383cef94e7eca425fa0b0097ed349", {"code_string": "\"\"\"This example upgrades an ad to use upgraded URLs.\"\"\"\nfrom googleads import adwords\nfrom googleads import errors\nADGROUP_ID = 'INSERT_ADGROUP_ID_HERE'\nAD_ID = 'INSERT_AD_ID_HERE'\n", "code_toks_joined": "<STRING> <NEWLINE> from googleads import adwords <NEWLINE> from googleads import errors <NEWLINE> ADGROUP_ID = <STRING> <NEWLINE> AD_ID = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"This example upgrades an ad to use upgraded URLs.\"\"\"", "'INSERT_ADGROUP_ID_HERE'", "'INSERT_AD_ID_HERE'"]}}], ["a6b96d621440ea842c14db970835e57e", {"code_string": "def _get_sm_name(o):\n    if isinstance(o, StorageManager):\n        return o.name\n    else:\n        return str(o)\n", "code_toks_joined": "def _get_sm_name ( o ) : <NEWLINE> <INDENT> if isinstance ( o , StorageManager ) : <NEWLINE> <INDENT> return o . name <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return str ( o ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["8c7d98d82b11d59eb85a2f5c180f17bd", {"code_string": "def __init__(self, text = None, head = False, cl = None, ident = None, style = None, attrs = None):\n    super().__init__(cl = cl, ident = ident, style = style, attrs = attrs)\n    if text:\n        self._children.append(text)\n    self.head = head\n", "code_toks_joined": "def __init__ ( self , text = None , head = False , cl = None , ident = None , style = None , attrs = None ) : <NEWLINE> <INDENT> super ( ) . __init__ ( cl = cl , ident = ident , style = style , attrs = attrs ) <NEWLINE> if text : <NEWLINE> <INDENT> self . _children . append ( text ) <NEWLINE> <DEDENT> self . head = head <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["6e0d3fc353bc3dbd85498b5d1020c979", {"code_string": "def test_condition_type1_variant3(self):\n    response = ConditionAIMLTests.test_client.bot.ask_question(\"test\", \"TYPE1 VARIANT3\")\n    self.assertIsNotNone(response)\n    self.assertEquals(response, \"Y\")\n", "code_toks_joined": "def test_condition_type1_variant3 ( self ) : <NEWLINE> <INDENT> response = ConditionAIMLTests . test_client . bot . ask_question ( <STRING> , <STRING> ) <NEWLINE> self . assertIsNotNone ( response ) <NEWLINE> self . assertEquals ( response , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"test\"", "\"TYPE1 VARIANT3\"", "\"Y\""]}}], ["be55c4d6a687b0072773f8c4512da04a", {"code_string": "import pprint\nfrom unittest import TestCase\nfrom..nbjson import reads, writes\nfrom.nbexamples import nb0\n", "code_toks_joined": "import pprint <NEWLINE> from unittest import TestCase <NEWLINE> from . . nbjson import reads , writes <NEWLINE> from . nbexamples import nb0 <NEWLINE>", "anonymize_dict": {}}], ["0f2dcf730a01a426ee07132b497ad4e3", {"code_string": "def last_request_status(self):\n    \"\"\"Get the last HTTP request status from the last call to the Pronto API\"\"\"\n    return self.__last_request_status\n", "code_toks_joined": "def last_request_status ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . __last_request_status <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Get the last HTTP request status from the last call to the Pronto API\"\"\""]}}], ["05b170da113f6637c9023b21e71af134", {"code_string": "def create_dummy_class(klass, dependency):\n    \"\"\"When a dependency of a class is not available, create a dummy class which throws ImportError when used.\"\"\"\n    class _Dummy(object):\n        def __init__(self, * args, ** kwargs):\n            raise ImportError(\"Cannot import '{}', therefore '{}' is not available\".format(dependency, klass))\n    return _Dummy\n", "code_toks_joined": "def create_dummy_class ( klass , dependency ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> class _Dummy ( object ) : <NEWLINE> <INDENT> def __init__ ( self , * args , ** kwargs ) : <NEWLINE> <INDENT> raise ImportError ( <STRING> . format ( dependency , klass ) ) <NEWLINE> <DEDENT> <DEDENT> return _Dummy <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"When a dependency of a class is not available, create a dummy class which throws ImportError when used.\"\"\"", "\"Cannot import '{}', therefore '{}' is not available\""]}}], ["81d2a3178ed51a912418084fa75d54e5", {"code_string": "from django.test import TestCase\nimport re\nexample_unshrunk = \"\"\"\"survey\",,,,,\"\"\"\nexample_3q = \"\"\"\"survey\",,,,,\"\"\"\n", "code_toks_joined": "from django . test import TestCase <NEWLINE> import re <NEWLINE> example_unshrunk = <STRING> <NEWLINE> example_3q = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"\"survey\",,,,,\"\"\"", "\"\"\"\"survey\",,,,,\"\"\""]}}], ["f01aafa7778f8f820df4afeb8747a32c", {"code_string": "\"\"\" CLI interface for Rally OVS. \"\"\"\nfrom __future__ import print_function\nimport sys\nfrom rally.cli import cliutils\nfrom rally.common import profile\nfrom rally_ovs.cli.commands import deployment\nfrom rally_ovs.cli.commands import task\nprofile.profile = profile.PROFILE_OVS\novs_categories = {\n    \"deployment\": deployment.DeploymentCommands,\n    \"task\": task.TaskCommands,\n}\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import print_function <NEWLINE> import sys <NEWLINE> from rally . cli import cliutils <NEWLINE> from rally . common import profile <NEWLINE> from rally_ovs . cli . commands import deployment <NEWLINE> from rally_ovs . cli . commands import task <NEWLINE> profile . profile = profile . PROFILE_OVS <NEWLINE> ovs_categories = { <NEWLINE> <INDENT> <STRING> : deployment . DeploymentCommands , <NEWLINE> <STRING> : task . TaskCommands , <NEWLINE> <DEDENT> } <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\" CLI interface for Rally OVS. \"\"\"", "\"deployment\"", "\"task\""]}}], ["f0bee87445f92b19c3140d3b096f08b2", {"code_string": "def _get_log_url(self, response):\n    url = None\n    if not response or not isinstance(response, dict) or not response.has_key('protogeni_error_url'):\n        return url\n    return response['protogeni_error_url']\n", "code_toks_joined": "def _get_log_url ( self , response ) : <NEWLINE> <INDENT> url = None <NEWLINE> if not response or not isinstance ( response , dict ) or not response . has_key ( <STRING> ) : <NEWLINE> <INDENT> return url <NEWLINE> <DEDENT> return response [ <STRING> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'protogeni_error_url'", "'protogeni_error_url'"]}}], ["ad3179a07fc984630910822afdf86353", {"code_string": "def oscillations(N):\n    x = zeros(N + 1)\n    for n in range(N + 1):\n        x[n] = exp(- 4 * n / float(N)) * sin(8 * pi * n / float(N))\n    return x\n", "code_toks_joined": "def oscillations ( N ) : <NEWLINE> <INDENT> x = zeros ( N + 1 ) <NEWLINE> for n in range ( N + 1 ) : <NEWLINE> <INDENT> x [ n ] = exp ( - 4 * n / float ( N ) ) * sin ( 8 * pi * n / float ( N ) ) <NEWLINE> <DEDENT> return x <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["5406d932d91760e265f15e52b1687cb7", {"code_string": "def open(cls, context = None):\n    if context is None:\n        context = {}\n    return cls(** context)\n", "code_toks_joined": "def open ( cls , context = None ) : <NEWLINE> <INDENT> if context is None : <NEWLINE> <INDENT> context = { } <NEWLINE> <DEDENT> return cls ( ** context ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["2fb1af0ccd30a021086d8c4e44e56df6", {"code_string": "class Values:\n    def __init__(self):\n        self.matrixR = [1.0, 0.0, 0.0]\n        self.matrixG = [0.0, 1.0, 0.0]\n        self.matrixB = [0.0, 0.0, 1.0]\n        self.matrixC = [0.0, 0.0, 0.0]\n        self.brightR = 1.0\n        self.brightG = 1.0\n        self.brightB = 1.0\n        self.contrast = 1.0\n        self.saturation = 1.0\n", "code_toks_joined": "class Values : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> self . matrixR = [ 1.0 , 0.0 , 0.0 ] <NEWLINE> self . matrixG = [ 0.0 , 1.0 , 0.0 ] <NEWLINE> self . matrixB = [ 0.0 , 0.0 , 1.0 ] <NEWLINE> self . matrixC = [ 0.0 , 0.0 , 0.0 ] <NEWLINE> self . brightR = 1.0 <NEWLINE> self . brightG = 1.0 <NEWLINE> self . brightB = 1.0 <NEWLINE> self . contrast = 1.0 <NEWLINE> self . saturation = 1.0 <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["aba4b22fd4c9a52523db1b03c11ae707", {"code_string": "def from_features(features):\n    \"\"\"Extracts a list of FieldInfos from a list of dicts representing\"\"\"\n    master = {}\n    for feature in features:\n        for field_key, field_info in _iter_field_infos(feature):\n            new_fi = FieldInfo(\n                field_key,\n                None,\n                field_info\n            )\n            master[field_key] = new_fi\n    return master\n", "code_toks_joined": "def from_features ( features ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> master = { } <NEWLINE> for feature in features : <NEWLINE> <INDENT> for field_key , field_info in _iter_field_infos ( feature ) : <NEWLINE> <INDENT> new_fi = FieldInfo ( <NEWLINE> <INDENT> field_key , <NEWLINE> None , <NEWLINE> field_info <NEWLINE> <DEDENT> ) <NEWLINE> master [ field_key ] = new_fi <NEWLINE> <DEDENT> <DEDENT> return master <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Extracts a list of FieldInfos from a list of dicts representing\"\"\""]}}], ["3221b2969345201f437d0380b4c838ea", {"code_string": "def range2list(str):\n    \"\"\"Converts a GSB range to a list of intervals\"\"\"\n    r = []\n    parts = str.split(',')\n    for part in parts:\n        minmax = part.split('-', 2)\n        if len(minmax) == 1:\n            val = int(part[0])\n            r.append((val, val))\n        else:\n            r.append((int(minmax[0]), int(minmax[1])))\n    return r\n", "code_toks_joined": "def range2list ( str ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> r = [ ] <NEWLINE> parts = str . split ( <STRING> ) <NEWLINE> for part in parts : <NEWLINE> <INDENT> minmax = part . split ( <STRING> , 2 ) <NEWLINE> if len ( minmax ) == 1 : <NEWLINE> <INDENT> val = int ( part [ 0 ] ) <NEWLINE> r . append ( ( val , val ) ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> r . append ( ( int ( minmax [ 0 ] ) , int ( minmax [ 1 ] ) ) ) <NEWLINE> <DEDENT> <DEDENT> return r <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Converts a GSB range to a list of intervals\"\"\"", "','", "'-'"]}}], ["4ab164af6f3e5b5412e02c4996403716", {"code_string": "def formula_1d(init, coeff, variable):\n    value = init * numpy.exp(coeff * variable)\n    return value\n", "code_toks_joined": "def formula_1d ( init , coeff , variable ) : <NEWLINE> <INDENT> value = init * numpy . exp ( coeff * variable ) <NEWLINE> return value <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["272b1219792e8c877be2962aac92c86b", {"code_string": "'''The app module, containing the app factory function.'''\nfrom flask import Flask, render_template\nfrom useradvocacy.settings import ProdConfig\nfrom useradvocacy.assets import assets\nfrom useradvocacy.extensions import(\n    bcrypt,\n    cache,\n    db,\n    login_manager,\n    migrate,\n    debug_toolbar,\n)\nfrom useradvocacy import public, user, reports, dashboards, data\n", "code_toks_joined": "<STRING> <NEWLINE> from flask import Flask , render_template <NEWLINE> from useradvocacy . settings import ProdConfig <NEWLINE> from useradvocacy . assets import assets <NEWLINE> from useradvocacy . extensions import ( <NEWLINE> <INDENT> bcrypt , <NEWLINE> cache , <NEWLINE> db , <NEWLINE> login_manager , <NEWLINE> migrate , <NEWLINE> debug_toolbar , <NEWLINE> <DEDENT> ) <NEWLINE> from useradvocacy import public , user , reports , dashboards , data <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''The app module, containing the app factory function.'''"]}}], ["8190aad2fa315fe02f3831cbf18578af", {"code_string": "\"\"\"Installation schemes.\"\"\"\nimport sysconfig\nfor name in sysconfig.get_scheme_names():\n    print(name)\n", "code_toks_joined": "<STRING> <NEWLINE> import sysconfig <NEWLINE> for name in sysconfig . get_scheme_names ( ) : <NEWLINE> <INDENT> print ( name ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Installation schemes.\"\"\""]}}], ["c22a26e9f3a56931d39ef7af802c6d24", {"code_string": "\"Feature extractors for Pacman game states\"\nfrom game import Directions, Actions\nimport util\n", "code_toks_joined": "<STRING> <NEWLINE> from game import Directions , Actions <NEWLINE> import util <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"Feature extractors for Pacman game states\""]}}], ["615f9d6f9ba2b44a1a3485abe318d4f3", {"code_string": "def __init__(self, access_key, secret_key, cloud_id = None, api_host = 'api.pandastream.com', api_port = 443):\n    self.cloud_id = cloud_id\n    self.access_key = access_key\n    self.secret_key = secret_key\n    self.api_host = api_host\n    self.api_port = api_port\n    self.api_version = 2\n    self.videos = GroupRetriever(self, Video)\n    self.clouds = GroupRetriever(self, Cloud)\n    self.encodings = GroupRetriever(self, Encoding)\n    self.profiles = GroupRetriever(self, Profile)\n    self.notifications = SingleRetriever(self, Notifications)\n", "code_toks_joined": "def __init__ ( self , access_key , secret_key , cloud_id = None , api_host = <STRING> , api_port = 443 ) : <NEWLINE> <INDENT> self . cloud_id = cloud_id <NEWLINE> self . access_key = access_key <NEWLINE> self . secret_key = secret_key <NEWLINE> self . api_host = api_host <NEWLINE> self . api_port = api_port <NEWLINE> self . api_version = 2 <NEWLINE> self . videos = GroupRetriever ( self , Video ) <NEWLINE> self . clouds = GroupRetriever ( self , Cloud ) <NEWLINE> self . encodings = GroupRetriever ( self , Encoding ) <NEWLINE> self . profiles = GroupRetriever ( self , Profile ) <NEWLINE> self . notifications = SingleRetriever ( self , Notifications ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'api.pandastream.com'"]}}], ["ee4a99c648a52e8e1ca267594195a3a8", {"code_string": "class PagesForModerationPanel(object):\n    name = 'pages_for_moderation'\n    order = 200\n    def __init__(self, request):\n        self.request = request\n        user_perms = UserPagePermissionsProxy(request.user)\n        self.page_revisions_for_moderation = user_perms.revisions_for_moderation().select_related('page', 'user').order_by('-created_at')\n    def render(self):\n        return render_to_string('wagtailadmin/home/pages_for_moderation.html', {\n            'page_revisions_for_moderation': self.page_revisions_for_moderation,\n        }, request = self.request)\n", "code_toks_joined": "class PagesForModerationPanel ( object ) : <NEWLINE> <INDENT> name = <STRING> <NEWLINE> order = 200 <NEWLINE> def __init__ ( self , request ) : <NEWLINE> <INDENT> self . request = request <NEWLINE> user_perms = UserPagePermissionsProxy ( request . user ) <NEWLINE> self . page_revisions_for_moderation = user_perms . revisions_for_moderation ( ) . select_related ( <STRING> , <STRING> ) . order_by ( <STRING> ) <NEWLINE> <DEDENT> def render ( self ) : <NEWLINE> <INDENT> return render_to_string ( <STRING> , { <NEWLINE> <INDENT> <STRING> : self . page_revisions_for_moderation , <NEWLINE> <DEDENT> } , request = self . request ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'pages_for_moderation'", "'page'", "'user'", "'-created_at'", "'wagtailadmin/home/pages_for_moderation.html'", "'page_revisions_for_moderation'"]}}], ["0393cb3b99320dc8ab815057e110b6c1", {"code_string": "def main(argv):\n    data_files = [\n        'Austerlitz_seizoen_2016-2017.xlsx',\n        'Austerlitz_seizoen_2017-2018.xlsx',\n    ]\n    data_dir = '/home/bas/src/dartsense/data'\n    for file_name in data_files:\n        pprint(file_name)\n        wb = openpyxl.load_workbook(\"%s/%s\" %(data_dir, file_name), read_only = True)\n", "code_toks_joined": "def main ( argv ) : <NEWLINE> <INDENT> data_files = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <DEDENT> ] <NEWLINE> data_dir = <STRING> <NEWLINE> for file_name in data_files : <NEWLINE> <INDENT> pprint ( file_name ) <NEWLINE> wb = openpyxl . load_workbook ( <STRING> % ( data_dir , file_name ) , read_only = True ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Austerlitz_seizoen_2016-2017.xlsx'", "'Austerlitz_seizoen_2017-2018.xlsx'", "'/home/bas/src/dartsense/data'", "\"%s/%s\""]}}], ["55c90227cd8e69c6d692e40327676770", {"code_string": "def test():\n    assert 2 == rom05(0)\n    assert 4 == rom05(1)\n    assert 6 == rom05(2)\n", "code_toks_joined": "def test ( ) : <NEWLINE> <INDENT> assert 2 == rom05 ( 0 ) <NEWLINE> assert 4 == rom05 ( 1 ) <NEWLINE> assert 6 == rom05 ( 2 ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["fa9adb54ca4c9e2f2896b9f487dc9aaf", {"code_string": "def parse_items(self, response):\n    \"\"\"This method, as well as any other Request callback,\"\"\"\n    sel = Selector(response)\n    job_item, company_item = response.meta['job_item'], response.meta['company_item']\n    company_item['introduction'] = ' '.join(sel.xpath('//ul[@class=\"c_feature\"]/li/text()').extract())\n    company_item['homepage'] = sel.xpath('//ul[@class=\"c_feature\"]/li[last()]/a/text()').extract_first()\n    job_item['requirement'] = ' '.join(sel.xpath('//dd[@class=\"job_bt\"]/div/p/text()').extract())\n    job_item['company'] = company_item\n    yield job_item\n", "code_toks_joined": "def parse_items ( self , response ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> sel = Selector ( response ) <NEWLINE> job_item , company_item = response . meta [ <STRING> ] , response . meta [ <STRING> ] <NEWLINE> company_item [ <STRING> ] = <STRING> . join ( sel . xpath ( <STRING> ) . extract ( ) ) <NEWLINE> company_item [ <STRING> ] = sel . xpath ( <STRING> ) . extract_first ( ) <NEWLINE> job_item [ <STRING> ] = <STRING> . join ( sel . xpath ( <STRING> ) . extract ( ) ) <NEWLINE> job_item [ <STRING> ] = company_item <NEWLINE> yield job_item <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"This method, as well as any other Request callback,\"\"\"", "'job_item'", "'company_item'", "'introduction'", "' '", "'//ul[@class=\"c_feature\"]/li/text()'", "'homepage'", "'//ul[@class=\"c_feature\"]/li[last()]/a/text()'", "'requirement'", "' '", "'//dd[@class=\"job_bt\"]/div/p/text()'", "'company'"]}}], ["eae2f873d8c66c592abc53310a88e2ff", {"code_string": "def compress(result, next):\n    count = int(result[- 1]) if result[- 1].isdigit() else 1\n    last = result[- 1] if count == 1 else result[- 2]\n    if next == last:\n        index = None if count == 1 else - 1\n        result = result[: index] + str(count + 1)\n    else:\n        result += next\n    return result\n", "code_toks_joined": "def compress ( result , next ) : <NEWLINE> <INDENT> count = int ( result [ - 1 ] ) if result [ - 1 ] . isdigit ( ) else 1 <NEWLINE> last = result [ - 1 ] if count == 1 else result [ - 2 ] <NEWLINE> if next == last : <NEWLINE> <INDENT> index = None if count == 1 else - 1 <NEWLINE> result = result [ : index ] + str ( count + 1 ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> result += next <NEWLINE> <DEDENT> return result <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["d0258b7c9b1682a41554a1d3098ebf9b", {"code_string": "class AttributeOptionGroupAdmin(admin.ModelAdmin):\n    list_display = ('name', 'option_summary')\n    inlines = [AttributeOptionInline, ]\n", "code_toks_joined": "class AttributeOptionGroupAdmin ( admin . ModelAdmin ) : <NEWLINE> <INDENT> list_display = ( <STRING> , <STRING> ) <NEWLINE> inlines = [ AttributeOptionInline , ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'name'", "'option_summary'"]}}], ["a7a67c91b10ee5620d94f1ba63878328", {"code_string": "def populate_parser(parent_parser):\n    parser = parent_parser.add_parser(\"get_topology\",\n        description = \"Read a .gro and retrieve the number residues\",\n        formatter_class = ArgumentDefaultsHelpFormatter)\n    parser.add_argument(\"grofile\", help = \"A .gro file\")\n    parser.set_defaults(func = run)\n", "code_toks_joined": "def populate_parser ( parent_parser ) : <NEWLINE> <INDENT> parser = parent_parser . add_parser ( <STRING> , <NEWLINE> <INDENT> description = <STRING> , <NEWLINE> formatter_class = ArgumentDefaultsHelpFormatter ) <NEWLINE> <DEDENT> parser . add_argument ( <STRING> , help = <STRING> ) <NEWLINE> parser . set_defaults ( func = run ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"get_topology\"", "\"Read a .gro and retrieve the number residues\"", "\"grofile\"", "\"A .gro file\""]}}], ["1f874ec4a177540e97bb526135689ec5", {"code_string": "def random_serial_number(size: int):\n    serial_number = []\n    for i in range(size):\n        while True:\n            val = random.randint(0, size) + 1\n            if val not in serial_number:\n                break\n        serial_number.append(val)\n    return serial_number\n", "code_toks_joined": "def random_serial_number ( size : int ) : <NEWLINE> <INDENT> serial_number = [ ] <NEWLINE> for i in range ( size ) : <NEWLINE> <INDENT> while True : <NEWLINE> <INDENT> val = random . randint ( 0 , size ) + 1 <NEWLINE> if val not in serial_number : <NEWLINE> <INDENT> break <NEWLINE> <DEDENT> <DEDENT> serial_number . append ( val ) <NEWLINE> <DEDENT> return serial_number <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["846cb6762f62451afe74d22c5e583bfb", {"code_string": "def updateProgress(self, progress, msg):\n    self.splash.showMessage(msg, alignment = QtCore.Qt.AlignBottom, color = self.textColor)\n    self.progressBar.setValue(progress)\n    self.app.processEvents()\n", "code_toks_joined": "def updateProgress ( self , progress , msg ) : <NEWLINE> <INDENT> self . splash . showMessage ( msg , alignment = QtCore . Qt . AlignBottom , color = self . textColor ) <NEWLINE> self . progressBar . setValue ( progress ) <NEWLINE> self . app . processEvents ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["0a4e4490efca444abd1b330adfb1a961", {"code_string": "class ShowVersion(CommandoApplication):\n    \"\"\"Simple example to run ``show version`` on devices.\"\"\"\n    commands = ['show version']\n", "code_toks_joined": "class ShowVersion ( CommandoApplication ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> commands = [ <STRING> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Simple example to run ``show version`` on devices.\"\"\"", "'show version'"]}}], ["e46a4bd18c4e2893b5aa1417c8451574", {"code_string": "class WPConfModifEPaymentWorldPayDataModif(WPConfModifEPaymentWorldPayBase):\n    \"\"\"world pay configuration page \"\"\"\n    def _getTabContent(self, params):\n        wc = WConfModifEPaymentWorldPayDataModif(self._conf)\n        p = {'postURL': quoteattr(str(localUrlHandlers.UHConfModifEPaymentWorldPayPerformDataModif.getURL(self._conf)))}\n        return wc.getHTML(p)\n", "code_toks_joined": "class WPConfModifEPaymentWorldPayDataModif ( WPConfModifEPaymentWorldPayBase ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def _getTabContent ( self , params ) : <NEWLINE> <INDENT> wc = WConfModifEPaymentWorldPayDataModif ( self . _conf ) <NEWLINE> p = { <STRING> : quoteattr ( str ( localUrlHandlers . UHConfModifEPaymentWorldPayPerformDataModif . getURL ( self . _conf ) ) ) } <NEWLINE> return wc . getHTML ( p ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"world pay configuration page \"\"\"", "'postURL'"]}}], ["3f8f99ca04a7f01b80f009c0284b7f43", {"code_string": "class CircularLayout(Layout):\n    name = 'circular'\n    def draw(self, sampler, canvas):\n        pass\n", "code_toks_joined": "class CircularLayout ( Layout ) : <NEWLINE> <INDENT> name = <STRING> <NEWLINE> def draw ( self , sampler , canvas ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'circular'"]}}], ["ec060e624f3eebad4f8f78b73b89b029", {"code_string": "def test_cust_all(self):\n    parser = create_db.build_arg_parser()\n    args = parser.parse_args('cust --all'.split())\n    self.assertEqual(args.func, create_db.create_multi_cust_dbs)\n    self.assertEqual(args.org, None)\n    self.assertEqual(args.all, True)\n", "code_toks_joined": "def test_cust_all ( self ) : <NEWLINE> <INDENT> parser = create_db . build_arg_parser ( ) <NEWLINE> args = parser . parse_args ( <STRING> . split ( ) ) <NEWLINE> self . assertEqual ( args . func , create_db . create_multi_cust_dbs ) <NEWLINE> self . assertEqual ( args . org , None ) <NEWLINE> self . assertEqual ( args . all , True ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'cust --all'"]}}], ["4f5ef351f1cd09bb075c55d560108104", {"code_string": "def setup_systems(run_input, system_params):\n    systems = MultiSystem(run_input, system_params)\n    return systems\n", "code_toks_joined": "def setup_systems ( run_input , system_params ) : <NEWLINE> <INDENT> systems = MultiSystem ( run_input , system_params ) <NEWLINE> return systems <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["f1f8a47cb6129706171f6c8c06a51237", {"code_string": "class AuditLogEntryEvent(object):\n    MEMBER_INVITE = 1\n    MEMBER_ADD = 2\n    MEMBER_ACCEPT = 3\n    MEMBER_EDIT = 4\n    MEMBER_REMOVE = 5\n    ORG_ADD = 10\n    ORG_EDIT = 11\n    TEAM_ADD = 20\n    TEAM_EDIT = 21\n    TEAM_REMOVE = 22\n    PROJECT_ADD = 30\n    PROJECT_EDIT = 31\n    PROJECT_REMOVE = 32\n    PROJECT_SET_PUBLIC = 33\n    PROJECT_SET_PRIVATE = 34\n    TAGKEY_REMOVE = 40\n    PROJECTKEY_ADD = 50\n    PROJECTKEY_EDIT = 51\n    PROJECTKEY_REMOVE = 52\n    PROJECTKEY_ENABLE = 53\n    PROJECTKEY_DISABLE = 53\n    SSO_ENABLE = 60\n    SSO_DISABLE = 61\n    SSO_EDIT = 62\n    SSO_IDENTITY_LINK = 63\n", "code_toks_joined": "class AuditLogEntryEvent ( object ) : <NEWLINE> <INDENT> MEMBER_INVITE = 1 <NEWLINE> MEMBER_ADD = 2 <NEWLINE> MEMBER_ACCEPT = 3 <NEWLINE> MEMBER_EDIT = 4 <NEWLINE> MEMBER_REMOVE = 5 <NEWLINE> ORG_ADD = 10 <NEWLINE> ORG_EDIT = 11 <NEWLINE> TEAM_ADD = 20 <NEWLINE> TEAM_EDIT = 21 <NEWLINE> TEAM_REMOVE = 22 <NEWLINE> PROJECT_ADD = 30 <NEWLINE> PROJECT_EDIT = 31 <NEWLINE> PROJECT_REMOVE = 32 <NEWLINE> PROJECT_SET_PUBLIC = 33 <NEWLINE> PROJECT_SET_PRIVATE = 34 <NEWLINE> TAGKEY_REMOVE = 40 <NEWLINE> PROJECTKEY_ADD = 50 <NEWLINE> PROJECTKEY_EDIT = 51 <NEWLINE> PROJECTKEY_REMOVE = 52 <NEWLINE> PROJECTKEY_ENABLE = 53 <NEWLINE> PROJECTKEY_DISABLE = 53 <NEWLINE> SSO_ENABLE = 60 <NEWLINE> SSO_DISABLE = 61 <NEWLINE> SSO_EDIT = 62 <NEWLINE> SSO_IDENTITY_LINK = 63 <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["caf84d91842065c9f7ee3a349c0d93cd", {"code_string": "def members(self):\n    \"\"\"\u7fa4\u804a\u7684\u6210\u5458\u5217\u8868\"\"\"\n    def raw_member_list(update = False):\n        if update:\n            self.update_group()\n        return self.raw.get('MemberList', list())\n    ret = Chats(source = self)\n    ret.extend(map(\n        lambda x: Member(x, self),\n        raw_member_list() or raw_member_list(True)\n    ))\n    return ret\n", "code_toks_joined": "def members ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def raw_member_list ( update = False ) : <NEWLINE> <INDENT> if update : <NEWLINE> <INDENT> self . update_group ( ) <NEWLINE> <DEDENT> return self . raw . get ( <STRING> , list ( ) ) <NEWLINE> <DEDENT> ret = Chats ( source = self ) <NEWLINE> ret . extend ( map ( <NEWLINE> <INDENT> lambda x : Member ( x , self ) , <NEWLINE> raw_member_list ( ) or raw_member_list ( True ) <NEWLINE> <DEDENT> ) ) <NEWLINE> return ret <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"\u7fa4\u804a\u7684\u6210\u5458\u5217\u8868\"\"\"", "'MemberList'"]}}], ["a4b03af0909c1284b107dec61dc47bd1", {"code_string": "def test_raises_error_for_abn_containing_a_letter(self):\n    \"\"\"Test an ABN containing a letter is invalid.\"\"\"\n    invalid_abn = '5300408561A'\n    validator = AUBusinessNumberFieldValidator()\n    self.assertRaises(ValidationError, lambda: validator(invalid_abn))\n", "code_toks_joined": "def test_raises_error_for_abn_containing_a_letter ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> invalid_abn = <STRING> <NEWLINE> validator = AUBusinessNumberFieldValidator ( ) <NEWLINE> self . assertRaises ( ValidationError , lambda : validator ( invalid_abn ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test an ABN containing a letter is invalid.\"\"\"", "'5300408561A'"]}}], ["ce31530d2af308507a34f33b8af6b453", {"code_string": "from sys import argv\nprint('Type your file name again:')\nfile_again = raw_input('> ')\ntxt_again = open(file_again)\nprint(txt_again.read())\ntxt_again.close()\n", "code_toks_joined": "from sys import argv <NEWLINE> print ( <STRING> ) <NEWLINE> file_again = raw_input ( <STRING> ) <NEWLINE> txt_again = open ( file_again ) <NEWLINE> print ( txt_again . read ( ) ) <NEWLINE> txt_again . close ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'Type your file name again:'", "'> '"]}}], ["23496216e4f0554abe6720b482754b3e", {"code_string": "class IPodPlistEvent(event.PythonDatetimeEvent):\n    \"\"\"An event object for an entry in the iPod plist file.\"\"\"\n    DATA_TYPE = 'ipod:device:entry'\n    def __init__(self, datetime_timestamp, device_id, device_info):\n        \"\"\"Initialize the event.\"\"\"\n        super(IPodPlistEvent, self).__init__(\n            datetime_timestamp, eventdata.EventTimestamp.LAST_CONNECTED)\n        self.device_id = device_id\n        for key, value in device_info.iteritems():\n            if key == 'Connected':\n                continue\n            attribute_name = key.lower().replace(u' ', u'_')\n            setattr(self, attribute_name, value)\n", "code_toks_joined": "class IPodPlistEvent ( event . PythonDatetimeEvent ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> DATA_TYPE = <STRING> <NEWLINE> def __init__ ( self , datetime_timestamp , device_id , device_info ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> super ( IPodPlistEvent , self ) . __init__ ( <NEWLINE> <INDENT> datetime_timestamp , eventdata . EventTimestamp . LAST_CONNECTED ) <NEWLINE> <DEDENT> self . device_id = device_id <NEWLINE> for key , value in device_info . iteritems ( ) : <NEWLINE> <INDENT> if key == <STRING> : <NEWLINE> <INDENT> continue <NEWLINE> <DEDENT> attribute_name = key . lower ( ) . replace ( <STRING> , <STRING> ) <NEWLINE> setattr ( self , attribute_name , value ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"An event object for an entry in the iPod plist file.\"\"\"", "'ipod:device:entry'", "\"\"\"Initialize the event.\"\"\"", "'Connected'", "u' '", "u'_'"]}}], ["ca2bb134bed06bce188bec227a4f5afa", {"code_string": "def p5(n):\n    r = dict()\n    for i in range(1, n + 1):\n        decompose(i, r)\n    res = 1\n    for i in r.keys():\n        res *= i ** r[i]\n    return res\n", "code_toks_joined": "def p5 ( n ) : <NEWLINE> <INDENT> r = dict ( ) <NEWLINE> for i in range ( 1 , n + 1 ) : <NEWLINE> <INDENT> decompose ( i , r ) <NEWLINE> <DEDENT> res = 1 <NEWLINE> for i in r . keys ( ) : <NEWLINE> <INDENT> res *= i ** r [ i ] <NEWLINE> <DEDENT> return res <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["79698dcccbb0f73e72ed3d52700b90f9", {"code_string": "def get(self):\n    if not self.user:\n        self.redirect_login()\n        return\n    comment_id = int(self.request.get('comment_id'))\n    comment = Comment.by_id(comment_id)\n    if not comment:\n        self.error(404)\n        return\n    if comment.author_id != self.user.key().id():\n        self.redirect_login()\n        return\n    self.render_edit_comment(comment)\n", "code_toks_joined": "def get ( self ) : <NEWLINE> <INDENT> if not self . user : <NEWLINE> <INDENT> self . redirect_login ( ) <NEWLINE> return <NEWLINE> <DEDENT> comment_id = int ( self . request . get ( <STRING> ) ) <NEWLINE> comment = Comment . by_id ( comment_id ) <NEWLINE> if not comment : <NEWLINE> <INDENT> self . error ( 404 ) <NEWLINE> return <NEWLINE> <DEDENT> if comment . author_id != self . user . key ( ) . id ( ) : <NEWLINE> <INDENT> self . redirect_login ( ) <NEWLINE> return <NEWLINE> <DEDENT> self . render_edit_comment ( comment ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'comment_id'"]}}], ["eb971d373ffa41ce34d103bfb77b2c20", {"code_string": "'''Configuration parameters of MulandWeb'''\nimport os\nmuland_binary = os.getenv('MULAND_BINARY_PATH', 'bin/muland')\nmuland_work = os.getenv('MULAND_WORK_PATH', 'work')\nmulandweb_host = os.getenv('MULANDWEB_HOST', '0.0.0.0')\nmulandweb_port = int(os.getenv('MULANDWEB_PORT', 8000))\nmulandweb_memfile_max = int(os.getenv('MULANDWEB_MEMFILE_MAX', 5 * 1024 * 1024))\ndb_url = os.getenv('MULAND_DB_URL', 'postgresql://gis:gis@localhost/gis')\ndb_prefix = os.getenv('MULAND_DB_PREFIX', '')\ntry:\n    from mulandlocal import *\nexcept ImportError:\n    pass\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> muland_binary = os . getenv ( <STRING> , <STRING> ) <NEWLINE> muland_work = os . getenv ( <STRING> , <STRING> ) <NEWLINE> mulandweb_host = os . getenv ( <STRING> , <STRING> ) <NEWLINE> mulandweb_port = int ( os . getenv ( <STRING> , 8000 ) ) <NEWLINE> mulandweb_memfile_max = int ( os . getenv ( <STRING> , 5 * 1024 * 1024 ) ) <NEWLINE> db_url = os . getenv ( <STRING> , <STRING> ) <NEWLINE> db_prefix = os . getenv ( <STRING> , <STRING> ) <NEWLINE> try : <NEWLINE> <INDENT> from mulandlocal import * <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Configuration parameters of MulandWeb'''", "'MULAND_BINARY_PATH'", "'bin/muland'", "'MULAND_WORK_PATH'", "'work'", "'MULANDWEB_HOST'", "'0.0.0.0'", "'MULANDWEB_PORT'", "'MULANDWEB_MEMFILE_MAX'", "'MULAND_DB_URL'", "'postgresql://gis:gis@localhost/gis'", "'MULAND_DB_PREFIX'", "''"]}}], ["7318cb9cbf6df5028453e087168bd3a9", {"code_string": "def test_redirect_with_script_prefix(self):\n    previous_script_prefix = urlresolvers.get_script_prefix()\n    urlresolvers.set_script_prefix('/prefix/')\n    r1 = self.request_factory.get('/nl-be/test/independent/')\n    r2 = self.middleware.process_request(r1)\n    self.assertEqual(301, r2.status_code)\n    self.assertEqual('/prefix/test/independent/', r2['Location'])\n    r3 = self.request_factory.get('/test/independent/')\n    r4 = self.middleware.process_request(r3)\n    self.assertEqual(None, r4)\n    urlresolvers.set_script_prefix(previous_script_prefix)\n", "code_toks_joined": "def test_redirect_with_script_prefix ( self ) : <NEWLINE> <INDENT> previous_script_prefix = urlresolvers . get_script_prefix ( ) <NEWLINE> urlresolvers . set_script_prefix ( <STRING> ) <NEWLINE> r1 = self . request_factory . get ( <STRING> ) <NEWLINE> r2 = self . middleware . process_request ( r1 ) <NEWLINE> self . assertEqual ( 301 , r2 . status_code ) <NEWLINE> self . assertEqual ( <STRING> , r2 [ <STRING> ] ) <NEWLINE> r3 = self . request_factory . get ( <STRING> ) <NEWLINE> r4 = self . middleware . process_request ( r3 ) <NEWLINE> self . assertEqual ( None , r4 ) <NEWLINE> urlresolvers . set_script_prefix ( previous_script_prefix ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/prefix/'", "'/nl-be/test/independent/'", "'/prefix/test/independent/'", "'Location'", "'/test/independent/'"]}}], ["d519a17fc2ac90b39e33f1417b64b199", {"code_string": "\"\"\"@author: zengchunyun\"\"\"\nimport threading\nimport time\nj_list = []\n", "code_toks_joined": "<STRING> <NEWLINE> import threading <NEWLINE> import time <NEWLINE> j_list = [ ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"@author: zengchunyun\"\"\""]}}], ["0cdb3e8d7c545689127228ddb1f4d2a6", {"code_string": "from __future__ import absolute_import, unicode_literals\nfrom django.db import models\nfrom taggit.managers import TaggableManager\nfrom wagtail.wagtailsearch import index\n", "code_toks_joined": "from __future__ import absolute_import , unicode_literals <NEWLINE> from django . db import models <NEWLINE> from taggit . managers import TaggableManager <NEWLINE> from wagtail . wagtailsearch import index <NEWLINE>", "anonymize_dict": {}}], ["7d51fa0bf8cf9aa98e7f2676a0ca83d0", {"code_string": "import os\nfrom _core import lib\nRESOURCE_PATH = os.path.join('..', 'resources')\nSHADER_PATH = os.path.abspath(os.path.join(RESOURCE_PATH, 'shaders', 'simple'))\nIMAGE_PATH = os.path.abspath(os.path.join(RESOURCE_PATH, 'images',\n    'uvtemplate.dds'))\ncore = lib.NewCore()\nlib.Core_Init(core, SHADER_PATH.encode('utf-8'), IMAGE_PATH.encode('utf-8'))\nlib.Core_Run(core)\nlib.DeleteCore(core)\n", "code_toks_joined": "import os <NEWLINE> from _core import lib <NEWLINE> RESOURCE_PATH = os . path . join ( <STRING> , <STRING> ) <NEWLINE> SHADER_PATH = os . path . abspath ( os . path . join ( RESOURCE_PATH , <STRING> , <STRING> ) ) <NEWLINE> IMAGE_PATH = os . path . abspath ( os . path . join ( RESOURCE_PATH , <STRING> , <NEWLINE> <INDENT> <STRING> ) ) <NEWLINE> <DEDENT> core = lib . NewCore ( ) <NEWLINE> lib . Core_Init ( core , SHADER_PATH . encode ( <STRING> ) , IMAGE_PATH . encode ( <STRING> ) ) <NEWLINE> lib . Core_Run ( core ) <NEWLINE> lib . DeleteCore ( core ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'..'", "'resources'", "'shaders'", "'simple'", "'images'", "'uvtemplate.dds'", "'utf-8'", "'utf-8'"]}}], ["e5ba6879fa39a0ca058abece42915e9e", {"code_string": "from datetime import datetime\nGAME_VIDEO_BASE_URL = \"http://www.nfl.com/feeds-rs/videos/byGameCenter/{0}.json\"\nLIVE_UPDATE_BASE_URL = \"http://www.nfl.com/liveupdate/game-center/{0}/{0}_gtd.json\"\n", "code_toks_joined": "from datetime import datetime <NEWLINE> GAME_VIDEO_BASE_URL = <STRING> <NEWLINE> LIVE_UPDATE_BASE_URL = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"http://www.nfl.com/feeds-rs/videos/byGameCenter/{0}.json\"", "\"http://www.nfl.com/liveupdate/game-center/{0}/{0}_gtd.json\""]}}], ["02a436f9c19a4d00b5700d707b66814d", {"code_string": "from rhum.utils.crc8 import CRC8Utils\nprint(CRC8Utils.check('test', 0xb9))\nprint(CRC8Utils.check('test', 0xb5))\n", "code_toks_joined": "from rhum . utils . crc8 import CRC8Utils <NEWLINE> print ( CRC8Utils . check ( <STRING> , 0xb9 ) ) <NEWLINE> print ( CRC8Utils . check ( <STRING> , 0xb5 ) ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'test'", "'test'"]}}], ["b54bd7d9a37313dd344abd885025b051", {"code_string": "def assertExitedStateNTimesRecently(self, times, card, state, when):\n    StateLog = self._get_target_class()\n    state_logs = StateLog.objects.filter(card = card, state = state).order_by('-entered')\n    assert times == len(state_logs)\n    self.assertEqualDateTimes(state_logs[0].exited, when)\n    assert state_logs[0].entered is not None\n    for i in xrange(1, times - 1):\n        assert state_logs[i].entered != when\n        assert state_logs[i].exited != when\n", "code_toks_joined": "def assertExitedStateNTimesRecently ( self , times , card , state , when ) : <NEWLINE> <INDENT> StateLog = self . _get_target_class ( ) <NEWLINE> state_logs = StateLog . objects . filter ( card = card , state = state ) . order_by ( <STRING> ) <NEWLINE> assert times == len ( state_logs ) <NEWLINE> self . assertEqualDateTimes ( state_logs [ 0 ] . exited , when ) <NEWLINE> assert state_logs [ 0 ] . entered is not None <NEWLINE> for i in xrange ( 1 , times - 1 ) : <NEWLINE> <INDENT> assert state_logs [ i ] . entered != when <NEWLINE> assert state_logs [ i ] . exited != when <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'-entered'"]}}], ["735d3a5ec89983b115fc3cc925a5cf41", {"code_string": "def test_frozendict_hash(self):\n    \"\"\" Ensure that a frozendict is hashable. \"\"\"\n    hash(frozendict({'name': 'Joe', 'age': 42}))\n    hash(frozendict({\n        'user_id': (42, 'Joe'),\n        'line_ids': [(0, 0, {'values': [42]})],\n    }))\n", "code_toks_joined": "def test_frozendict_hash ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> hash ( frozendict ( { <STRING> : <STRING> , <STRING> : 42 } ) ) <NEWLINE> hash ( frozendict ( { <NEWLINE> <INDENT> <STRING> : ( 42 , <STRING> ) , <NEWLINE> <STRING> : [ ( 0 , 0 , { <STRING> : [ 42 ] } ) ] , <NEWLINE> <DEDENT> } ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Ensure that a frozendict is hashable. \"\"\"", "'name'", "'Joe'", "'age'", "'user_id'", "'Joe'", "'line_ids'", "'values'"]}}], ["14681bc748a341622772728529da292a", {"code_string": "def assertTranslate(self, machine, lang = 'cs', word = 'world', empty = False):\n    translation = machine.translate(lang, word, MockUnit(), None)\n    self.assertIsInstance(translation, list)\n    if not empty:\n        self.assertTrue(len(translation) > 0)\n", "code_toks_joined": "def assertTranslate ( self , machine , lang = <STRING> , word = <STRING> , empty = False ) : <NEWLINE> <INDENT> translation = machine . translate ( lang , word , MockUnit ( ) , None ) <NEWLINE> self . assertIsInstance ( translation , list ) <NEWLINE> if not empty : <NEWLINE> <INDENT> self . assertTrue ( len ( translation ) > 0 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'cs'", "'world'"]}}], ["19548396624b1769d8e0d9f9b4a5a648", {"code_string": "def getName(self):\n    \"\"\"Return plugin name\"\"\"\n    return None\n", "code_toks_joined": "def getName ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return None <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Return plugin name\"\"\""]}}], ["b1c728d332341bd8d0c7c03d9e7abbdf", {"code_string": "class UserBasedScalableNumerator(MRJob):\n    def steps(self):\n        return[\n            MRStep(mapper = self.mapper_getUser,\n                reducer = self.reducer_countMoiveForUser)\n        ]\n    def mapper_getUser(self, _, line):\n        if not line.strip():\n            pass\n        else:\n            user = line.strip().split(\"\\t\")[0]\n            yield user, 1\n    def reducer_countMoiveForUser(self, user, count):\n        yield \"Numerator\", (user, sum(count))\n", "code_toks_joined": "class UserBasedScalableNumerator ( MRJob ) : <NEWLINE> <INDENT> def steps ( self ) : <NEWLINE> <INDENT> return [ <NEWLINE> <INDENT> MRStep ( mapper = self . mapper_getUser , <NEWLINE> <INDENT> reducer = self . reducer_countMoiveForUser ) <NEWLINE> <DEDENT> <DEDENT> ] <NEWLINE> <DEDENT> def mapper_getUser ( self , _ , line ) : <NEWLINE> <INDENT> if not line . strip ( ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> user = line . strip ( ) . split ( <STRING> ) [ 0 ] <NEWLINE> yield user , 1 <NEWLINE> <DEDENT> <DEDENT> def reducer_countMoiveForUser ( self , user , count ) : <NEWLINE> <INDENT> yield <STRING> , ( user , sum ( count ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\\t\"", "\"Numerator\""]}}], ["c95e9f7171963623a287c933d89e5ec7", {"code_string": "def publish():\n    \"\"\" \"\"\"\n    print('\\n####### Publish... #######')\n    all()\n    local('git add .')\n    local('git commit -am \"Released version {}\"'.format(VERSION))\n    local('git tag -f -a {} -m \"{}\"'.format(VERSION, DATE))\n    local('git checkout stable')\n    local('git merge master')\n    local('git push origin')\n    local('git push origin --tags')\n    local('git checkout master')\n", "code_toks_joined": "def publish ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> print ( <STRING> ) <NEWLINE> all ( ) <NEWLINE> local ( <STRING> ) <NEWLINE> local ( <STRING> . format ( VERSION ) ) <NEWLINE> local ( <STRING> . format ( VERSION , DATE ) ) <NEWLINE> local ( <STRING> ) <NEWLINE> local ( <STRING> ) <NEWLINE> local ( <STRING> ) <NEWLINE> local ( <STRING> ) <NEWLINE> local ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" \"\"\"", "'\\n####### Publish... #######'", "'git add .'", "'git commit -am \"Released version {}\"'", "'git tag -f -a {} -m \"{}\"'", "'git checkout stable'", "'git merge master'", "'git push origin'", "'git push origin --tags'", "'git checkout master'"]}}], ["5b746b8ca1219295784907ec612e875c", {"code_string": "class PageCyclerIntlHiRu(_PageCycler):\n    \"\"\"Page load time benchmark for a variety of pages in Hindi and Russian.\"\"\"\n    page_set = page_sets.IntlHiRuPageSet\n    @ classmethod\n    def Name(cls):\n        return 'page_cycler.intl_hi_ru'\n", "code_toks_joined": "class PageCyclerIntlHiRu ( _PageCycler ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> page_set = page_sets . IntlHiRuPageSet <NEWLINE> @ classmethod <NEWLINE> def Name ( cls ) : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Page load time benchmark for a variety of pages in Hindi and Russian.\"\"\"", "'page_cycler.intl_hi_ru'"]}}], ["5f9b938af8f55d3491e614b907c96cf6", {"code_string": "def run(visual, program_runner):\n    score = 0\n    try:\n        stage.init()\n        if visual:\n            graphics.init()\n        theme.init()\n        score = gameloop.start(program_runner)\n    finally:\n        exit()\n    return score\n", "code_toks_joined": "def run ( visual , program_runner ) : <NEWLINE> <INDENT> score = 0 <NEWLINE> try : <NEWLINE> <INDENT> stage . init ( ) <NEWLINE> if visual : <NEWLINE> <INDENT> graphics . init ( ) <NEWLINE> <DEDENT> theme . init ( ) <NEWLINE> score = gameloop . start ( program_runner ) <NEWLINE> <DEDENT> finally : <NEWLINE> <INDENT> exit ( ) <NEWLINE> <DEDENT> return score <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ded018c5b2ef33b17d02b56e84c35644", {"code_string": "def account_info(iso, bank_acc):\n    '''Consult the online database for this country to obtain its'''\n    if iso in _account_info:\n        return _account_info[iso](bank_acc)\n    return False\n", "code_toks_joined": "def account_info ( iso , bank_acc ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if iso in _account_info : <NEWLINE> <INDENT> return _account_info [ iso ] ( bank_acc ) <NEWLINE> <DEDENT> return False <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Consult the online database for this country to obtain its'''"]}}], ["b3c6787d9315c4bb85b2efc2e6261c48", {"code_string": "def test_add_histogram_value_wrong_variable(self):\n    cc = CrayonClient(port = self.test_server_port)\n    foo = cc.create_experiment(\"foo\")\n    data = {\"min\": 0,\n        \"max\": 100,\n        \"num\": 3,\n        \"bucket_limit\": [10, 50, 30],\n        \"bucket\": [5, 45, 25]}\n    self.assertRaises(ValueError, foo.add_histogram_value,\n        \"\", data)\n", "code_toks_joined": "def test_add_histogram_value_wrong_variable ( self ) : <NEWLINE> <INDENT> cc = CrayonClient ( port = self . test_server_port ) <NEWLINE> foo = cc . create_experiment ( <STRING> ) <NEWLINE> data = { <STRING> : 0 , <NEWLINE> <INDENT> <STRING> : 100 , <NEWLINE> <STRING> : 3 , <NEWLINE> <STRING> : [ 10 , 50 , 30 ] , <NEWLINE> <STRING> : [ 5 , 45 , 25 ] } <NEWLINE> <DEDENT> self . assertRaises ( ValueError , foo . add_histogram_value , <NEWLINE> <INDENT> <STRING> , data ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"foo\"", "\"min\"", "\"max\"", "\"num\"", "\"bucket_limit\"", "\"bucket\"", "\"\""]}}], ["47cbe10d3287249f58ffd5874429932a", {"code_string": "def cb_ballinimage(self, balls: BallsInImage):\n    if balls.candidates:\n        ball = balls.candidates[0]\n        self.bestball_in_image = ball.center.x, ball.center.y\n", "code_toks_joined": "def cb_ballinimage ( self , balls : BallsInImage ) : <NEWLINE> <INDENT> if balls . candidates : <NEWLINE> <INDENT> ball = balls . candidates [ 0 ] <NEWLINE> self . bestball_in_image = ball . center . x , ball . center . y <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["656633691ee3be92f4ba3ad8c944e23d", {"code_string": "def test_formula_terms_variables(self):\n    assert len(self.formula_terms_variables) == 1\n    assert hasattr(self.formula_terms_variable, 'formula_terms')\n    assert self.formula_terms_variable.standard_name == 'ocean_s_coordinate_g1'\n", "code_toks_joined": "def test_formula_terms_variables ( self ) : <NEWLINE> <INDENT> assert len ( self . formula_terms_variables ) == 1 <NEWLINE> assert hasattr ( self . formula_terms_variable , <STRING> ) <NEWLINE> assert self . formula_terms_variable . standard_name == <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'formula_terms'", "'ocean_s_coordinate_g1'"]}}], ["648e72c5e8c2513a906b8ef8a4010393", {"code_string": "def get_responsible(section, key):\n    \"\"\":param section: Section to search for\"\"\"\n    first = CFG_PATHS[- 1]\n    paths = reversed(CFG_PATHS)\n    for path in paths:\n        config = ConfigParser.ConfigParser()\n        config.read(path)\n        if config.has_option(section, key):\n            return path\n    return first\n", "code_toks_joined": "def get_responsible ( section , key ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> first = CFG_PATHS [ - 1 ] <NEWLINE> paths = reversed ( CFG_PATHS ) <NEWLINE> for path in paths : <NEWLINE> <INDENT> config = ConfigParser . ConfigParser ( ) <NEWLINE> config . read ( path ) <NEWLINE> if config . has_option ( section , key ) : <NEWLINE> <INDENT> return path <NEWLINE> <DEDENT> <DEDENT> return first <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\":param section: Section to search for\"\"\""]}}], ["b7bd1ba20878269db8f00a416eab46c8", {"code_string": "def __init__(self, * args, ** kwargs):\n    super().__init__(* args, ** kwargs)\n    self.user_id = self.slack_client.api_call(\"auth.test\")[\"user_id\"]\n    self.store_file = open(\"{}_store.json\".format(type(self).__name__), 'r+')\n    try:\n        self.store = json.load(self.store_file)\n    except:\n        self.store = {}\n", "code_toks_joined": "def __init__ ( self , * args , ** kwargs ) : <NEWLINE> <INDENT> super ( ) . __init__ ( * args , ** kwargs ) <NEWLINE> self . user_id = self . slack_client . api_call ( <STRING> ) [ <STRING> ] <NEWLINE> self . store_file = open ( <STRING> . format ( type ( self ) . __name__ ) , <STRING> ) <NEWLINE> try : <NEWLINE> <INDENT> self . store = json . load ( self . store_file ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> self . store = { } <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"auth.test\"", "\"user_id\"", "\"{}_store.json\"", "'r+'"]}}], ["73f63cbd3b2c0ef2a48fbf1b080053e7", {"code_string": "import base_partner_merge_ccorp\nimport base_partner_merge_address_ccorp\n", "code_toks_joined": "import base_partner_merge_ccorp <NEWLINE> import base_partner_merge_address_ccorp <NEWLINE>", "anonymize_dict": {}}], ["14f0accbc283941126ff4567a992f206", {"code_string": "from __future__ import absolute_import, unicode_literals\nfrom binascii import Error\nfrom django.core.management.base import NoArgsCommand\nfrom ... import backend\nfrom ... session import SessionStore\n", "code_toks_joined": "from __future__ import absolute_import , unicode_literals <NEWLINE> from binascii import Error <NEWLINE> from django . core . management . base import NoArgsCommand <NEWLINE> from ... import backend <NEWLINE> from ... session import SessionStore <NEWLINE>", "anonymize_dict": {}}], ["be57a27fe0cd1b3ef745d91c838b0b30", {"code_string": "from authentication.views import MainLoginView, FirstLoginView, LogoutView\nfrom django.conf.urls import patterns, url\nurlpatterns = patterns('',\n    url('^login/$', MainLoginView.as_view(),\n        name = \"main_login\"),\n    url('^logout/$', LogoutView.as_view(),\n        name = \"logout\"),\n    url('^login/firstlogin/', FirstLoginView.as_view(),\n        name = \"first_login\")\n)\n", "code_toks_joined": "from authentication . views import MainLoginView , FirstLoginView , LogoutView <NEWLINE> from django . conf . urls import patterns , url <NEWLINE> urlpatterns = patterns ( <STRING> , <NEWLINE> <INDENT> url ( <STRING> , MainLoginView . as_view ( ) , <NEWLINE> <INDENT> name = <STRING> ) , <NEWLINE> <DEDENT> url ( <STRING> , LogoutView . as_view ( ) , <NEWLINE> <INDENT> name = <STRING> ) , <NEWLINE> <DEDENT> url ( <STRING> , FirstLoginView . as_view ( ) , <NEWLINE> <INDENT> name = <STRING> ) <NEWLINE> <DEDENT> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["''", "'^login/$'", "\"main_login\"", "'^logout/$'", "\"logout\"", "'^login/firstlogin/'", "\"first_login\""]}}], ["f116138c5f95e8a75a3816a6621d4d04", {"code_string": "def __init__(self, * args):\n    this = _SimAppObjNameDefault_DistributionSystem_RefrigerationLoop.new_SimAppObjNameDefault_DistributionSystem_RefrigerationLoop_sequence(* args)\n    try:\n        self.this.append(this)\n    except:\n        self.this = this\n", "code_toks_joined": "def __init__ ( self , * args ) : <NEWLINE> <INDENT> this = _SimAppObjNameDefault_DistributionSystem_RefrigerationLoop . new_SimAppObjNameDefault_DistributionSystem_RefrigerationLoop_sequence ( * args ) <NEWLINE> try : <NEWLINE> <INDENT> self . this . append ( this ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> self . this = this <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["6b5cf58523037fb1d31e7c2cca40972d", {"code_string": "from jiver import __version__\nimport os\nimport sys\ntry:\n    from setuptools import setup\nexcept ImportError:\n    from distutils.core import setup\ndependencies = ['docopt', 'termcolor']\n", "code_toks_joined": "from jiver import __version__ <NEWLINE> import os <NEWLINE> import sys <NEWLINE> try : <NEWLINE> <INDENT> from setuptools import setup <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> from distutils . core import setup <NEWLINE> <DEDENT> dependencies = [ <STRING> , <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'docopt'", "'termcolor'"]}}], ["432d292e715baea8fa0105eb4ddce117", {"code_string": "def add(self, mac, ip):\n    assert mac not in[x[0] for x in self._nodesMACIPPairs]\n    assert ip not in[x[1] for x in self._nodesMACIPPairs]\n    self._nodesMACIPPairs.append((mac, ip))\n    self._reload()\n", "code_toks_joined": "def add ( self , mac , ip ) : <NEWLINE> <INDENT> assert mac not in [ x [ 0 ] for x in self . _nodesMACIPPairs ] <NEWLINE> assert ip not in [ x [ 1 ] for x in self . _nodesMACIPPairs ] <NEWLINE> self . _nodesMACIPPairs . append ( ( mac , ip ) ) <NEWLINE> self . _reload ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["f302f6c4c81db9017df18d9f17d8b93e", {"code_string": "def get_selections(module, pkg):\n    cmd = [module.get_bin_path('debconf-show', True), pkg]\n    rc, out, err = module.run_command(' '.join(cmd))\n    if rc != 0:\n        module.fail_json(msg = err)\n    selections = {}\n    for line in out.splitlines():\n        (key, value) = line.split(':', 1)\n        selections[key.strip('*').strip()] = value.strip()\n    return selections\n", "code_toks_joined": "def get_selections ( module , pkg ) : <NEWLINE> <INDENT> cmd = [ module . get_bin_path ( <STRING> , True ) , pkg ] <NEWLINE> rc , out , err = module . run_command ( <STRING> . join ( cmd ) ) <NEWLINE> if rc != 0 : <NEWLINE> <INDENT> module . fail_json ( msg = err ) <NEWLINE> <DEDENT> selections = { } <NEWLINE> for line in out . splitlines ( ) : <NEWLINE> <INDENT> ( key , value ) = line . split ( <STRING> , 1 ) <NEWLINE> selections [ key . strip ( <STRING> ) . strip ( ) ] = value . strip ( ) <NEWLINE> <DEDENT> return selections <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'debconf-show'", "' '", "':'", "'*'"]}}], ["39098dafd53dba0a101d2365c9e6f316", {"code_string": "from crawler import TCrawler\nfrom segments_index import TSegmentIndexWriter\nfrom utils import TCustomCounter\nfrom ling_utils import CASE_UPPER, CASE_TITLE, CASE_LOWER\nfrom ling_utils import span_tokenize_windows1251\nfrom ling_utils import unify_word\nimport sys\nimport os\nREDUCERS_COUNT = 100\nREDUCERS_FILES_BUFFER = 1000000\nWEIGHT_SHIFT = 2\nSEGMENT_POS_SHIFT = 6\nBOOK_SHIFT = 20\nSEGMENT_SIZE = (1 << SEGMENT_POS_SHIFT)\n", "code_toks_joined": "from crawler import TCrawler <NEWLINE> from segments_index import TSegmentIndexWriter <NEWLINE> from utils import TCustomCounter <NEWLINE> from ling_utils import CASE_UPPER , CASE_TITLE , CASE_LOWER <NEWLINE> from ling_utils import span_tokenize_windows1251 <NEWLINE> from ling_utils import unify_word <NEWLINE> import sys <NEWLINE> import os <NEWLINE> REDUCERS_COUNT = 100 <NEWLINE> REDUCERS_FILES_BUFFER = 1000000 <NEWLINE> WEIGHT_SHIFT = 2 <NEWLINE> SEGMENT_POS_SHIFT = 6 <NEWLINE> BOOK_SHIFT = 20 <NEWLINE> SEGMENT_SIZE = ( 1 << SEGMENT_POS_SHIFT ) <NEWLINE>", "anonymize_dict": {}}], ["b1379e38a52cd6ca6798f7adf35ab99e", {"code_string": "from learning.bayesian_learning.agents import TheEyeAgent\nfrom opencog.atomspace import AtomSpace\nfrom opencog.cogserver import Server\n__author__ = 'Keyvan'\nif __name__ == '__main__':\n    server = Server()\n    server.add_mind_agent(TheEyeAgent())\n    server.run(AtomSpace())\n", "code_toks_joined": "from learning . bayesian_learning . agents import TheEyeAgent <NEWLINE> from opencog . atomspace import AtomSpace <NEWLINE> from opencog . cogserver import Server <NEWLINE> __author__ = <STRING> <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> server = Server ( ) <NEWLINE> server . add_mind_agent ( TheEyeAgent ( ) ) <NEWLINE> server . run ( AtomSpace ( ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Keyvan'", "'__main__'"]}}], ["2c0b8ba92ef956e7eee257c24eef8f78", {"code_string": "\"\"\"Retrieving spots from pskreporter.info.\"\"\"\nimport sys\nimport requests\nimport xml.dom.minidom as minidom\nfrom PySide import QtCore, QtGui\nfrom.import _spotting, _callinfo, _grid, _location, _config\n", "code_toks_joined": "<STRING> <NEWLINE> import sys <NEWLINE> import requests <NEWLINE> import xml . dom . minidom as minidom <NEWLINE> from PySide import QtCore , QtGui <NEWLINE> from . import _spotting , _callinfo , _grid , _location , _config <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Retrieving spots from pskreporter.info.\"\"\""]}}], ["f6a2ed89ff9249cc69503b9de0a53778", {"code_string": "import odoo.addons.decimal_precision as dp\nfrom odoo import fields, models, api, tools\nfrom odoo.exceptions import UserError\n", "code_toks_joined": "import odoo . addons . decimal_precision as dp <NEWLINE> from odoo import fields , models , api , tools <NEWLINE> from odoo . exceptions import UserError <NEWLINE>", "anonymize_dict": {}}], ["cabdbe1474d18587c0e9bedf1e93dd7c", {"code_string": "def bench_xpath_class_repeat(self, children):\n    for child in children:\n        xpath = self.etree.XPath(\"./*[0]\")\n        xpath(child)\n", "code_toks_joined": "def bench_xpath_class_repeat ( self , children ) : <NEWLINE> <INDENT> for child in children : <NEWLINE> <INDENT> xpath = self . etree . XPath ( <STRING> ) <NEWLINE> xpath ( child ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"./*[0]\""]}}], ["225d5befb8aedb560422b4c9e697de61", {"code_string": "from django.http import HttpResponse\nimport numpy as np\nimport matplotlib\nfrom matplotlib.pyplot import get_cmap, colorbar, legend\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_agg import FigureCanvasAgg\nimport wms.add_cmaps\nfrom wms.mpl_handler import DEFAULT_HATCHES\nfrom wms import logger\nfrom matplotlib import rcParams\nrcParams['font.family'] = 'sans-serif'\nrcParams['font.sans-serif'] = ['Bitstream Vera Sans']\nrcParams['font.serif'] = ['Bitstream Vera Sans']\nrcParams['font.size'] = '10'\nrcParams['figure.autolayout'] = True\n", "code_toks_joined": "from django . http import HttpResponse <NEWLINE> import numpy as np <NEWLINE> import matplotlib <NEWLINE> from matplotlib . pyplot import get_cmap , colorbar , legend <NEWLINE> import matplotlib . pyplot as plt <NEWLINE> from matplotlib . backends . backend_agg import FigureCanvasAgg <NEWLINE> import wms . add_cmaps <NEWLINE> from wms . mpl_handler import DEFAULT_HATCHES <NEWLINE> from wms import logger <NEWLINE> from matplotlib import rcParams <NEWLINE> rcParams [ <STRING> ] = <STRING> <NEWLINE> rcParams [ <STRING> ] = [ <STRING> ] <NEWLINE> rcParams [ <STRING> ] = [ <STRING> ] <NEWLINE> rcParams [ <STRING> ] = <STRING> <NEWLINE> rcParams [ <STRING> ] = True <NEWLINE>", "anonymize_dict": {"<STRING>": ["'font.family'", "'sans-serif'", "'font.sans-serif'", "'Bitstream Vera Sans'", "'font.serif'", "'Bitstream Vera Sans'", "'font.size'", "'10'", "'figure.autolayout'"]}}], ["66ccf2b95386f84d7eb3bc9cc464ee2a", {"code_string": "def disable_mocktime():\n    global MOCKTIME\n    MOCKTIME = 0\n", "code_toks_joined": "def disable_mocktime ( ) : <NEWLINE> <INDENT> global MOCKTIME <NEWLINE> MOCKTIME = 0 <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["0c9303187ce49884a53a32abd7efe752", {"code_string": "\"\"\" Map the Lyapunov exponent for a given set of initial conditions. \"\"\"\n__author__ = \"adrn <adrn@astro.columbia.edu>\"\nimport sys\nfrom streammorphology import ExperimentRunner\nfrom streammorphology.lyapunov import Lyapmap\nrunner = ExperimentRunner(ExperimentClass = Lyapmap)\nrunner.run()\nsys.exit(0)\n", "code_toks_joined": "<STRING> <NEWLINE> __author__ = <STRING> <NEWLINE> import sys <NEWLINE> from streammorphology import ExperimentRunner <NEWLINE> from streammorphology . lyapunov import Lyapmap <NEWLINE> runner = ExperimentRunner ( ExperimentClass = Lyapmap ) <NEWLINE> runner . run ( ) <NEWLINE> sys . exit ( 0 ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\" Map the Lyapunov exponent for a given set of initial conditions. \"\"\"", "\"adrn <adrn@astro.columbia.edu>\""]}}], ["f88d9404576e8a21260048b8fbd19d6e", {"code_string": "def _fetch(self, force):\n    if not force:\n        value = self.get_local_only()\n        if not value == DoesNotExist:\n            return value\n        value = self.value_from_cache_data(cache.get(self.key))\n        if not value == DoesNotExist:\n            return value\n    cache_data = self.generate_cache_data()\n    return self.value_from_cache_data(cache_data)\n", "code_toks_joined": "def _fetch ( self , force ) : <NEWLINE> <INDENT> if not force : <NEWLINE> <INDENT> value = self . get_local_only ( ) <NEWLINE> if not value == DoesNotExist : <NEWLINE> <INDENT> return value <NEWLINE> <DEDENT> value = self . value_from_cache_data ( cache . get ( self . key ) ) <NEWLINE> if not value == DoesNotExist : <NEWLINE> <INDENT> return value <NEWLINE> <DEDENT> <DEDENT> cache_data = self . generate_cache_data ( ) <NEWLINE> return self . value_from_cache_data ( cache_data ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["9a52c337aa55dc4cb0afe9ac4de138ea", {"code_string": "\"\"\"Module providing user session storage setup\"\"\"\nfrom five import grok\nfrom zope.interface import Interface\nfrom zope.globalrequest import getRequest\nfrom collective.beaker.interfaces import ISession\nSESSION_KEY = 'Uh53dAfH2JPzI/lIhBvN72RJzZVv6zk5'\n", "code_toks_joined": "<STRING> <NEWLINE> from five import grok <NEWLINE> from zope . interface import Interface <NEWLINE> from zope . globalrequest import getRequest <NEWLINE> from collective . beaker . interfaces import ISession <NEWLINE> SESSION_KEY = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Module providing user session storage setup\"\"\"", "'Uh53dAfH2JPzI/lIhBvN72RJzZVv6zk5'"]}}], ["ca7a05121185c9ce4c371f939830ac5a", {"code_string": "class CeleryTestCase(TestCase):\n    \"\"\"Test case that handles a full fledged Celery application\"\"\"\n    def setUp(self):\n        self.tracer = get_dummy_tracer()\n        self._original_tracer = ddtrace.tracer\n        ddtrace.tracer = self.tracer\n        self.app = patch_app(Celery('celery.test_app', broker = BROKER_URL, backend = BACKEND_URL))\n", "code_toks_joined": "class CeleryTestCase ( TestCase ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def setUp ( self ) : <NEWLINE> <INDENT> self . tracer = get_dummy_tracer ( ) <NEWLINE> self . _original_tracer = ddtrace . tracer <NEWLINE> ddtrace . tracer = self . tracer <NEWLINE> self . app = patch_app ( Celery ( <STRING> , broker = BROKER_URL , backend = BACKEND_URL ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test case that handles a full fledged Celery application\"\"\"", "'celery.test_app'"]}}], ["b0afbc1d8b14ea9c23fe668ac0d6780c", {"code_string": "def resizeHalf(srcPath):\n    convert_command = CONVERT + ' {0} -resize 50% -unsharp 2x0.6+0.8+0.03  {1}'\n    dstPath = srcPath.replace(HIGH_ROOT, LOW_ROOT)\n    if not os.path.exists(os.path.dirname(dstPath)):\n        os.system(\"mkdir -p '%s'\" % os.path.dirname(dstPath))\n    cmd = convert_command.format(srcPath, dstPath)\n    print(srcPath, '->', dstPath, \" ... done\")\n    os.system(cmd)\n", "code_toks_joined": "def resizeHalf ( srcPath ) : <NEWLINE> <INDENT> convert_command = CONVERT + <STRING> <NEWLINE> dstPath = srcPath . replace ( HIGH_ROOT , LOW_ROOT ) <NEWLINE> if not os . path . exists ( os . path . dirname ( dstPath ) ) : <NEWLINE> <INDENT> os . system ( <STRING> % os . path . dirname ( dstPath ) ) <NEWLINE> <DEDENT> cmd = convert_command . format ( srcPath , dstPath ) <NEWLINE> print ( srcPath , <STRING> , dstPath , <STRING> ) <NEWLINE> os . system ( cmd ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["' {0} -resize 50% -unsharp 2x0.6+0.8+0.03  {1}'", "\"mkdir -p '%s'\"", "'->'", "\" ... done\""]}}], ["4ba7a672e3df9a82fdc2907b7ec8e63e", {"code_string": "from setuptools import setup\nsetup(\n    name = 'prjwithdatafile',\n    version = \"1.0\",\n    packages = ['prjwithdatafile'],\n    data_files = [\n        (r'packages1', ['prjwithdatafile/README.txt']),\n        (r'packages2', ['prjwithdatafile/README.txt'])\n    ]\n)\n", "code_toks_joined": "from setuptools import setup <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> data_files = [ <NEWLINE> <INDENT> ( <STRING> , [ <STRING> ] ) , <NEWLINE> ( <STRING> , [ <STRING> ] ) <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'prjwithdatafile'", "\"1.0\"", "'prjwithdatafile'", "r'packages1'", "'prjwithdatafile/README.txt'", "r'packages2'", "'prjwithdatafile/README.txt'"]}}], ["18c172432e9f10bf67059c603c69a36a", {"code_string": "def test_timeout():\n    sp = svm.SVC(C = 1, kernel = lambda x, y: x * y.T, probability = True,\n        max_iter = 1)\n    with warnings.catch_warnings(record = True) as foo:\n        sp.fit(X_sp, Y)\n        nose_assert_equal(len(foo), 1, msg = foo)\n        nose_assert_equal(foo[0].category, ConvergenceWarning,\n            msg = foo[0].category)\n", "code_toks_joined": "def test_timeout ( ) : <NEWLINE> <INDENT> sp = svm . SVC ( C = 1 , kernel = lambda x , y : x * y . T , probability = True , <NEWLINE> <INDENT> max_iter = 1 ) <NEWLINE> <DEDENT> with warnings . catch_warnings ( record = True ) as foo : <NEWLINE> <INDENT> sp . fit ( X_sp , Y ) <NEWLINE> nose_assert_equal ( len ( foo ) , 1 , msg = foo ) <NEWLINE> nose_assert_equal ( foo [ 0 ] . category , ConvergenceWarning , <NEWLINE> <INDENT> msg = foo [ 0 ] . category ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["fba6e3fb41c693ffed20911f2d281e6f", {"code_string": "from __future__ import division, absolute_import, print_function\n__all__ = ['atleast_1d', 'atleast_2d', 'atleast_3d', 'vstack', 'hstack']\nfrom.import numeric as _nx\nfrom.numeric import array, asanyarray, newaxis\n", "code_toks_joined": "from __future__ import division , absolute_import , print_function <NEWLINE> __all__ = [ <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE> from . import numeric as _nx <NEWLINE> from . numeric import array , asanyarray , newaxis <NEWLINE>", "anonymize_dict": {"<STRING>": ["'atleast_1d'", "'atleast_2d'", "'atleast_3d'", "'vstack'", "'hstack'"]}}], ["3d2c6287a6f73e0148334531299afcd3", {"code_string": "import logging\nfrom hashlib import sha1\nfrom pylons import app_globals\nlog = logging.getLogger(__name__)\nSEP = \"|\"\n", "code_toks_joined": "import logging <NEWLINE> from hashlib import sha1 <NEWLINE> from pylons import app_globals <NEWLINE> log = logging . getLogger ( __name__ ) <NEWLINE> SEP = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"|\""]}}], ["a827f6e2eeacc34fd57e397c447d31de", {"code_string": "def electrum_path(self):\n    path = self.get('electrum_path')\n    if path is None:\n        path = self.user_dir()\n    if self.get('testnet'):\n        path = os.path.join(path, 'testnet')\n    if not os.path.exists(path):\n        if os.path.islink(path):\n            raise BaseException('Dangling link: ' + path)\n        os.mkdir(path)\n    self.print_error(\"electrum directory\", path)\n    return path\n", "code_toks_joined": "def electrum_path ( self ) : <NEWLINE> <INDENT> path = self . get ( <STRING> ) <NEWLINE> if path is None : <NEWLINE> <INDENT> path = self . user_dir ( ) <NEWLINE> <DEDENT> if self . get ( <STRING> ) : <NEWLINE> <INDENT> path = os . path . join ( path , <STRING> ) <NEWLINE> <DEDENT> if not os . path . exists ( path ) : <NEWLINE> <INDENT> if os . path . islink ( path ) : <NEWLINE> <INDENT> raise BaseException ( <STRING> + path ) <NEWLINE> <DEDENT> os . mkdir ( path ) <NEWLINE> <DEDENT> self . print_error ( <STRING> , path ) <NEWLINE> return path <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'electrum_path'", "'testnet'", "'testnet'", "'Dangling link: '", "\"electrum directory\""]}}], ["108404944874ed4768ad3c02b7d31a4f", {"code_string": "def __init__(self, mainWindow, * args, ** kwargs):\n    super().__init__(* args, ** kwargs)\n    self.window = mainWindow\n", "code_toks_joined": "def __init__ ( self , mainWindow , * args , ** kwargs ) : <NEWLINE> <INDENT> super ( ) . __init__ ( * args , ** kwargs ) <NEWLINE> self . window = mainWindow <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["9401d43abd73144e03afdb68f454c11f", {"code_string": "class product_template(models.Model):\n    _inherit = 'product.template'\n    other_sale_description = fields.Char(\n        'Other Sale Description',\n    )\n", "code_toks_joined": "class product_template ( models . Model ) : <NEWLINE> <INDENT> _inherit = <STRING> <NEWLINE> other_sale_description = fields . Char ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'product.template'", "'Other Sale Description'"]}}], ["7ac0ba0b80c8223326a748d2864f644e", {"code_string": "class VoteUpCommentAction(VoteUpAction):\n    def repute_users(self):\n        pass\n    def process_action(self):\n        self.process_vote_action(1)\n    def cancel_action(self):\n        super(VoteUpAction, self).cancel_action()\n    def describe(self, viewer = None):\n        return self.describe_vote(_(\"liked\"), viewer)\n", "code_toks_joined": "class VoteUpCommentAction ( VoteUpAction ) : <NEWLINE> <INDENT> def repute_users ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def process_action ( self ) : <NEWLINE> <INDENT> self . process_vote_action ( 1 ) <NEWLINE> <DEDENT> def cancel_action ( self ) : <NEWLINE> <INDENT> super ( VoteUpAction , self ) . cancel_action ( ) <NEWLINE> <DEDENT> def describe ( self , viewer = None ) : <NEWLINE> <INDENT> return self . describe_vote ( _ ( <STRING> ) , viewer ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"liked\""]}}], ["48fd4cffd1e87813d826776a780a6525", {"code_string": "def __init__(self, parent = None):\n    super().__init__(parent)\n    self.player = Player()\n    self.resize(15, 15)\n    self._current_mode = self.player.playback_mode\n    self._set_mode()\n", "code_toks_joined": "def __init__ ( self , parent = None ) : <NEWLINE> <INDENT> super ( ) . __init__ ( parent ) <NEWLINE> self . player = Player ( ) <NEWLINE> self . resize ( 15 , 15 ) <NEWLINE> self . _current_mode = self . player . playback_mode <NEWLINE> self . _set_mode ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["3b492267cf80cb6d1650df00e895c34d", {"code_string": "def request(self, path, ** kwargs):\n    \"\"\"Makes a request to one of the routes exposed by this test\"\"\"\n    self.http_client.fetch(self.get_url(path), self.stop, ** kwargs)\n    return self.wait()\n", "code_toks_joined": "def request ( self , path , ** kwargs ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . http_client . fetch ( self . get_url ( path ) , self . stop , ** kwargs ) <NEWLINE> return self . wait ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Makes a request to one of the routes exposed by this test\"\"\""]}}], ["8a90b0741f6e80142f2e1a74d540fd13", {"code_string": "from golem.appconfig import CommonConfig\nfrom golem.core.simpleconfig import SimpleConfig\nfrom golem.testutils import TempDirFixture\n", "code_toks_joined": "from golem . appconfig import CommonConfig <NEWLINE> from golem . core . simpleconfig import SimpleConfig <NEWLINE> from golem . testutils import TempDirFixture <NEWLINE>", "anonymize_dict": {}}], ["c9bbb64e7dcdb421052e643e5ea2dde1", {"code_string": "def txt_to_cfg(pos):\n    file = 'grammar/%s' % pos\n    lines = open(file).readlines()\n    for line in lines:\n        word = line.strip()\n        word = word.replace(' ', '_')\n        rule = \"%s -> '%s'\" %(pos, word)\n        yield rule\n", "code_toks_joined": "def txt_to_cfg ( pos ) : <NEWLINE> <INDENT> file = <STRING> % pos <NEWLINE> lines = open ( file ) . readlines ( ) <NEWLINE> for line in lines : <NEWLINE> <INDENT> word = line . strip ( ) <NEWLINE> word = word . replace ( <STRING> , <STRING> ) <NEWLINE> rule = <STRING> % ( pos , word ) <NEWLINE> yield rule <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'grammar/%s'", "' '", "'_'", "\"%s -> '%s'\""]}}], ["b4c14c03f3ea5d3878225c5cef1f4ee8", {"code_string": "def decode_mixture(P, entropy_cutoff):\n    \"\"\" Given P, a (|sequences| x |models|)-matrix where P_{ij} =\"\"\"\n    nr_seqs = numarray.shape(P)[0]\n    result = [None] * nr_seqs\n    for i in xrange(nr_seqs):\n        e = Entropy(P[i])\n        if e < entropy_cutoff:\n            result[i] = int(numarray.argmax(P[i]))\n    return result\n", "code_toks_joined": "def decode_mixture ( P , entropy_cutoff ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> nr_seqs = numarray . shape ( P ) [ 0 ] <NEWLINE> result = [ None ] * nr_seqs <NEWLINE> for i in xrange ( nr_seqs ) : <NEWLINE> <INDENT> e = Entropy ( P [ i ] ) <NEWLINE> if e < entropy_cutoff : <NEWLINE> <INDENT> result [ i ] = int ( numarray . argmax ( P [ i ] ) ) <NEWLINE> <DEDENT> <DEDENT> return result <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Given P, a (|sequences| x |models|)-matrix where P_{ij} =\"\"\""]}}], ["1ba7bb4698e70075633cf8a8ddd53832", {"code_string": "__author__ = \"Jo\u00e3o Magalh\u00e3es <joamag@hive.pt>\"\n\"\"\" The author(s) of the module \"\"\"\n__version__ = \"1.0.0\"\n\"\"\" The version of the module \"\"\"\n__revision__ = \"$LastChangedRevision$\"\n\"\"\" The revision number of the module \"\"\"\n__date__ = \"$LastChangedDate$\"\n\"\"\" The last change date of the module \"\"\"\n__copyright__ = \"Copyright (c) 2008-2015 Hive Solutions Lda.\"\n\"\"\" The copyright for the module \"\"\"\n__license__ = \"Apache License, Version 2.0\"\n\"\"\" The license for the module \"\"\"\nimport unittest\nimport appier\n", "code_toks_joined": "__author__ = <STRING> <NEWLINE> <STRING> <NEWLINE> __version__ = <STRING> <NEWLINE> <STRING> <NEWLINE> __revision__ = <STRING> <NEWLINE> <STRING> <NEWLINE> __date__ = <STRING> <NEWLINE> <STRING> <NEWLINE> __copyright__ = <STRING> <NEWLINE> <STRING> <NEWLINE> __license__ = <STRING> <NEWLINE> <STRING> <NEWLINE> import unittest <NEWLINE> import appier <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"Jo\u00e3o Magalh\u00e3es <joamag@hive.pt>\"", "\"\"\" The author(s) of the module \"\"\"", "\"1.0.0\"", "\"\"\" The version of the module \"\"\"", "\"$LastChangedRevision$\"", "\"\"\" The revision number of the module \"\"\"", "\"$LastChangedDate$\"", "\"\"\" The last change date of the module \"\"\"", "\"Copyright (c) 2008-2015 Hive Solutions Lda.\"", "\"\"\" The copyright for the module \"\"\"", "\"Apache License, Version 2.0\"", "\"\"\" The license for the module \"\"\""]}}], ["8aebe159f5670a0791d87361fc7849af", {"code_string": "def _write_lcd(self):\n    if self.ablib_available:\n        self.lcd.setcurpos(0, 0)\n        self.lcd.putstring('Hello World :-)')\n        timestring = time.strftime(\"%d.%m.  %H:%M:%S\")\n        self.lcd.setcurpos(0, 1)\n        self.lcd.putstring(timestring)\n", "code_toks_joined": "def _write_lcd ( self ) : <NEWLINE> <INDENT> if self . ablib_available : <NEWLINE> <INDENT> self . lcd . setcurpos ( 0 , 0 ) <NEWLINE> self . lcd . putstring ( <STRING> ) <NEWLINE> timestring = time . strftime ( <STRING> ) <NEWLINE> self . lcd . setcurpos ( 0 , 1 ) <NEWLINE> self . lcd . putstring ( timestring ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Hello World :-)'", "\"%d.%m.  %H:%M:%S\""]}}], ["eaa78347eacbbf88e25b9cf6a4e0dc75", {"code_string": "def load_abstracts():\n    f = open(p + '/abstracts.csv', 'rU')\n    reader = csv.reader(f)\n    for row in reader:\n        papers[row[0]] = {\n            'title': unicode(row[1], \"ISO-8859-1\"),\n            'abstract': unicode(row[2], \"ISO-8859-1\")}\n", "code_toks_joined": "def load_abstracts ( ) : <NEWLINE> <INDENT> f = open ( p + <STRING> , <STRING> ) <NEWLINE> reader = csv . reader ( f ) <NEWLINE> for row in reader : <NEWLINE> <INDENT> papers [ row [ 0 ] ] = { <NEWLINE> <INDENT> <STRING> : unicode ( row [ 1 ] , <STRING> ) , <NEWLINE> <STRING> : unicode ( row [ 2 ] , <STRING> ) } <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/abstracts.csv'", "'rU'", "'title'", "\"ISO-8859-1\"", "'abstract'", "\"ISO-8859-1\""]}}], ["c8230c1c9dff73a1f2ae279cbff458c5", {"code_string": "def setController(self, controller):\n    \"\"\"Associates a controller to the view.\"\"\"\n    self._controller = controller\n    pass\n", "code_toks_joined": "def setController ( self , controller ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . _controller = controller <NEWLINE> pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Associates a controller to the view.\"\"\""]}}], ["919682bc39c64fd8cff5783b170a904b", {"code_string": "\"\"\"Test than modules in gevent.green package are indeed green.\"\"\"\nimport greentest\nfrom gevent import monkey\nmonkey.patch_all()\nimport sys\ntry:\n    import urllib2\nexcept ImportError:\n    from urllib import request as urllib2\ntry:\n    import BaseHTTPServer\nexcept ImportError:\n    from http import server as BaseHTTPServer\nimport gevent\n", "code_toks_joined": "<STRING> <NEWLINE> import greentest <NEWLINE> from gevent import monkey <NEWLINE> monkey . patch_all ( ) <NEWLINE> import sys <NEWLINE> try : <NEWLINE> <INDENT> import urllib2 <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> from urllib import request as urllib2 <NEWLINE> <DEDENT> try : <NEWLINE> <INDENT> import BaseHTTPServer <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> from http import server as BaseHTTPServer <NEWLINE> <DEDENT> import gevent <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Test than modules in gevent.green package are indeed green.\"\"\""]}}], ["5e40b360525a93f82a3af0e0763491e9", {"code_string": "from django.http import HttpResponse\nfrom django.template import RequestContext, loader\nfrom fedinv import settings\nfrom event.forms import EventForm\nfrom swag.models import SwagType\n", "code_toks_joined": "from django . http import HttpResponse <NEWLINE> from django . template import RequestContext , loader <NEWLINE> from fedinv import settings <NEWLINE> from event . forms import EventForm <NEWLINE> from swag . models import SwagType <NEWLINE>", "anonymize_dict": {}}], ["db9c1b4152ea918247680228f0337f74", {"code_string": "import os\nimport flask_app\nfrom zair import __all__\napp = flask_app.app\nif __name__ == '__main__':\n    app.run(host = \"0.0.0.0\", port = int(os.environ.get(\"PORT\", 8080)), debug = app.config['DEBUG'])\n", "code_toks_joined": "import os <NEWLINE> import flask_app <NEWLINE> from zair import __all__ <NEWLINE> app = flask_app . app <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> app . run ( host = <STRING> , port = int ( os . environ . get ( <STRING> , 8080 ) ) , debug = app . config [ <STRING> ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'__main__'", "\"0.0.0.0\"", "\"PORT\"", "'DEBUG'"]}}], ["2570bc40e87f14fd6c950bb4e9a622aa", {"code_string": "class FixedLastmodMixedSitemap(Sitemap):\n    changefreq = \"never\"\n    priority = 0.5\n    location = '/location/'\n    loop = 0\n    def items(self):\n        o1 = TestModel()\n        o1.lastmod = datetime(2013, 3, 13, 10, 0, 0)\n        o2 = TestModel()\n        return[o1, o2]\n", "code_toks_joined": "class FixedLastmodMixedSitemap ( Sitemap ) : <NEWLINE> <INDENT> changefreq = <STRING> <NEWLINE> priority = 0.5 <NEWLINE> location = <STRING> <NEWLINE> loop = 0 <NEWLINE> def items ( self ) : <NEWLINE> <INDENT> o1 = TestModel ( ) <NEWLINE> o1 . lastmod = datetime ( 2013 , 3 , 13 , 10 , 0 , 0 ) <NEWLINE> o2 = TestModel ( ) <NEWLINE> return [ o1 , o2 ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"never\"", "'/location/'"]}}], ["9a63670a1f6a002252baf06779962df1", {"code_string": "def upgrade():\n    op.alter_column('category', 'name',\n        existing_type = mysql.VARCHAR(length = 20),\n        nullable = False)\n    op.add_column('post', sa.Column('body_html', sa.Text(), nullable = True))\n", "code_toks_joined": "def upgrade ( ) : <NEWLINE> <INDENT> op . alter_column ( <STRING> , <STRING> , <NEWLINE> <INDENT> existing_type = mysql . VARCHAR ( length = 20 ) , <NEWLINE> nullable = False ) <NEWLINE> <DEDENT> op . add_column ( <STRING> , sa . Column ( <STRING> , sa . Text ( ) , nullable = True ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'category'", "'name'", "'post'", "'body_html'"]}}], ["39a21c2c26bcc5e4deba95d79c53cf48", {"code_string": "class DateTimeGenerator(TemplateArgsGenerator):\n    def __init__(self, name, format):\n        self.name = name\n        self.format = format\n    def gen_args(self):\n        yield self.name, datetime.datetime.now().strftime(self.format)\n", "code_toks_joined": "class DateTimeGenerator ( TemplateArgsGenerator ) : <NEWLINE> <INDENT> def __init__ ( self , name , format ) : <NEWLINE> <INDENT> self . name = name <NEWLINE> self . format = format <NEWLINE> <DEDENT> def gen_args ( self ) : <NEWLINE> <INDENT> yield self . name , datetime . datetime . now ( ) . strftime ( self . format ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["73b64606341cf30799ee95aec7d14941", {"code_string": "\"\"\"superlists URL Configuration\"\"\"\nfrom django.conf.urls import url\nimport lists.views as views\nurlpatterns = [\n    url(r'^new$', views.new_list, name = 'new_list'),\n    url(r'^(\\d+)/$', views.view_list, name = 'view_list'),\n]\n", "code_toks_joined": "<STRING> <NEWLINE> from django . conf . urls import url <NEWLINE> import lists . views as views <NEWLINE> urlpatterns = [ <NEWLINE> <INDENT> url ( <STRING> , views . new_list , name = <STRING> ) , <NEWLINE> url ( <STRING> , views . view_list , name = <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"superlists URL Configuration\"\"\"", "r'^new$'", "'new_list'", "r'^(\\d+)/$'", "'view_list'"]}}], ["1d4a8e905c3befc38f766c3160502131", {"code_string": "def unctrl(ch):\n    '''Return a a printable representation of character ch.'''\n    return b2s(curses.unctrl(ch))\n", "code_toks_joined": "def unctrl ( ch ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return b2s ( curses . unctrl ( ch ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Return a a printable representation of character ch.'''"]}}], ["0daba9ebea2537552710a3e41e0b4895", {"code_string": "class MicrocomputerAdmin(admin.ModelAdmin):\n    list_display = ('model', 'name')\n    ordering = ('model', )\n", "code_toks_joined": "class MicrocomputerAdmin ( admin . ModelAdmin ) : <NEWLINE> <INDENT> list_display = ( <STRING> , <STRING> ) <NEWLINE> ordering = ( <STRING> , ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'model'", "'name'", "'model'"]}}], ["5c095ab2e6c71b727516609d1938de17", {"code_string": "def run(self):\n    for serieLocalID in self.toRefresh.copy():\n        if serieLocalID in self.updateInProgress:\n            continue\n        task = DownloadSerieTask(serieLocalID)\n        runnable = Runnable(task)\n        runnable.task.serieUpdated.connect(self._serieUpdated)\n        runnable.task.serieUpdateStatus.connect(self.serieUpdateStatus)\n        self.threadPool.tryStart(runnable)\n        self.toRefresh.discard(serieLocalID)\n        self.updateInProgress.add(serieLocalID)\n", "code_toks_joined": "def run ( self ) : <NEWLINE> <INDENT> for serieLocalID in self . toRefresh . copy ( ) : <NEWLINE> <INDENT> if serieLocalID in self . updateInProgress : <NEWLINE> <INDENT> continue <NEWLINE> <DEDENT> task = DownloadSerieTask ( serieLocalID ) <NEWLINE> runnable = Runnable ( task ) <NEWLINE> runnable . task . serieUpdated . connect ( self . _serieUpdated ) <NEWLINE> runnable . task . serieUpdateStatus . connect ( self . serieUpdateStatus ) <NEWLINE> self . threadPool . tryStart ( runnable ) <NEWLINE> self . toRefresh . discard ( serieLocalID ) <NEWLINE> self . updateInProgress . add ( serieLocalID ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["e2b58bb1bc21916a6a4db071f433bb33", {"code_string": "'''swap case: swap the lower case to upper and vice-versa for a given string'''\nmsg = input()\nprint(msg.swapcase())\n", "code_toks_joined": "<STRING> <NEWLINE> msg = input ( ) <NEWLINE> print ( msg . swapcase ( ) ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''swap case: swap the lower case to upper and vice-versa for a given string'''"]}}], ["584f1b44de1da2eef1394498f1e6ce3f", {"code_string": "def remove(self, collection_name, criteria):\n    api = self.collection(collection_name)\n    return api.remove(criteria)\n", "code_toks_joined": "def remove ( self , collection_name , criteria ) : <NEWLINE> <INDENT> api = self . collection ( collection_name ) <NEWLINE> return api . remove ( criteria ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["0f23d8574500e147201709b4bf5728c9", {"code_string": "from oslo_log import log as logging\nfrom sqlalchemy import Column, ForeignKey, MetaData, Table\nfrom sqlalchemy import Boolean, DateTime, Integer, String\nfrom cinder.i18n import _\nLOG = logging.getLogger(__name__)\n", "code_toks_joined": "from oslo_log import log as logging <NEWLINE> from sqlalchemy import Column , ForeignKey , MetaData , Table <NEWLINE> from sqlalchemy import Boolean , DateTime , Integer , String <NEWLINE> from cinder . i18n import _ <NEWLINE> LOG = logging . getLogger ( __name__ ) <NEWLINE>", "anonymize_dict": {}}], ["b45157fd64a74cac8c53156568adfe3c", {"code_string": "\"\"\"A class to start/stop the apache http server used by layout tests.\"\"\"\nimport logging\nimport os\nimport re\nimport socket\nimport sys\nfrom webkitpy.layout_tests.servers import http_server_base\n_log = logging.getLogger(__name__)\n", "code_toks_joined": "<STRING> <NEWLINE> import logging <NEWLINE> import os <NEWLINE> import re <NEWLINE> import socket <NEWLINE> import sys <NEWLINE> from webkitpy . layout_tests . servers import http_server_base <NEWLINE> _log = logging . getLogger ( __name__ ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"A class to start/stop the apache http server used by layout tests.\"\"\""]}}], ["1ab8e5153229602a6344adfe0b905312", {"code_string": "def register():\n    bpy.utils.register_class(BisectMirror)\n    bpy.utils.register_class(AutoMirror)\n    bpy.utils.register_class(AlignVertices)\n", "code_toks_joined": "def register ( ) : <NEWLINE> <INDENT> bpy . utils . register_class ( BisectMirror ) <NEWLINE> bpy . utils . register_class ( AutoMirror ) <NEWLINE> bpy . utils . register_class ( AlignVertices ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["d207ecca848de3b8cbada47e22fdad32", {"code_string": "from setuptools import setup\nsetup(\n    name = 'pimp_board',\n    packages = ['pimp_board'],\n    include_package_data = True,\n    install_requires = [\n        'flask',\n        'psycopg2',\n        'Flask-SQLAlchemy',\n        'Flask-Migrate',\n        'flask-login==0.2.7',\n        'bcrypt'\n    ],\n)\n", "code_toks_joined": "from setuptools import setup <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> include_package_data = True , <NEWLINE> install_requires = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> <NEWLINE> <DEDENT> ] , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'pimp_board'", "'pimp_board'", "'flask'", "'psycopg2'", "'Flask-SQLAlchemy'", "'Flask-Migrate'", "'flask-login==0.2.7'", "'bcrypt'"]}}], ["6f7dadf00bd677da1063d8e14b485064", {"code_string": "from zipa import api_github_com as github\nrepos = github.orgs.django.repos\nfor repo in repos[{'sort': 'created', 'direction': 'desc'}]:\n    print(repo.name)\n", "code_toks_joined": "from zipa import api_github_com as github <NEWLINE> repos = github . orgs . django . repos <NEWLINE> for repo in repos [ { <STRING> : <STRING> , <STRING> : <STRING> } ] : <NEWLINE> <INDENT> print ( repo . name ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'sort'", "'created'", "'direction'", "'desc'"]}}], ["9ea82c5b5be4c7c975e5303efd1d2704", {"code_string": "def m(i, j, L, M):\n    if M - s(i, j, L) >= 0:\n        return 0\n    else:\n        cont = inf\n        for k in range(i, j):\n            aux = S(i, k, M, L) + m(k + 1, j, L, M)\n            if aux < cont:\n                cont = aux\n        return cont\n", "code_toks_joined": "def m ( i , j , L , M ) : <NEWLINE> <INDENT> if M - s ( i , j , L ) >= 0 : <NEWLINE> <INDENT> return 0 <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> cont = inf <NEWLINE> for k in range ( i , j ) : <NEWLINE> <INDENT> aux = S ( i , k , M , L ) + m ( k + 1 , j , L , M ) <NEWLINE> if aux < cont : <NEWLINE> <INDENT> cont = aux <NEWLINE> <DEDENT> <DEDENT> return cont <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["a3cb4738871f876e8184218b4d2b01d2", {"code_string": "def list_ace(archive, compression, cmd, verbosity, interactive):\n    \"\"\"List an ACE archive.\"\"\"\n    cmdlist = [cmd]\n    if verbosity > 1:\n        cmdlist.append('v')\n    else:\n        cmdlist.append('l')\n    cmdlist.append(archive)\n    return cmdlist\n", "code_toks_joined": "def list_ace ( archive , compression , cmd , verbosity , interactive ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> cmdlist = [ cmd ] <NEWLINE> if verbosity > 1 : <NEWLINE> <INDENT> cmdlist . append ( <STRING> ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> cmdlist . append ( <STRING> ) <NEWLINE> <DEDENT> cmdlist . append ( archive ) <NEWLINE> return cmdlist <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"List an ACE archive.\"\"\"", "'v'", "'l'"]}}], ["d7606a735258fb96703ad4d89237e021", {"code_string": "from __future__ import(absolute_import, division, print_function)\nfrom six.moves import(filter, input, map, range, zip)\nimport iris.tests as tests\nfrom iris.std_names import STD_NAMES\n", "code_toks_joined": "from __future__ import ( absolute_import , division , print_function ) <NEWLINE> from six . moves import ( filter , input , map , range , zip ) <NEWLINE> import iris . tests as tests <NEWLINE> from iris . std_names import STD_NAMES <NEWLINE>", "anonymize_dict": {}}], ["2859e1ba03cfe03b158ed78ddcc8ab86", {"code_string": "def _killcurses(signal, frame):\n    \"\"\" Kills Application if curses was used \"\"\"\n    curses.echo()\n    curses.nocbreak()\n    curses.endwin()\n    sys.exit(0)\n", "code_toks_joined": "def _killcurses ( signal , frame ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> curses . echo ( ) <NEWLINE> curses . nocbreak ( ) <NEWLINE> curses . endwin ( ) <NEWLINE> sys . exit ( 0 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Kills Application if curses was used \"\"\""]}}], ["b1613e33c2c3651e9269603d55c01f06", {"code_string": "'''Bryan Bonvallet'''\nfrom XdY import *\nfrom series import InfiniteSequence\n", "code_toks_joined": "<STRING> <NEWLINE> from XdY import * <NEWLINE> from series import InfiniteSequence <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Bryan Bonvallet'''"]}}], ["ca536797a7d5e6933e70c6044c7ea252", {"code_string": "def supress_warnings():\n    original_warn = warnings.warn\n    warnings.warn = silent_warnings\n    yield\n    warnings.warn = original_warn\n", "code_toks_joined": "def supress_warnings ( ) : <NEWLINE> <INDENT> original_warn = warnings . warn <NEWLINE> warnings . warn = silent_warnings <NEWLINE> yield <NEWLINE> warnings . warn = original_warn <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["69c15e1f8f8b4e659bad7634fe18d512", {"code_string": "class SetLangNavPlugin(BaseAdminPlugin):\n    def block_top_navmenu(self, context, nodes):\n        context = get_context_dict(context)\n        context['redirect_to'] = self.request.get_full_path()\n        nodes.append(loader.render_to_string('xadmin/blocks/comm.top.setlang.html', context = context))\n", "code_toks_joined": "class SetLangNavPlugin ( BaseAdminPlugin ) : <NEWLINE> <INDENT> def block_top_navmenu ( self , context , nodes ) : <NEWLINE> <INDENT> context = get_context_dict ( context ) <NEWLINE> context [ <STRING> ] = self . request . get_full_path ( ) <NEWLINE> nodes . append ( loader . render_to_string ( <STRING> , context = context ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'redirect_to'", "'xadmin/blocks/comm.top.setlang.html'"]}}], ["1ec8d47945fdc10a108c29ddaddd8477", {"code_string": "def calculate_perplexity(log_probs):\n    perp = 0\n    for p in log_probs:\n        perp += - p\n    return np.exp(perp / len(log_probs))\n", "code_toks_joined": "def calculate_perplexity ( log_probs ) : <NEWLINE> <INDENT> perp = 0 <NEWLINE> for p in log_probs : <NEWLINE> <INDENT> perp += - p <NEWLINE> <DEDENT> return np . exp ( perp / len ( log_probs ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["6f708363f78ced834fe6f4ba8bd52745", {"code_string": "class DetailsMixin(DescriptionMixin):\n    def __init__(self, * args, ** kwargs):\n        self.required = kwargs.pop('required', None)\n        super(DetailsMixin, self).__init__(* args, ** kwargs)\n", "code_toks_joined": "class DetailsMixin ( DescriptionMixin ) : <NEWLINE> <INDENT> def __init__ ( self , * args , ** kwargs ) : <NEWLINE> <INDENT> self . required = kwargs . pop ( <STRING> , None ) <NEWLINE> super ( DetailsMixin , self ) . __init__ ( * args , ** kwargs ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'required'"]}}], ["e85647913e8f4e26eb69c9432f9355cf", {"code_string": "def implied_subfeature(feature, subvalue, value_string):\n    assert isinstance(feature, Feature)\n    assert isinstance(subvalue, basestring)\n    assert isinstance(value_string, basestring)\n    result = __find_implied_subfeature(feature, subvalue, value_string)\n    if not result:\n        raise InvalidValue(\"'%s' is not a known subfeature value of '%s%s'\" %(subvalue, feature, value_string))\n    return result\n", "code_toks_joined": "def implied_subfeature ( feature , subvalue , value_string ) : <NEWLINE> <INDENT> assert isinstance ( feature , Feature ) <NEWLINE> assert isinstance ( subvalue , basestring ) <NEWLINE> assert isinstance ( value_string , basestring ) <NEWLINE> result = __find_implied_subfeature ( feature , subvalue , value_string ) <NEWLINE> if not result : <NEWLINE> <INDENT> raise InvalidValue ( <STRING> % ( subvalue , feature , value_string ) ) <NEWLINE> <DEDENT> return result <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"'%s' is not a known subfeature value of '%s%s'\""]}}], ["f8d208b6bc5c5061c1220dc78e6bc394", {"code_string": "from nose.tools import eq_, raises\nfrom nanodb_driver.driver import Driver, ConnectionTimedOut, ServerRequestError\nfrom test.helper import MockServer\n", "code_toks_joined": "from nose . tools import eq_ , raises <NEWLINE> from nanodb_driver . driver import Driver , ConnectionTimedOut , ServerRequestError <NEWLINE> from test . helper import MockServer <NEWLINE>", "anonymize_dict": {}}], ["2c69778ed0e74273d8ebc84fad840a3d", {"code_string": "import codecs\nfrom ansiblereview import Result, Error\nfrom ansiblelint.utils import get_action_tasks, normalize_task, parse_yaml_linenumbers\n", "code_toks_joined": "import codecs <NEWLINE> from ansiblereview import Result , Error <NEWLINE> from ansiblelint . utils import get_action_tasks , normalize_task , parse_yaml_linenumbers <NEWLINE>", "anonymize_dict": {}}], ["4394040b98f53fa70f7c542e26ab3037", {"code_string": "def token(self, token):\n    \"\"\"Set a token for the request (chainable).\"\"\"\n    return self.header(\"Authorization\", \"Bearer {}\".format(token))\n", "code_toks_joined": "def token ( self , token ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . header ( <STRING> , <STRING> . format ( token ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Set a token for the request (chainable).\"\"\"", "\"Authorization\"", "\"Bearer {}\""]}}], ["9d2bc8d5c0e4a370e3bd1d7d35d83355", {"code_string": "__version__ = '0.5.0'\n__version_info__ = (0, 5, 0)\nfrom django.utils.translation import ugettext_lazy as _\n", "code_toks_joined": "__version__ = <STRING> <NEWLINE> __version_info__ = ( 0 , 5 , 0 ) <NEWLINE> from django . utils . translation import ugettext_lazy as _ <NEWLINE>", "anonymize_dict": {"<STRING>": ["'0.5.0'"]}}], ["ab1b57e19685b02c1355ac11355799b7", {"code_string": "def match(self, vistrail, action):\n    self.setCurrentVistrail(vistrail)\n    query = self.queries_by_vistrail[vistrail]\n    return query.match(vistrail, action)\n", "code_toks_joined": "def match ( self , vistrail , action ) : <NEWLINE> <INDENT> self . setCurrentVistrail ( vistrail ) <NEWLINE> query = self . queries_by_vistrail [ vistrail ] <NEWLINE> return query . match ( vistrail , action ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["bcb958b932dad7c1d53b65a1d7779b04", {"code_string": "def _get_prop(self, prop):\n    if prop == 'src':\n        return self.get_src()\n    return super(self.__class__, self)._get_prop(prop)\n", "code_toks_joined": "def _get_prop ( self , prop ) : <NEWLINE> <INDENT> if prop == <STRING> : <NEWLINE> <INDENT> return self . get_src ( ) <NEWLINE> <DEDENT> return super ( self . __class__ , self ) . _get_prop ( prop ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'src'"]}}], ["0196c66ac2f758ce45d06fa5fb23241b", {"code_string": "from sympy import diff, Eq, init_printing, pprint, symbols, simplify\ninit_printing()\nC, Ca, Cb, f, F, rhoS = symbols('C Ca Cb f F rhoS')\nchemenergy = rhoS *(C - Ca) ** 2 *(Cb - C) ** 2\npprint(Eq(F, simplify(chemenergy)))\npprint(Eq(f, simplify(diff(chemenergy, C))))\n", "code_toks_joined": "from sympy import diff , Eq , init_printing , pprint , symbols , simplify <NEWLINE> init_printing ( ) <NEWLINE> C , Ca , Cb , f , F , rhoS = symbols ( <STRING> ) <NEWLINE> chemenergy = rhoS * ( C - Ca ) ** 2 * ( Cb - C ) ** 2 <NEWLINE> pprint ( Eq ( F , simplify ( chemenergy ) ) ) <NEWLINE> pprint ( Eq ( f , simplify ( diff ( chemenergy , C ) ) ) ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'C Ca Cb f F rhoS'"]}}], ["70a1e3a03a996be072638ecd5e3a812f", {"code_string": "def __nonzero__(self):\n    \"\"\"Count as nonzero only if a valid repeat rule is defined.\"\"\"\n    return self._rrule is not None\n", "code_toks_joined": "def __nonzero__ ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . _rrule is not None <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Count as nonzero only if a valid repeat rule is defined.\"\"\""]}}], ["4394d79bd07d71cf8f7f0ae36982ef23", {"code_string": "def get_path_hash(self, unhashed_path):\n    if self.hash_cache.get_path_hash(unhashed_path) is None:\n        file = self.get_file(unhashed_path)\n        if file is None:\n            return None\n        try:\n            hash_str = get_hash(file.handle)\n            self.hash_cache.set_path_hash(unhashed_path, hash_str)\n        finally:\n            file.handle.close()\n    return self.hash_cache.get_path_hash(unhashed_path)\n", "code_toks_joined": "def get_path_hash ( self , unhashed_path ) : <NEWLINE> <INDENT> if self . hash_cache . get_path_hash ( unhashed_path ) is None : <NEWLINE> <INDENT> file = self . get_file ( unhashed_path ) <NEWLINE> if file is None : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> try : <NEWLINE> <INDENT> hash_str = get_hash ( file . handle ) <NEWLINE> self . hash_cache . set_path_hash ( unhashed_path , hash_str ) <NEWLINE> <DEDENT> finally : <NEWLINE> <INDENT> file . handle . close ( ) <NEWLINE> <DEDENT> <DEDENT> return self . hash_cache . get_path_hash ( unhashed_path ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["6f463e50df0399f16ae48571402e9e33", {"code_string": "class Command(BaseCommand):\n    help = 'Send email notifications for unpaid order.'\n    def handle(self, * args, ** options):\n        email_unpaid_orders(verbose = options['verbosity'])\n        if options['verbosity'] > 0:\n            self.stdout.write(self.style.SUCCESS('Successfully sent email notifications for unpaid orders.'))\n", "code_toks_joined": "class Command ( BaseCommand ) : <NEWLINE> <INDENT> help = <STRING> <NEWLINE> def handle ( self , * args , ** options ) : <NEWLINE> <INDENT> email_unpaid_orders ( verbose = options [ <STRING> ] ) <NEWLINE> if options [ <STRING> ] > 0 : <NEWLINE> <INDENT> self . stdout . write ( self . style . SUCCESS ( <STRING> ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Send email notifications for unpaid order.'", "'verbosity'", "'verbosity'", "'Successfully sent email notifications for unpaid orders.'"]}}], ["fd847b5a9e800bda4984b9bae794993c", {"code_string": "def build_directory():\n    if os.path.exists('locale'):\n        pass\n    else:\n        os.mkdir('locale')\n    if os.path.exists(whoosh_database):\n        pass\n    else:\n        os.makedirs(whoosh_database)\n", "code_toks_joined": "def build_directory ( ) : <NEWLINE> <INDENT> if os . path . exists ( <STRING> ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> os . mkdir ( <STRING> ) <NEWLINE> <DEDENT> if os . path . exists ( whoosh_database ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> os . makedirs ( whoosh_database ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'locale'", "'locale'"]}}], ["7ec14b086278dcfd3265ac3a62eb0734", {"code_string": "def forwards(self, orm):\n    db.add_column(u'articles_author', 'slug',\n        self.gf('autoslug.fields.AutoSlugField')(unique_with = (), max_length = 50, blank = True, populate_from = None, unique = True, null = True),\n        keep_default = False)\n", "code_toks_joined": "def forwards ( self , orm ) : <NEWLINE> <INDENT> db . add_column ( <STRING> , <STRING> , <NEWLINE> <INDENT> self . gf ( <STRING> ) ( unique_with = ( ) , max_length = 50 , blank = True , populate_from = None , unique = True , null = True ) , <NEWLINE> keep_default = False ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["u'articles_author'", "'slug'", "'autoslug.fields.AutoSlugField'"]}}], ["45ae73a4cd2710e0479f7de3c524fa23", {"code_string": "import json\nimport httpretty\nfrom w3af_api_client import Connection\nfrom w3af_api_client.tests.base import BaseAPITest\nfrom w3af_api_client.tests.test_scan import INDEX_RESPONSE, VERSION_RESPONSE\nSCAN_LIST_RESPONSE = json.dumps({'items': [{'id': 0,\n    'href': '/scans/0',\n    'target_urls': [''],\n    'status': 'Running',\n    'errors': True},\n    {'id': 1,\n    'href': '/scans/1',\n    'target_urls': [''],\n    'status': 'Stopped',\n    'errors': False}\n    ]})\n", "code_toks_joined": "import json <NEWLINE> import httpretty <NEWLINE> from w3af_api_client import Connection <NEWLINE> from w3af_api_client . tests . base import BaseAPITest <NEWLINE> from w3af_api_client . tests . test_scan import INDEX_RESPONSE , VERSION_RESPONSE <NEWLINE> SCAN_LIST_RESPONSE = json . dumps ( { <STRING> : [ { <STRING> : 0 , <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : [ <STRING> ] , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : True } , <NEWLINE> { <STRING> : 1 , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : [ <STRING> ] , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : False } <NEWLINE> ] } ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'items'", "'id'", "'href'", "'/scans/0'", "'target_urls'", "''", "'status'", "'Running'", "'errors'", "'id'", "'href'", "'/scans/1'", "'target_urls'", "''", "'status'", "'Stopped'", "'errors'"]}}], ["aaddfa14c467b7e82b6137b05533ff72", {"code_string": "from libopenzwave._version import __version__\nfrom libopenzwave._global import *\nfrom libopenzwave.manager import PyManager\nfrom libopenzwave.options import PyOptions\n", "code_toks_joined": "from libopenzwave . _version import __version__ <NEWLINE> from libopenzwave . _global import * <NEWLINE> from libopenzwave . manager import PyManager <NEWLINE> from libopenzwave . options import PyOptions <NEWLINE>", "anonymize_dict": {}}], ["c99a0729624192358c43d923903989e5", {"code_string": "class EfficientFib(object):\n    cache = {}\n    def calc(self, n):\n        if n < 2:\n            return n\n        if n in self.cache:\n            return self.cache[n]\n        else:\n            fibn = self.calc(n - 1) + self.calc(n - 2)\n            self.cache[n] = fibn\n            return fibn\n", "code_toks_joined": "class EfficientFib ( object ) : <NEWLINE> <INDENT> cache = { } <NEWLINE> def calc ( self , n ) : <NEWLINE> <INDENT> if n < 2 : <NEWLINE> <INDENT> return n <NEWLINE> <DEDENT> if n in self . cache : <NEWLINE> <INDENT> return self . cache [ n ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> fibn = self . calc ( n - 1 ) + self . calc ( n - 2 ) <NEWLINE> self . cache [ n ] = fibn <NEWLINE> return fibn <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["fbc9ba9c0048d6818e447f1338fc3722", {"code_string": "def test_set_single_string_contents_via_init(self):\n    x = FileMocker('foo')\n    self.assertEqual(x('anything.txt').read(), 'foo')\n", "code_toks_joined": "def test_set_single_string_contents_via_init ( self ) : <NEWLINE> <INDENT> x = FileMocker ( <STRING> ) <NEWLINE> self . assertEqual ( x ( <STRING> ) . read ( ) , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'foo'", "'anything.txt'", "'foo'"]}}], ["c28d36a75fbffef34823998c38634ff3", {"code_string": "\"\"\"`piece` contains class that represent the pieces that formed a chess game\"\"\"\nfrom math import hypot\nfrom math import sqrt\n", "code_toks_joined": "<STRING> <NEWLINE> from math import hypot <NEWLINE> from math import sqrt <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"`piece` contains class that represent the pieces that formed a chess game\"\"\""]}}], ["381e9cd1d34cd2bbe14ce24cd7097436", {"code_string": "def forwards(self, orm):\n    db.add_column('poll_rule', 'rule',\n        self.gf('django.db.models.fields.IntegerField')(max_length = 10, null = True),\n        keep_default = False)\n", "code_toks_joined": "def forwards ( self , orm ) : <NEWLINE> <INDENT> db . add_column ( <STRING> , <STRING> , <NEWLINE> <INDENT> self . gf ( <STRING> ) ( max_length = 10 , null = True ) , <NEWLINE> keep_default = False ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'poll_rule'", "'rule'", "'django.db.models.fields.IntegerField'"]}}], ["face60c67d9269bdca2576f66c6f6f34", {"code_string": "import datetime\nimport re\nfrom functools import total_ordering\nfrom math import floor\nfrom dateutil.parser import parse\nfrom bvggrabber.utils.format import timeformat\nfrom bvggrabber.utils.json import ObjectJSONEncoder\n", "code_toks_joined": "import datetime <NEWLINE> import re <NEWLINE> from functools import total_ordering <NEWLINE> from math import floor <NEWLINE> from dateutil . parser import parse <NEWLINE> from bvggrabber . utils . format import timeformat <NEWLINE> from bvggrabber . utils . json import ObjectJSONEncoder <NEWLINE>", "anonymize_dict": {}}], ["c5db11c6e1252e9da7c4070bb5e09cba", {"code_string": "def endsInLeft(self, str):\n    endsInRegex = \".*LEFT$\"\n    matching = bool(re.match(endsInRegex, str.upper()))\n    return matching\n", "code_toks_joined": "def endsInLeft ( self , str ) : <NEWLINE> <INDENT> endsInRegex = <STRING> <NEWLINE> matching = bool ( re . match ( endsInRegex , str . upper ( ) ) ) <NEWLINE> return matching <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\".*LEFT$\""]}}], ["01c3ece75be9a02b0a085b15198d01ce", {"code_string": "import sys\nimport platform\nif platform.python_version() < '2.7':\n    import unittest2 as unittest\nelse:\n    import unittest\nfrom os.path import dirname\nif __name__ == '__main__':\n    here = dirname(__file__)\n    sys.path.insert(0, here + '/..')\nimport ctrie\n", "code_toks_joined": "import sys <NEWLINE> import platform <NEWLINE> if platform . python_version ( ) < <STRING> : <NEWLINE> <INDENT> import unittest2 as unittest <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> import unittest <NEWLINE> <DEDENT> from os . path import dirname <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> here = dirname ( __file__ ) <NEWLINE> sys . path . insert ( 0 , here + <STRING> ) <NEWLINE> <DEDENT> import ctrie <NEWLINE>", "anonymize_dict": {"<STRING>": ["'2.7'", "'__main__'", "'/..'"]}}], ["e24b80af71592ba81371373345f5e5e6", {"code_string": "import sys\nimport os.path\nfrom django.core.management import execute_manager\nfrom django.core.management import setup_environ, execute_from_command_line\ntry:\n    import settings\nexcept ImportError:\n    sys.stderr.write(\"Error: Can't find the file 'settings.py' in the directory containing %r. It appears you've customized things.\\nYou'll have to run django-admin.py, passing it your settings module.\\n(If the file settings.py does indeed exist, it's causing an ImportError somehow.)\\n\" % __file__)\n    sys.exit(1)\nsys.path.insert(0, settings.PROJECT_ROOT.replace('/test_project', ''))\nsetup_environ(settings)\nif __name__ == \"__main__\":\n    execute_from_command_line()\n", "code_toks_joined": "import sys <NEWLINE> import os . path <NEWLINE> from django . core . management import execute_manager <NEWLINE> from django . core . management import setup_environ , execute_from_command_line <NEWLINE> try : <NEWLINE> <INDENT> import settings <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> sys . stderr . write ( <STRING> % __file__ ) <NEWLINE> sys . exit ( 1 ) <NEWLINE> <DEDENT> sys . path . insert ( 0 , settings . PROJECT_ROOT . replace ( <STRING> , <STRING> ) ) <NEWLINE> setup_environ ( settings ) <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> execute_from_command_line ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Error: Can't find the file 'settings.py' in the directory containing %r. It appears you've customized things.\\nYou'll have to run django-admin.py, passing it your settings module.\\n(If the file settings.py does indeed exist, it's causing an ImportError somehow.)\\n\"", "'/test_project'", "''", "\"__main__\""]}}], ["94ddbb423f3140ac83ad5e551d26b86d", {"code_string": "def __init__(self):\n    super(WalktoTemplateSM, self).__init__()\n    self.name = 'Walk to Template'\n    self.add_parameter('parameter_set', 'drc_step_2D')\n    self.add_parameter('hand_side', 'left')\n", "code_toks_joined": "def __init__ ( self ) : <NEWLINE> <INDENT> super ( WalktoTemplateSM , self ) . __init__ ( ) <NEWLINE> self . name = <STRING> <NEWLINE> self . add_parameter ( <STRING> , <STRING> ) <NEWLINE> self . add_parameter ( <STRING> , <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Walk to Template'", "'parameter_set'", "'drc_step_2D'", "'hand_side'", "'left'"]}}], ["a6e65e49e02ffdbbe5a411ebaeb42e11", {"code_string": "def __dateTimeChanged(self, qDateTime):\n    delimited = str(qDateTime.toString(QtCore.Qt.ISODate))\n    undelimited = \"%s%s%sT%s%s%s\" %(\n        delimited[0: 4],\n        delimited[5: 7],\n        delimited[8: 10],\n        delimited[11: 13],\n        delimited[14: 16],\n        delimited[17: 19],\n    )\n    with Gaffer.UndoContext(self.getPlug().ancestor(Gaffer.ScriptNode)):\n        self.getPlug().setValue(undelimited)\n", "code_toks_joined": "def __dateTimeChanged ( self , qDateTime ) : <NEWLINE> <INDENT> delimited = str ( qDateTime . toString ( QtCore . Qt . ISODate ) ) <NEWLINE> undelimited = <STRING> % ( <NEWLINE> <INDENT> delimited [ 0 : 4 ] , <NEWLINE> delimited [ 5 : 7 ] , <NEWLINE> delimited [ 8 : 10 ] , <NEWLINE> delimited [ 11 : 13 ] , <NEWLINE> delimited [ 14 : 16 ] , <NEWLINE> delimited [ 17 : 19 ] , <NEWLINE> <DEDENT> ) <NEWLINE> with Gaffer . UndoContext ( self . getPlug ( ) . ancestor ( Gaffer . ScriptNode ) ) : <NEWLINE> <INDENT> self . getPlug ( ) . setValue ( undelimited ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"%s%s%sT%s%s%s\""]}}], ["6fcaa66158293bb3d6c66aa245716745", {"code_string": "def recur_node(node, level = 0):\n    print(\"  \" + \"\\t\" * level + \"- \" + str(node))\n    for child in node.children:\n        recur_node(child, level + 1)\n", "code_toks_joined": "def recur_node ( node , level = 0 ) : <NEWLINE> <INDENT> print ( <STRING> + <STRING> * level + <STRING> + str ( node ) ) <NEWLINE> for child in node . children : <NEWLINE> <INDENT> recur_node ( child , level + 1 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"  \"", "\"\\t\"", "\"- \""]}}], ["0ebb39ca6f9ff16ca972448b7d67d769", {"code_string": "def backwards(self, orm):\n    db.add_column(u'photocontest_photo', 'thumbnail',\n        self.gf('django.db.models.fields.files.ImageField')(max_length = 100, null = True, blank = True),\n        keep_default = False)\n    raise RuntimeError(\"Cannot reverse this migration. 'Photo.photo' and its values cannot be restored.\")\n    db.alter_column(u'photocontest_photo', 'photo', self.gf('django.db.models.fields.files.ImageField')(max_length = 100))\n", "code_toks_joined": "def backwards ( self , orm ) : <NEWLINE> <INDENT> db . add_column ( <STRING> , <STRING> , <NEWLINE> <INDENT> self . gf ( <STRING> ) ( max_length = 100 , null = True , blank = True ) , <NEWLINE> keep_default = False ) <NEWLINE> <DEDENT> raise RuntimeError ( <STRING> ) <NEWLINE> db . alter_column ( <STRING> , <STRING> , self . gf ( <STRING> ) ( max_length = 100 ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["u'photocontest_photo'", "'thumbnail'", "'django.db.models.fields.files.ImageField'", "\"Cannot reverse this migration. 'Photo.photo' and its values cannot be restored.\"", "u'photocontest_photo'", "'photo'", "'django.db.models.fields.files.ImageField'"]}}], ["cb75db5a8b643e578585eb075192365e", {"code_string": "class Square(Shape):\n    def __init__(self):\n        Shape.__init__(self)\n        self.polygon = Polygon(((0, 0), (25, 0), (25, 25), (0, 25)))\n", "code_toks_joined": "class Square ( Shape ) : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> Shape . __init__ ( self ) <NEWLINE> self . polygon = Polygon ( ( ( 0 , 0 ) , ( 25 , 0 ) , ( 25 , 25 ) , ( 0 , 25 ) ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["fd1bc59fd6e62a50fa503ad96b3f93c6", {"code_string": "def check_language_code(code):\n    if code is None:\n        return None\n    code = str_to_unicode(code)\n    if code not in getUtility(ILanguageManager):\n        msg = \"\"\"Missing language: {0}\"\"\".format(code)\n        raise Import21Error(msg)\n    return code\n", "code_toks_joined": "def check_language_code ( code ) : <NEWLINE> <INDENT> if code is None : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> code = str_to_unicode ( code ) <NEWLINE> if code not in getUtility ( ILanguageManager ) : <NEWLINE> <INDENT> msg = <STRING> . format ( code ) <NEWLINE> raise Import21Error ( msg ) <NEWLINE> <DEDENT> return code <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Missing language: {0}\"\"\""]}}], ["7f2e93adbe1d3f19e0ca4c4c5fad5227", {"code_string": "from token_reader import USBTokenReader, NoTokensAvailableError, read_tokens_from_file\nfrom token import BadTokenFormatError, Token\nfrom token_collector import MQTTCollector, GITCollector, MailCollector, MQTTTokenForwarder\n", "code_toks_joined": "from token_reader import USBTokenReader , NoTokensAvailableError , read_tokens_from_file <NEWLINE> from token import BadTokenFormatError , Token <NEWLINE> from token_collector import MQTTCollector , GITCollector , MailCollector , MQTTTokenForwarder <NEWLINE>", "anonymize_dict": {}}], ["0ff67729c5ca9dd294bbde4f6207d1fd", {"code_string": "\"\"\"Pretty print TeXcount output\"\"\"\nimport argparse\nimport os\nimport shlex\nimport subprocess\nimport time\n", "code_toks_joined": "<STRING> <NEWLINE> import argparse <NEWLINE> import os <NEWLINE> import shlex <NEWLINE> import subprocess <NEWLINE> import time <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Pretty print TeXcount output\"\"\""]}}], ["7bcd16f62800ebb72389ae43355fba8d", {"code_string": "class ActionsTests(unittest.TestCase):\n    def setUp(self):\n        pass\n    def test_interpreter_do_method(self):\n        self.assertTrue(hasattr(TestAction, '_interpreter_do_method'))\n    def test_do(self):\n        interpreter = mock.Mock()\n        action = TestAction(attr_1 = 1, attr_2 = 666)\n        action.do(interpreter)\n        self.assertEqual(interpreter.do_test_action.call_args_list, [mock.call(action = action)])\n", "code_toks_joined": "class ActionsTests ( unittest . TestCase ) : <NEWLINE> <INDENT> def setUp ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def test_interpreter_do_method ( self ) : <NEWLINE> <INDENT> self . assertTrue ( hasattr ( TestAction , <STRING> ) ) <NEWLINE> <DEDENT> def test_do ( self ) : <NEWLINE> <INDENT> interpreter = mock . Mock ( ) <NEWLINE> action = TestAction ( attr_1 = 1 , attr_2 = 666 ) <NEWLINE> action . do ( interpreter ) <NEWLINE> self . assertEqual ( interpreter . do_test_action . call_args_list , [ mock . call ( action = action ) ] ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'_interpreter_do_method'"]}}], ["f4dd77e1645dfc9ca8e01d18df14484c", {"code_string": "import os\nfrom task import Task, Project\n__version__ = 1\n", "code_toks_joined": "import os <NEWLINE> from task import Task , Project <NEWLINE> __version__ = 1 <NEWLINE>", "anonymize_dict": {}}], ["5f550abdb2630f86b23b53520b55a30b", {"code_string": "def startService(self):\n    service.Service.startService(self)\n    self.calls = [task.LoopingCall(d.transfer) for d in self.domains]\n    i = 0\n    from twisted.internet import reactor\n    for c in self.calls:\n        reactor.callLater(i, c.start, 60 * 60)\n        i += 1\n", "code_toks_joined": "def startService ( self ) : <NEWLINE> <INDENT> service . Service . startService ( self ) <NEWLINE> self . calls = [ task . LoopingCall ( d . transfer ) for d in self . domains ] <NEWLINE> i = 0 <NEWLINE> from twisted . internet import reactor <NEWLINE> for c in self . calls : <NEWLINE> <INDENT> reactor . callLater ( i , c . start , 60 * 60 ) <NEWLINE> i += 1 <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["50da4b2c03ea0cc9c951f164b7b1b8fb", {"code_string": "def __getattr__(self, key):\n    if key in self.__DEFAULTS:\n        return getattr(self.settings,\n            self.prefix + key, self.__DEFAULTS[key])\n    else:\n        from django.core.exceptions import ImproperlyConfigured\n        try:\n            return getattr(self.settings, self.prefix + key)\n        except AttributeError:\n            raise ImproperlyConfigured('settings %s is missing' % self.prefix + key)\n", "code_toks_joined": "def __getattr__ ( self , key ) : <NEWLINE> <INDENT> if key in self . __DEFAULTS : <NEWLINE> <INDENT> return getattr ( self . settings , <NEWLINE> <INDENT> self . prefix + key , self . __DEFAULTS [ key ] ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> from django . core . exceptions import ImproperlyConfigured <NEWLINE> try : <NEWLINE> <INDENT> return getattr ( self . settings , self . prefix + key ) <NEWLINE> <DEDENT> except AttributeError : <NEWLINE> <INDENT> raise ImproperlyConfigured ( <STRING> % self . prefix + key ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'settings %s is missing'"]}}], ["4d54d9d1bdaca6a739366e931db02e76", {"code_string": "\"\"\"Random utilities that don't fit anywhere else. Internal use only.\"\"\"\nfrom functools import wraps\nfrom twisted.internet import defer\n", "code_toks_joined": "<STRING> <NEWLINE> from functools import wraps <NEWLINE> from twisted . internet import defer <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Random utilities that don't fit anywhere else. Internal use only.\"\"\""]}}], ["8e6a63740066f9d35f6dbd17faf0ebb9", {"code_string": "import pandas as pd\nimport sys\nsavename = sys.argv[1]\nfilename_1990 = 'data/Earthquake_Datasets/EQCanOB_1990.csv'\nfilename_2004 = 'data/Earthquake_Datasets/EQCanOB_2004.csv'\nfilename_2006 = 'data/Earthquake_Datasets/EQCanOB_2006.csv'\nfilename_2008 = 'data/Earthquake_Datasets/EQCanOB_2008.csv'\nfilename_2010 = 'data/Earthquake_Datasets/EQCanOB_2010.csv'\nfilename_2012 = 'data/Earthquake_Datasets/EQCanOB_2012.csv'\nearthquakes_1990 = pd.read_csv(filename_1990, sep = ',')\nearthquakes_2004 = pd.read_csv(filename_2004, sep = ',')\nearthquakes_2006 = pd.read_csv(filename_2006, sep = ',')\nearthquakes_2008 = pd.read_csv(filename_2008, sep = ',')\nearthquakes_2010 = pd.read_csv(filename_2010, sep = ',')\nearthquakes_2012 = pd.read_csv(filename_2012, sep = ',')\n", "code_toks_joined": "import pandas as pd <NEWLINE> import sys <NEWLINE> savename = sys . argv [ 1 ] <NEWLINE> filename_1990 = <STRING> <NEWLINE> filename_2004 = <STRING> <NEWLINE> filename_2006 = <STRING> <NEWLINE> filename_2008 = <STRING> <NEWLINE> filename_2010 = <STRING> <NEWLINE> filename_2012 = <STRING> <NEWLINE> earthquakes_1990 = pd . read_csv ( filename_1990 , sep = <STRING> ) <NEWLINE> earthquakes_2004 = pd . read_csv ( filename_2004 , sep = <STRING> ) <NEWLINE> earthquakes_2006 = pd . read_csv ( filename_2006 , sep = <STRING> ) <NEWLINE> earthquakes_2008 = pd . read_csv ( filename_2008 , sep = <STRING> ) <NEWLINE> earthquakes_2010 = pd . read_csv ( filename_2010 , sep = <STRING> ) <NEWLINE> earthquakes_2012 = pd . read_csv ( filename_2012 , sep = <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'data/Earthquake_Datasets/EQCanOB_1990.csv'", "'data/Earthquake_Datasets/EQCanOB_2004.csv'", "'data/Earthquake_Datasets/EQCanOB_2006.csv'", "'data/Earthquake_Datasets/EQCanOB_2008.csv'", "'data/Earthquake_Datasets/EQCanOB_2010.csv'", "'data/Earthquake_Datasets/EQCanOB_2012.csv'", "','", "','", "','", "','", "','", "','"]}}], ["a5b1b84196e11fc9de02f4454007e2ea", {"code_string": "import six\ncollect_ignore = []\nif six.PY3:\n    for fn in open('tests/py3-ignores.txt'):\n        if fn.strip():\n            collect_ignore.append(fn.strip())\n", "code_toks_joined": "import six <NEWLINE> collect_ignore = [ ] <NEWLINE> if six . PY3 : <NEWLINE> <INDENT> for fn in open ( <STRING> ) : <NEWLINE> <INDENT> if fn . strip ( ) : <NEWLINE> <INDENT> collect_ignore . append ( fn . strip ( ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'tests/py3-ignores.txt'"]}}], ["2436807a804959389329dfd15165554f", {"code_string": "def get_mapping(modules):\n    return[\n        (r\"/\", MainHandler),\n        (r\"/coinbasewatcher\", CoinbaseWatcherHandler, dict(modules = modules)),\n    ]\n", "code_toks_joined": "def get_mapping ( modules ) : <NEWLINE> <INDENT> return [ <NEWLINE> <INDENT> ( <STRING> , MainHandler ) , <NEWLINE> ( <STRING> , CoinbaseWatcherHandler , dict ( modules = modules ) ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["r\"/\"", "r\"/coinbasewatcher\""]}}], ["7150b8f6119e0b3c42414b14b1b3f249", {"code_string": "\"\"\"This script computes the fiber flat field correction from a DESI continuum lamp frame.\"\"\"\nfrom desispec.io import read_frame\nfrom desispec.io import read_fibermap\nfrom desispec.io import read_fiberflat\nfrom desispec.io import write_sky\nfrom desispec.fiberflat import apply_fiberflat\nfrom desispec.sky import compute_sky\nfrom desispec.log import get_logger\nimport argparse\nimport numpy as np\nimport sys\n", "code_toks_joined": "<STRING> <NEWLINE> from desispec . io import read_frame <NEWLINE> from desispec . io import read_fibermap <NEWLINE> from desispec . io import read_fiberflat <NEWLINE> from desispec . io import write_sky <NEWLINE> from desispec . fiberflat import apply_fiberflat <NEWLINE> from desispec . sky import compute_sky <NEWLINE> from desispec . log import get_logger <NEWLINE> import argparse <NEWLINE> import numpy as np <NEWLINE> import sys <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"This script computes the fiber flat field correction from a DESI continuum lamp frame.\"\"\""]}}], ["65e8b9a99bd8029acaf7468ff9432449", {"code_string": "'''This example illustrates the edgeSnap function in the Image class'''\nprint(__doc__)\nimport cv2\nfrom simplecv.api import Color, Image\nfrom simplecv.ui import Window\n", "code_toks_joined": "<STRING> <NEWLINE> print ( __doc__ ) <NEWLINE> import cv2 <NEWLINE> from simplecv . api import Color , Image <NEWLINE> from simplecv . ui import Window <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''This example illustrates the edgeSnap function in the Image class'''"]}}], ["56bc791033c1e79cc9e6fd5c282765e1", {"code_string": "import mock\nfrom hwk import udev\nfrom hwk.tests.unit import base\n", "code_toks_joined": "import mock <NEWLINE> from hwk import udev <NEWLINE> from hwk . tests . unit import base <NEWLINE>", "anonymize_dict": {}}], ["e1aa355e7513f0f0833b285632438690", {"code_string": "from tornado.tcpserver import TCPServer\nfrom tornado.tcpclient import TCPClient\nfrom tornado.iostream import StreamClosedError\nfrom tornado.ioloop import IOLoop, PeriodicCallback\nfrom tornado import gen\n", "code_toks_joined": "from tornado . tcpserver import TCPServer <NEWLINE> from tornado . tcpclient import TCPClient <NEWLINE> from tornado . iostream import StreamClosedError <NEWLINE> from tornado . ioloop import IOLoop , PeriodicCallback <NEWLINE> from tornado import gen <NEWLINE>", "anonymize_dict": {}}], ["c571ed6d0cd3e1a6954e3ae6c7fe7829", {"code_string": "def cancel(cls, payments):\n    \"\"\"Cancel all payment transactions related to payment\"\"\"\n    PaymentTransaction = Pool().get('payment_gateway.transaction')\n    payment_transactions = []\n    for payment in payments:\n        payment_transactions.extend(payment.payment_transactions)\n    PaymentTransaction.cancel(payment_transactions)\n", "code_toks_joined": "def cancel ( cls , payments ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> PaymentTransaction = Pool ( ) . get ( <STRING> ) <NEWLINE> payment_transactions = [ ] <NEWLINE> for payment in payments : <NEWLINE> <INDENT> payment_transactions . extend ( payment . payment_transactions ) <NEWLINE> <DEDENT> PaymentTransaction . cancel ( payment_transactions ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Cancel all payment transactions related to payment\"\"\"", "'payment_gateway.transaction'"]}}], ["5717197f18ed80e1e2041f425f8b3df5", {"code_string": "from OSIM.Modeling.CircuitSystemEquations import CircuitSystemEquations\nfrom OSIM.Simulation.CircuitAnalysis.CircuitAnalyser import CircuitAnalyser\nfrom OSIM.Simulation.NetToComp import NetToComp\nseq = CircuitSystemEquations(NetToComp('twoTrans.net').getComponents())\nca = CircuitAnalyser(seq)\nca.printDCOp([\"R1\"])\n", "code_toks_joined": "from OSIM . Modeling . CircuitSystemEquations import CircuitSystemEquations <NEWLINE> from OSIM . Simulation . CircuitAnalysis . CircuitAnalyser import CircuitAnalyser <NEWLINE> from OSIM . Simulation . NetToComp import NetToComp <NEWLINE> seq = CircuitSystemEquations ( NetToComp ( <STRING> ) . getComponents ( ) ) <NEWLINE> ca = CircuitAnalyser ( seq ) <NEWLINE> ca . printDCOp ( [ <STRING> ] ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'twoTrans.net'", "\"R1\""]}}], ["de9510375a53a5f93798dd6e077d3f04", {"code_string": "def err_check(r):\n    x = r.json()\n    try:\n        if x['error'] == 'Invalid Phone Number':\n            raise InvalidPhoneNumber('Invalid Phone Number. Response %s ' % r.json(), r.json())\n    except KeyError:\n        pass\n    if r.status_code == 202 or r.status_code == 200:\n        return r.text\n    else:\n        raise SonarError('Returned non 202 status. Status code: %s' % r.status_code, r.status_code)\n", "code_toks_joined": "def err_check ( r ) : <NEWLINE> <INDENT> x = r . json ( ) <NEWLINE> try : <NEWLINE> <INDENT> if x [ <STRING> ] == <STRING> : <NEWLINE> <INDENT> raise InvalidPhoneNumber ( <STRING> % r . json ( ) , r . json ( ) ) <NEWLINE> <DEDENT> <DEDENT> except KeyError : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> if r . status_code == 202 or r . status_code == 200 : <NEWLINE> <INDENT> return r . text <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> raise SonarError ( <STRING> % r . status_code , r . status_code ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'error'", "'Invalid Phone Number'", "'Invalid Phone Number. Response %s '", "'Returned non 202 status. Status code: %s'"]}}], ["17fe8af15b92f1d97ed0d94214e437fa", {"code_string": "def _print_name(self, name, data = None):\n    if data is None:\n        self._handle.write(\"%s %s\\n\" %(\"*\" * self._colwidth, name))\n    else:\n        self._handle.write(\"%-*s: %s\\n\" %(\n            self._colwidth, name[: self._colwidth],\n            data[: self._maxwidth - self._colwidth - 2].rstrip()))\n", "code_toks_joined": "def _print_name ( self , name , data = None ) : <NEWLINE> <INDENT> if data is None : <NEWLINE> <INDENT> self . _handle . write ( <STRING> % ( <STRING> * self . _colwidth , name ) ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . _handle . write ( <STRING> % ( <NEWLINE> <INDENT> self . _colwidth , name [ : self . _colwidth ] , <NEWLINE> data [ : self . _maxwidth - self . _colwidth - 2 ] . rstrip ( ) ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"%s %s\\n\"", "\"*\"", "\"%-*s: %s\\n\""]}}], ["4fcacfe5ecc7c90dfb0e1d70a2a5b3e9", {"code_string": "from setuptools import setup\nsetup(\n    name = 'logn',\n    version = '0.1',\n    py_modules = ['logninja'],\n    install_requires = [\n        'Click',\n    ],\n    entry_points = '''[console_scripts]''',\n)\n", "code_toks_joined": "from setuptools import setup <NEWLINE> setup ( <NEWLINE> <INDENT> name = <STRING> , <NEWLINE> version = <STRING> , <NEWLINE> py_modules = [ <STRING> ] , <NEWLINE> install_requires = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <DEDENT> ] , <NEWLINE> entry_points = <STRING> , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'logn'", "'0.1'", "'logninja'", "'Click'", "'''[console_scripts]'''"]}}], ["283974f354bddb30da3fb4396d94aceb", {"code_string": "def heapSort(lst):\n    \"\"\"heapSort(List(Orderable)) -> List(Ordered)\"\"\"\n    t = len(lst)\n    i = arrayHeap.mkHeap(t, arrayHeap.less)\n    r = []\n    for elem in lst:\n        arrayHeap.add(i, elem)\n    for el in range(len(lst)):\n        r.append(arrayHeap.removeMin(i))\n    return r\n", "code_toks_joined": "def heapSort ( lst ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> t = len ( lst ) <NEWLINE> i = arrayHeap . mkHeap ( t , arrayHeap . less ) <NEWLINE> r = [ ] <NEWLINE> for elem in lst : <NEWLINE> <INDENT> arrayHeap . add ( i , elem ) <NEWLINE> <DEDENT> for el in range ( len ( lst ) ) : <NEWLINE> <INDENT> r . append ( arrayHeap . removeMin ( i ) ) <NEWLINE> <DEDENT> return r <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"heapSort(List(Orderable)) -> List(Ordered)\"\"\""]}}], ["00bae5084d3591f27ece87dd976961b7", {"code_string": "class ApacheModfcgidPlugin(Plugin):\n    name = 'apache-mod_fcgid'\n    homepage = 'https://httpd.apache.org/mod_fcgid/'\n    matchers = [\n        {'header': ('Server', 'mod_fcgid/(?P<version>[0-9\\.]+)')},\n    ]\n", "code_toks_joined": "class ApacheModfcgidPlugin ( Plugin ) : <NEWLINE> <INDENT> name = <STRING> <NEWLINE> homepage = <STRING> <NEWLINE> matchers = [ <NEWLINE> <INDENT> { <STRING> : ( <STRING> , <STRING> ) } , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'apache-mod_fcgid'", "'https://httpd.apache.org/mod_fcgid/'", "'header'", "'Server'", "'mod_fcgid/(?P<version>[0-9\\.]+)'"]}}], ["6fe8191f3697cf1e949cc102db6abadf", {"code_string": "def unpack(archive, to_directory = None):\n    if not to_directory:\n        to_directory = os.path.dirname(archive.name)\n    if archive.name.endswith(\".zip\"):\n        return extract_zip(archive, to_directory)\n    else:\n        file_list = extract_tar_file(archive, to_directory)\n        return[x.name for x in file_list]\n", "code_toks_joined": "def unpack ( archive , to_directory = None ) : <NEWLINE> <INDENT> if not to_directory : <NEWLINE> <INDENT> to_directory = os . path . dirname ( archive . name ) <NEWLINE> <DEDENT> if archive . name . endswith ( <STRING> ) : <NEWLINE> <INDENT> return extract_zip ( archive , to_directory ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> file_list = extract_tar_file ( archive , to_directory ) <NEWLINE> return [ x . name for x in file_list ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\".zip\""]}}], ["71e60e7542437fb0da101b3910119637", {"code_string": "def default_script():\n    \"\"\"Provides a default script to use when no embedded script is available.\"\"\"\n    return \"\"\"[[script]]\"\"\"\n", "code_toks_joined": "def default_script ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Provides a default script to use when no embedded script is available.\"\"\"", "\"\"\"[[script]]\"\"\""]}}], ["5cb4d3b3236097f809b61b40b6cfbc3b", {"code_string": "import json\nfrom decimal import Decimal\nfrom datetime import datetime, date\n", "code_toks_joined": "import json <NEWLINE> from decimal import Decimal <NEWLINE> from datetime import datetime , date <NEWLINE>", "anonymize_dict": {}}], ["e952c73cecf0534652dbd8f3fc4ad6da", {"code_string": "import io\nimport os\nimport sys\nimport time\nfrom IOST_Prepare import IOST_Prepare\nfrom IOST_Config import *\nimport gtk\nimport gtk.glade\nIOST_WMain_AutoMail_Debug_Enable = 1\n", "code_toks_joined": "import io <NEWLINE> import os <NEWLINE> import sys <NEWLINE> import time <NEWLINE> from IOST_Prepare import IOST_Prepare <NEWLINE> from IOST_Config import * <NEWLINE> import gtk <NEWLINE> import gtk . glade <NEWLINE> IOST_WMain_AutoMail_Debug_Enable = 1 <NEWLINE>", "anonymize_dict": {}}], ["1ed14c9b381683b14c680102d8f351f2", {"code_string": "class MyInteractive(cmd.Cmd):\n    intro = 'Welcome to my interactive program!' + ' (type help for a list of commands.)'\n    prompt = '(my_program) '\n    file = None\n    @ docopt_cmd\n    def do_tcp(self, arg):\n        \"\"\"Usage: tcp <host> <port> [--timeout=<seconds>]\"\"\"\n        print(arg)\n    @ docopt_cmd\n    def do_serial(self, arg):\n        \"\"\"Usage: serial <port> [--baud=<n>] [--timeout=<seconds>]\"\"\"\n        print(arg)\n    def do_quit(self, arg):\n        \"\"\"Quits out of Interactive Mode.\"\"\"\n        print('Good Bye!')\n        exit()\n", "code_toks_joined": "class MyInteractive ( cmd . Cmd ) : <NEWLINE> <INDENT> intro = <STRING> + <STRING> <NEWLINE> prompt = <STRING> <NEWLINE> file = None <NEWLINE> @ docopt_cmd <NEWLINE> def do_tcp ( self , arg ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> print ( arg ) <NEWLINE> <DEDENT> @ docopt_cmd <NEWLINE> def do_serial ( self , arg ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> print ( arg ) <NEWLINE> <DEDENT> def do_quit ( self , arg ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> print ( <STRING> ) <NEWLINE> exit ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Welcome to my interactive program!'", "' (type help for a list of commands.)'", "'(my_program) '", "\"\"\"Usage: tcp <host> <port> [--timeout=<seconds>]\"\"\"", "\"\"\"Usage: serial <port> [--baud=<n>] [--timeout=<seconds>]\"\"\"", "\"\"\"Quits out of Interactive Mode.\"\"\"", "'Good Bye!'"]}}], ["5b0d4ef729d7e03d490f7eaf1202b5ec", {"code_string": "import os\nfrom DIRAC import S_OK, S_ERROR, gConfig, gLogger\nfrom DIRAC.Core.Utilities import List\nfrom DIRAC.ConfigurationSystem.Client.Helpers import Registry\nfrom DIRAC.ConfigurationSystem.Client.Helpers import CSGlobals\nfrom DIRAC.Core.DISET.AuthManager import AuthManager\nfrom DIRAC.Core.DISET.ThreadConfig import ThreadConfig\nfrom WebAppDIRAC.Lib import Conf\n", "code_toks_joined": "import os <NEWLINE> from DIRAC import S_OK , S_ERROR , gConfig , gLogger <NEWLINE> from DIRAC . Core . Utilities import List <NEWLINE> from DIRAC . ConfigurationSystem . Client . Helpers import Registry <NEWLINE> from DIRAC . ConfigurationSystem . Client . Helpers import CSGlobals <NEWLINE> from DIRAC . Core . DISET . AuthManager import AuthManager <NEWLINE> from DIRAC . Core . DISET . ThreadConfig import ThreadConfig <NEWLINE> from WebAppDIRAC . Lib import Conf <NEWLINE>", "anonymize_dict": {}}], ["ad2d833c847d6c8901f3fd7bc681cab1", {"code_string": "def test_main():\n    global boundaries, linecount\n    boundaries = 0\n    linecount = 0\n    f = cStringIO.StringIO(msg)\n    getMIMEMsg(multifile.MultiFile(f))\n    assert boundaries == 2\n    assert linecount == 9\n", "code_toks_joined": "def test_main ( ) : <NEWLINE> <INDENT> global boundaries , linecount <NEWLINE> boundaries = 0 <NEWLINE> linecount = 0 <NEWLINE> f = cStringIO . StringIO ( msg ) <NEWLINE> getMIMEMsg ( multifile . MultiFile ( f ) ) <NEWLINE> assert boundaries == 2 <NEWLINE> assert linecount == 9 <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["fd6f136eb742f1635691ace14e751c02", {"code_string": "def edgesFromBoolImg(arr, dtype = None):\n    '''takes a binary image (usually a mask)'''\n    out = np.zeros_like(arr, dtype = dtype)\n    _calc(arr, out)\n    _calc(arr.T, out.T)\n    return out\n", "code_toks_joined": "def edgesFromBoolImg ( arr , dtype = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> out = np . zeros_like ( arr , dtype = dtype ) <NEWLINE> _calc ( arr , out ) <NEWLINE> _calc ( arr . T , out . T ) <NEWLINE> return out <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''takes a binary image (usually a mask)'''"]}}], ["56f12911fc35f62bf748c659d60902f9", {"code_string": "def run(core, actor, target, commandString):\n    print('do you do anything?!')\n    return\n", "code_toks_joined": "def run ( core , actor , target , commandString ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> return <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'do you do anything?!'"]}}], ["22cfd7fa180486699f525fae62b5f448", {"code_string": "from flask import current_app\nfrom functools import wraps\nfrom hashlib import md5\nfrom changes.ext.redis import UnableToGetLock\nfrom changes.config import redis\n", "code_toks_joined": "from flask import current_app <NEWLINE> from functools import wraps <NEWLINE> from hashlib import md5 <NEWLINE> from changes . ext . redis import UnableToGetLock <NEWLINE> from changes . config import redis <NEWLINE>", "anonymize_dict": {}}], ["9610da34f274562501feb18c7a64c8f5", {"code_string": "def test_id_to_name_and_params_list_args(self):\n    task_id = \"InputText(date=2014-12-29,foo=[bar,baz-foo])\"\n    (name, params) = luigi.task.id_to_name_and_params(task_id)\n    self.assertEquals(name, \"InputText\")\n    self.assertEquals(params, dict(date = \"2014-12-29\", foo = [\"bar\", \"baz-foo\"]))\n", "code_toks_joined": "def test_id_to_name_and_params_list_args ( self ) : <NEWLINE> <INDENT> task_id = <STRING> <NEWLINE> ( name , params ) = luigi . task . id_to_name_and_params ( task_id ) <NEWLINE> self . assertEquals ( name , <STRING> ) <NEWLINE> self . assertEquals ( params , dict ( date = <STRING> , foo = [ <STRING> , <STRING> ] ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"InputText(date=2014-12-29,foo=[bar,baz-foo])\"", "\"InputText\"", "\"2014-12-29\"", "\"bar\"", "\"baz-foo\""]}}], ["688d15552b2108dcb1cf721e91c93dda", {"code_string": "def __init__(self, game):\n    self.game = game\n    self.dpad = {}\n", "code_toks_joined": "def __init__ ( self , game ) : <NEWLINE> <INDENT> self . game = game <NEWLINE> self . dpad = { } <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["d2751a30f4ac3aa222e0a4119e045132", {"code_string": "def test_create_region_with_conflicting_ids(self):\n    \"\"\"Call ``PUT /regions/{region_id}`` with conflicting region IDs.\"\"\"\n    ref = self.new_region_ref()\n    self.put(\n        '/regions/%s' % uuid.uuid4().hex,\n        body = {'region': ref},\n        expected_status = 400)\n", "code_toks_joined": "def test_create_region_with_conflicting_ids ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> ref = self . new_region_ref ( ) <NEWLINE> self . put ( <NEWLINE> <INDENT> <STRING> % uuid . uuid4 ( ) . hex , <NEWLINE> body = { <STRING> : ref } , <NEWLINE> expected_status = 400 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Call ``PUT /regions/{region_id}`` with conflicting region IDs.\"\"\"", "'/regions/%s'", "'region'"]}}], ["e7cfb1e1f870462c440a1171294fe97b", {"code_string": "def __getitem__(self, key):\n    if isinstance(key, str) or isinstance(key, unicode):\n        if key in self.headers:\n            pos = self.headers.index(key)\n            return[row[pos] for row in self._data]\n        else:\n            raise KeyError\n    else:\n        _results = self._data[key]\n        if isinstance(_results, Row):\n            return _results.tuple\n        else:\n            return[result.tuple for result in _results]\n", "code_toks_joined": "def __getitem__ ( self , key ) : <NEWLINE> <INDENT> if isinstance ( key , str ) or isinstance ( key , unicode ) : <NEWLINE> <INDENT> if key in self . headers : <NEWLINE> <INDENT> pos = self . headers . index ( key ) <NEWLINE> return [ row [ pos ] for row in self . _data ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> raise KeyError <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> _results = self . _data [ key ] <NEWLINE> if isinstance ( _results , Row ) : <NEWLINE> <INDENT> return _results . tuple <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return [ result . tuple for result in _results ] <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["1b29d554cc2ea75b8fc01f8fa456fcd0", {"code_string": "from __future__ import unicode_literals\nimport os\nfrom paste.deploy import loadapp\nfrom waitress import serve\nif __name__ == \"__main__\":\n    port = int(os.environ.get(\"PORT\", 5000))\n    app = loadapp('config:production.ini', relative_to = \".\")\n    serve(app, host = \"0.0.0.0\", port = port)\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> import os <NEWLINE> from paste . deploy import loadapp <NEWLINE> from waitress import serve <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> port = int ( os . environ . get ( <STRING> , 5000 ) ) <NEWLINE> app = loadapp ( <STRING> , relative_to = <STRING> ) <NEWLINE> serve ( app , host = <STRING> , port = port ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"__main__\"", "\"PORT\"", "'config:production.ini'", "\".\"", "\"0.0.0.0\""]}}], ["03f7d7580448c53590a3999659eadf0b", {"code_string": "def test_actual_code():\n    text = \"\"\"something before\"\"\"\n    expected = \"\"\"session.query(\"\"\"\n    assert_transform(sqla_count, text, [expected])\n", "code_toks_joined": "def test_actual_code ( ) : <NEWLINE> <INDENT> text = <STRING> <NEWLINE> expected = <STRING> <NEWLINE> assert_transform ( sqla_count , text , [ expected ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"something before\"\"\"", "\"\"\"session.query(\"\"\""]}}], ["a12e7270b968c34fadb8c4223b3db7dd", {"code_string": "def set_resource_image_from_url(self, url):\n    \"\"\"Similar to set_resource_image() except that it fetches the image\"\"\"\n    req = urllib2.Request(url, headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_5_8; en-US) AppleWebKit/534.13 (KHTML, like Gecko) Chrome/9.0.597.102 Safari/534.13\"})\n    f = urllib2.urlopen(req)\n    self.set_resource_image(f)\n    f.close()\n", "code_toks_joined": "def set_resource_image_from_url ( self , url ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> req = urllib2 . Request ( url , headers = { <STRING> : <STRING> } ) <NEWLINE> f = urllib2 . urlopen ( req ) <NEWLINE> self . set_resource_image ( f ) <NEWLINE> f . close ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Similar to set_resource_image() except that it fetches the image\"\"\"", "\"User-Agent\"", "\"Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_5_8; en-US) AppleWebKit/534.13 (KHTML, like Gecko) Chrome/9.0.597.102 Safari/534.13\""]}}], ["4110f35be685373c8e0f7094e1306be7", {"code_string": "def bin(num, width = 0):\n    \"\"\"Return a binary string representation.\"\"\"\n    num = long(num)\n    s = _int2bitstring(num)\n    if width:\n        pad = '0'\n        if num < 0:\n            pad = '1'\n        return(width - len(s)) * pad + s\n    return s\n", "code_toks_joined": "def bin ( num , width = 0 ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> num = long ( num ) <NEWLINE> s = _int2bitstring ( num ) <NEWLINE> if width : <NEWLINE> <INDENT> pad = <STRING> <NEWLINE> if num < 0 : <NEWLINE> <INDENT> pad = <STRING> <NEWLINE> <DEDENT> return ( width - len ( s ) ) * pad + s <NEWLINE> <DEDENT> return s <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Return a binary string representation.\"\"\"", "'0'", "'1'"]}}], ["ad0764c0b59e5cdb08f543e0d0625e72", {"code_string": "def drawCheck(surface, widget):\n    if not widget.enabled:\n        s2 = \"disabled\"\n    elif widget.focused:\n        s2 = \"focused\"\n    else:\n        s2 = \"enabled\"\n    if widget.checked:\n        s3 = \"on\"\n    else:\n        s3 = \"off\"\n    style = \"%s-%s-%s\" %(widget.style or \"check\", s2, s3)\n    drawBox(surface, widget, style)\n    drawTextAndIcons(surface, widget, style)\n    return widget.rect\n", "code_toks_joined": "def drawCheck ( surface , widget ) : <NEWLINE> <INDENT> if not widget . enabled : <NEWLINE> <INDENT> s2 = <STRING> <NEWLINE> <DEDENT> elif widget . focused : <NEWLINE> <INDENT> s2 = <STRING> <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> s2 = <STRING> <NEWLINE> <DEDENT> if widget . checked : <NEWLINE> <INDENT> s3 = <STRING> <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> s3 = <STRING> <NEWLINE> <DEDENT> style = <STRING> % ( widget . style or <STRING> , s2 , s3 ) <NEWLINE> drawBox ( surface , widget , style ) <NEWLINE> drawTextAndIcons ( surface , widget , style ) <NEWLINE> return widget . rect <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"disabled\"", "\"focused\"", "\"enabled\"", "\"on\"", "\"off\"", "\"%s-%s-%s\"", "\"check\""]}}], ["f1b88fc3b3b53aa35253c3b8cb0ee72d", {"code_string": "def dist_qualifier(cls, dist):\n    dist_key = dist.strip().lower()\n    if dist_key in['all', 'even']:\n        return 'diststyle({})'.format(dist_key)\n    else:\n        return 'diststyle key distkey(\"{}\")'.format(dist_key)\n", "code_toks_joined": "def dist_qualifier ( cls , dist ) : <NEWLINE> <INDENT> dist_key = dist . strip ( ) . lower ( ) <NEWLINE> if dist_key in [ <STRING> , <STRING> ] : <NEWLINE> <INDENT> return <STRING> . format ( dist_key ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return <STRING> . format ( dist_key ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'all'", "'even'", "'diststyle({})'", "'diststyle key distkey(\"{}\")'"]}}], ["c8118e4c59da0757b536e1ade0cc3fbf", {"code_string": "def dump(self, team, order):\n    print(\"vvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\")\n    print(\"team=\", team, \"  order=\", order, \"  role=\", order[\"role\"])\n    print(\"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n", "code_toks_joined": "def dump ( self , team , order ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> print ( <STRING> , team , <STRING> , order , <STRING> , order [ <STRING> ] ) <NEWLINE> print ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"vvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\"", "\"team=\"", "\"  order=\"", "\"  role=\"", "\"role\"", "\"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\""]}}], ["70426c2bf6565469298833ae6d84e525", {"code_string": "def _get_trusted(self, cr, uid, context = None):\n    if context == None:\n        context = {}\n    return context.get('trusted', False)\n", "code_toks_joined": "def _get_trusted ( self , cr , uid , context = None ) : <NEWLINE> <INDENT> if context == None : <NEWLINE> <INDENT> context = { } <NEWLINE> <DEDENT> return context . get ( <STRING> , False ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'trusted'"]}}], ["dbff7b73a1ea8812ffe0caca4dfff4e6", {"code_string": "from tests.unit import AWSMockServiceTestCase\nfrom boto.s3.connection import S3Connection\nfrom boto.s3.bucket import Bucket\nfrom boto.s3.tagging import Tag\n", "code_toks_joined": "from tests . unit import AWSMockServiceTestCase <NEWLINE> from boto . s3 . connection import S3Connection <NEWLINE> from boto . s3 . bucket import Bucket <NEWLINE> from boto . s3 . tagging import Tag <NEWLINE>", "anonymize_dict": {}}], ["db38f5eb8d063507da42d8c55abf261c", {"code_string": "def assert_subclass(item, Class):\n    if not issubclass(item, Class):\n        raise TypeError('expected {expected}, got {got}'.format(\n            expected = Class.__name__,\n            got = item.__name__\n        ))\n", "code_toks_joined": "def assert_subclass ( item , Class ) : <NEWLINE> <INDENT> if not issubclass ( item , Class ) : <NEWLINE> <INDENT> raise TypeError ( <STRING> . format ( <NEWLINE> <INDENT> expected = Class . __name__ , <NEWLINE> got = item . __name__ <NEWLINE> <DEDENT> ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'expected {expected}, got {got}'"]}}], ["dc06fd76fdab04ef79f2479dc9b5b6ba", {"code_string": "from __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom future.builtins import next\nfrom future.builtins import str\nfrom future import standard_library\nstandard_library.install_hooks()\nfrom past.builtins import basestring\nimport io\nimport collections\nfrom.tools import enum, py2_iterable\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> from __future__ import print_function <NEWLINE> from __future__ import division <NEWLINE> from __future__ import absolute_import <NEWLINE> from future . builtins import next <NEWLINE> from future . builtins import str <NEWLINE> from future import standard_library <NEWLINE> standard_library . install_hooks ( ) <NEWLINE> from past . builtins import basestring <NEWLINE> import io <NEWLINE> import collections <NEWLINE> from . tools import enum , py2_iterable <NEWLINE>", "anonymize_dict": {}}], ["0cced8a260fbc045aa7de42f55701794", {"code_string": "class ContactInformation(models.Model):\n    \"\"\"Model corresponding to Contact Us form fields\"\"\"\n    timestamp = models.DateTimeField(auto_now_add = True)\n    contact_name = models.CharField(max_length = 100, null = False, blank = False)\n    contact_email = models.EmailField(max_length = 200, null = False, blank = False)\n    contact_comment = models.TextField(null = False, blank = False)\n", "code_toks_joined": "class ContactInformation ( models . Model ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> timestamp = models . DateTimeField ( auto_now_add = True ) <NEWLINE> contact_name = models . CharField ( max_length = 100 , null = False , blank = False ) <NEWLINE> contact_email = models . EmailField ( max_length = 200 , null = False , blank = False ) <NEWLINE> contact_comment = models . TextField ( null = False , blank = False ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Model corresponding to Contact Us form fields\"\"\""]}}], ["7afa0c2cd21cee6640b50050956a6920", {"code_string": "def test_lexer(sourceFile, outFile):\n    comp = Compiler(sourceFile, outFile, True)\n    comp.lexer_driver()\n", "code_toks_joined": "def test_lexer ( sourceFile , outFile ) : <NEWLINE> <INDENT> comp = Compiler ( sourceFile , outFile , True ) <NEWLINE> comp . lexer_driver ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["37af03c5fb4a1522faab163dc1079138", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('authentication', '0008_auto_20150609_2309'),\n    ]\n    operations = [\n        migrations.AlterField(\n            model_name = 'registertoken',\n            name = 'created',\n            field = models.DateTimeField(default = datetime.datetime(2016, 2, 5, 15, 24, 23, 587829), verbose_name = b'created', auto_now_add = True),\n            preserve_default = True,\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . AlterField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . DateTimeField ( default = datetime . datetime ( 2016 , 2 , 5 , 15 , 24 , 23 , 587829 ) , verbose_name = <STRING> , auto_now_add = True ) , <NEWLINE> preserve_default = True , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'authentication'", "'0008_auto_20150609_2309'", "'registertoken'", "'created'", "b'created'"]}}], ["466599e209c6b2f483aee19cf4255dfd", {"code_string": "def callback(parser):\n    if not site.home():\n        sys.exit(\"Error: cannot locate the site's home directory.\")\n    if not os.path.exists(site.out()):\n        sys.exit(\"Error: cannot locate the site's output directory.\")\n    utils.cleardir(site.out())\n", "code_toks_joined": "def callback ( parser ) : <NEWLINE> <INDENT> if not site . home ( ) : <NEWLINE> <INDENT> sys . exit ( <STRING> ) <NEWLINE> <DEDENT> if not os . path . exists ( site . out ( ) ) : <NEWLINE> <INDENT> sys . exit ( <STRING> ) <NEWLINE> <DEDENT> utils . cleardir ( site . out ( ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Error: cannot locate the site's home directory.\"", "\"Error: cannot locate the site's output directory.\""]}}], ["77b960b97f420d84b1c91555cee774ee", {"code_string": "import openwns.simulator\nthisSimulator = openwns.simulator.OpenWNS()\nopenwns.simulator.setSimulator(thisSimulator)\n", "code_toks_joined": "import openwns . simulator <NEWLINE> thisSimulator = openwns . simulator . OpenWNS ( ) <NEWLINE> openwns . simulator . setSimulator ( thisSimulator ) <NEWLINE>", "anonymize_dict": {}}], ["e4ea536da3474714e8d568c14dffe843", {"code_string": "def load(self, config, container_builder):\n    definition = ioc.component.Definition('ioc.event.Dispatcher', kwargs = {\n        'logger': ioc.component.Reference('logger')\n    })\n    container_builder.add('ioc.extra.event_dispatcher', definition)\n", "code_toks_joined": "def load ( self , config , container_builder ) : <NEWLINE> <INDENT> definition = ioc . component . Definition ( <STRING> , kwargs = { <NEWLINE> <INDENT> <STRING> : ioc . component . Reference ( <STRING> ) <NEWLINE> <DEDENT> } ) <NEWLINE> container_builder . add ( <STRING> , definition ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'ioc.event.Dispatcher'", "'logger'", "'logger'", "'ioc.extra.event_dispatcher'"]}}], ["39b83e36ef04e22b450b330c1f53e69c", {"code_string": "def test_write_one_yeast_protein():\n    qid = \"Q27547347\"\n    taxid = '559292'\n    entrezgene = '856002'\n    _test_write_one_protein(qid, entrezgene, taxid)\n", "code_toks_joined": "def test_write_one_yeast_protein ( ) : <NEWLINE> <INDENT> qid = <STRING> <NEWLINE> taxid = <STRING> <NEWLINE> entrezgene = <STRING> <NEWLINE> _test_write_one_protein ( qid , entrezgene , taxid ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Q27547347\"", "'559292'", "'856002'"]}}], ["aa8b284495f7f7629a406d0ab5507035", {"code_string": "def gotoURL(self, url, cookies = None, headers = None):\n    r = requests.get(url, cookies = cookies, headers = headers)\n    while int(r.headers[\"content-length\"]) <= 3000:\n        print(\"retrying URL %s...\" % url)\n        r = requests.get(url, cookies = cookies, headers = headers)\n    return r.text\n", "code_toks_joined": "def gotoURL ( self , url , cookies = None , headers = None ) : <NEWLINE> <INDENT> r = requests . get ( url , cookies = cookies , headers = headers ) <NEWLINE> while int ( r . headers [ <STRING> ] ) <= 3000 : <NEWLINE> <INDENT> print ( <STRING> % url ) <NEWLINE> r = requests . get ( url , cookies = cookies , headers = headers ) <NEWLINE> <DEDENT> return r . text <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"content-length\"", "\"retrying URL %s...\""]}}], ["85623b36580748a3601cf11468972f46", {"code_string": "def gdal_version_info():\n    ver = gdal_version().decode()\n    m = version_regex.match(ver)\n    if not m:\n        raise GDALException('Could not parse GDAL version string \"%s\"' % ver)\n    return{key: m.group(key) for key in('major', 'minor', 'subminor')}\n", "code_toks_joined": "def gdal_version_info ( ) : <NEWLINE> <INDENT> ver = gdal_version ( ) . decode ( ) <NEWLINE> m = version_regex . match ( ver ) <NEWLINE> if not m : <NEWLINE> <INDENT> raise GDALException ( <STRING> % ver ) <NEWLINE> <DEDENT> return { key : m . group ( key ) for key in ( <STRING> , <STRING> , <STRING> ) } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Could not parse GDAL version string \"%s\"'", "'major'", "'minor'", "'subminor'"]}}], ["f26f6430b877aa7ef4b28acf505ce35a", {"code_string": "from __future__ import print_function, unicode_literals\nimport os\nimport sys\nfrom logging import DEBUG, FileHandler, getLogger\nfrom twisted.internet.error import CannotListenError\nfrom deluge.common import run_profiled\nfrom deluge.configmanager import get_config_dir\nfrom deluge.ui.baseargparser import BaseArgParser\nfrom deluge.ui.translations_util import set_dummy_trans\n", "code_toks_joined": "from __future__ import print_function , unicode_literals <NEWLINE> import os <NEWLINE> import sys <NEWLINE> from logging import DEBUG , FileHandler , getLogger <NEWLINE> from twisted . internet . error import CannotListenError <NEWLINE> from deluge . common import run_profiled <NEWLINE> from deluge . configmanager import get_config_dir <NEWLINE> from deluge . ui . baseargparser import BaseArgParser <NEWLINE> from deluge . ui . translations_util import set_dummy_trans <NEWLINE>", "anonymize_dict": {}}], ["c56e26b81446d6ad0dc0bb810c84ea95", {"code_string": "def convertItems(self, items):\n    result = Bag()\n    for k, node in enumerate(items):\n        label = node.label\n        value = node.value\n        attr = dict(node.attr)\n        if label == 'method':\n            label = attr.get('name')\n        if label == 'property':\n            label = attr.get('name')\n        else:\n            label = 'r_%i' % k\n        if label:\n            result.setItem(label, value, attr)\n    return result\n", "code_toks_joined": "def convertItems ( self , items ) : <NEWLINE> <INDENT> result = Bag ( ) <NEWLINE> for k , node in enumerate ( items ) : <NEWLINE> <INDENT> label = node . label <NEWLINE> value = node . value <NEWLINE> attr = dict ( node . attr ) <NEWLINE> if label == <STRING> : <NEWLINE> <INDENT> label = attr . get ( <STRING> ) <NEWLINE> <DEDENT> if label == <STRING> : <NEWLINE> <INDENT> label = attr . get ( <STRING> ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> label = <STRING> % k <NEWLINE> <DEDENT> if label : <NEWLINE> <INDENT> result . setItem ( label , value , attr ) <NEWLINE> <DEDENT> <DEDENT> return result <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'method'", "'name'", "'property'", "'name'", "'r_%i'"]}}], ["3ef719644b7c46d72c840ae3621c9d17", {"code_string": "class Property:\n    def __init__(self, herbie_name):\n        self.herbie_name = herbie_name\n", "code_toks_joined": "class Property : <NEWLINE> <INDENT> def __init__ ( self , herbie_name ) : <NEWLINE> <INDENT> self . herbie_name = herbie_name <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["b1f8e69b74851524d647fbb986a4fd95", {"code_string": "def test_access_with_password_in_header(self, caplog):\n    \"\"\"Test access with password in URL.\"\"\"\n    caplog.set_level(logging.WARNING,\n        logger = 'requests.packages.urllib3.connectionpool')\n    req = requests.get(\n        _url(const.URL_API),\n        headers = {const.HTTP_HEADER_HA_AUTH: API_PASSWORD})\n    assert req.status_code == 200\n    logs = caplog.text\n    assert API_PASSWORD not in logs\n", "code_toks_joined": "def test_access_with_password_in_header ( self , caplog ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> caplog . set_level ( logging . WARNING , <NEWLINE> <INDENT> logger = <STRING> ) <NEWLINE> <DEDENT> req = requests . get ( <NEWLINE> <INDENT> _url ( const . URL_API ) , <NEWLINE> headers = { const . HTTP_HEADER_HA_AUTH : API_PASSWORD } ) <NEWLINE> <DEDENT> assert req . status_code == 200 <NEWLINE> logs = caplog . text <NEWLINE> assert API_PASSWORD not in logs <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test access with password in URL.\"\"\"", "'requests.packages.urllib3.connectionpool'"]}}], ["f79ba63c2b2d6a19dd0fa6587a1050a2", {"code_string": "def describe():\n    from subprocess import check_output\n    cwd = os.path.dirname(__file__)\n    return check_output('git describe', cwd = cwd, shell = True).decode('utf-8').strip()\n", "code_toks_joined": "def describe ( ) : <NEWLINE> <INDENT> from subprocess import check_output <NEWLINE> cwd = os . path . dirname ( __file__ ) <NEWLINE> return check_output ( <STRING> , cwd = cwd , shell = True ) . decode ( <STRING> ) . strip ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'git describe'", "'utf-8'"]}}], ["b45466f8f0cdd447216a7835d11e7878", {"code_string": "def test_bad_metrics_create_subcommand(self):\n    argstrings = [\n        'metric-create metric1',\n        'metric-create 123',\n        'metric-create',\n    ]\n    _shell = monascaclient.shell.MonascaShell()\n    for argstr in argstrings:\n        self.assertRaises(SystemExit, _shell.main, argstr.split())\n", "code_toks_joined": "def test_bad_metrics_create_subcommand ( self ) : <NEWLINE> <INDENT> argstrings = [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <DEDENT> ] <NEWLINE> _shell = monascaclient . shell . MonascaShell ( ) <NEWLINE> for argstr in argstrings : <NEWLINE> <INDENT> self . assertRaises ( SystemExit , _shell . main , argstr . split ( ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'metric-create metric1'", "'metric-create 123'", "'metric-create'"]}}], ["360fbf15024d58207ba8aa64a5938162", {"code_string": "def get_entrance_exam_content(request, course):\n    \"\"\"Get the entrance exam content information (ie, chapter module)\"\"\"\n    required_content = get_required_content(course, request.user)\n    exam_module = None\n    for content in required_content:\n        usage_key = course.id.make_usage_key_from_deprecated_string(content)\n        module_item = modulestore().get_item(usage_key)\n        if not module_item.hide_from_toc and module_item.is_entrance_exam:\n            exam_module = module_item\n            break\n    return exam_module\n", "code_toks_joined": "def get_entrance_exam_content ( request , course ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> required_content = get_required_content ( course , request . user ) <NEWLINE> exam_module = None <NEWLINE> for content in required_content : <NEWLINE> <INDENT> usage_key = course . id . make_usage_key_from_deprecated_string ( content ) <NEWLINE> module_item = modulestore ( ) . get_item ( usage_key ) <NEWLINE> if not module_item . hide_from_toc and module_item . is_entrance_exam : <NEWLINE> <INDENT> exam_module = module_item <NEWLINE> break <NEWLINE> <DEDENT> <DEDENT> return exam_module <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Get the entrance exam content information (ie, chapter module)\"\"\""]}}], ["5a1a8ea3b74d66b84df230c476043517", {"code_string": "\"\"\"See docstring for AndroidSDKVersioner class\"\"\"\nimport xml.etree.cElementTree as ET\nimport urllib2\nfrom autopkglib import Processor, ProcessorError\n__all__ = [\"AndroidSDKVersioner\"]\n", "code_toks_joined": "<STRING> <NEWLINE> import xml . etree . cElementTree as ET <NEWLINE> import urllib2 <NEWLINE> from autopkglib import Processor , ProcessorError <NEWLINE> __all__ = [ <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"See docstring for AndroidSDKVersioner class\"\"\"", "\"AndroidSDKVersioner\""]}}], ["d104ed7dfc4c4932a05d98fbf8974a3c", {"code_string": "from baseparser import BaseParser\nimport bs4\nimport re\n", "code_toks_joined": "from baseparser import BaseParser <NEWLINE> import bs4 <NEWLINE> import re <NEWLINE>", "anonymize_dict": {}}], ["af774a5110d53d4fd71e3b87860cf028", {"code_string": "class ItemFilter(FilterSet):\n    class Meta:\n        model = Item\n        fields = {\n            'name': ['icontains'],\n            'categories': ['exact'],\n        }\n    @ property\n    def form(self):\n        form = super().form\n        helper = FormHelper()\n        helper.form_method = 'GET'\n        helper.layout = Layout(\n            Field('name__icontains'),\n            Field('categories'),\n        )\n        helper.add_input(Submit('filter', 'Filter'))\n        form.helper = helper\n        return form\n", "code_toks_joined": "class ItemFilter ( FilterSet ) : <NEWLINE> <INDENT> class Meta : <NEWLINE> <INDENT> model = Item <NEWLINE> fields = { <NEWLINE> <INDENT> <STRING> : [ <STRING> ] , <NEWLINE> <STRING> : [ <STRING> ] , <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT> @ property <NEWLINE> def form ( self ) : <NEWLINE> <INDENT> form = super ( ) . form <NEWLINE> helper = FormHelper ( ) <NEWLINE> helper . form_method = <STRING> <NEWLINE> helper . layout = Layout ( <NEWLINE> <INDENT> Field ( <STRING> ) , <NEWLINE> Field ( <STRING> ) , <NEWLINE> <DEDENT> ) <NEWLINE> helper . add_input ( Submit ( <STRING> , <STRING> ) ) <NEWLINE> form . helper = helper <NEWLINE> return form <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'name'", "'icontains'", "'categories'", "'exact'", "'GET'", "'name__icontains'", "'categories'", "'filter'", "'Filter'"]}}], ["c8ee202bb21ac63ace4b658d9bcde0ee", {"code_string": "def test(self):\n    try:\n        self.connect()\n    except:\n        return False\n    return True\n", "code_toks_joined": "def test ( self ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> self . connect ( ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> return True <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["6d5feba8c27c79fed4fd3d5c63cf54d2", {"code_string": "def main():\n    import tempfile\n    import shutil\n    base_directory = tempfile.mkdtemp()\n    image_urls = ['http://assets-s3.usmagazine.com/uploads/assets/articles/69549-gisele-bundchen-rides-atv-in-bikini-with-13-month-old-daughter-vivian-forgoes-he/1389720163_gisele-bundchen-article.jpg',\n        'http://assets-s3.usmagazine.com/uploads/assets/photo_galleries/regular_galleries/1984-golden-globes-celebrity-pda/1389715650_golden-globes-pda-350.jpg',\n        'http://assets-s3.usmagazine.com/uploads/assets/article_photos/617e98a3ef19b29fc33a0312cdb2bd22a5ddef1e.jpg',\n        'http://assets-s3.usmagazine.com/uploads/assets/articles/69549-gisele-bundchen-rides-atv-in-bikini-with-13-month-old-daughter-vivian-forgoes-he/1389720163_gisele-bundchen-zoom.jpg',\n        ]\n    print(compare_similarity(image_urls, base_directory))\n    shutil.rmtree(base_directory)\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> import tempfile <NEWLINE> import shutil <NEWLINE> base_directory = tempfile . mkdtemp ( ) <NEWLINE> image_urls = [ <STRING> , <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> ] <NEWLINE> <DEDENT> print ( compare_similarity ( image_urls , base_directory ) ) <NEWLINE> shutil . rmtree ( base_directory ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'http://assets-s3.usmagazine.com/uploads/assets/articles/69549-gisele-bundchen-rides-atv-in-bikini-with-13-month-old-daughter-vivian-forgoes-he/1389720163_gisele-bundchen-article.jpg'", "'http://assets-s3.usmagazine.com/uploads/assets/photo_galleries/regular_galleries/1984-golden-globes-celebrity-pda/1389715650_golden-globes-pda-350.jpg'", "'http://assets-s3.usmagazine.com/uploads/assets/article_photos/617e98a3ef19b29fc33a0312cdb2bd22a5ddef1e.jpg'", "'http://assets-s3.usmagazine.com/uploads/assets/articles/69549-gisele-bundchen-rides-atv-in-bikini-with-13-month-old-daughter-vivian-forgoes-he/1389720163_gisele-bundchen-zoom.jpg'"]}}], ["070c7bcabb01cdef3e7e6b84420e63c1", {"code_string": "import re\nimport ast\nimport sys\nfrom setuptools import setup, find_packages\nfrom setuptools.command.test import test as TestCommand\nfrom codecs import open\nfrom os import path\n", "code_toks_joined": "import re <NEWLINE> import ast <NEWLINE> import sys <NEWLINE> from setuptools import setup , find_packages <NEWLINE> from setuptools . command . test import test as TestCommand <NEWLINE> from codecs import open <NEWLINE> from os import path <NEWLINE>", "anonymize_dict": {}}], ["38c0bdbe0594f33c5a2cce8201e95316", {"code_string": "from flask import Request\nfrom aleph.views.util import extract_next_url\nfrom aleph.tests.util import TestCase\n", "code_toks_joined": "from flask import Request <NEWLINE> from aleph . views . util import extract_next_url <NEWLINE> from aleph . tests . util import TestCase <NEWLINE>", "anonymize_dict": {}}], ["c68b330c401129b67224f1a705eed173", {"code_string": "def _show_details(self, item_view):\n    with api.new_store() as store:\n        model = store.fetch(item_view)\n        run_dialog(ReturnedSaleDialog, self, store, model)\n        store.retval = store.get_pending_count() > 0\n", "code_toks_joined": "def _show_details ( self , item_view ) : <NEWLINE> <INDENT> with api . new_store ( ) as store : <NEWLINE> <INDENT> model = store . fetch ( item_view ) <NEWLINE> run_dialog ( ReturnedSaleDialog , self , store , model ) <NEWLINE> store . retval = store . get_pending_count ( ) > 0 <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["933954a84e775391a5e9012849e34108", {"code_string": "import sys\nimport os\nimport re\nimport fileinput\nfrom math import sqrt\nimport scipy\nimport numpy as np\nimport scipy.stats as stats\nimport pylab as pimport\nimport matplotlib.pyplot as plt\n", "code_toks_joined": "import sys <NEWLINE> import os <NEWLINE> import re <NEWLINE> import fileinput <NEWLINE> from math import sqrt <NEWLINE> import scipy <NEWLINE> import numpy as np <NEWLINE> import scipy . stats as stats <NEWLINE> import pylab as pimport <NEWLINE> import matplotlib . pyplot as plt <NEWLINE>", "anonymize_dict": {}}], ["9af31b773b34b7a43ebe75c22e07b7bc", {"code_string": "def logfilter(samplerate, signal, * args, ** kwargs):\n    \"\"\"extracts log mel filterbank energies from a given signal\"\"\"\n    feat = filter(samplerate, signal, * args, ** kwargs)\n    return np.log(feat)\n", "code_toks_joined": "def logfilter ( samplerate , signal , * args , ** kwargs ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> feat = filter ( samplerate , signal , * args , ** kwargs ) <NEWLINE> return np . log ( feat ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"extracts log mel filterbank energies from a given signal\"\"\""]}}], ["252b428a81848d198d7e66812c16c0ed", {"code_string": "import sys\nimport json\nfor filepath in sys.argv[1: ]:\n    with open(filepath) as f:\n        try:\n            oyster = json.load(f)\n        except ValueError:\n            sys.stderr.write(\"In file: {}\\n\".format(filepath))\n            raise\n    with open(filepath, 'w') as f:\n        json.dump(oyster, f, ensure_ascii = False, indent = 4, separators = (',', ': '), sort_keys = True)\n        f.write('\\n')\n", "code_toks_joined": "import sys <NEWLINE> import json <NEWLINE> for filepath in sys . argv [ 1 : ] : <NEWLINE> <INDENT> with open ( filepath ) as f : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> oyster = json . load ( f ) <NEWLINE> <DEDENT> except ValueError : <NEWLINE> <INDENT> sys . stderr . write ( <STRING> . format ( filepath ) ) <NEWLINE> raise <NEWLINE> <DEDENT> <DEDENT> with open ( filepath , <STRING> ) as f : <NEWLINE> <INDENT> json . dump ( oyster , f , ensure_ascii = False , indent = 4 , separators = ( <STRING> , <STRING> ) , sort_keys = True ) <NEWLINE> f . write ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"In file: {}\\n\"", "'w'", "','", "': '", "'\\n'"]}}], ["1c4f2496d2f881f5e82a900f1fdebfd6", {"code_string": "def delete_tenant(mgmt_root, name):\n    try:\n        p = mgmt_root.cm.cloud.tenants_s.tenant.load(name = name)\n    except HTTPError as err:\n        if err.response.status_code != 404:\n            raise\n        return\n    p.delete()\n", "code_toks_joined": "def delete_tenant ( mgmt_root , name ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> p = mgmt_root . cm . cloud . tenants_s . tenant . load ( name = name ) <NEWLINE> <DEDENT> except HTTPError as err : <NEWLINE> <INDENT> if err . response . status_code != 404 : <NEWLINE> <INDENT> raise <NEWLINE> <DEDENT> return <NEWLINE> <DEDENT> p . delete ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["40885143850ad2c82a29adde9ac8ee4f", {"code_string": "def clear_cart(request):\n    if request.method == 'POST':\n        if request.is_ajax():\n            cart = Cart(request.session)\n            cart.clear()\n            return JsonResponse({\n                'message': 'cleared cart'\n            })\n", "code_toks_joined": "def clear_cart ( request ) : <NEWLINE> <INDENT> if request . method == <STRING> : <NEWLINE> <INDENT> if request . is_ajax ( ) : <NEWLINE> <INDENT> cart = Cart ( request . session ) <NEWLINE> cart . clear ( ) <NEWLINE> return JsonResponse ( { <NEWLINE> <INDENT> <STRING> : <STRING> <NEWLINE> <DEDENT> } ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'POST'", "'message'", "'cleared cart'"]}}], ["f13a98a7ad37f55fa7cf24d705309346", {"code_string": "'''Licensed to the Apache Software Foundation (ASF) under one'''\nimport cgi\nimport os\nimport rrdtool\nimport sys\n", "code_toks_joined": "<STRING> <NEWLINE> import cgi <NEWLINE> import os <NEWLINE> import rrdtool <NEWLINE> import sys <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Licensed to the Apache Software Foundation (ASF) under one'''"]}}], ["036ebb12af715d36ce62b5c6ea3a6718", {"code_string": "from __future__ import unicode_literals\nfrom django.conf import settings\nfrom django.db import migrations, models\nimport django.db.models.deletion\nimport meals.models\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> from django . conf import settings <NEWLINE> from django . db import migrations , models <NEWLINE> import django . db . models . deletion <NEWLINE> import meals . models <NEWLINE>", "anonymize_dict": {}}], ["b29cb97e791588dc718391bccb5114b1", {"code_string": "def hanning(cube, decimate = True):\n    cube.allow_huge_operations = True\n    smcube = cube[1: - 1, : , : ] * 0.5\n    smcube += cube[0: - 2, : , : ] * 0.25\n    smcube += cube[2: , : , : ] * 0.25\n    if decimate:\n        smcube = smcube[1: : 2, : , : ]\n    return smcube\n", "code_toks_joined": "def hanning ( cube , decimate = True ) : <NEWLINE> <INDENT> cube . allow_huge_operations = True <NEWLINE> smcube = cube [ 1 : - 1 , : , : ] * 0.5 <NEWLINE> smcube += cube [ 0 : - 2 , : , : ] * 0.25 <NEWLINE> smcube += cube [ 2 : , : , : ] * 0.25 <NEWLINE> if decimate : <NEWLINE> <INDENT> smcube = smcube [ 1 : : 2 , : , : ] <NEWLINE> <DEDENT> return smcube <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["b3151647c668e755f12015ad99162864", {"code_string": "def RunGenerateLibrary():\n    from googleapis.codegen import generate_library\n    run_script_module.RunScriptModule(generate_library)\n", "code_toks_joined": "def RunGenerateLibrary ( ) : <NEWLINE> <INDENT> from googleapis . codegen import generate_library <NEWLINE> run_script_module . RunScriptModule ( generate_library ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["d86c3c3f0fd48c422705ee44f49986c7", {"code_string": "class GType(PackageElement, Type):\n    def __init__(self, name, package = None, is_external = False):\n        PackageElement.__init__(self, name, package, is_external)\n        Type.__init__(self)\n    def get_name(self):\n        return self.name\n", "code_toks_joined": "class GType ( PackageElement , Type ) : <NEWLINE> <INDENT> def __init__ ( self , name , package = None , is_external = False ) : <NEWLINE> <INDENT> PackageElement . __init__ ( self , name , package , is_external ) <NEWLINE> Type . __init__ ( self ) <NEWLINE> <DEDENT> def get_name ( self ) : <NEWLINE> <INDENT> return self . name <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["73d175852affeb50807157d3a2035050", {"code_string": "import unittest\nimport os\nimport datetime\nimport numpy as np\nfrom gpm_repo import gpm_wrapper\n", "code_toks_joined": "import unittest <NEWLINE> import os <NEWLINE> import datetime <NEWLINE> import numpy as np <NEWLINE> from gpm_repo import gpm_wrapper <NEWLINE>", "anonymize_dict": {}}], ["373c77b102d468a4cf489d2e85289d6f", {"code_string": "class UserProfile(FacebookProfileModel):\n    '''Inherit the properties from django facebook'''\n    user = models.OneToOneField(get_user_model())\n", "code_toks_joined": "class UserProfile ( FacebookProfileModel ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> user = models . OneToOneField ( get_user_model ( ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Inherit the properties from django facebook'''"]}}], ["4271d462fb7bfedd6a5d42d345f68b24", {"code_string": "from __future__ import print_function\nfrom __future__ import absolute_import\nfrom PyOpenWorm.muscle import Muscle\nfrom PyOpenWorm.neuron import Neuron\nfrom.DataTestTemplate import _DataTest\n", "code_toks_joined": "from __future__ import print_function <NEWLINE> from __future__ import absolute_import <NEWLINE> from PyOpenWorm . muscle import Muscle <NEWLINE> from PyOpenWorm . neuron import Neuron <NEWLINE> from . DataTestTemplate import _DataTest <NEWLINE>", "anonymize_dict": {}}], ["a8042cdd548b363f41b2aa4a7df74f61", {"code_string": "def getDescription(self):\n    if self.sourcetype == self.WMIFILES_MONITOR:\n        return self.hostname\n    return BasicDataSource.BasicDataSource.getDescription(self)\n", "code_toks_joined": "def getDescription ( self ) : <NEWLINE> <INDENT> if self . sourcetype == self . WMIFILES_MONITOR : <NEWLINE> <INDENT> return self . hostname <NEWLINE> <DEDENT> return BasicDataSource . BasicDataSource . getDescription ( self ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["a8dd73f24eb492aaf386ef40e2141d2d", {"code_string": "class ASCIIFileSystemStorage(FileSystemStorage):\n    \"\"\"Convert unicode characters in name to ASCII characters.\"\"\"\n    def get_valid_name(self, name):\n        if not isinstance(name, unicode):\n            name = unicode(name)\n        name = unicodedata.normalize('NFKD', name).encode('ascii', 'ignore')\n        return super(ASCIIFileSystemStorage, self).get_valid_name(name)\n", "code_toks_joined": "class ASCIIFileSystemStorage ( FileSystemStorage ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def get_valid_name ( self , name ) : <NEWLINE> <INDENT> if not isinstance ( name , unicode ) : <NEWLINE> <INDENT> name = unicode ( name ) <NEWLINE> <DEDENT> name = unicodedata . normalize ( <STRING> , name ) . encode ( <STRING> , <STRING> ) <NEWLINE> return super ( ASCIIFileSystemStorage , self ) . get_valid_name ( name ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Convert unicode characters in name to ASCII characters.\"\"\"", "'NFKD'", "'ascii'", "'ignore'"]}}], ["5da895e325ac4e257fc481db2cd84bd2", {"code_string": "def testGetInfo(self):\n    info = self.Server.info()\n    self.assert_(info.has_key('version'))\n", "code_toks_joined": "def testGetInfo ( self ) : <NEWLINE> <INDENT> info = self . Server . info ( ) <NEWLINE> self . assert_ ( info . has_key ( <STRING> ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'version'"]}}], ["9033ec6e83126062b20e3664cba6252d", {"code_string": "def example():\n    f = open(INPUT)\n    while 1:\n        gid = codes_grib_new_from_file(f)\n        if gid is None:\n            break\n        iterid = codes_keys_iterator_new(gid, 'ls')\n        while codes_keys_iterator_next(iterid):\n            keyname = codes_keys_iterator_get_name(iterid)\n            keyval = codes_get_string(iterid, keyname)\n            print(\"%s = %s\" %(keyname, keyval))\n        codes_keys_iterator_delete(iterid)\n        codes_release(gid)\n    f.close()\n", "code_toks_joined": "def example ( ) : <NEWLINE> <INDENT> f = open ( INPUT ) <NEWLINE> while 1 : <NEWLINE> <INDENT> gid = codes_grib_new_from_file ( f ) <NEWLINE> if gid is None : <NEWLINE> <INDENT> break <NEWLINE> <DEDENT> iterid = codes_keys_iterator_new ( gid , <STRING> ) <NEWLINE> while codes_keys_iterator_next ( iterid ) : <NEWLINE> <INDENT> keyname = codes_keys_iterator_get_name ( iterid ) <NEWLINE> keyval = codes_get_string ( iterid , keyname ) <NEWLINE> print ( <STRING> % ( keyname , keyval ) ) <NEWLINE> <DEDENT> codes_keys_iterator_delete ( iterid ) <NEWLINE> codes_release ( gid ) <NEWLINE> <DEDENT> f . close ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'ls'", "\"%s = %s\""]}}], ["b1b8fa20ec6960210f6f017bd70db242", {"code_string": "def getOtherStats(dir, distance_threshold, size_threshold):\n    import clone_refiner\n    stat = clone_refiner.main(dir, distance_threshold, size_threshold, True)\n    for i in stat:\n        print(i)\n", "code_toks_joined": "def getOtherStats ( dir , distance_threshold , size_threshold ) : <NEWLINE> <INDENT> import clone_refiner <NEWLINE> stat = clone_refiner . main ( dir , distance_threshold , size_threshold , True ) <NEWLINE> for i in stat : <NEWLINE> <INDENT> print ( i ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["3e63492f2079207f4182c3095a591ff8", {"code_string": "def main():\n    j = 1\n    while 1:\n        j += 1\n        n = j *(3 * j - 1) // 2\n        for k in range(j - 1, 0, - 1):\n            m = k *(3 * k - 1) // 2\n            if(is_pentagonal(n - m) and is_pentagonal(n + m)):\n                return n - m\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> j = 1 <NEWLINE> while 1 : <NEWLINE> <INDENT> j += 1 <NEWLINE> n = j * ( 3 * j - 1 ) // 2 <NEWLINE> for k in range ( j - 1 , 0 , - 1 ) : <NEWLINE> <INDENT> m = k * ( 3 * k - 1 ) // 2 <NEWLINE> if ( is_pentagonal ( n - m ) and is_pentagonal ( n + m ) ) : <NEWLINE> <INDENT> return n - m <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["07f5e7d8bac9b4d7281161f3c61db7d2", {"code_string": "\"\"\"Editra Business Model Library: Operating System Utilities\"\"\"\n__author__ = \"Cody Precord <cprecord@editra.org>\"\n__svnid__ = \"$Id: $\"\n__revision__ = \"$Revision: $\"\n__all__ = ['InstallTermHandler', ]\nimport wx\nimport signal\nimport collections\nHASWIN32 = False\nif wx.Platform == '__WXMSW__':\n    try:\n        import win32api\n    except ImportError:\n        HASWIN32 = False\n    else:\n        HASWIN32 = True\n", "code_toks_joined": "<STRING> <NEWLINE> __author__ = <STRING> <NEWLINE> __svnid__ = <STRING> <NEWLINE> __revision__ = <STRING> <NEWLINE> __all__ = [ <STRING> , ] <NEWLINE> import wx <NEWLINE> import signal <NEWLINE> import collections <NEWLINE> HASWIN32 = False <NEWLINE> if wx . Platform == <STRING> : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> import win32api <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> HASWIN32 = False <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> HASWIN32 = True <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Editra Business Model Library: Operating System Utilities\"\"\"", "\"Cody Precord <cprecord@editra.org>\"", "\"$Id: $\"", "\"$Revision: $\"", "'InstallTermHandler'", "'__WXMSW__'"]}}], ["61d2e9987dec04b8b3ae4aa304e8b7d2", {"code_string": "def main():\n    f = file(sys.argv[2], 'w')\n    try:\n        for line in file(sys.argv[1]):\n            line = re.sub('filename=\"[^\"]*/hwp5/', 'filename=\"pyhwp/hwp5/', line)\n            f.write(line)\n    finally:\n        f.close()\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> f = file ( sys . argv [ 2 ] , <STRING> ) <NEWLINE> try : <NEWLINE> <INDENT> for line in file ( sys . argv [ 1 ] ) : <NEWLINE> <INDENT> line = re . sub ( <STRING> , <STRING> , line ) <NEWLINE> f . write ( line ) <NEWLINE> <DEDENT> <DEDENT> finally : <NEWLINE> <INDENT> f . close ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'w'", "'filename=\"[^\"]*/hwp5/'", "'filename=\"pyhwp/hwp5/'"]}}], ["c97251e4039cbe08be62dc914bda22b7", {"code_string": "def __init__(self, toolboxdef):\n    \"\"\"Create a new Toolbox instance. Wrapbox objects are generated\"\"\"\n    self.__gobject_init__()\n    self.buttons = []\n    self.shortcuts = {}\n    self._construct(toolboxdef)\n", "code_toks_joined": "def __init__ ( self , toolboxdef ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . __gobject_init__ ( ) <NEWLINE> self . buttons = [ ] <NEWLINE> self . shortcuts = { } <NEWLINE> self . _construct ( toolboxdef ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Create a new Toolbox instance. Wrapbox objects are generated\"\"\""]}}], ["fd570041c2f4098f7c2108c1a02eaaf7", {"code_string": "\"\"\"author: Panagiotis Mavrogiorgos\"\"\"\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\nfrom __future__ import absolute_import\nimport datetime\nfrom south.db import db\nfrom south.v2 import DataMigration\nfrom django.conf import settings\nfrom django.db import models\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import division <NEWLINE> from __future__ import print_function <NEWLINE> from __future__ import unicode_literals <NEWLINE> from __future__ import absolute_import <NEWLINE> import datetime <NEWLINE> from south . db import db <NEWLINE> from south . v2 import DataMigration <NEWLINE> from django . conf import settings <NEWLINE> from django . db import models <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"author: Panagiotis Mavrogiorgos\"\"\""]}}], ["929bc43871c627a020f463c7fa6ee29a", {"code_string": "def add_alias_for(lang, alias, mapper):\n    \"\"\"Given a language which is not being added to the supported langs,\"\"\"\n    alias_list = mapper[lang].setdefault('aliases', [])\n    alias_list.append(alias)\n", "code_toks_joined": "def add_alias_for ( lang , alias , mapper ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> alias_list = mapper [ lang ] . setdefault ( <STRING> , [ ] ) <NEWLINE> alias_list . append ( alias ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Given a language which is not being added to the supported langs,\"\"\"", "'aliases'"]}}], ["f4807b6aceafd33a18e516624865f08b", {"code_string": "class RegexValidatorTests(TestCase):\n    def test_valid_string(self):\n        valid_string = 'foobar'\n        eq_(validate_regex(valid_string), valid_string)\n    def test_valid_regex(self):\n        valid_regex = '/\\d+/'\n        eq_(validate_regex(valid_regex), valid_regex)\n    def test_invalid_regex(self):\n        bogus_regex = '/(?P\\d+)/'\n        assert_raises(ValidationError, validate_regex, bogus_regex)\n", "code_toks_joined": "class RegexValidatorTests ( TestCase ) : <NEWLINE> <INDENT> def test_valid_string ( self ) : <NEWLINE> <INDENT> valid_string = <STRING> <NEWLINE> eq_ ( validate_regex ( valid_string ) , valid_string ) <NEWLINE> <DEDENT> def test_valid_regex ( self ) : <NEWLINE> <INDENT> valid_regex = <STRING> <NEWLINE> eq_ ( validate_regex ( valid_regex ) , valid_regex ) <NEWLINE> <DEDENT> def test_invalid_regex ( self ) : <NEWLINE> <INDENT> bogus_regex = <STRING> <NEWLINE> assert_raises ( ValidationError , validate_regex , bogus_regex ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'foobar'", "'/\\d+/'", "'/(?P\\d+)/'"]}}], ["b89cf5c55d9796a88a66fff2a6ee1dc3", {"code_string": "def set_started(self, date = None):\n    if isinstance(date, NoneType):\n        self._started = datetime.datetime.utcnow().isoformat()\n    else:\n        self._started = date\n", "code_toks_joined": "def set_started ( self , date = None ) : <NEWLINE> <INDENT> if isinstance ( date , NoneType ) : <NEWLINE> <INDENT> self . _started = datetime . datetime . utcnow ( ) . isoformat ( ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . _started = date <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["91fdbc5c37f6897e215dbb647fbb6523", {"code_string": "import pandas as pd\nimport numpy as np\nimport re\nimport copy\nfrom math import *\nfrom datetime import datetime\nimport networkx as nx\n", "code_toks_joined": "import pandas as pd <NEWLINE> import numpy as np <NEWLINE> import re <NEWLINE> import copy <NEWLINE> from math import * <NEWLINE> from datetime import datetime <NEWLINE> import networkx as nx <NEWLINE>", "anonymize_dict": {}}], ["7112f4bb604a459c95ded64681025361", {"code_string": "def spySetMax(env, max):\n    'Set spy max capacity.'\n    env.spy.setMax(max)\n    return 'ok'\n", "code_toks_joined": "def spySetMax ( env , max ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> env . spy . setMax ( max ) <NEWLINE> return <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Set spy max capacity.'", "'ok'"]}}], ["ac25d6cfcfe95b07458e51e6581a2c40", {"code_string": "from GlobalHeader import *\nfrom mrjob.compat import get_jobconf_value\nfrom mrjob.job import MRJob\nfrom mrjob.protocol import JSONProtocol\nfrom mrjob.step import MRStep\nimport math\nimport sys\n", "code_toks_joined": "from GlobalHeader import * <NEWLINE> from mrjob . compat import get_jobconf_value <NEWLINE> from mrjob . job import MRJob <NEWLINE> from mrjob . protocol import JSONProtocol <NEWLINE> from mrjob . step import MRStep <NEWLINE> import math <NEWLINE> import sys <NEWLINE>", "anonymize_dict": {}}], ["c0ae8c00972b0aed5e559ccc667685ff", {"code_string": "def __init__(self):\n    self._pos = 0\n    self._positionsHit = {}\n    for i in range(boardSize):\n        self._positionsHit[i] = 0\n    self._doublesTurns = 0\n    self._jailed = False\n    self._jailedTurns = 0\n    self._turns = 0\n", "code_toks_joined": "def __init__ ( self ) : <NEWLINE> <INDENT> self . _pos = 0 <NEWLINE> self . _positionsHit = { } <NEWLINE> for i in range ( boardSize ) : <NEWLINE> <INDENT> self . _positionsHit [ i ] = 0 <NEWLINE> <DEDENT> self . _doublesTurns = 0 <NEWLINE> self . _jailed = False <NEWLINE> self . _jailedTurns = 0 <NEWLINE> self . _turns = 0 <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["5221261d636eb8479b1706608c2dd1b2", {"code_string": "def __init__(self, callback = None, ttype = None, source = None):\n    \"\"\" \u521d\u59cb\u5316\u722c\u866b\u5bf9\u8c61 \"\"\"\n    self.group = Group()\n    self.task_queue = Queue()\n    self.task_type = ttype\n    self.cb = callback\n    self.source = source\n    self.task_name = \"%s-%s-%s\" %(socket.gethostname(),\n        self.source,\n        self.task_type)\n", "code_toks_joined": "def __init__ ( self , callback = None , ttype = None , source = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . group = Group ( ) <NEWLINE> self . task_queue = Queue ( ) <NEWLINE> self . task_type = ttype <NEWLINE> self . cb = callback <NEWLINE> self . source = source <NEWLINE> self . task_name = <STRING> % ( socket . gethostname ( ) , <NEWLINE> <INDENT> self . source , <NEWLINE> self . task_type ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" \u521d\u59cb\u5316\u722c\u866b\u5bf9\u8c61 \"\"\"", "\"%s-%s-%s\""]}}], ["684bdbab907d90ae5dd5425e09699955", {"code_string": "\"\"\" Simple regression test for the Densely connected MLP \"\"\"\nimport logging\nlogging.basicConfig(level = 'INFO')\nimport matplotlib\nmatplotlib.use('pdf')\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport mlp\nprint('-> Generating the data')\nnp.random.seed(750)\nN_TRAIN = 100000\nN_TEST = 1000\nNOISE_STDDEV = 0.1\nPATH_TRAIN = 'sine.training.txt'\nPATH_TEST = 'sine.test.txt'\n", "code_toks_joined": "<STRING> <NEWLINE> import logging <NEWLINE> logging . basicConfig ( level = <STRING> ) <NEWLINE> import matplotlib <NEWLINE> matplotlib . use ( <STRING> ) <NEWLINE> import matplotlib . pyplot as plt <NEWLINE> import numpy as np <NEWLINE> import mlp <NEWLINE> print ( <STRING> ) <NEWLINE> np . random . seed ( 750 ) <NEWLINE> N_TRAIN = 100000 <NEWLINE> N_TEST = 1000 <NEWLINE> NOISE_STDDEV = 0.1 <NEWLINE> PATH_TRAIN = <STRING> <NEWLINE> PATH_TEST = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\" Simple regression test for the Densely connected MLP \"\"\"", "'INFO'", "'pdf'", "'-> Generating the data'", "'sine.training.txt'", "'sine.test.txt'"]}}], ["054c4b8d1b62975dcb620ef8f828504e", {"code_string": "from django.db import models\nfrom edc_base.audit_trail import AuditTrail\nfrom edc_base.model.models import BaseUuidModel\nfrom edc_lab.lab_packing.models import PackingListMixin\nfrom edc_sync.models import SyncModelMixin\nfrom..managers import PackingListManager\n", "code_toks_joined": "from django . db import models <NEWLINE> from edc_base . audit_trail import AuditTrail <NEWLINE> from edc_base . model . models import BaseUuidModel <NEWLINE> from edc_lab . lab_packing . models import PackingListMixin <NEWLINE> from edc_sync . models import SyncModelMixin <NEWLINE> from . . managers import PackingListManager <NEWLINE>", "anonymize_dict": {}}], ["0650db81fb5b5cdc5bf95e0def83e08d", {"code_string": "import argparse\nimport smtplib\nimport os\nimport getpass\nfrom email.mime.text import MIMEText\nimport sys\nsys.path.insert(0, '..')\nfrom conf import work_dir\nfrom options import cfg2dict\nfrom build_template import _from_template\nargs = None\npassword = None\n", "code_toks_joined": "import argparse <NEWLINE> import smtplib <NEWLINE> import os <NEWLINE> import getpass <NEWLINE> from email . mime . text import MIMEText <NEWLINE> import sys <NEWLINE> sys . path . insert ( 0 , <STRING> ) <NEWLINE> from conf import work_dir <NEWLINE> from options import cfg2dict <NEWLINE> from build_template import _from_template <NEWLINE> args = None <NEWLINE> password = None <NEWLINE>", "anonymize_dict": {"<STRING>": ["'..'"]}}], ["e5d03feb21e6ba36250eb923f1887a7b", {"code_string": "def fetch(self, url):\n    response = requests.get(url)\n    return response.content\n", "code_toks_joined": "def fetch ( self , url ) : <NEWLINE> <INDENT> response = requests . get ( url ) <NEWLINE> return response . content <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["3dba5455c4197e52ce9e02309bed8a67", {"code_string": "def getText(self):\n    assert self.type not in(self.LOCK, self.SLOT_NUMBER), \"error\"\n    percent = None\n    if self.type == self.SNRTEXT:\n        percent = self.source.snr\n    elif self.type == self.AGCTEXT:\n        percent = self.source.agc\n    if percent is None:\n        return \"N/A\"\n    return \"%d\" %(percent * 100 / 65536)\n", "code_toks_joined": "def getText ( self ) : <NEWLINE> <INDENT> assert self . type not in ( self . LOCK , self . SLOT_NUMBER ) , <STRING> <NEWLINE> percent = None <NEWLINE> if self . type == self . SNRTEXT : <NEWLINE> <INDENT> percent = self . source . snr <NEWLINE> <DEDENT> elif self . type == self . AGCTEXT : <NEWLINE> <INDENT> percent = self . source . agc <NEWLINE> <DEDENT> if percent is None : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> return <STRING> % ( percent * 100 / 65536 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"error\"", "\"N/A\"", "\"%d\""]}}], ["d0c6b5575bd761af50bed85c0911b819", {"code_string": "def do_ecuRegister(self, data):\n    if data[\"primary_ecu_serial\"] == \"drop_request\":\n        return\n    elif data[\"primary_ecu_serial\"].startswith(\"status_\"):\n        self.send_response(int(data[\"primary_ecu_serial\"][7: ]))\n        self.end_headers()\n    elif data[\"primary_ecu_serial\"] == \"noerrors\":\n        self.send_response(200)\n        self.end_headers()\n        self.wfile.write(\"{}\")\n", "code_toks_joined": "def do_ecuRegister ( self , data ) : <NEWLINE> <INDENT> if data [ <STRING> ] == <STRING> : <NEWLINE> <INDENT> return <NEWLINE> <DEDENT> elif data [ <STRING> ] . startswith ( <STRING> ) : <NEWLINE> <INDENT> self . send_response ( int ( data [ <STRING> ] [ 7 : ] ) ) <NEWLINE> self . end_headers ( ) <NEWLINE> <DEDENT> elif data [ <STRING> ] == <STRING> : <NEWLINE> <INDENT> self . send_response ( 200 ) <NEWLINE> self . end_headers ( ) <NEWLINE> self . wfile . write ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"primary_ecu_serial\"", "\"drop_request\"", "\"primary_ecu_serial\"", "\"status_\"", "\"primary_ecu_serial\"", "\"primary_ecu_serial\"", "\"noerrors\"", "\"{}\""]}}], ["d02f21839c58c47a9a5ce111d650441e", {"code_string": "from mpi4py import MPI\nif __name__ == '__main__':\n    comm = MPI.COMM_WORLD\n    rank = comm.Get_rank()\n    size = comm.Get_size()\n    send_buffer = [rank * size + i for i in range(size)]\n    data = comm.alltoall(send_buffer)\n    print('rank {0}: {1}'.format(rank, ', '.join((str(x) for x in data))))\n", "code_toks_joined": "from mpi4py import MPI <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> comm = MPI . COMM_WORLD <NEWLINE> rank = comm . Get_rank ( ) <NEWLINE> size = comm . Get_size ( ) <NEWLINE> send_buffer = [ rank * size + i for i in range ( size ) ] <NEWLINE> data = comm . alltoall ( send_buffer ) <NEWLINE> print ( <STRING> . format ( rank , <STRING> . join ( ( str ( x ) for x in data ) ) ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'__main__'", "'rank {0}: {1}'", "', '"]}}], ["ce2cd49783702cfda5a33d9eaba1cdeb", {"code_string": "from __future__ import unicode_literals\nfrom optparse import make_option\nfrom django.core.management.base import NoArgsCommand\nfrom docutil.cache_util import clear_cache\nfrom docutil.commands_util import recocommand\nfrom docutil.str_util import smart_decode\nfrom codebase.actions import link_code\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> from optparse import make_option <NEWLINE> from django . core . management . base import NoArgsCommand <NEWLINE> from docutil . cache_util import clear_cache <NEWLINE> from docutil . commands_util import recocommand <NEWLINE> from docutil . str_util import smart_decode <NEWLINE> from codebase . actions import link_code <NEWLINE>", "anonymize_dict": {}}], ["8923ef97574be5992422936891ee5721", {"code_string": "def login(self, password):\n    response = self.session.post(self.base_url + 'admin_web', {\n        'username': 'admin',\n        'password': password,\n    })\n    match = re.search(u'\u5df2\u7ecf\u9519\u8bef.*\u6b21', response.text)\n    if match:\n        return match.group()\n    else:\n        self.stok = re.search('stok=\\w+', response.text).group()\n        self.api_base_url = self.base_url + ';' + self.stok + '/api/'\n        return True\n", "code_toks_joined": "def login ( self , password ) : <NEWLINE> <INDENT> response = self . session . post ( self . base_url + <STRING> , { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : password , <NEWLINE> <DEDENT> } ) <NEWLINE> match = re . search ( <STRING> , response . text ) <NEWLINE> if match : <NEWLINE> <INDENT> return match . group ( ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . stok = re . search ( <STRING> , response . text ) . group ( ) <NEWLINE> self . api_base_url = self . base_url + <STRING> + self . stok + <STRING> <NEWLINE> return True <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'admin_web'", "'username'", "'admin'", "'password'", "u'\u5df2\u7ecf\u9519\u8bef.*\u6b21'", "'stok=\\w+'", "';'", "'/api/'"]}}], ["0cd0b8e5a6495e980802db91ad0aaf0d", {"code_string": "def __init__(self, notification_owner_id, notification_author_id, analysis_comment_id):\n    Notification.__init__(self, notification_owner_id, notification_author_id)\n    self.analysis_comment_id = analysis_comment_id\n", "code_toks_joined": "def __init__ ( self , notification_owner_id , notification_author_id , analysis_comment_id ) : <NEWLINE> <INDENT> Notification . __init__ ( self , notification_owner_id , notification_author_id ) <NEWLINE> self . analysis_comment_id = analysis_comment_id <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["eb7dc9e8ec1ec33ad3ecb5cb84431159", {"code_string": "def get_function_abi(cpu, os, machine):\n    if os == 'linux' and machine == 'i386':\n        return I386CdeclAbi(cpu)\n    elif os == 'linux' and machine == 'amd64':\n        return SystemVAbi(cpu)\n    elif os == 'linux' and machine == 'armv7':\n        return Armv7CdeclAbi(cpu)\n    else:\n        return NotImplementedError(\"OS and machine combination not supported: {}/{}\".format(os, machine))\n", "code_toks_joined": "def get_function_abi ( cpu , os , machine ) : <NEWLINE> <INDENT> if os == <STRING> and machine == <STRING> : <NEWLINE> <INDENT> return I386CdeclAbi ( cpu ) <NEWLINE> <DEDENT> elif os == <STRING> and machine == <STRING> : <NEWLINE> <INDENT> return SystemVAbi ( cpu ) <NEWLINE> <DEDENT> elif os == <STRING> and machine == <STRING> : <NEWLINE> <INDENT> return Armv7CdeclAbi ( cpu ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return NotImplementedError ( <STRING> . format ( os , machine ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'linux'", "'i386'", "'linux'", "'amd64'", "'linux'", "'armv7'", "\"OS and machine combination not supported: {}/{}\""]}}], ["eb7612456fa154c813c12d3916f1eba0", {"code_string": "def load_flows(self, flows):\n    for i in flows:\n        if i.response:\n            l = self.flowmap.setdefault(self._hash(i), [])\n            l.append(i)\n", "code_toks_joined": "def load_flows ( self , flows ) : <NEWLINE> <INDENT> for i in flows : <NEWLINE> <INDENT> if i . response : <NEWLINE> <INDENT> l = self . flowmap . setdefault ( self . _hash ( i ) , [ ] ) <NEWLINE> l . append ( i ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["b384bed60cff99fde8f193d94a83fe0d", {"code_string": "def forwards(self, orm):\n    db.create_table(u'pages_page', (\n        (u'id', self.gf('django.db.models.fields.AutoField')(primary_key = True)),\n        ('title', self.gf('django.db.models.fields.CharField')(max_length = 60)),\n        ('body', self.gf('django.db.models.fields.TextField')()),\n        ('keywords', self.gf('django.db.models.fields.CharField')(max_length = 200)),\n        ('is_published', self.gf('django.db.models.fields.BooleanField')(default = False)),\n    ))\n    db.send_create_signal(u'pages', ['Page'])\n", "code_toks_joined": "def forwards ( self , orm ) : <NEWLINE> <INDENT> db . create_table ( <STRING> , ( <NEWLINE> <INDENT> ( <STRING> , self . gf ( <STRING> ) ( primary_key = True ) ) , <NEWLINE> ( <STRING> , self . gf ( <STRING> ) ( max_length = 60 ) ) , <NEWLINE> ( <STRING> , self . gf ( <STRING> ) ( ) ) , <NEWLINE> ( <STRING> , self . gf ( <STRING> ) ( max_length = 200 ) ) , <NEWLINE> ( <STRING> , self . gf ( <STRING> ) ( default = False ) ) , <NEWLINE> <DEDENT> ) ) <NEWLINE> db . send_create_signal ( <STRING> , [ <STRING> ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["u'pages_page'", "u'id'", "'django.db.models.fields.AutoField'", "'title'", "'django.db.models.fields.CharField'", "'body'", "'django.db.models.fields.TextField'", "'keywords'", "'django.db.models.fields.CharField'", "'is_published'", "'django.db.models.fields.BooleanField'", "u'pages'", "'Page'"]}}], ["20e00bef248d909395b943f19ea92645", {"code_string": "def backward(self, indexes, grad_outputs):\n    x, gamma = self.get_retained_inputs()\n    gy, = grad_outputs\n    f = BatchNormalizationGrad(\n        self.eps, self.use_cudnn, self.mode, self.expander, self.axis,\n        self.mean, self.inv_std)\n    return f(x, gamma, gy)\n", "code_toks_joined": "def backward ( self , indexes , grad_outputs ) : <NEWLINE> <INDENT> x , gamma = self . get_retained_inputs ( ) <NEWLINE> gy , = grad_outputs <NEWLINE> f = BatchNormalizationGrad ( <NEWLINE> <INDENT> self . eps , self . use_cudnn , self . mode , self . expander , self . axis , <NEWLINE> self . mean , self . inv_std ) <NEWLINE> <DEDENT> return f ( x , gamma , gy ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["2c88d0ced2581c229dcc97dbd2e8154e", {"code_string": "import math\nfrom pyspark import SparkConf, SparkContext\nfrom pyspark.sql import SQLContext, functions as sqlfunctions, types\nfrom pyspark.tests import QuietTest as SuppressSparkLogs\nfrom graphframes import GraphFrame\nfrom graphframes.lib import AggregateMessages as AM\nimport graphframes.examples\n__all__ = ['BeliefPropagation']\n", "code_toks_joined": "import math <NEWLINE> from pyspark import SparkConf , SparkContext <NEWLINE> from pyspark . sql import SQLContext , functions as sqlfunctions , types <NEWLINE> from pyspark . tests import QuietTest as SuppressSparkLogs <NEWLINE> from graphframes import GraphFrame <NEWLINE> from graphframes . lib import AggregateMessages as AM <NEWLINE> import graphframes . examples <NEWLINE> __all__ = [ <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'BeliefPropagation'"]}}], ["4a1f5a24c0aabadc166a6e8c72236fd6", {"code_string": "from gym import Env\nimport matplotlib.pyplot as plt\nimport numpy as np\n", "code_toks_joined": "from gym import Env <NEWLINE> import matplotlib . pyplot as plt <NEWLINE> import numpy as np <NEWLINE>", "anonymize_dict": {}}], ["b3d7ed2bc9b7c115c154efbb3a5d079f", {"code_string": "import sys\nimport os\nfrom os import path\nsys.path.append(\".\")\nfrom igor.vcs.git import Git\n", "code_toks_joined": "import sys <NEWLINE> import os <NEWLINE> from os import path <NEWLINE> sys . path . append ( <STRING> ) <NEWLINE> from igor . vcs . git import Git <NEWLINE>", "anonymize_dict": {"<STRING>": ["\".\""]}}], ["896d68fbdd9f1a361367c4b26514137e", {"code_string": "import re\nimport datetime\nfrom south.db import db\nfrom south.v2 import DataMigration\nfrom django.db import models\nfrom transifex.resources.models import(Resource, SourceEntity, Translation,\n    Template)\nfrom xml.sax.saxutils import escape, unescape\n", "code_toks_joined": "import re <NEWLINE> import datetime <NEWLINE> from south . db import db <NEWLINE> from south . v2 import DataMigration <NEWLINE> from django . db import models <NEWLINE> from transifex . resources . models import ( Resource , SourceEntity , Translation , <NEWLINE> <INDENT> Template ) <NEWLINE> <DEDENT> from xml . sax . saxutils import escape , unescape <NEWLINE>", "anonymize_dict": {}}], ["58f68b46479faad868bcc64483a49724", {"code_string": "def backspace(self, length):\n    for _ in range(length):\n        sys.stdout.write('\\b')\n        sys.stdout.flush()\n        self.typing_change()\n        time.sleep(self.type_delay)\n", "code_toks_joined": "def backspace ( self , length ) : <NEWLINE> <INDENT> for _ in range ( length ) : <NEWLINE> <INDENT> sys . stdout . write ( <STRING> ) <NEWLINE> sys . stdout . flush ( ) <NEWLINE> self . typing_change ( ) <NEWLINE> time . sleep ( self . type_delay ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'\\b'"]}}], ["97febe4cbdaa545d40d3419eae6d026f", {"code_string": "class Node(object):\n    def __init__(self, data = None, previous = None):\n        self.data = data\n        self.previous = previous\n", "code_toks_joined": "class Node ( object ) : <NEWLINE> <INDENT> def __init__ ( self , data = None , previous = None ) : <NEWLINE> <INDENT> self . data = data <NEWLINE> self . previous = previous <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["6b2f3cbdca8a1bc20631d8d8561924c1", {"code_string": "from Axon.AxonExceptions import AxonException as _AxonException\nclass socketSendFailure(_AxonException): pass\nclass connectionClosedown(_AxonException): pass\nclass connectionDied(connectionClosedown): pass\nclass connectionDiedSending(connectionDied): pass\nclass connectionDiedReceiving(connectionDied): pass\nclass connectionServerShutdown(connectionClosedown): pass\n", "code_toks_joined": "from Axon . AxonExceptions import AxonException as _AxonException <NEWLINE> class socketSendFailure ( _AxonException ) : pass <NEWLINE> class connectionClosedown ( _AxonException ) : pass <NEWLINE> class connectionDied ( connectionClosedown ) : pass <NEWLINE> class connectionDiedSending ( connectionDied ) : pass <NEWLINE> class connectionDiedReceiving ( connectionDied ) : pass <NEWLINE> class connectionServerShutdown ( connectionClosedown ) : pass <NEWLINE>", "anonymize_dict": {}}], ["e60a830182a5e648dd4ec43ebc2a00e7", {"code_string": "def test():\n    \"\"\"locally imports defaultPresets\"\"\"\n    global curDict\n    if fail:\n        import defaultPresets\n        curDict = defaultPresets.defPresetDict\n", "code_toks_joined": "def test ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> global curDict <NEWLINE> if fail : <NEWLINE> <INDENT> import defaultPresets <NEWLINE> curDict = defaultPresets . defPresetDict <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"locally imports defaultPresets\"\"\""]}}], ["645f2b8af722960f2c0d8d8c0d0fb83e", {"code_string": "class TestController(Sofa.PythonScriptController):\n    def __init__(self):\n        return None\n    def onBeginAnimationStep(self, v):\n        name = self.findData(\"name\")\n        name.setValue(123)\n    def onEndAnimationStep(self, v):\n        name = self.findData(\"name\")\n        name.setValue(123)\n    def f2(self):\n        f3()\n    def draw(self):\n        self.f2()\n", "code_toks_joined": "class TestController ( Sofa . PythonScriptController ) : <NEWLINE> <INDENT> def __init__ ( self ) : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> def onBeginAnimationStep ( self , v ) : <NEWLINE> <INDENT> name = self . findData ( <STRING> ) <NEWLINE> name . setValue ( 123 ) <NEWLINE> <DEDENT> def onEndAnimationStep ( self , v ) : <NEWLINE> <INDENT> name = self . findData ( <STRING> ) <NEWLINE> name . setValue ( 123 ) <NEWLINE> <DEDENT> def f2 ( self ) : <NEWLINE> <INDENT> f3 ( ) <NEWLINE> <DEDENT> def draw ( self ) : <NEWLINE> <INDENT> self . f2 ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"name\"", "\"name\""]}}], ["91f303677c0ba834bed049e6795ddf89", {"code_string": "class BugreportTests(unittest.TestCase):\n    def test_default(self):\n        report = bugreport()\n        self.assertFalse('Unknown Celery version' in report)\n        self.assertTrue('tornado' in report)\n        self.assertTrue('babel' in report)\n        self.assertTrue('celery' in report)\n    def test_with_app(self):\n        app = Celery()\n        report = bugreport(app)\n        self.assertFalse('Unknown Celery version' in report)\n        self.assertTrue('tornado' in report)\n        self.assertTrue('babel' in report)\n        self.assertTrue('celery' in report)\n", "code_toks_joined": "class BugreportTests ( unittest . TestCase ) : <NEWLINE> <INDENT> def test_default ( self ) : <NEWLINE> <INDENT> report = bugreport ( ) <NEWLINE> self . assertFalse ( <STRING> in report ) <NEWLINE> self . assertTrue ( <STRING> in report ) <NEWLINE> self . assertTrue ( <STRING> in report ) <NEWLINE> self . assertTrue ( <STRING> in report ) <NEWLINE> <DEDENT> def test_with_app ( self ) : <NEWLINE> <INDENT> app = Celery ( ) <NEWLINE> report = bugreport ( app ) <NEWLINE> self . assertFalse ( <STRING> in report ) <NEWLINE> self . assertTrue ( <STRING> in report ) <NEWLINE> self . assertTrue ( <STRING> in report ) <NEWLINE> self . assertTrue ( <STRING> in report ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Unknown Celery version'", "'tornado'", "'babel'", "'celery'", "'Unknown Celery version'", "'tornado'", "'babel'", "'celery'"]}}], ["867d8465092715928b8b43b5e426e523", {"code_string": "def is_prime(num):\n    if num < 2:\n        return False\n    for i in range(num):\n        if i < 2:\n            continue\n        if num % i == 0:\n            return False\n    return True\n", "code_toks_joined": "def is_prime ( num ) : <NEWLINE> <INDENT> if num < 2 : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> for i in range ( num ) : <NEWLINE> <INDENT> if i < 2 : <NEWLINE> <INDENT> continue <NEWLINE> <DEDENT> if num % i == 0 : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> <DEDENT> return True <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["c0cb8f8b0683bc26c4535b90399713fc", {"code_string": "class tektronixMSO4034(tektronixMSO4000):\n    \"Tektronix MSO4034 IVI oscilloscope driver\"\n    def __init__(self, * args, ** kwargs):\n        self.__dict__.setdefault('_instrument_id', 'MSO4034')\n        super(tektronixMSO4034, self).__init__(* args, ** kwargs)\n        self._analog_channel_count = 4\n        self._digital_channel_count = 16\n        self._channel_count = self._analog_channel_count + self._digital_channel_count\n        self._bandwidth = 350e6\n        self._init_channels()\n", "code_toks_joined": "class tektronixMSO4034 ( tektronixMSO4000 ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , * args , ** kwargs ) : <NEWLINE> <INDENT> self . __dict__ . setdefault ( <STRING> , <STRING> ) <NEWLINE> super ( tektronixMSO4034 , self ) . __init__ ( * args , ** kwargs ) <NEWLINE> self . _analog_channel_count = 4 <NEWLINE> self . _digital_channel_count = 16 <NEWLINE> self . _channel_count = self . _analog_channel_count + self . _digital_channel_count <NEWLINE> self . _bandwidth = 350e6 <NEWLINE> self . _init_channels ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Tektronix MSO4034 IVI oscilloscope driver\"", "'_instrument_id'", "'MSO4034'"]}}], ["af0c03b2dbf591db594392505c84311c", {"code_string": "def get_lowest_bid_id(self, orders):\n    lowest_bid_id = None\n    lowest_bid_price = float('inf')\n    for order in orders:\n        if order['type'] == 'bid' and float(order['price']) < lowest_bid_price:\n            lowest_bid_price = float(order['price'])\n            lowest_bid_id = order['id']\n    return lowest_bid_id\n", "code_toks_joined": "def get_lowest_bid_id ( self , orders ) : <NEWLINE> <INDENT> lowest_bid_id = None <NEWLINE> lowest_bid_price = float ( <STRING> ) <NEWLINE> for order in orders : <NEWLINE> <INDENT> if order [ <STRING> ] == <STRING> and float ( order [ <STRING> ] ) < lowest_bid_price : <NEWLINE> <INDENT> lowest_bid_price = float ( order [ <STRING> ] ) <NEWLINE> lowest_bid_id = order [ <STRING> ] <NEWLINE> <DEDENT> <DEDENT> return lowest_bid_id <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'inf'", "'type'", "'bid'", "'price'", "'price'", "'id'"]}}], ["cd391299b4b50140afa9d7a6207a7fe5", {"code_string": "def do_yank_pop(self):\n    if self.smart_match(self.previous_key, ['C-y', 'M-y']):\n        self.owner.yank_pop(self.yank_index)\n        self.yank_index -= 1\n    return ''\n", "code_toks_joined": "def do_yank_pop ( self ) : <NEWLINE> <INDENT> if self . smart_match ( self . previous_key , [ <STRING> , <STRING> ] ) : <NEWLINE> <INDENT> self . owner . yank_pop ( self . yank_index ) <NEWLINE> self . yank_index -= 1 <NEWLINE> <DEDENT> return <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'C-y'", "'M-y'", "''"]}}], ["eeaa69fdb2d64ebb73bf15b6e6df11d6", {"code_string": "def code_detecter(data):\n    try:\n        return chardet.detect(data)['encoding']\n    except:\n        return 'cp866'\n", "code_toks_joined": "def code_detecter ( data ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> return chardet . detect ( data ) [ <STRING> ] <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'encoding'", "'cp866'"]}}], ["6686a01ab01962bd3d058cc81ee3df39", {"code_string": "from inspect import isgenerator\nfrom collections import namedtuple\nimport numpy as np\nfrom scipy import linalg, sparse\nfrom..externals.six import string_types\nfrom..source_estimate import SourceEstimate\nfrom..epochs import _BaseEpochs\nfrom..evoked import Evoked, EvokedArray\nfrom..utils import logger, _reject_data_segments, warn\nfrom..io.pick import pick_types, pick_info\nfrom..fixes import in1d\n", "code_toks_joined": "from inspect import isgenerator <NEWLINE> from collections import namedtuple <NEWLINE> import numpy as np <NEWLINE> from scipy import linalg , sparse <NEWLINE> from . . externals . six import string_types <NEWLINE> from . . source_estimate import SourceEstimate <NEWLINE> from . . epochs import _BaseEpochs <NEWLINE> from . . evoked import Evoked , EvokedArray <NEWLINE> from . . utils import logger , _reject_data_segments , warn <NEWLINE> from . . io . pick import pick_types , pick_info <NEWLINE> from . . fixes import in1d <NEWLINE>", "anonymize_dict": {}}], ["4a1d6940f4bd593d9565485528aaf061", {"code_string": "def __init__(self, textSettings, customTitle = None, customIcon = None, customThumb = None):\n    self.textSettings = textSettings\n    self.customTitle = customTitle\n    self.customIcon = customIcon\n    self.customThumb = customThumb\n", "code_toks_joined": "def __init__ ( self , textSettings , customTitle = None , customIcon = None , customThumb = None ) : <NEWLINE> <INDENT> self . textSettings = textSettings <NEWLINE> self . customTitle = customTitle <NEWLINE> self . customIcon = customIcon <NEWLINE> self . customThumb = customThumb <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["c73257b3c146fcdbb63034ecfd9aee26", {"code_string": "def clear(self):\n    \"\"\"Clear all printed lines\"\"\"\n    sys.stdout.write(\n        self.lines *(terminal.UP + terminal.BOL + terminal.CLEAR_EOL)\n    )\n", "code_toks_joined": "def clear ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> sys . stdout . write ( <NEWLINE> <INDENT> self . lines * ( terminal . UP + terminal . BOL + terminal . CLEAR_EOL ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Clear all printed lines\"\"\""]}}], ["30e8093e79efd3d13153ae1a9fb3fc61", {"code_string": "def is_fieldcode(self, concept):\n    \"\"\"Determines whether the provided concept from a mapping\"\"\"\n    result = False\n    if concept.simple:\n        result = self._available(concept.lbfc)\n    return result\n", "code_toks_joined": "def is_fieldcode ( self , concept ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> result = False <NEWLINE> if concept . simple : <NEWLINE> <INDENT> result = self . _available ( concept . lbfc ) <NEWLINE> <DEDENT> return result <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Determines whether the provided concept from a mapping\"\"\""]}}], ["a726b5d40ac0ae78bcf82bfb407a1505", {"code_string": "def trans_status(status, to_label = False):\n    if asbool(to_label):\n        return label_status_translation.get(status, status)\n    return dict_status.get(status, status)\n", "code_toks_joined": "def trans_status ( status , to_label = False ) : <NEWLINE> <INDENT> if asbool ( to_label ) : <NEWLINE> <INDENT> return label_status_translation . get ( status , status ) <NEWLINE> <DEDENT> return dict_status . get ( status , status ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["137e39c5c3950b2e2a0bd0e13d1d461d", {"code_string": "def clone(self, name):\n    \"\"\"Clone an existing test script.\"\"\"\n    if self.id is None:\n        raise Exception(\"Missing id: This API requires a monitor ID be supplied.\")\n    clone_script = {\"id\": self.id, \"cloneName\": name}\n    return self.connection.post(self.service + \"/clone\", json.dumps(clone_script))\n", "code_toks_joined": "def clone ( self , name ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if self . id is None : <NEWLINE> <INDENT> raise Exception ( <STRING> ) <NEWLINE> <DEDENT> clone_script = { <STRING> : self . id , <STRING> : name } <NEWLINE> return self . connection . post ( self . service + <STRING> , json . dumps ( clone_script ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Clone an existing test script.\"\"\"", "\"Missing id: This API requires a monitor ID be supplied.\"", "\"id\"", "\"cloneName\"", "\"/clone\""]}}], ["c6e2bd93cda12b8cbd9632826a3ed8b3", {"code_string": "def getDetail(self, rid):\n    url = 'http://wjw.sysu.edu.cn/api/score_detail?resource_id=' + rid\n    res = self.session.get(url).content.decode('utf-8')\n    try:\n        res = re.findall(r'primary:(\\[.+?\\])', res)[0].replace('\\\\/', '/')\n    except IndexError:\n        return[]\n    else:\n        return json.loads(res)\n", "code_toks_joined": "def getDetail ( self , rid ) : <NEWLINE> <INDENT> url = <STRING> + rid <NEWLINE> res = self . session . get ( url ) . content . decode ( <STRING> ) <NEWLINE> try : <NEWLINE> <INDENT> res = re . findall ( <STRING> , res ) [ 0 ] . replace ( <STRING> , <STRING> ) <NEWLINE> <DEDENT> except IndexError : <NEWLINE> <INDENT> return [ ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return json . loads ( res ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'http://wjw.sysu.edu.cn/api/score_detail?resource_id='", "'utf-8'", "r'primary:(\\[.+?\\])'", "'\\\\/'", "'/'"]}}], ["0ea0453ba39696b13863e381cfe8708d", {"code_string": "class ObsObject(object):\n    def __init__(self, x_rel, uvi_rel, x_abs, y_rel, y_abs):\n        self.x_rel, self.uvi_rel, self.x_abs, self.y_rel, self.y_abs = x_rel, uvi_rel, x_abs, y_rel, y_abs\n", "code_toks_joined": "class ObsObject ( object ) : <NEWLINE> <INDENT> def __init__ ( self , x_rel , uvi_rel , x_abs , y_rel , y_abs ) : <NEWLINE> <INDENT> self . x_rel , self . uvi_rel , self . x_abs , self . y_rel , self . y_abs = x_rel , uvi_rel , x_abs , y_rel , y_abs <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["76f6a8a5cdb13a86a5ff34f94f2971c3", {"code_string": "class fedex_message(models.TransientModel):\n    _name = \"fedex.message\"\n    _description = \"Fedex Message Display\"\n    name = fields.Text('Message')\n", "code_toks_joined": "class fedex_message ( models . TransientModel ) : <NEWLINE> <INDENT> _name = <STRING> <NEWLINE> _description = <STRING> <NEWLINE> name = fields . Text ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"fedex.message\"", "\"Fedex Message Display\"", "'Message'"]}}], ["f173d682a12e61bc1d43397c17556fe7", {"code_string": "def test_delete_item():\n    table = create_table()\n    item_data = {\n        'forum_name': 'LOLCat Forum',\n        'Body': 'http://url_to_lolcat.gif',\n        'SentBy': 'User A',\n        'ReceivedTime': '12/9/2011 11:36:03 PM',\n    }\n    item = Item(table, item_data)\n    item['subject'] = 'Check this out!'\n    item.save()\n    table.count().should.equal(1)\n    response = item.delete()\n    response.should.equal(True)\n    table.count().should.equal(0)\n    item.delete().should.equal(False)\n", "code_toks_joined": "def test_delete_item ( ) : <NEWLINE> <INDENT> table = create_table ( ) <NEWLINE> item_data = { <NEWLINE> <INDENT> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <DEDENT> } <NEWLINE> item = Item ( table , item_data ) <NEWLINE> item [ <STRING> ] = <STRING> <NEWLINE> item . save ( ) <NEWLINE> table . count ( ) . should . equal ( 1 ) <NEWLINE> response = item . delete ( ) <NEWLINE> response . should . equal ( True ) <NEWLINE> table . count ( ) . should . equal ( 0 ) <NEWLINE> item . delete ( ) . should . equal ( False ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'forum_name'", "'LOLCat Forum'", "'Body'", "'http://url_to_lolcat.gif'", "'SentBy'", "'User A'", "'ReceivedTime'", "'12/9/2011 11:36:03 PM'", "'subject'", "'Check this out!'"]}}], ["b6fd85f4bf1085eccc15b69fa237787e", {"code_string": "import re\nfrom django import template\nfrom django.conf import settings\nfrom django.template import TemplateSyntaxError\nfrom django.utils import six\nfrom django.utils.encoding import smart_str\nfrom django_hosts.reverse import reverse_full\nregister = template.Library()\nkwarg_re = re.compile(r\"(?:(\\w+)=)?(.+)\")\n", "code_toks_joined": "import re <NEWLINE> from django import template <NEWLINE> from django . conf import settings <NEWLINE> from django . template import TemplateSyntaxError <NEWLINE> from django . utils import six <NEWLINE> from django . utils . encoding import smart_str <NEWLINE> from django_hosts . reverse import reverse_full <NEWLINE> register = template . Library ( ) <NEWLINE> kwarg_re = re . compile ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["r\"(?:(\\w+)=)?(.+)\""]}}], ["ffdecbe86247c98d666d6a1c709bbe54", {"code_string": "n = int(input())\narr = list(map(int, input().split()))\nqts = [0 for i in range(101)]\nfor i in range(n):\n    qts[arr[i]] += 1\nprint(n - max(qts))\n", "code_toks_joined": "n = int ( input ( ) ) <NEWLINE> arr = list ( map ( int , input ( ) . split ( ) ) ) <NEWLINE> qts = [ 0 for i in range ( 101 ) ] <NEWLINE> for i in range ( n ) : <NEWLINE> <INDENT> qts [ arr [ i ] ] += 1 <NEWLINE> <DEDENT> print ( n - max ( qts ) ) <NEWLINE>", "anonymize_dict": {}}], ["2e307dd49403129da4f5d778595ff485", {"code_string": "def delete(self, client = None):\n    \"\"\"API call:  delete the subscription via a DELETE request.\"\"\"\n    client = self._require_client(client)\n    api = client.subscriber_api\n    api.subscription_delete(self.full_name)\n", "code_toks_joined": "def delete ( self , client = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> client = self . _require_client ( client ) <NEWLINE> api = client . subscriber_api <NEWLINE> api . subscription_delete ( self . full_name ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"API call:  delete the subscription via a DELETE request.\"\"\""]}}], ["00cd53d3de708499edd5681d3cc392df", {"code_string": "def json_object(self, recursive = True):\n    obj = {\n        \"Id\": self.v_id,\n        \"ds:RetrievalMethod Type\": self.v_retrieval_method_type,\n        \"ds:RetrievalMethod URI\": self.v_retrieval_method_uri,\n        \"enc:CipherReference URI\": self.v_cipher_reference_uri,\n        \"enc:EncryptionMethod Algorithm\":\n            self.v_encryption_method_algorithm,\n    }\n    return obj\n", "code_toks_joined": "def json_object ( self , recursive = True ) : <NEWLINE> <INDENT> obj = { <NEWLINE> <INDENT> <STRING> : self . v_id , <NEWLINE> <STRING> : self . v_retrieval_method_type , <NEWLINE> <STRING> : self . v_retrieval_method_uri , <NEWLINE> <STRING> : self . v_cipher_reference_uri , <NEWLINE> <STRING> : <NEWLINE> <INDENT> self . v_encryption_method_algorithm , <NEWLINE> <DEDENT> <DEDENT> } <NEWLINE> return obj <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Id\"", "\"ds:RetrievalMethod Type\"", "\"ds:RetrievalMethod URI\"", "\"enc:CipherReference URI\"", "\"enc:EncryptionMethod Algorithm\""]}}], ["a10997ee28d5d8a746677c7f6f8b217a", {"code_string": "def predict_ints(self, inputs):\n    preds = self.predict_func(self.spark, self.model, inputs)\n    return[str(p) for p in preds]\n", "code_toks_joined": "def predict_ints ( self , inputs ) : <NEWLINE> <INDENT> preds = self . predict_func ( self . spark , self . model , inputs ) <NEWLINE> return [ str ( p ) for p in preds ] <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["1812637cdaa6a504d5bfa86d807d5874", {"code_string": "def progress_callback(total_downloaded, total_size):\n    global progress_dialog\n    if progress_dialog == None:\n        progress_dialog = create_progress_dialog()\n        progress_dialog.Show()\n    if total_downloaded == total_size:\n        progress_dialog.Destroy()\n    else:\n        progress_dialog.Update((total_downloaded * 100) / total_size, _(u\"Updating... %s of %s\") %(str(utils.convert_bytes(total_downloaded)), str(utils.convert_bytes(total_size))))\n", "code_toks_joined": "def progress_callback ( total_downloaded , total_size ) : <NEWLINE> <INDENT> global progress_dialog <NEWLINE> if progress_dialog == None : <NEWLINE> <INDENT> progress_dialog = create_progress_dialog ( ) <NEWLINE> progress_dialog . Show ( ) <NEWLINE> <DEDENT> if total_downloaded == total_size : <NEWLINE> <INDENT> progress_dialog . Destroy ( ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> progress_dialog . Update ( ( total_downloaded * 100 ) / total_size , _ ( <STRING> ) % ( str ( utils . convert_bytes ( total_downloaded ) ) , str ( utils . convert_bytes ( total_size ) ) ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["u\"Updating... %s of %s\""]}}], ["c54983be24b64586e4f14fd5e50367b6", {"code_string": "def bind(self, userargs):\n    self.rq.bind(userargs)\n    return self\n", "code_toks_joined": "def bind ( self , userargs ) : <NEWLINE> <INDENT> self . rq . bind ( userargs ) <NEWLINE> return self <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["250a1655a91d4a62af9c1b9cddbcb646", {"code_string": "class BaseTestCase(unittest.TestCase):\n    def setUp(self):\n        Application.app.wsgi_app = FlaskTestClientProxy(Application.app.wsgi_app)\n        Application.app.config['TESTING'] = True\n        Application.app.config['WTF_CSRF_ENABLED'] = False\n        self.app = Application.app.test_client()\n        self._app = Application.app\n    def tearDown(self):\n        pass\n    def test_sample(self):\n        response = self.app.get('/')\n        assert '' in response.data.decode('UTF-8')\n", "code_toks_joined": "class BaseTestCase ( unittest . TestCase ) : <NEWLINE> <INDENT> def setUp ( self ) : <NEWLINE> <INDENT> Application . app . wsgi_app = FlaskTestClientProxy ( Application . app . wsgi_app ) <NEWLINE> Application . app . config [ <STRING> ] = True <NEWLINE> Application . app . config [ <STRING> ] = False <NEWLINE> self . app = Application . app . test_client ( ) <NEWLINE> self . _app = Application . app <NEWLINE> <DEDENT> def tearDown ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def test_sample ( self ) : <NEWLINE> <INDENT> response = self . app . get ( <STRING> ) <NEWLINE> assert <STRING> in response . data . decode ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'TESTING'", "'WTF_CSRF_ENABLED'", "'/'", "''", "'UTF-8'"]}}], ["ddca09d8e11e24560c67988cc7f9ae68", {"code_string": "def add_current_tie(self, name, available_ties):\n    if self.fit_radioButton.isChecked() and self.ties_comboBox.findText(name) == - 1:\n        self.ties_comboBox.addItem(name)\n", "code_toks_joined": "def add_current_tie ( self , name , available_ties ) : <NEWLINE> <INDENT> if self . fit_radioButton . isChecked ( ) and self . ties_comboBox . findText ( name ) == - 1 : <NEWLINE> <INDENT> self . ties_comboBox . addItem ( name ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["51e75480aa7bf6ff2cf315a029fe443f", {"code_string": "\"\"\"Base proxy module used to create compatible consoles\"\"\"\nimport os\nimport sys\nfrom oslo_config import cfg\nfrom oslo_log import log as logging\nfrom nova.console import websocketproxy\nfrom nova.openstack.common.report import guru_meditation_report as gmr\nfrom nova import version\nCONF = cfg.CONF\nCONF.import_opt('record', 'nova.cmd.novnc')\nCONF.import_opt('daemon', 'nova.cmd.novnc')\nCONF.import_opt('ssl_only', 'nova.cmd.novnc')\nCONF.import_opt('source_is_ipv6', 'nova.cmd.novnc')\nCONF.import_opt('cert', 'nova.cmd.novnc')\nCONF.import_opt('key', 'nova.cmd.novnc')\nCONF.import_opt('web', 'nova.cmd.novnc')\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> import sys <NEWLINE> from oslo_config import cfg <NEWLINE> from oslo_log import log as logging <NEWLINE> from nova . console import websocketproxy <NEWLINE> from nova . openstack . common . report import guru_meditation_report as gmr <NEWLINE> from nova import version <NEWLINE> CONF = cfg . CONF <NEWLINE> CONF . import_opt ( <STRING> , <STRING> ) <NEWLINE> CONF . import_opt ( <STRING> , <STRING> ) <NEWLINE> CONF . import_opt ( <STRING> , <STRING> ) <NEWLINE> CONF . import_opt ( <STRING> , <STRING> ) <NEWLINE> CONF . import_opt ( <STRING> , <STRING> ) <NEWLINE> CONF . import_opt ( <STRING> , <STRING> ) <NEWLINE> CONF . import_opt ( <STRING> , <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Base proxy module used to create compatible consoles\"\"\"", "'record'", "'nova.cmd.novnc'", "'daemon'", "'nova.cmd.novnc'", "'ssl_only'", "'nova.cmd.novnc'", "'source_is_ipv6'", "'nova.cmd.novnc'", "'cert'", "'nova.cmd.novnc'", "'key'", "'nova.cmd.novnc'", "'web'", "'nova.cmd.novnc'"]}}], ["221df3bd6d50abaab1d041cbbbbeeb97", {"code_string": "def test_get_printer_info(tmpdir):\n    ppd_path = tmpdir.join('ppd')\n    ppd_path.write('this is a ppd')\n    cups = mock.Mock(name = 'cups')\n    cups.getPPD.return_value = str(ppd_path)\n    cups.getPrinterAttributes.return_value = {\n        'printer-info': mock.sentinel.desc\n    }\n    ppd, description = cloudprint.get_printer_info(cups, 'foo')\n    assert ppd == 'this is a ppd'\n    assert description == mock.sentinel.desc\n    cups.getPPD.assert_called_with('foo')\n    cups.getPrinterAttributes.assert_called_with('foo')\n", "code_toks_joined": "def test_get_printer_info ( tmpdir ) : <NEWLINE> <INDENT> ppd_path = tmpdir . join ( <STRING> ) <NEWLINE> ppd_path . write ( <STRING> ) <NEWLINE> cups = mock . Mock ( name = <STRING> ) <NEWLINE> cups . getPPD . return_value = str ( ppd_path ) <NEWLINE> cups . getPrinterAttributes . return_value = { <NEWLINE> <INDENT> <STRING> : mock . sentinel . desc <NEWLINE> <DEDENT> } <NEWLINE> ppd , description = cloudprint . get_printer_info ( cups , <STRING> ) <NEWLINE> assert ppd == <STRING> <NEWLINE> assert description == mock . sentinel . desc <NEWLINE> cups . getPPD . assert_called_with ( <STRING> ) <NEWLINE> cups . getPrinterAttributes . assert_called_with ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'ppd'", "'this is a ppd'", "'cups'", "'printer-info'", "'foo'", "'this is a ppd'", "'foo'", "'foo'"]}}], ["b5c8c3a3a4dd2f8e2a4c86671e11c403", {"code_string": "class JsonHandler(webapp2.RequestHandler):\n    \"\"\"A JSON-emitting handler.\"\"\"\n    def emit_json(self, data):\n        self.response.headers['Content-Type'] = 'application/json'\n        self.response.write(json.dumps(data))\n", "code_toks_joined": "class JsonHandler ( webapp2 . RequestHandler ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def emit_json ( self , data ) : <NEWLINE> <INDENT> self . response . headers [ <STRING> ] = <STRING> <NEWLINE> self . response . write ( json . dumps ( data ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"A JSON-emitting handler.\"\"\"", "'Content-Type'", "'application/json'"]}}], ["2f882dd7d66dbb92f7164cf1bb19cc91", {"code_string": "from __future__ import print_function\ntry:\n    import sqlite3 as sqlite\nexcept ImportError as e:\n    from pysqlite2 import dbapi2 as sqlite\nfrom weboob.core import Weboob\nfrom weboob.exceptions import ModuleLoadError\nimport sys\nimport logging\nlevel = logging.DEBUG\nlogging.basicConfig(stream = sys.stdout, level = level)\n", "code_toks_joined": "from __future__ import print_function <NEWLINE> try : <NEWLINE> <INDENT> import sqlite3 as sqlite <NEWLINE> <DEDENT> except ImportError as e : <NEWLINE> <INDENT> from pysqlite2 import dbapi2 as sqlite <NEWLINE> <DEDENT> from weboob . core import Weboob <NEWLINE> from weboob . exceptions import ModuleLoadError <NEWLINE> import sys <NEWLINE> import logging <NEWLINE> level = logging . DEBUG <NEWLINE> logging . basicConfig ( stream = sys . stdout , level = level ) <NEWLINE>", "anonymize_dict": {}}], ["9236c19d4a9427f18cbf737d08911b22", {"code_string": "def executeWithPriceOnly(self, price):\n    currenTime = time.strftime(\"%H:%M:%S\")\n    timeInSeconds = self._get_sec(currenTime)\n    correcpondingAlphabet = self._findCorrespondingAlphabetForGivenTime(timeInSeconds, self.timeFrameToAlphabetList)\n    if self.doStoreOnlyInHeap == True:\n        self._isAlphabetAlreadyIncludedInTheTick(price, correcpondingAlphabet)\n", "code_toks_joined": "def executeWithPriceOnly ( self , price ) : <NEWLINE> <INDENT> currenTime = time . strftime ( <STRING> ) <NEWLINE> timeInSeconds = self . _get_sec ( currenTime ) <NEWLINE> correcpondingAlphabet = self . _findCorrespondingAlphabetForGivenTime ( timeInSeconds , self . timeFrameToAlphabetList ) <NEWLINE> if self . doStoreOnlyInHeap == True : <NEWLINE> <INDENT> self . _isAlphabetAlreadyIncludedInTheTick ( price , correcpondingAlphabet ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"%H:%M:%S\""]}}], ["8581b2aae0588e6271846cbf55d8ad87", {"code_string": "from zeit.newsletter.newsletter import Newsletter\nimport mock\nimport zeit.newsletter.testing\n", "code_toks_joined": "from zeit . newsletter . newsletter import Newsletter <NEWLINE> import mock <NEWLINE> import zeit . newsletter . testing <NEWLINE>", "anonymize_dict": {}}], ["44feaa3fb32c5aa4b572ca201edf01dc", {"code_string": "def operation(self):\n    \"\"\":return str: The type of job being run.\"\"\"\n    return self._operation\n", "code_toks_joined": "def operation ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . _operation <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\":return str: The type of job being run.\"\"\""]}}], ["939387edd7f3dc7b462b5d2ef3679b0d", {"code_string": "def __init__(self):\n    addApiView('charts.view', self.automationView)\n    addApiView('charts.ignore', self.ignoreView)\n", "code_toks_joined": "def __init__ ( self ) : <NEWLINE> <INDENT> addApiView ( <STRING> , self . automationView ) <NEWLINE> addApiView ( <STRING> , self . ignoreView ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'charts.view'", "'charts.ignore'"]}}], ["ddb0a4d08253323008cfa2d727b9a137", {"code_string": "def __init__(self, serviceName, url, failureLimit, retestDelay):\n    self._init()\n    (self).serviceName = serviceName\n    (self).url = url\n    (self).breaker = behaviors.CircuitBreaker(((((u\"[\") +(serviceName)) +(u\" at \")) +(url)) +(u\"]\"), failureLimit, retestDelay)\n", "code_toks_joined": "def __init__ ( self , serviceName , url , failureLimit , retestDelay ) : <NEWLINE> <INDENT> self . _init ( ) <NEWLINE> ( self ) . serviceName = serviceName <NEWLINE> ( self ) . url = url <NEWLINE> ( self ) . breaker = behaviors . CircuitBreaker ( ( ( ( ( <STRING> ) + ( serviceName ) ) + ( <STRING> ) ) + ( url ) ) + ( <STRING> ) , failureLimit , retestDelay ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["u\"[\"", "u\" at \"", "u\"]\""]}}], ["47d72a73d02e5cc9f78fd5569020b89e", {"code_string": "class Nothing(Chain):\n    def step(self):\n        globals.controller.empty_input()\n        self.interruptible = True\n", "code_toks_joined": "class Nothing ( Chain ) : <NEWLINE> <INDENT> def step ( self ) : <NEWLINE> <INDENT> globals . controller . empty_input ( ) <NEWLINE> self . interruptible = True <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["71d4d94ddc3f1d888b05c6f00afebc30", {"code_string": "def _6():\n    gw(1, 0, 99)\n    sa(sp() + sp());\n    return 7\n", "code_toks_joined": "def _6 ( ) : <NEWLINE> <INDENT> gw ( 1 , 0 , 99 ) <NEWLINE> sa ( sp ( ) + sp ( ) ) ; <NEWLINE> return 7 <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["e007de8c9d109c9ef875253ec63410b4", {"code_string": "import numpy\nimport csv\nimport datetime\nimport sys\nimport os.path\nunscaled_mmsi = [224068000, 224098250, 224108130]\n", "code_toks_joined": "import numpy <NEWLINE> import csv <NEWLINE> import datetime <NEWLINE> import sys <NEWLINE> import os . path <NEWLINE> unscaled_mmsi = [ 224068000 , 224098250 , 224108130 ] <NEWLINE>", "anonymize_dict": {}}], ["6cd38a3ccb4920d4ded974119dd2f9d6", {"code_string": "from functools import wraps\nfrom django.contrib.auth.decorators import login_required\nfrom django.core.exceptions import PermissionDenied\nfrom.models import Member\n", "code_toks_joined": "from functools import wraps <NEWLINE> from django . contrib . auth . decorators import login_required <NEWLINE> from django . core . exceptions import PermissionDenied <NEWLINE> from . models import Member <NEWLINE>", "anonymize_dict": {}}], ["f78aad4f6bfe63396318675843bac25b", {"code_string": "class GazelleTest(BackendTest):\n    BACKEND = 'gazelle'\n    def test_torrent(self):\n        l = list(self.backend.iter_torrents('sex'))\n        if len(l) > 0:\n            self.backend.get_torrent_file(l[0].id)\n", "code_toks_joined": "class GazelleTest ( BackendTest ) : <NEWLINE> <INDENT> BACKEND = <STRING> <NEWLINE> def test_torrent ( self ) : <NEWLINE> <INDENT> l = list ( self . backend . iter_torrents ( <STRING> ) ) <NEWLINE> if len ( l ) > 0 : <NEWLINE> <INDENT> self . backend . get_torrent_file ( l [ 0 ] . id ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'gazelle'", "'sex'"]}}], ["78421df828fcc20909a6cef910447a53", {"code_string": "def ontvkg_genres():\n    items = []\n    item_list = get_genres()\n    items = [{\n        'label': item['label'],\n        'path': plugin.url_for('ontvkg_shows_by_genre', type = 'genre', id = item['id']),\n        'thumbnail': item['icon'],\n    } for item in item_list]\n    return items\n", "code_toks_joined": "def ontvkg_genres ( ) : <NEWLINE> <INDENT> items = [ ] <NEWLINE> item_list = get_genres ( ) <NEWLINE> items = [ { <NEWLINE> <INDENT> <STRING> : item [ <STRING> ] , <NEWLINE> <STRING> : plugin . url_for ( <STRING> , type = <STRING> , id = item [ <STRING> ] ) , <NEWLINE> <STRING> : item [ <STRING> ] , <NEWLINE> <DEDENT> } for item in item_list ] <NEWLINE> return items <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'label'", "'label'", "'path'", "'ontvkg_shows_by_genre'", "'genre'", "'id'", "'thumbnail'", "'icon'"]}}], ["047c99b2b5e3d8dfb6e9a63d024b8d70", {"code_string": "def dmesg_and_objdump(application):\n    app_name = application.split('/')[- 1][: 15]\n    error, output = commands.getstatusoutput(\"dmesg | tac\")\n    errmsg = None\n    for line in output.split('\\n'):\n        if app_name in line:\n            errmsg = line.strip()\n            break\n    error, dottxt_asm = commands.getstatusoutput('objdump -d -S %s' % application)\n    return errmsg, dottxt_asm.split('\\n')\n", "code_toks_joined": "def dmesg_and_objdump ( application ) : <NEWLINE> <INDENT> app_name = application . split ( <STRING> ) [ - 1 ] [ : 15 ] <NEWLINE> error , output = commands . getstatusoutput ( <STRING> ) <NEWLINE> errmsg = None <NEWLINE> for line in output . split ( <STRING> ) : <NEWLINE> <INDENT> if app_name in line : <NEWLINE> <INDENT> errmsg = line . strip ( ) <NEWLINE> break <NEWLINE> <DEDENT> <DEDENT> error , dottxt_asm = commands . getstatusoutput ( <STRING> % application ) <NEWLINE> return errmsg , dottxt_asm . split ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/'", "\"dmesg | tac\"", "'\\n'", "'objdump -d -S %s'", "'\\n'"]}}], ["ea79f7798b8c3e4266ccac2809212f72", {"code_string": "def GetBookmarks():\n    oc = ObjectContainer(title2 = unicode(L('Bookmarks')))\n    response = service.get_bookmarks()\n    for media in archive.HandleMediaList(response['data']['bookmarks']):\n        oc.add(media)\n    return oc\n", "code_toks_joined": "def GetBookmarks ( ) : <NEWLINE> <INDENT> oc = ObjectContainer ( title2 = unicode ( L ( <STRING> ) ) ) <NEWLINE> response = service . get_bookmarks ( ) <NEWLINE> for media in archive . HandleMediaList ( response [ <STRING> ] [ <STRING> ] ) : <NEWLINE> <INDENT> oc . add ( media ) <NEWLINE> <DEDENT> return oc <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Bookmarks'", "'data'", "'bookmarks'"]}}], ["4d2e9254ebb1febc3f03e338183c03ee", {"code_string": "class Crawler(CrawlerBase):\n    schedule = 'Mo,We,Fr'\n    time_zone = 'US/Pacific'\n    def crawl(self, pub_date):\n        page = self.parse_page('http://www.gunnerkrigg.com/index2.php')\n        url = page.src('img[src*=\"/comics/\"]')\n        title = page.alt('img[src*=\"/comics/\"]')\n        text = ''\n        for content in page.text(\n            'table[cellpadding=\"5\"] td', allow_multiple = True):\n            text += content + '\\n\\n'\n        text = text.strip()\n        return CrawlerImage(url, title, text)\n", "code_toks_joined": "class Crawler ( CrawlerBase ) : <NEWLINE> <INDENT> schedule = <STRING> <NEWLINE> time_zone = <STRING> <NEWLINE> def crawl ( self , pub_date ) : <NEWLINE> <INDENT> page = self . parse_page ( <STRING> ) <NEWLINE> url = page . src ( <STRING> ) <NEWLINE> title = page . alt ( <STRING> ) <NEWLINE> text = <STRING> <NEWLINE> for content in page . text ( <NEWLINE> <INDENT> <STRING> , allow_multiple = True ) : <NEWLINE> text += content + <STRING> <NEWLINE> <DEDENT> text = text . strip ( ) <NEWLINE> return CrawlerImage ( url , title , text ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Mo,We,Fr'", "'US/Pacific'", "'http://www.gunnerkrigg.com/index2.php'", "'img[src*=\"/comics/\"]'", "'img[src*=\"/comics/\"]'", "''", "'table[cellpadding=\"5\"] td'", "'\\n\\n'"]}}], ["c7487a475c6b8a0c2a2ed95506c42647", {"code_string": "\"\"\"OnionShare | https://onionshare.org/\"\"\"\nfrom __future__ import division\nimport os, sys, subprocess, inspect, platform, argparse, threading, time, math, inspect, platform\nfrom PyQt4 import QtCore, QtGui\nimport common\ntry:\n    import onionshare\nexcept ImportError:\n    sys.path.append(os.path.abspath(common.onionshare_gui_dir + \"/..\"))\n    import onionshare\nfrom onionshare import strings, helpers, web\nfrom file_selection import FileSelection\nfrom server_status import ServerStatus\nfrom downloads import Downloads\nfrom options import Options\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import division <NEWLINE> import os , sys , subprocess , inspect , platform , argparse , threading , time , math , inspect , platform <NEWLINE> from PyQt4 import QtCore , QtGui <NEWLINE> import common <NEWLINE> try : <NEWLINE> <INDENT> import onionshare <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> sys . path . append ( os . path . abspath ( common . onionshare_gui_dir + <STRING> ) ) <NEWLINE> import onionshare <NEWLINE> <DEDENT> from onionshare import strings , helpers , web <NEWLINE> from file_selection import FileSelection <NEWLINE> from server_status import ServerStatus <NEWLINE> from downloads import Downloads <NEWLINE> from options import Options <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"OnionShare | https://onionshare.org/\"\"\"", "\"/..\""]}}], ["ceb4c5baaf44a5862cd1cd199bc90a46", {"code_string": "\"\"\"MemoryFile Data\"\"\"\nimport c4d\nfrom c4d.storage import HyperFile, MemoryFileStruct\n", "code_toks_joined": "<STRING> <NEWLINE> import c4d <NEWLINE> from c4d . storage import HyperFile , MemoryFileStruct <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"MemoryFile Data\"\"\""]}}], ["104a9d73bea6142fd03720645ed7a83a", {"code_string": "class L1ADimensions(Enum):\n    echo_sample_ind = \"echo_sample_ind\"\n    sar_ku_pulse_burst_ind = \"sar_ku_pulse_burst_ind\"\n    sar_c_pulse_burst_ind = \"sar_c_pulse_burst_ind\"\n    ltm_max_ind = \"ltm_max_ind\"\n    time_l1a_echo_sar_ku = \"time_l1a_echo_sar_ku\"\n    time_l1a_echo_plrm = \"time_l1a_echo_plrm\"\n", "code_toks_joined": "class L1ADimensions ( Enum ) : <NEWLINE> <INDENT> echo_sample_ind = <STRING> <NEWLINE> sar_ku_pulse_burst_ind = <STRING> <NEWLINE> sar_c_pulse_burst_ind = <STRING> <NEWLINE> ltm_max_ind = <STRING> <NEWLINE> time_l1a_echo_sar_ku = <STRING> <NEWLINE> time_l1a_echo_plrm = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"echo_sample_ind\"", "\"sar_ku_pulse_burst_ind\"", "\"sar_c_pulse_burst_ind\"", "\"ltm_max_ind\"", "\"time_l1a_echo_sar_ku\"", "\"time_l1a_echo_plrm\""]}}], ["be0425b676cfdcefcf2ef4d863f73b55", {"code_string": "class ViewForm(forms.Form):\n    viewsorting = forms.ChoiceField(choices = VIEWSORTING,\n        widget = forms.Select(attrs = {\"style\": \"width:150px;margin-left:10px;\",\n            \"class\": \"pull-right form-control input-sm\"}))\n", "code_toks_joined": "class ViewForm ( forms . Form ) : <NEWLINE> <INDENT> viewsorting = forms . ChoiceField ( choices = VIEWSORTING , <NEWLINE> <INDENT> widget = forms . Select ( attrs = { <STRING> : <STRING> , <NEWLINE> <INDENT> <STRING> : <STRING> } ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"style\"", "\"width:150px;margin-left:10px;\"", "\"class\"", "\"pull-right form-control input-sm\""]}}], ["5f0e95feb9e3adc5c33569439d19c9c5", {"code_string": "def my_dict(x):\n    for i in x:\n        if x % 2 == 0:\n            print('even')\n        else:\n            print('odd')\n", "code_toks_joined": "def my_dict ( x ) : <NEWLINE> <INDENT> for i in x : <NEWLINE> <INDENT> if x % 2 == 0 : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'even'", "'odd'"]}}], ["75d308d7f3fb563ea09f797082234e65", {"code_string": "def to(self, event):\n    setting = \"to-%s\" % event[\"args_split\"][0]\n    messages = event[\"target\"].get_setting(setting, [])\n    messages.append([event[\"user\"].nickname,\n        \" \".join(event[\"args_split\"][1: ])])\n    event[\"target\"].set_setting(setting, messages)\n    event[\"stdout\"].write(\"Message saved\")\n", "code_toks_joined": "def to ( self , event ) : <NEWLINE> <INDENT> setting = <STRING> % event [ <STRING> ] [ 0 ] <NEWLINE> messages = event [ <STRING> ] . get_setting ( setting , [ ] ) <NEWLINE> messages . append ( [ event [ <STRING> ] . nickname , <NEWLINE> <INDENT> <STRING> . join ( event [ <STRING> ] [ 1 : ] ) ] ) <NEWLINE> <DEDENT> event [ <STRING> ] . set_setting ( setting , messages ) <NEWLINE> event [ <STRING> ] . write ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"to-%s\"", "\"args_split\"", "\"target\"", "\"user\"", "\" \"", "\"args_split\"", "\"target\"", "\"stdout\"", "\"Message saved\""]}}], ["a14c1a98aa85cc57ec50a1e413fc557b", {"code_string": "def require_ajax(func):\n    \"\"\"Checks to see if the request sent is of ajax type.\"\"\"\n    @ wraps(func)\n    def _decorator(request, * args, ** kwargs):\n        if request.is_ajax():\n            return func(request, * args, ** kwargs)\n        else:\n            raise Http404()\n    return _decorator\n", "code_toks_joined": "def require_ajax ( func ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> @ wraps ( func ) <NEWLINE> def _decorator ( request , * args , ** kwargs ) : <NEWLINE> <INDENT> if request . is_ajax ( ) : <NEWLINE> <INDENT> return func ( request , * args , ** kwargs ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> raise Http404 ( ) <NEWLINE> <DEDENT> <DEDENT> return _decorator <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Checks to see if the request sent is of ajax type.\"\"\""]}}], ["6c645899c093000e81fd21eecf0c1696", {"code_string": "import unittest\nimport pygame\nimport pygame.image\nfrom pgzero.screen import Screen\nfrom pgzero.loaders import set_root, images\npygame.init()\nsurf = pygame.display.set_mode((200, 100))\n", "code_toks_joined": "import unittest <NEWLINE> import pygame <NEWLINE> import pygame . image <NEWLINE> from pgzero . screen import Screen <NEWLINE> from pgzero . loaders import set_root , images <NEWLINE> pygame . init ( ) <NEWLINE> surf = pygame . display . set_mode ( ( 200 , 100 ) ) <NEWLINE>", "anonymize_dict": {}}], ["07c9b9f47138c0513511dbbce62bebf1", {"code_string": "\"\"\"___       __     __\"\"\"\nfrom setuptools import setup\nsetup(name = 'ezurl',\n    version = \"0.1.3.25\",\n    description = 'URL Generation for Python',\n    author = 'Joshua Walters',\n    author_email = 'therealdolphman@gmail.com',\n    url = 'https://github.com/Dolphman/ezurl',\n    packages = ['ezurl'],\n    keywords = ['URL Generation', 'Python URL generation', 'Python URL'],\n    classifiers = [\"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n        \"Topic :: Utilities\",\n        \"Programming Language :: Python :: 2.7\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.0\",\n        \"Programming Language :: Python :: 3.1\",\n        \"Programming Language :: Python :: 3.2\",\n        \"Programming Language :: Python :: 3.3\",\n        \"Programming Language :: Python :: 3.4\",\n        \"Programming Language :: Python :: 3.5\"],\n    license = \"MIT\"\n    )\n", "code_toks_joined": "<STRING> <NEWLINE> from setuptools import setup <NEWLINE> setup ( name = <STRING> , <NEWLINE> <INDENT> version = <STRING> , <NEWLINE> description = <STRING> , <NEWLINE> author = <STRING> , <NEWLINE> author_email = <STRING> , <NEWLINE> url = <STRING> , <NEWLINE> packages = [ <STRING> ] , <NEWLINE> keywords = [ <STRING> , <STRING> , <STRING> ] , <NEWLINE> classifiers = [ <STRING> , <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> ] , <NEWLINE> <DEDENT> license = <STRING> <NEWLINE> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"___       __     __\"\"\"", "'ezurl'", "\"0.1.3.25\"", "'URL Generation for Python'", "'Joshua Walters'", "'therealdolphman@gmail.com'", "'https://github.com/Dolphman/ezurl'", "'ezurl'", "'URL Generation'", "'Python URL generation'", "'Python URL'", "\"License :: OSI Approved :: MIT License\"", "\"Operating System :: OS Independent\"", "\"Topic :: Utilities\"", "\"Programming Language :: Python :: 2.7\"", "\"Programming Language :: Python :: 3\"", "\"Programming Language :: Python :: 3.0\"", "\"Programming Language :: Python :: 3.1\"", "\"Programming Language :: Python :: 3.2\"", "\"Programming Language :: Python :: 3.3\"", "\"Programming Language :: Python :: 3.4\"", "\"Programming Language :: Python :: 3.5\"", "\"MIT\""]}}], ["de55a6b38ab9c3fade17bd3ed301876f", {"code_string": "import os\nimport sys\npath = os.path.abspath(__file__)\npath = os.path.dirname(os.path.dirname(path))\nos.chdir(path)\nsys.path.append(path)\nfrom config import *\nmode1 = __import__(pat, fromlist = True)\nif hasattr(mode1, classname):\n    cls = getattr(mode1, classname)\n    obj = cls()\n    obj.f1()\n", "code_toks_joined": "import os <NEWLINE> import sys <NEWLINE> path = os . path . abspath ( __file__ ) <NEWLINE> path = os . path . dirname ( os . path . dirname ( path ) ) <NEWLINE> os . chdir ( path ) <NEWLINE> sys . path . append ( path ) <NEWLINE> from config import * <NEWLINE> mode1 = __import__ ( pat , fromlist = True ) <NEWLINE> if hasattr ( mode1 , classname ) : <NEWLINE> <INDENT> cls = getattr ( mode1 , classname ) <NEWLINE> obj = cls ( ) <NEWLINE> obj . f1 ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["0bd23f720addc723f4aac04e71b7dc43", {"code_string": "class Category(models.Model):\n    title = models.CharField(max_length = 20)\n    slug = models.SlugField()\n    description = models.TextField(blank = True, null = True)\n    def __unicode__(self):\n        return self.title\n    class Meta:\n        ordering = ['title']\n        verbose_name_plural = \"categories\"\n", "code_toks_joined": "class Category ( models . Model ) : <NEWLINE> <INDENT> title = models . CharField ( max_length = 20 ) <NEWLINE> slug = models . SlugField ( ) <NEWLINE> description = models . TextField ( blank = True , null = True ) <NEWLINE> def __unicode__ ( self ) : <NEWLINE> <INDENT> return self . title <NEWLINE> <DEDENT> class Meta : <NEWLINE> <INDENT> ordering = [ <STRING> ] <NEWLINE> verbose_name_plural = <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'title'", "\"categories\""]}}], ["7815e5884f45c88896de44efc1757894", {"code_string": "def write_plain_text(self, text, start, end):\n    if start < end:\n        self.wrapped.write(text[start: end])\n        self.wrapped.flush()\n", "code_toks_joined": "def write_plain_text ( self , text , start , end ) : <NEWLINE> <INDENT> if start < end : <NEWLINE> <INDENT> self . wrapped . write ( text [ start : end ] ) <NEWLINE> self . wrapped . flush ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["6a8f06858f11f0cc0a694c89e0f97966", {"code_string": "class Action:\n    def same_as(self, other):\n        return self is other\n", "code_toks_joined": "class Action : <NEWLINE> <INDENT> def same_as ( self , other ) : <NEWLINE> <INDENT> return self is other <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["9eaeeaa057282be407dc01a533444b6a", {"code_string": "def source_pitch_range(self):\n    r'''Gets source pitch range of registration component.'''\n    return self._source_pitch_range\n", "code_toks_joined": "def source_pitch_range ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . _source_pitch_range <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["r'''Gets source pitch range of registration component.'''"]}}], ["53d9cacd76ee8eb5cb1ec917fd9cf2fd", {"code_string": "def postCaseCleanup(self):\n    \"\"\"Called by L{unittest.TestCase} after a test to catch any logged errors\"\"\"\n    calls = self._cleanPending()\n    if calls:\n        aggregate = DirtyReactorAggregateError(calls)\n        self.result.addError(self.test, Failure(aggregate))\n        return False\n    return True\n", "code_toks_joined": "def postCaseCleanup ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> calls = self . _cleanPending ( ) <NEWLINE> if calls : <NEWLINE> <INDENT> aggregate = DirtyReactorAggregateError ( calls ) <NEWLINE> self . result . addError ( self . test , Failure ( aggregate ) ) <NEWLINE> return False <NEWLINE> <DEDENT> return True <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Called by L{unittest.TestCase} after a test to catch any logged errors\"\"\""]}}], ["095095407ebbed4bd0423fcb04abd187", {"code_string": "def __init__(self, name = '', doc = '', args = (), type = 'kw', timeout = None):\n    self.parent = None\n    self.name = name\n    self.doc = doc\n    self.args = args\n    self.type = type\n    self.timeout = timeout\n    self.messages = None\n    self.keywords = None\n", "code_toks_joined": "def __init__ ( self , name = <STRING> , doc = <STRING> , args = ( ) , type = <STRING> , timeout = None ) : <NEWLINE> <INDENT> self . parent = None <NEWLINE> self . name = name <NEWLINE> self . doc = doc <NEWLINE> self . args = args <NEWLINE> self . type = type <NEWLINE> self . timeout = timeout <NEWLINE> self . messages = None <NEWLINE> self . keywords = None <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["''", "''", "'kw'"]}}], ["3d9a7607e32a3ee78c9374bd13f3df88", {"code_string": "def apt_install(packages):\n    if not packages:\n        return()\n    return('apt-get install -yq --no-install-recommends ' + ' '.join(packages), )\n", "code_toks_joined": "def apt_install ( packages ) : <NEWLINE> <INDENT> if not packages : <NEWLINE> <INDENT> return ( ) <NEWLINE> <DEDENT> return ( <STRING> + <STRING> . join ( packages ) , ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'apt-get install -yq --no-install-recommends '", "' '"]}}], ["c05676697dda92d3b42b2f2cfd3c7074", {"code_string": "def append_or_empty_output_dir(parent, output_dir):\n    '''dialog if output dir content can be deleted or has to be appended'''\n    message_box = QMessageBox()\n    message_box.setWindowTitle('Directory is not empty')\n    message_box.setText(\"Directory {} is not empty. Clean or append it's content?\".format(output_dir))\n    button_clean = QPushButton('Clean it')\n    message_box.addButton(button_clean, QMessageBox.YesRole)\n    button_cancel = QPushButton('Cancel')\n    message_box.addButton(button_cancel, QMessageBox.NoRole)\n    button_append = QPushButton('Append')\n    message_box.addButton(button_append, QMessageBox.ActionRole)\n    ret = message_box.exec_();\n    return ret\n", "code_toks_joined": "def append_or_empty_output_dir ( parent , output_dir ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> message_box = QMessageBox ( ) <NEWLINE> message_box . setWindowTitle ( <STRING> ) <NEWLINE> message_box . setText ( <STRING> . format ( output_dir ) ) <NEWLINE> button_clean = QPushButton ( <STRING> ) <NEWLINE> message_box . addButton ( button_clean , QMessageBox . YesRole ) <NEWLINE> button_cancel = QPushButton ( <STRING> ) <NEWLINE> message_box . addButton ( button_cancel , QMessageBox . NoRole ) <NEWLINE> button_append = QPushButton ( <STRING> ) <NEWLINE> message_box . addButton ( button_append , QMessageBox . ActionRole ) <NEWLINE> ret = message_box . exec_ ( ) ; <NEWLINE> return ret <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''dialog if output dir content can be deleted or has to be appended'''", "'Directory is not empty'", "\"Directory {} is not empty. Clean or append it's content?\"", "'Clean it'", "'Cancel'", "'Append'"]}}], ["bccc07c55394d5f769d1f466cee0ca35", {"code_string": "def copy_param(target_link, source_link):\n    \"\"\"Copy parameters of a link to another link.\"\"\"\n    target_params = dict(target_link.namedparams())\n    for param_name, param in source_link.namedparams():\n        target_params[param_name].data[: ] = param.data\n", "code_toks_joined": "def copy_param ( target_link , source_link ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> target_params = dict ( target_link . namedparams ( ) ) <NEWLINE> for param_name , param in source_link . namedparams ( ) : <NEWLINE> <INDENT> target_params [ param_name ] . data [ : ] = param . data <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Copy parameters of a link to another link.\"\"\""]}}], ["0bbd6d74fd4340e4f0da3572fa674930", {"code_string": "class MovingObject(Object):\n    def __init__(self, window, game, init_point, slope):\n        Object.__init__(self, window, game)\n        self.point = init_point\n        self.slope = slope\n", "code_toks_joined": "class MovingObject ( Object ) : <NEWLINE> <INDENT> def __init__ ( self , window , game , init_point , slope ) : <NEWLINE> <INDENT> Object . __init__ ( self , window , game ) <NEWLINE> self . point = init_point <NEWLINE> self . slope = slope <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["b1323df437096fb59736a76aeba8c1b4", {"code_string": "from json import load\nfrom urllib2 import urlopen\nfrom pprint import pprint\nimport operator\nbaseurl = 'http://api.openweathermap.org/data/2.5/weather?q='\ncities = [\"tel_aviv\", \"groningen\"]\nsubstract = 273\n", "code_toks_joined": "from json import load <NEWLINE> from urllib2 import urlopen <NEWLINE> from pprint import pprint <NEWLINE> import operator <NEWLINE> baseurl = <STRING> <NEWLINE> cities = [ <STRING> , <STRING> ] <NEWLINE> substract = 273 <NEWLINE>", "anonymize_dict": {"<STRING>": ["'http://api.openweathermap.org/data/2.5/weather?q='", "\"tel_aviv\"", "\"groningen\""]}}], ["f94ab9d265f41d651aaadde41a2600f1", {"code_string": "def rollback_checkpoints(self, rollback = 1):\n    \"\"\"Rollback saved checkpoints.\"\"\"\n    try:\n        self.reverter.rollback_checkpoints(rollback)\n    except errors.ReverterError as err:\n        raise errors.PluginError(str(err))\n    self.aug.load()\n", "code_toks_joined": "def rollback_checkpoints ( self , rollback = 1 ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> try : <NEWLINE> <INDENT> self . reverter . rollback_checkpoints ( rollback ) <NEWLINE> <DEDENT> except errors . ReverterError as err : <NEWLINE> <INDENT> raise errors . PluginError ( str ( err ) ) <NEWLINE> <DEDENT> self . aug . load ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Rollback saved checkpoints.\"\"\""]}}], ["bed2192b9a6acf0c3d11cb6f399e001c", {"code_string": "import sys\nimport gevent\nfrom gevent import monkey\nif not 'unittest' in sys.modules:\n    monkey.patch_all()\nimport requests\nimport uuid\nimport json\nimport hashlib\nimport socket\nfrom disc_utils import *\nfrom disc_consts import *\nimport services\nimport hashlib\nimport socket\nfrom sandesh.discovery_client import ttypes as sandesh\nfrom pysandesh.connection_info import ConnectionState\nfrom pysandesh.gen_py.process_info.ttypes import ConnectionStatus, ConnectionType\n", "code_toks_joined": "import sys <NEWLINE> import gevent <NEWLINE> from gevent import monkey <NEWLINE> if not <STRING> in sys . modules : <NEWLINE> <INDENT> monkey . patch_all ( ) <NEWLINE> <DEDENT> import requests <NEWLINE> import uuid <NEWLINE> import json <NEWLINE> import hashlib <NEWLINE> import socket <NEWLINE> from disc_utils import * <NEWLINE> from disc_consts import * <NEWLINE> import services <NEWLINE> import hashlib <NEWLINE> import socket <NEWLINE> from sandesh . discovery_client import ttypes as sandesh <NEWLINE> from pysandesh . connection_info import ConnectionState <NEWLINE> from pysandesh . gen_py . process_info . ttypes import ConnectionStatus , ConnectionType <NEWLINE>", "anonymize_dict": {"<STRING>": ["'unittest'"]}}], ["c5bb7d950704dd1b999d863bfbca3779", {"code_string": "from kivy import platform\n__all__ = ('Billing', )\nif platform() == 'android':\n    from openIABilling import OpenIABilling as Billing\nelse:\n    from mockbilling import MockBilling as Billing\n", "code_toks_joined": "from kivy import platform <NEWLINE> __all__ = ( <STRING> , ) <NEWLINE> if platform ( ) == <STRING> : <NEWLINE> <INDENT> from openIABilling import OpenIABilling as Billing <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> from mockbilling import MockBilling as Billing <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Billing'", "'android'"]}}], ["f4df2fa6217c7cf1ae08ceaf4ebb7235", {"code_string": "def randomUUID():\n    \"\"\"Generate a random UUID.\"\"\"\n    return[random.randint(0, 255) for dummy in range(0, 16)]\n", "code_toks_joined": "def randomUUID ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return [ random . randint ( 0 , 255 ) for dummy in range ( 0 , 16 ) ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Generate a random UUID.\"\"\""]}}], ["0a9e34f7ff804e13b698ca351b815665", {"code_string": "class BaseView(Resource):\n    def abort_if_does_not_exist(self, o_id):\n        o, is_new = self.__managed_class__.get_unique(o_id)\n        if is_new:\n            self.__managed_class__.remove_from_cache(o)\n            abort(404, message = \"Job {} doesn't exist\".format(o_id))\n        return o\n    def pagination(self, page = 1, step = 10):\n        pass\n", "code_toks_joined": "class BaseView ( Resource ) : <NEWLINE> <INDENT> def abort_if_does_not_exist ( self , o_id ) : <NEWLINE> <INDENT> o , is_new = self . __managed_class__ . get_unique ( o_id ) <NEWLINE> if is_new : <NEWLINE> <INDENT> self . __managed_class__ . remove_from_cache ( o ) <NEWLINE> abort ( 404 , message = <STRING> . format ( o_id ) ) <NEWLINE> <DEDENT> return o <NEWLINE> <DEDENT> def pagination ( self , page = 1 , step = 10 ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Job {} doesn't exist\""]}}], ["424413290d59e85b75c18a649ec876ed", {"code_string": "def dfs_do_func_on_graph(node, func, * args, ** kwargs):\n    '''invoke func on each node of the dr graph'''\n    for _node in node.tree_iterator():\n        func(_node, * args, ** kwargs)\n", "code_toks_joined": "def dfs_do_func_on_graph ( node , func , * args , ** kwargs ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> for _node in node . tree_iterator ( ) : <NEWLINE> <INDENT> func ( _node , * args , ** kwargs ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''invoke func on each node of the dr graph'''"]}}], ["7aef7dfb79ce18b3c6648a0a597dd28d", {"code_string": "def create_html_summary():\n    txt = '<HTML><BODY>'\n    for f in files:\n        txt += summarise_file_as_html(f)\n    txt += '</BODY></HTML>'\n    with open('open_cyc_summary.html', 'w') as fop:\n        fop.write(txt)\n    print('Done')\n", "code_toks_joined": "def create_html_summary ( ) : <NEWLINE> <INDENT> txt = <STRING> <NEWLINE> for f in files : <NEWLINE> <INDENT> txt += summarise_file_as_html ( f ) <NEWLINE> <DEDENT> txt += <STRING> <NEWLINE> with open ( <STRING> , <STRING> ) as fop : <NEWLINE> <INDENT> fop . write ( txt ) <NEWLINE> <DEDENT> print ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'<HTML><BODY>'", "'</BODY></HTML>'", "'open_cyc_summary.html'", "'w'", "'Done'"]}}], ["1dd610bfaf681c53baccda56d292d7c4", {"code_string": "def xmlrpc_get_message(self):\n    if self.completed:\n        response = {\"mode\": \"confirm\"}\n        response[\"confirm\"] = self.value\n        Timer(1, self.xmlrpc_kill).start()\n        self.after(10, self.withdraw)\n        return response\n    else:\n        return None\n", "code_toks_joined": "def xmlrpc_get_message ( self ) : <NEWLINE> <INDENT> if self . completed : <NEWLINE> <INDENT> response = { <STRING> : <STRING> } <NEWLINE> response [ <STRING> ] = self . value <NEWLINE> Timer ( 1 , self . xmlrpc_kill ) . start ( ) <NEWLINE> self . after ( 10 , self . withdraw ) <NEWLINE> return response <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"mode\"", "\"confirm\"", "\"confirm\""]}}], ["e9667de88e9f1147c11a2428b35203ec", {"code_string": "def test_instance_field_overrides_class(self):\n    class Person3(m.Model):\n        name = m.CharField()\n        birthday = m.DateTimeField()\n    person = Person3()\n    person.add_field('birthday', m.DateField())\n    self.assertTrue(isinstance(person.get_field('birthday'), m.DateField))\n", "code_toks_joined": "def test_instance_field_overrides_class ( self ) : <NEWLINE> <INDENT> class Person3 ( m . Model ) : <NEWLINE> <INDENT> name = m . CharField ( ) <NEWLINE> birthday = m . DateTimeField ( ) <NEWLINE> <DEDENT> person = Person3 ( ) <NEWLINE> person . add_field ( <STRING> , m . DateField ( ) ) <NEWLINE> self . assertTrue ( isinstance ( person . get_field ( <STRING> ) , m . DateField ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'birthday'", "'birthday'"]}}], ["70ba350cf753bd94346845e2e1ad3d96", {"code_string": "class LeaseTable(Base):\n    \"\"\" SQL alchemy class to manipulate the rows of the lease_table table in the\"\"\"\n    __tablename__ = 'lease_table'\n    job_id = Column(Integer, primary_key = True)\n    slice_hrn = Column(String)\n    def __init__(self, job_id, slice_hrn):\n        \"\"\"Defines a row of the lease_table table\"\"\"\n        self.job_id = job_id\n        self.slice_hrn = slice_hrn\n    def __repr__(self):\n        \"\"\"Prints the SQLAlchemy record to the format defined\"\"\"\n        result = \"job_id %s, slice_hrn = %s\" %(self.job_id,\n            self.slice_hrn)\n        return result\n", "code_toks_joined": "class LeaseTable ( Base ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> __tablename__ = <STRING> <NEWLINE> job_id = Column ( Integer , primary_key = True ) <NEWLINE> slice_hrn = Column ( String ) <NEWLINE> def __init__ ( self , job_id , slice_hrn ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . job_id = job_id <NEWLINE> self . slice_hrn = slice_hrn <NEWLINE> <DEDENT> def __repr__ ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> result = <STRING> % ( self . job_id , <NEWLINE> <INDENT> self . slice_hrn ) <NEWLINE> <DEDENT> return result <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" SQL alchemy class to manipulate the rows of the lease_table table in the\"\"\"", "'lease_table'", "\"\"\"Defines a row of the lease_table table\"\"\"", "\"\"\"Prints the SQLAlchemy record to the format defined\"\"\"", "\"job_id %s, slice_hrn = %s\""]}}], ["9dbb6f8ab71348407be0c0b32b7a4225", {"code_string": "def test_report_error(self):\n    showerror = Mbox.showerror\n    Equal = self.assertEqual\n    pat = '[a-z'\n    msg = 'unexpected end of regular expression'\n    Equal(self.engine.report_error(pat, msg), None)\n    Equal(showerror.title, 'Regular expression error')\n    expected_message = (\"Error: \" + msg + \"\\nPattern: [a-z\")\n    Equal(showerror.message, expected_message)\n    Equal(self.engine.report_error(pat, msg, 5), None)\n    Equal(showerror.title, 'Regular expression error')\n    expected_message += \"\\nOffset: 5\"\n    Equal(showerror.message, expected_message)\n", "code_toks_joined": "def test_report_error ( self ) : <NEWLINE> <INDENT> showerror = Mbox . showerror <NEWLINE> Equal = self . assertEqual <NEWLINE> pat = <STRING> <NEWLINE> msg = <STRING> <NEWLINE> Equal ( self . engine . report_error ( pat , msg ) , None ) <NEWLINE> Equal ( showerror . title , <STRING> ) <NEWLINE> expected_message = ( <STRING> + msg + <STRING> ) <NEWLINE> Equal ( showerror . message , expected_message ) <NEWLINE> Equal ( self . engine . report_error ( pat , msg , 5 ) , None ) <NEWLINE> Equal ( showerror . title , <STRING> ) <NEWLINE> expected_message += <STRING> <NEWLINE> Equal ( showerror . message , expected_message ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'[a-z'", "'unexpected end of regular expression'", "'Regular expression error'", "\"Error: \"", "\"\\nPattern: [a-z\"", "'Regular expression error'", "\"\\nOffset: 5\""]}}], ["b9e558d9185339a86a6aa8e4c71f3634", {"code_string": "def main(platform):\n    ap = argparse.ArgumentParser(description = \"ONL Platform tool.\")\n    ap.add_argument(\"--info\", action = 'store_true')\n    ap.add_argument(\"--env\", action = 'store_true')\n    ops = ap.parse_args()\n    if ops.info:\n        print(platform)\n    if ops.env:\n        print(platform.get_environment())\n", "code_toks_joined": "def main ( platform ) : <NEWLINE> <INDENT> ap = argparse . ArgumentParser ( description = <STRING> ) <NEWLINE> ap . add_argument ( <STRING> , action = <STRING> ) <NEWLINE> ap . add_argument ( <STRING> , action = <STRING> ) <NEWLINE> ops = ap . parse_args ( ) <NEWLINE> if ops . info : <NEWLINE> <INDENT> print ( platform ) <NEWLINE> <DEDENT> if ops . env : <NEWLINE> <INDENT> print ( platform . get_environment ( ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"ONL Platform tool.\"", "\"--info\"", "'store_true'", "\"--env\"", "'store_true'"]}}], ["cc88ac4b4a94428126ed4e6eccfc4190", {"code_string": "def test_set_cell_content(field):\n    \"\"\" Test if set_cell() behaves properly. \"\"\"\n    x = y = 0\n    assert field.field[(x, y)] is None\n    field.set_cell_content(x, y, 'FOOD')\n    assert field.field[(x, y)] == 'FOOD'\n    with pytest.raises(KeyError):\n        field.set_cell_content(field.width, 0, 'FOOD')\n", "code_toks_joined": "def test_set_cell_content ( field ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> x = y = 0 <NEWLINE> assert field . field [ ( x , y ) ] is None <NEWLINE> field . set_cell_content ( x , y , <STRING> ) <NEWLINE> assert field . field [ ( x , y ) ] == <STRING> <NEWLINE> with pytest . raises ( KeyError ) : <NEWLINE> <INDENT> field . set_cell_content ( field . width , 0 , <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Test if set_cell() behaves properly. \"\"\"", "'FOOD'", "'FOOD'", "'FOOD'"]}}], ["bbef8263437cbeab21dc0f2dcc042c0e", {"code_string": "import uuid\nimport sys\nfrom twisted.python import log\nfrom twisted.internet import reactor\nfrom twisted.web.server import Site\nfrom twisted.web.wsgi import WSGIResource\nfrom flask import Flask, render_template\nfrom autobahn.twisted.websocket import WebSocketServerFactory, WebSocketServerProtocol\nfrom autobahn.twisted.resource import WebSocketResource, WSGIRootResource, HTTPChannelHixie76Aware\n", "code_toks_joined": "import uuid <NEWLINE> import sys <NEWLINE> from twisted . python import log <NEWLINE> from twisted . internet import reactor <NEWLINE> from twisted . web . server import Site <NEWLINE> from twisted . web . wsgi import WSGIResource <NEWLINE> from flask import Flask , render_template <NEWLINE> from autobahn . twisted . websocket import WebSocketServerFactory , WebSocketServerProtocol <NEWLINE> from autobahn . twisted . resource import WebSocketResource , WSGIRootResource , HTTPChannelHixie76Aware <NEWLINE>", "anonymize_dict": {}}], ["cd1a431935321293f15df128a6cac108", {"code_string": "from __future__ import unicode_literals\nfrom django.apps import apps\nfrom django.conf import settings\nfrom django.db import connection\nfrom django.test import TestCase, skipIfDBFeature, skipUnlessDBFeature\nfrom.models.tablespaces import(\n    Article, ArticleRef, Authors, Reviewers, Scientist, ScientistRef,\n)\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> from django . apps import apps <NEWLINE> from django . conf import settings <NEWLINE> from django . db import connection <NEWLINE> from django . test import TestCase , skipIfDBFeature , skipUnlessDBFeature <NEWLINE> from . models . tablespaces import ( <NEWLINE> <INDENT> Article , ArticleRef , Authors , Reviewers , Scientist , ScientistRef , <NEWLINE> <DEDENT> ) <NEWLINE>", "anonymize_dict": {}}], ["a0290230b7a4437aae9d6cfac82e9735", {"code_string": "def truncation_replacement(random, population, parents, offspring, args):\n    \"\"\"Replaces population with the best of the population and offspring.\"\"\"\n    psize = len(population)\n    population.extend(list(offspring))\n    population.sort(reverse = True)\n    return population[: psize]\n", "code_toks_joined": "def truncation_replacement ( random , population , parents , offspring , args ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> psize = len ( population ) <NEWLINE> population . extend ( list ( offspring ) ) <NEWLINE> population . sort ( reverse = True ) <NEWLINE> return population [ : psize ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Replaces population with the best of the population and offspring.\"\"\""]}}], ["a0f996759e0e1d7d8259b0e010712834", {"code_string": "class Users(Base):\n    email_address = fields.Email()\n    first_name = fields.String()\n    last_name = fields.String()\n", "code_toks_joined": "class Users ( Base ) : <NEWLINE> <INDENT> email_address = fields . Email ( ) <NEWLINE> first_name = fields . String ( ) <NEWLINE> last_name = fields . String ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["2a3a021351bc77c93858e38c74ff2d0a", {"code_string": "def test_repr(self):\n    foo = terminal.Color('foo')\n    foo.fgcolor = 'red'\n    assert repr(foo) == repr(str(foo))\n", "code_toks_joined": "def test_repr ( self ) : <NEWLINE> <INDENT> foo = terminal . Color ( <STRING> ) <NEWLINE> foo . fgcolor = <STRING> <NEWLINE> assert repr ( foo ) == repr ( str ( foo ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'foo'", "'red'"]}}], ["fad23da31688e953c5d579ab835093fa", {"code_string": "class SecurityGroups(horizon.Panel):\n    name = _(\"Security Groups\")\n    slug = 'security_groups'\n    permissions = ('openstack.services.network', )\n", "code_toks_joined": "class SecurityGroups ( horizon . Panel ) : <NEWLINE> <INDENT> name = _ ( <STRING> ) <NEWLINE> slug = <STRING> <NEWLINE> permissions = ( <STRING> , ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Security Groups\"", "'security_groups'", "'openstack.services.network'"]}}], ["9192feb46bd92d60f049c50f18c5ff1f", {"code_string": "def GetRequired():\n    with open('required.json', 'r') as fin:\n        return json.loads(fin.read())\n", "code_toks_joined": "def GetRequired ( ) : <NEWLINE> <INDENT> with open ( <STRING> , <STRING> ) as fin : <NEWLINE> <INDENT> return json . loads ( fin . read ( ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'required.json'", "'r'"]}}], ["a870c4d58b7ad76e3b5ea09bad845f6e", {"code_string": "def __init__(self, records):\n    try:\n        assert all(type(r) is FastaRecord for r in records)\n        assert all(len(r.sequence) == len(records[0].sequence)\n            for r in records)\n        self._records = records\n    except AssertionError:\n        raise ValueError(\"Invalid FASTA alignment data\")\n", "code_toks_joined": "def __init__ ( self , records ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> assert all ( type ( r ) is FastaRecord for r in records ) <NEWLINE> assert all ( len ( r . sequence ) == len ( records [ 0 ] . sequence ) <NEWLINE> <INDENT> for r in records ) <NEWLINE> <DEDENT> self . _records = records <NEWLINE> <DEDENT> except AssertionError : <NEWLINE> <INDENT> raise ValueError ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Invalid FASTA alignment data\""]}}], ["a0d21c8cd59d0637660c5bacab5eb584", {"code_string": "def test_works_with_dag(self):\n    self.art2.source.dependencies = [self.art4]\n    self.art3.source.dependencies = [self.art4]\n    self.art1.source.dependencies = [self.art2, self.art3]\n    self.verify_round_trip(self.art1)\n", "code_toks_joined": "def test_works_with_dag ( self ) : <NEWLINE> <INDENT> self . art2 . source . dependencies = [ self . art4 ] <NEWLINE> self . art3 . source . dependencies = [ self . art4 ] <NEWLINE> self . art1 . source . dependencies = [ self . art2 , self . art3 ] <NEWLINE> self . verify_round_trip ( self . art1 ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["667115ff570642d40fb9709869252b10", {"code_string": "def shutdown():\n    move.shutdown()\n    sensors.shutdown()\n    print(\"finished\")\n", "code_toks_joined": "def shutdown ( ) : <NEWLINE> <INDENT> move . shutdown ( ) <NEWLINE> sensors . shutdown ( ) <NEWLINE> print ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"finished\""]}}], ["921a15a448313fa613a7313bd14c041c", {"code_string": "from __future__ import print_function\nimport numpy as np\nimport tensorflow as tf\nfrom utility.duration import Duration\nimport utility.logger_tool\nimport logging\nimport os\nfrom A1_notmnistdataset.p5_findduplication import DataExploration\n", "code_toks_joined": "from __future__ import print_function <NEWLINE> import numpy as np <NEWLINE> import tensorflow as tf <NEWLINE> from utility . duration import Duration <NEWLINE> import utility . logger_tool <NEWLINE> import logging <NEWLINE> import os <NEWLINE> from A1_notmnistdataset . p5_findduplication import DataExploration <NEWLINE>", "anonymize_dict": {}}], ["59f81e63c06a88cc4310f4f6a8fc01d7", {"code_string": "import numpy as np\nimport wx\nfrom OM.Manager import ObjectManager\nimport funcs as fn\nimport scipy\n", "code_toks_joined": "import numpy as np <NEWLINE> import wx <NEWLINE> from OM . Manager import ObjectManager <NEWLINE> import funcs as fn <NEWLINE> import scipy <NEWLINE>", "anonymize_dict": {}}], ["56ed48e6bbdeb0672260f667e7929288", {"code_string": "\"\"\"@pagination \u5206\u9875\u88c5\u9970\u5668\"\"\"\nimport functools\nfrom flask import request, url_for\nimport json\n", "code_toks_joined": "<STRING> <NEWLINE> import functools <NEWLINE> from flask import request , url_for <NEWLINE> import json <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"@pagination \u5206\u9875\u88c5\u9970\u5668\"\"\""]}}], ["70ebb35de76346b64cbcd4095443d217", {"code_string": "\"\"\":mod:`boardinghouse.management.commands.flush`\"\"\"\nfrom django.core.management.commands.flush import Command\nfrom boardinghouse.schema import _wrap_command\nCommand.handle = _wrap_command(Command.handle)\n", "code_toks_joined": "<STRING> <NEWLINE> from django . core . management . commands . flush import Command <NEWLINE> from boardinghouse . schema import _wrap_command <NEWLINE> Command . handle = _wrap_command ( Command . handle ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\":mod:`boardinghouse.management.commands.flush`\"\"\""]}}], ["bd7710296788656529686ab33aac0683", {"code_string": "def test_dimensions(self):\n    from html5video.encoders.base import BaseEncoder\n    e = BaseEncoder('fake_file.mov')\n    self.assertEqual(e.dimensions, None)\n    e.dimensions = \"100x200\"\n    self.assertEqual(e.width, \"100\")\n    self.assertEqual(e.height, \"200\")\n    self.assertEqual(e.dimensions, \"100x200\")\n    with self.assertRaises(AttributeError):\n        e.dimensions = None\n", "code_toks_joined": "def test_dimensions ( self ) : <NEWLINE> <INDENT> from html5video . encoders . base import BaseEncoder <NEWLINE> e = BaseEncoder ( <STRING> ) <NEWLINE> self . assertEqual ( e . dimensions , None ) <NEWLINE> e . dimensions = <STRING> <NEWLINE> self . assertEqual ( e . width , <STRING> ) <NEWLINE> self . assertEqual ( e . height , <STRING> ) <NEWLINE> self . assertEqual ( e . dimensions , <STRING> ) <NEWLINE> with self . assertRaises ( AttributeError ) : <NEWLINE> <INDENT> e . dimensions = None <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'fake_file.mov'", "\"100x200\"", "\"100\"", "\"200\"", "\"100x200\""]}}], ["f8a42195030e85d504291d14c4c39d21", {"code_string": "class DiagnoseTestCase(TestCase):\n    def test_runCommand(self):\n        code, stdout, stderr = runCommand(\n            \"/bin/ls\", \"-al\", \"/\"\n        )\n        self.assertEquals(code, 0)\n        self.assertEquals(stderr, \"\")\n        self.assertTrue(\"total\" in stdout)\n    def test_runCommand_nonExistent(self):\n        self.assertRaises(FileNotFound, runCommand, \"/xyzzy/plugh/notthere\")\n", "code_toks_joined": "class DiagnoseTestCase ( TestCase ) : <NEWLINE> <INDENT> def test_runCommand ( self ) : <NEWLINE> <INDENT> code , stdout , stderr = runCommand ( <NEWLINE> <INDENT> <STRING> , <STRING> , <STRING> <NEWLINE> <DEDENT> ) <NEWLINE> self . assertEquals ( code , 0 ) <NEWLINE> self . assertEquals ( stderr , <STRING> ) <NEWLINE> self . assertTrue ( <STRING> in stdout ) <NEWLINE> <DEDENT> def test_runCommand_nonExistent ( self ) : <NEWLINE> <INDENT> self . assertRaises ( FileNotFound , runCommand , <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"/bin/ls\"", "\"-al\"", "\"/\"", "\"\"", "\"total\"", "\"/xyzzy/plugh/notthere\""]}}], ["68efd94fab16e58e0ba51d63eb67ac73", {"code_string": "def get_key(self, key, include_keys = False):\n    path = \"/keys/%s\" % key\n    if include_keys:\n        path += \"?include_keys=true\"\n    resp = self.server.request(\"get\", path)\n    return self.server.json_body(resp)\n", "code_toks_joined": "def get_key ( self , key , include_keys = False ) : <NEWLINE> <INDENT> path = <STRING> % key <NEWLINE> if include_keys : <NEWLINE> <INDENT> path += <STRING> <NEWLINE> <DEDENT> resp = self . server . request ( <STRING> , path ) <NEWLINE> return self . server . json_body ( resp ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"/keys/%s\"", "\"?include_keys=true\"", "\"get\""]}}], ["6a3c97d816ddf67a629eca6294c16c2a", {"code_string": "from abc import ABC, abstractmethod\nfrom collections import namedtuple\nfrom urllib.parse import urljoin\nfrom bs4 import BeautifulSoup\nLink = namedtuple('Link', ['text', 'url'])\n", "code_toks_joined": "from abc import ABC , abstractmethod <NEWLINE> from collections import namedtuple <NEWLINE> from urllib . parse import urljoin <NEWLINE> from bs4 import BeautifulSoup <NEWLINE> Link = namedtuple ( <STRING> , [ <STRING> , <STRING> ] ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'Link'", "'text'", "'url'"]}}], ["c50845583256ac80742b8e816cd8db32", {"code_string": "from.bot import dorna_go, commands\n__all__ = ['dorna_go', 'commands']\n", "code_toks_joined": "from . bot import dorna_go , commands <NEWLINE> __all__ = [ <STRING> , <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'dorna_go'", "'commands'"]}}], ["7932a6c50899b628fa9bc52bf60aa09b", {"code_string": "import os\nimport sys\nfrom mozbuild.base import MozbuildObject\nconfig = MozbuildObject.from_environment()\nfor var in('topsrcdir', 'topobjdir', 'defines', 'non_global_defines',\n    'substs'):\n    value = getattr(config, var)\n    setattr(sys.modules[__name__], var, value)\nsubsts = dict(substs)\nfor var in os.environ:\n    if var not in('CPP', 'CXXCPP', 'SHELL') and var in substs:\n        substs[var] = os.environ[var]\n", "code_toks_joined": "import os <NEWLINE> import sys <NEWLINE> from mozbuild . base import MozbuildObject <NEWLINE> config = MozbuildObject . from_environment ( ) <NEWLINE> for var in ( <STRING> , <STRING> , <STRING> , <STRING> , <NEWLINE> <INDENT> <STRING> ) : <NEWLINE> value = getattr ( config , var ) <NEWLINE> setattr ( sys . modules [ __name__ ] , var , value ) <NEWLINE> <DEDENT> substs = dict ( substs ) <NEWLINE> for var in os . environ : <NEWLINE> <INDENT> if var not in ( <STRING> , <STRING> , <STRING> ) and var in substs : <NEWLINE> <INDENT> substs [ var ] = os . environ [ var ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'topsrcdir'", "'topobjdir'", "'defines'", "'non_global_defines'", "'substs'", "'CPP'", "'CXXCPP'", "'SHELL'"]}}], ["f1a0c724919c1709238842e806c97ea6", {"code_string": "class JobForTest(MongoJob):\n    \"\"\"Test Job\"\"\"\n    collection_name = 'testcol'\n    def build_row(self, _str):\n        return{\n            \"name\": _str.strip(),\n            \"checked\": 0,\n            \"getted\": 0\n        }\n", "code_toks_joined": "class JobForTest ( MongoJob ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> collection_name = <STRING> <NEWLINE> def build_row ( self , _str ) : <NEWLINE> <INDENT> return { <NEWLINE> <INDENT> <STRING> : _str . strip ( ) , <NEWLINE> <STRING> : 0 , <NEWLINE> <STRING> : 0 <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test Job\"\"\"", "'testcol'", "\"name\"", "\"checked\"", "\"getted\""]}}], ["6f024a7d121836f092d84beb9716da57", {"code_string": "def forwards(self, orm):\n    \"Write your forwards methods here.\"\n    Book = orm['books.Book']\n    UserBook = orm['books.UserBook']\n    for book in Book.objects.all():\n        user = book.user\n        userBook = UserBook(user = user, book = book)\n        userBook.desired = book.desired\n        userBook.purchase_store = book.purchase_store\n        userBook.purchased = book.purchased\n        userBook.purchase_value = book.purchase_value\n        userBook.purchase_date = book.purchase_date\n        userBook.save()\n", "code_toks_joined": "def forwards ( self , orm ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> Book = orm [ <STRING> ] <NEWLINE> UserBook = orm [ <STRING> ] <NEWLINE> for book in Book . objects . all ( ) : <NEWLINE> <INDENT> user = book . user <NEWLINE> userBook = UserBook ( user = user , book = book ) <NEWLINE> userBook . desired = book . desired <NEWLINE> userBook . purchase_store = book . purchase_store <NEWLINE> userBook . purchased = book . purchased <NEWLINE> userBook . purchase_value = book . purchase_value <NEWLINE> userBook . purchase_date = book . purchase_date <NEWLINE> userBook . save ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Write your forwards methods here.\"", "'books.Book'", "'books.UserBook'"]}}], ["610a303a4c76f4d4946b57cc4c615d89", {"code_string": "import gettext\n__trans = gettext.translation('pisi', fallback = True)\n_ = __trans.ugettext\nimport pisi\nimport pisi.context as ctx\n", "code_toks_joined": "import gettext <NEWLINE> __trans = gettext . translation ( <STRING> , fallback = True ) <NEWLINE> _ = __trans . ugettext <NEWLINE> import pisi <NEWLINE> import pisi . context as ctx <NEWLINE>", "anonymize_dict": {"<STRING>": ["'pisi'"]}}], ["acc92c9a09627e62ebf2b96a32846e86", {"code_string": "from flatland.util import signal\nvalidator_validated = signal('validator_validated', doc = \"\"\" Emitted after a validator has processed an element.\"\"\")\n", "code_toks_joined": "from flatland . util import signal <NEWLINE> validator_validated = signal ( <STRING> , doc = <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'validator_validated'", "\"\"\" Emitted after a validator has processed an element.\"\"\""]}}], ["8beebdc0878a11a72ce5ffeeecde55a2", {"code_string": "\"\"\"Implements the user interface plug-in interface.\"\"\"\nimport luna.plugins\nimport automatic.state\n", "code_toks_joined": "<STRING> <NEWLINE> import luna . plugins <NEWLINE> import automatic . state <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Implements the user interface plug-in interface.\"\"\""]}}], ["86c8b3a14cb1b89a7e61555e34db2b61", {"code_string": "\"\"\"Pipeline for flexible modeling and extration of slitless spectroscopy\"\"\"\nfrom.version import __version__\nimport os\nif os.path.exists('README.rst') & os.path.exists('LICENSE.txt'):\n    print(\"\"\"Warning: `import grizli` will fail if the working directory is the place\"\"\")\nfrom.import utils_c\nfrom.import utils\nfrom.import grismconf\nfrom.import model\nfrom.import multifit\nif os.getenv('GRIZLI') is None:\n    print(\"\"\"Warning: $GRIZLI system variable not set, `grizli`\"\"\")\n", "code_toks_joined": "<STRING> <NEWLINE> from . version import __version__ <NEWLINE> import os <NEWLINE> if os . path . exists ( <STRING> ) & os . path . exists ( <STRING> ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT> from . import utils_c <NEWLINE> from . import utils <NEWLINE> from . import grismconf <NEWLINE> from . import model <NEWLINE> from . import multifit <NEWLINE> if os . getenv ( <STRING> ) is None : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Pipeline for flexible modeling and extration of slitless spectroscopy\"\"\"", "'README.rst'", "'LICENSE.txt'", "\"\"\"Warning: `import grizli` will fail if the working directory is the place\"\"\"", "'GRIZLI'", "\"\"\"Warning: $GRIZLI system variable not set, `grizli`\"\"\""]}}], ["c114bdb054ec7282067e887bb4b5376e", {"code_string": "from launcher.util.stack_config import StackConf, apply_template\nfrom launcher.util.configuration import LauncherConf\nfrom launcher.ansible.executor import generate as playbook_generate\nfrom StringIO import StringIO\nimport pytest\nimport yaml\nCONF = \"\"\"reboot_strategy: 'off'\"\"\"\nSTACK = \"\"\"services:\"\"\"\nEXPECTED_STACK = \"\"\"services:\"\"\"\n", "code_toks_joined": "from launcher . util . stack_config import StackConf , apply_template <NEWLINE> from launcher . util . configuration import LauncherConf <NEWLINE> from launcher . ansible . executor import generate as playbook_generate <NEWLINE> from StringIO import StringIO <NEWLINE> import pytest <NEWLINE> import yaml <NEWLINE> CONF = <STRING> <NEWLINE> STACK = <STRING> <NEWLINE> EXPECTED_STACK = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"reboot_strategy: 'off'\"\"\"", "\"\"\"services:\"\"\"", "\"\"\"services:\"\"\""]}}], ["9fca7434fe7269244ed6c1872ff5ecfd", {"code_string": "def anything_but(self, letter):\n    self.raw_source += '[^%s]*' % re.escape(letter)\n    return self\n", "code_toks_joined": "def anything_but ( self , letter ) : <NEWLINE> <INDENT> self . raw_source += <STRING> % re . escape ( letter ) <NEWLINE> return self <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'[^%s]*'"]}}], ["79ad3331c4ab733761c1bbee87b9648d", {"code_string": "def on_response(self, dialog, * args):\n    \"\"\"Dialog response\"\"\"\n    dialog.destroy()\n", "code_toks_joined": "def on_response ( self , dialog , * args ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> dialog . destroy ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Dialog response\"\"\""]}}], ["99fed5856fb83c92e2a9e8dcd6d25d0a", {"code_string": "def do_import(plugin_module_name):\n    \"\"\"dynamically import a module\"\"\"\n    try:\n        plugin_module = __import__(plugin_module_name)\n        if '.' in plugin_module_name:\n            modules = plugin_module_name.split('.')\n            for module in modules[1: ]:\n                plugin_module = getattr(plugin_module, module)\n        log.debug(\"found \" + plugin_module_name)\n        return plugin_module\n    except ImportError:\n        log.exception(\"failed to import %s\", plugin_module_name)\n        raise\n", "code_toks_joined": "def do_import ( plugin_module_name ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> try : <NEWLINE> <INDENT> plugin_module = __import__ ( plugin_module_name ) <NEWLINE> if <STRING> in plugin_module_name : <NEWLINE> <INDENT> modules = plugin_module_name . split ( <STRING> ) <NEWLINE> for module in modules [ 1 : ] : <NEWLINE> <INDENT> plugin_module = getattr ( plugin_module , module ) <NEWLINE> <DEDENT> <DEDENT> log . debug ( <STRING> + plugin_module_name ) <NEWLINE> return plugin_module <NEWLINE> <DEDENT> except ImportError : <NEWLINE> <INDENT> log . exception ( <STRING> , plugin_module_name ) <NEWLINE> raise <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"dynamically import a module\"\"\"", "'.'", "'.'", "\"found \"", "\"failed to import %s\""]}}], ["1ad0947812a49dbb84a9b4e7dd1b2c0b", {"code_string": "def mouseReleaseEvent(self, event):\n    if self.m_is_resize:\n        self.m_is_resize = False\n        self.restoreCursor()\n    else:\n        instrument = self.get_instrument()\n        if instrument:\n            instrument.mouse_release_event(event, self)\n    super().mouseReleaseEvent(event)\n", "code_toks_joined": "def mouseReleaseEvent ( self , event ) : <NEWLINE> <INDENT> if self . m_is_resize : <NEWLINE> <INDENT> self . m_is_resize = False <NEWLINE> self . restoreCursor ( ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> instrument = self . get_instrument ( ) <NEWLINE> if instrument : <NEWLINE> <INDENT> instrument . mouse_release_event ( event , self ) <NEWLINE> <DEDENT> <DEDENT> super ( ) . mouseReleaseEvent ( event ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["5cdd7274ad4110c37e9547e64a99f17a", {"code_string": "def runJob():\n    try:\n        getData()\n    except(Exception):\n        sys.stderr.write(\"Exception:\")\n        pass\n", "code_toks_joined": "def runJob ( ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> getData ( ) <NEWLINE> <DEDENT> except ( Exception ) : <NEWLINE> <INDENT> sys . stderr . write ( <STRING> ) <NEWLINE> pass <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Exception:\""]}}], ["65cc2330b7b117e8367ad2eafc973d05", {"code_string": "from..tasks import print_message\nprint_message('asdf')\n", "code_toks_joined": "from . . tasks import print_message <NEWLINE> print_message ( <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'asdf'"]}}], ["fef0c45586e8f393391def75c3662b0d", {"code_string": "def GetHostProject(self, project):\n    \"\"\"Get the XPN host for the given project.\"\"\"\n    request_tuple = (\n        self.client.projects,\n        'GetXpnHost',\n        self.messages.ComputeProjectsGetXpnHostRequest(project = project))\n    msg = 'get XPN host for project [{project}]'.format(project = project)\n    return self._MakeRequestSync(request_tuple, msg)\n", "code_toks_joined": "def GetHostProject ( self , project ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> request_tuple = ( <NEWLINE> <INDENT> self . client . projects , <NEWLINE> <STRING> , <NEWLINE> self . messages . ComputeProjectsGetXpnHostRequest ( project = project ) ) <NEWLINE> <DEDENT> msg = <STRING> . format ( project = project ) <NEWLINE> return self . _MakeRequestSync ( request_tuple , msg ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Get the XPN host for the given project.\"\"\"", "'GetXpnHost'", "'get XPN host for project [{project}]'"]}}], ["65a347456889ac0c80d9fc8d5da4277a", {"code_string": "def _get_position(self):\n    if self._player is None:\n        return 0\n    return self._player.get_position()\n", "code_toks_joined": "def _get_position ( self ) : <NEWLINE> <INDENT> if self . _player is None : <NEWLINE> <INDENT> return 0 <NEWLINE> <DEDENT> return self . _player . get_position ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["8629f6f1f17ca5cac53721402d5f239b", {"code_string": "def update(self, input_signal, torque, acceleration):\n    \"Redraw the screen.\"\n    self.draw_shapes(input_signal)\n    while gtk.events_pending():\n        gtk.main_iteration(False)\n    if self.screencast:\n        self.take_a_screenshot()\n", "code_toks_joined": "def update ( self , input_signal , torque , acceleration ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . draw_shapes ( input_signal ) <NEWLINE> while gtk . events_pending ( ) : <NEWLINE> <INDENT> gtk . main_iteration ( False ) <NEWLINE> <DEDENT> if self . screencast : <NEWLINE> <INDENT> self . take_a_screenshot ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Redraw the screen.\""]}}], ["65b97e69d8bc41161da7c6fbf8164182", {"code_string": "def RunBotCommands(options, commands, env):\n    print('Environment changes:')\n    print(DictDiff(dict(os.environ), env))\n    for command in commands:\n        print(bb_utils.CommandToString(command))\n        sys.stdout.flush()\n        if options.testing:\n            env['BUILDBOT_TESTING'] = '1'\n        return_code = subprocess.call(command, cwd = bb_utils.CHROME_SRC, env = env)\n        if return_code != 0:\n            return return_code\n", "code_toks_joined": "def RunBotCommands ( options , commands , env ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> print ( DictDiff ( dict ( os . environ ) , env ) ) <NEWLINE> for command in commands : <NEWLINE> <INDENT> print ( bb_utils . CommandToString ( command ) ) <NEWLINE> sys . stdout . flush ( ) <NEWLINE> if options . testing : <NEWLINE> <INDENT> env [ <STRING> ] = <STRING> <NEWLINE> <DEDENT> return_code = subprocess . call ( command , cwd = bb_utils . CHROME_SRC , env = env ) <NEWLINE> if return_code != 0 : <NEWLINE> <INDENT> return return_code <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Environment changes:'", "'BUILDBOT_TESTING'", "'1'"]}}], ["0d5daac7742da885131bc91129b7c771", {"code_string": "from importlib import import_module\nimport os\nimport pkgutil\nfrom threading import local\nfrom django.conf import settings\nfrom django.core.exceptions import ImproperlyConfigured\nfrom django.utils.functional import cached_property\nfrom django.utils._os import upath\nDEFAULT_LIBSMS_ALIAS = 'default'\n", "code_toks_joined": "from importlib import import_module <NEWLINE> import os <NEWLINE> import pkgutil <NEWLINE> from threading import local <NEWLINE> from django . conf import settings <NEWLINE> from django . core . exceptions import ImproperlyConfigured <NEWLINE> from django . utils . functional import cached_property <NEWLINE> from django . utils . _os import upath <NEWLINE> DEFAULT_LIBSMS_ALIAS = <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'default'"]}}], ["cd06454c73e4e5a9e5dc218295dd96c9", {"code_string": "\"\"\"Step contains the commands for steps\"\"\"\nfrom __future__ import(print_function,\n    unicode_literals,\n    division)\nimport subprocess\nimport os\nimport re\nimport time\nimport xml.etree.ElementTree as ET\nimport jube2.util\nimport jube2.conf\nimport jube2.log\nLOGGER = jube2.log.get_logger(__name__)\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import ( print_function , <NEWLINE> <INDENT> unicode_literals , <NEWLINE> division ) <NEWLINE> <DEDENT> import subprocess <NEWLINE> import os <NEWLINE> import re <NEWLINE> import time <NEWLINE> import xml . etree . ElementTree as ET <NEWLINE> import jube2 . util <NEWLINE> import jube2 . conf <NEWLINE> import jube2 . log <NEWLINE> LOGGER = jube2 . log . get_logger ( __name__ ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Step contains the commands for steps\"\"\""]}}], ["5d9705a3ba33279080453a220ef0fb15", {"code_string": "import argparse\nimport os, sys\nimport rcs_utils\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(description = 'Convert line number to ' +\n        'instruction ID or vice versa')\n    parser.add_argument('bc',\n        help = 'the path to the input LLVM bitcode')\n    parser.add_argument('loc',\n        help = 'file:lineno, i<ins ID>, or v<value ID>')\n    args = parser.parse_args()\n    cmd = rcs_utils.load_all_plugins('opt')\n    cmd += ' -locate-src'\n    cmd += ' -pos ' + args.loc\n    cmd += ' -disable-output'\n    cmd += ' < ' + args.bc\n    rcs_utils.invoke(cmd)\n", "code_toks_joined": "import argparse <NEWLINE> import os , sys <NEWLINE> import rcs_utils <NEWLINE> if __name__ == <STRING> : <NEWLINE> <INDENT> parser = argparse . ArgumentParser ( description = <STRING> + <NEWLINE> <INDENT> <STRING> ) <NEWLINE> <DEDENT> parser . add_argument ( <STRING> , <NEWLINE> <INDENT> help = <STRING> ) <NEWLINE> <DEDENT> parser . add_argument ( <STRING> , <NEWLINE> <INDENT> help = <STRING> ) <NEWLINE> <DEDENT> args = parser . parse_args ( ) <NEWLINE> cmd = rcs_utils . load_all_plugins ( <STRING> ) <NEWLINE> cmd += <STRING> <NEWLINE> cmd += <STRING> + args . loc <NEWLINE> cmd += <STRING> <NEWLINE> cmd += <STRING> + args . bc <NEWLINE> rcs_utils . invoke ( cmd ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'__main__'", "'Convert line number to '", "'instruction ID or vice versa'", "'bc'", "'the path to the input LLVM bitcode'", "'loc'", "'file:lineno, i<ins ID>, or v<value ID>'", "'opt'", "' -locate-src'", "' -pos '", "' -disable-output'", "' < '"]}}], ["0ebed916beca9abd03c687556e6d94cf", {"code_string": "def __init__(self, fixed: MQTTFixedHeader = None, variable_header: PacketIdVariableHeader = None):\n    if fixed is None:\n        header = MQTTFixedHeader(PUBREL, 0x02)\n    else:\n        if fixed.packet_type is not PUBREL:\n            raise HBMQTTException(\"Invalid fixed packet type %s for PubrelPacket init\" % fixed.packet_type)\n        header = fixed\n    super().__init__(header)\n    self.variable_header = variable_header\n    self.payload = None\n", "code_toks_joined": "def __init__ ( self , fixed : MQTTFixedHeader = None , variable_header : PacketIdVariableHeader = None ) : <NEWLINE> <INDENT> if fixed is None : <NEWLINE> <INDENT> header = MQTTFixedHeader ( PUBREL , 0x02 ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> if fixed . packet_type is not PUBREL : <NEWLINE> <INDENT> raise HBMQTTException ( <STRING> % fixed . packet_type ) <NEWLINE> <DEDENT> header = fixed <NEWLINE> <DEDENT> super ( ) . __init__ ( header ) <NEWLINE> self . variable_header = variable_header <NEWLINE> self . payload = None <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Invalid fixed packet type %s for PubrelPacket init\""]}}], ["8f3fba7695e8076e0219278e08e0a223", {"code_string": "def exit_from_exception():\n    \"\"\" Call if the user interrupted the shell at input \"\"\"\n    print('\\n')\n    exit()\n", "code_toks_joined": "def exit_from_exception ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> print ( <STRING> ) <NEWLINE> exit ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Call if the user interrupted the shell at input \"\"\"", "'\\n'"]}}], ["24309fb912a9c136e4b381553ea01804", {"code_string": "def sumfile(filename):\n    '''Returns an md5 hash for an object with read() method.'''\n    f = open(filename, \"rb\")\n    m = hashlib.new(\"md5\")\n    while True:\n        d = f.read(8096)\n        if not d:\n            break\n        m.update(d)\n    f.close()\n    return m.hexdigest()\n", "code_toks_joined": "def sumfile ( filename ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> f = open ( filename , <STRING> ) <NEWLINE> m = hashlib . new ( <STRING> ) <NEWLINE> while True : <NEWLINE> <INDENT> d = f . read ( 8096 ) <NEWLINE> if not d : <NEWLINE> <INDENT> break <NEWLINE> <DEDENT> m . update ( d ) <NEWLINE> <DEDENT> f . close ( ) <NEWLINE> return m . hexdigest ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Returns an md5 hash for an object with read() method.'''", "\"rb\"", "\"md5\""]}}], ["5c00e385f3bbf9436457cc558fe6920c", {"code_string": "class TestFeedController(TestController):\n    def test_index(self):\n        response = self.app.get(url(controller = 'feed', action = 'index'))\n", "code_toks_joined": "class TestFeedController ( TestController ) : <NEWLINE> <INDENT> def test_index ( self ) : <NEWLINE> <INDENT> response = self . app . get ( url ( controller = <STRING> , action = <STRING> ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'feed'", "'index'"]}}], ["fa9d6f0d99a5c674475bcd05693926ca", {"code_string": "class RutaAdmin(admin.ModelAdmin):\n    list_display = ('__unicode__', 'nombre')\n    search_fields = ['numero', 'nombre']\n    ordering = ['numero']\n", "code_toks_joined": "class RutaAdmin ( admin . ModelAdmin ) : <NEWLINE> <INDENT> list_display = ( <STRING> , <STRING> ) <NEWLINE> search_fields = [ <STRING> , <STRING> ] <NEWLINE> ordering = [ <STRING> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'__unicode__'", "'nombre'", "'numero'", "'nombre'", "'numero'"]}}], ["150838ef3aaf84940341a6527b08025b", {"code_string": "def onchange_partner_id(self, partner_id):\n    val = super(SaleOrder, self).onchange_partner_id(partner_id)\n    if partner_id:\n        partner = self.env['res.partner'].browse(partner_id)\n        comment, pcomment = partner._get_sale_comments()\n        val['value'].update({'comment': comment,\n            'propagated_comment': pcomment})\n    return val\n", "code_toks_joined": "def onchange_partner_id ( self , partner_id ) : <NEWLINE> <INDENT> val = super ( SaleOrder , self ) . onchange_partner_id ( partner_id ) <NEWLINE> if partner_id : <NEWLINE> <INDENT> partner = self . env [ <STRING> ] . browse ( partner_id ) <NEWLINE> comment , pcomment = partner . _get_sale_comments ( ) <NEWLINE> val [ <STRING> ] . update ( { <STRING> : comment , <NEWLINE> <INDENT> <STRING> : pcomment } ) <NEWLINE> <DEDENT> <DEDENT> return val <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'res.partner'", "'value'", "'comment'", "'propagated_comment'"]}}], ["e11659f07f3acc9a76547d3299c4504b", {"code_string": "list = ['apple', 'orange', 40, 'grapes', 'last item']\ndictionary = {'name': 'Chris', 'age': 31, 'phone_number': \"503-555-1234\"}\nnum = 0\nfor items in list:\n    num += 1\n    print(str(num) + ': ' + str(items))\nprint(num)\n", "code_toks_joined": "list = [ <STRING> , <STRING> , 40 , <STRING> , <STRING> ] <NEWLINE> dictionary = { <STRING> : <STRING> , <STRING> : 31 , <STRING> : <STRING> } <NEWLINE> num = 0 <NEWLINE> for items in list : <NEWLINE> <INDENT> num += 1 <NEWLINE> print ( str ( num ) + <STRING> + str ( items ) ) <NEWLINE> <DEDENT> print ( num ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["'apple'", "'orange'", "'grapes'", "'last item'", "'name'", "'Chris'", "'age'", "'phone_number'", "\"503-555-1234\"", "': '"]}}], ["93f16cba296baec50cd1f0426de5c75e", {"code_string": "class Language:\n    def isLang(self, line):\n        \"\"\"This language know about this line, cause it will be evaluated by using this lang class,\"\"\"\n        return False\n    def isLangPrefix(self, line):\n        \"\"\"Do the same as isLang method, except evaluation. This lang will be evaluated for completion\"\"\"\n        return False\n    def complete(self, line):\n        \"\"\"Complete this line\"\"\"\n        yield Completion('PLEASE IMPLEMENT COMPLETION')\n    def evaluate(self, line, processor = None, stdin = \"\"):\n        \"\"\"Evaluate this line\"\"\"\n        return \"\"\n", "code_toks_joined": "class Language : <NEWLINE> <INDENT> def isLang ( self , line ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return False <NEWLINE> <DEDENT> def isLangPrefix ( self , line ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return False <NEWLINE> <DEDENT> def complete ( self , line ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> yield Completion ( <STRING> ) <NEWLINE> <DEDENT> def evaluate ( self , line , processor = None , stdin = <STRING> ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return <STRING> <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"This language know about this line, cause it will be evaluated by using this lang class,\"\"\"", "\"\"\"Do the same as isLang method, except evaluation. This lang will be evaluated for completion\"\"\"", "\"\"\"Complete this line\"\"\"", "'PLEASE IMPLEMENT COMPLETION'", "\"\"", "\"\"\"Evaluate this line\"\"\"", "\"\""]}}], ["76b1c520a472d5728c22d409a7bbc3bc", {"code_string": "def rawCall(self, method, * args):\n    '''Make a remote call and return the raw response.'''\n    url = self.__createURL(method, args)\n    result = urlopen(url).read()\n    return result\n", "code_toks_joined": "def rawCall ( self , method , * args ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> url = self . __createURL ( method , args ) <NEWLINE> result = urlopen ( url ) . read ( ) <NEWLINE> return result <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Make a remote call and return the raw response.'''"]}}], ["5072c4cdb3d49dc5cfe7ca68266a0c8d", {"code_string": "class Migration(migrations.Migration):\n    dependencies = [\n        ('boletin', '0002_auto_20151211_0440'),\n    ]\n    operations = [\n        migrations.AlterField(\n            model_name = 'registrado',\n            name = 'email',\n            field = models.EmailField(default = 1, max_length = 254),\n            preserve_default = False,\n        ),\n    ]\n", "code_toks_joined": "class Migration ( migrations . Migration ) : <NEWLINE> <INDENT> dependencies = [ <NEWLINE> <INDENT> ( <STRING> , <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE> operations = [ <NEWLINE> <INDENT> migrations . AlterField ( <NEWLINE> <INDENT> model_name = <STRING> , <NEWLINE> name = <STRING> , <NEWLINE> field = models . EmailField ( default = 1 , max_length = 254 ) , <NEWLINE> preserve_default = False , <NEWLINE> <DEDENT> ) , <NEWLINE> <DEDENT> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'boletin'", "'0002_auto_20151211_0440'", "'registrado'", "'email'"]}}], ["b87992b45b4826a8823f50c303c433af", {"code_string": "class myExtractions(UserExtractions.UserExtractions):\n    def nodeDegree():\n        return degree\n    def betweenness():\n        return bCentrality\n    def closeness():\n        return cCentrality\n    def clusteringCoefficient():\n        return clustering\n    def greaterNeighborhoodState():\n        avg_neighbor_state = sum(neighborStates) / degree\n        if state >= avg_neighbor_state:\n            return 1\n        else:\n            return 0\n    def netIn():\n        netIn = inDegree - outDegree\n        return max(netIn, 0)\n", "code_toks_joined": "class myExtractions ( UserExtractions . UserExtractions ) : <NEWLINE> <INDENT> def nodeDegree ( ) : <NEWLINE> <INDENT> return degree <NEWLINE> <DEDENT> def betweenness ( ) : <NEWLINE> <INDENT> return bCentrality <NEWLINE> <DEDENT> def closeness ( ) : <NEWLINE> <INDENT> return cCentrality <NEWLINE> <DEDENT> def clusteringCoefficient ( ) : <NEWLINE> <INDENT> return clustering <NEWLINE> <DEDENT> def greaterNeighborhoodState ( ) : <NEWLINE> <INDENT> avg_neighbor_state = sum ( neighborStates ) / degree <NEWLINE> if state >= avg_neighbor_state : <NEWLINE> <INDENT> return 1 <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return 0 <NEWLINE> <DEDENT> <DEDENT> def netIn ( ) : <NEWLINE> <INDENT> netIn = inDegree - outDegree <NEWLINE> return max ( netIn , 0 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["dbdd3ae1f3fa1e01af3632e3c39af65e", {"code_string": "\"\"\"test_key_string.py -- from text, make a key string for use in dictionaries\"\"\"\n__author__ = \"Michael Conlon\"\n__copyright__ = \"Copyright 2013, University of Florida\"\n__license__ = \"BSD 3-Clause license\"\n__version__ = \"0.1\"\nimport vivotools as vt\nfrom datetime import datetime\nprint(datetime.now(), \"Start\")\nprint(vt.key_string(\"  A +Walk+ in (the) Woods\"))\nprint(vt.key_string(\"A wALK  in the, woods   \"))\nprint(vt.key_string(\"AWALKINTHEWOODS\"))\nprint(vt.key_string(\"awalkinthewoods\"))\nprint(datetime.now(), \"Finish\")\n", "code_toks_joined": "<STRING> <NEWLINE> __author__ = <STRING> <NEWLINE> __copyright__ = <STRING> <NEWLINE> __license__ = <STRING> <NEWLINE> __version__ = <STRING> <NEWLINE> import vivotools as vt <NEWLINE> from datetime import datetime <NEWLINE> print ( datetime . now ( ) , <STRING> ) <NEWLINE> print ( vt . key_string ( <STRING> ) ) <NEWLINE> print ( vt . key_string ( <STRING> ) ) <NEWLINE> print ( vt . key_string ( <STRING> ) ) <NEWLINE> print ( vt . key_string ( <STRING> ) ) <NEWLINE> print ( datetime . now ( ) , <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"test_key_string.py -- from text, make a key string for use in dictionaries\"\"\"", "\"Michael Conlon\"", "\"Copyright 2013, University of Florida\"", "\"BSD 3-Clause license\"", "\"0.1\"", "\"Start\"", "\"  A +Walk+ in (the) Woods\"", "\"A wALK  in the, woods   \"", "\"AWALKINTHEWOODS\"", "\"awalkinthewoods\"", "\"Finish\""]}}], ["64eca5531d3345682cc1c13c7bcee978", {"code_string": "def test_untransform(transfs):\n    transfs.untransform('\\.txt$', DummyTransformer)\n    assert transfs.list() =={'/', '/x', '/x/a.txt', '/x/b.png'}\n", "code_toks_joined": "def test_untransform ( transfs ) : <NEWLINE> <INDENT> transfs . untransform ( <STRING> , DummyTransformer ) <NEWLINE> assert transfs . list ( ) == { <STRING> , <STRING> , <STRING> , <STRING> } <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'\\.txt$'", "'/'", "'/x'", "'/x/a.txt'", "'/x/b.png'"]}}], ["bed71deeb6103cef97d8c0c7d6c72722", {"code_string": "def create_event_packet(self, title, text):\n    p = \"_e{{{title_len},{text_len}}}:{title}|{text}\".format(\n        title_len = len(title),\n        text_len = len(text),\n        title = title,\n        text = text\n        )\n    return p\n", "code_toks_joined": "def create_event_packet ( self , title , text ) : <NEWLINE> <INDENT> p = <STRING> . format ( <NEWLINE> <INDENT> title_len = len ( title ) , <NEWLINE> text_len = len ( text ) , <NEWLINE> title = title , <NEWLINE> text = text <NEWLINE> ) <NEWLINE> <DEDENT> return p <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"_e{{{title_len},{text_len}}}:{title}|{text}\""]}}], ["b420e6be07cba3a5224e3c4451587d6b", {"code_string": "def __init__(self, config, osc = None):\n    super(VolumeMigrate, self).__init__(config)\n    self.temp_username = utils.random_string(10)\n    self.temp_password = utils.random_string(10)\n    self.cinder_util = cinder_helper.CinderHelper(osc = self.osc)\n    self.nova_util = nova_helper.NovaHelper(osc = self.osc)\n", "code_toks_joined": "def __init__ ( self , config , osc = None ) : <NEWLINE> <INDENT> super ( VolumeMigrate , self ) . __init__ ( config ) <NEWLINE> self . temp_username = utils . random_string ( 10 ) <NEWLINE> self . temp_password = utils . random_string ( 10 ) <NEWLINE> self . cinder_util = cinder_helper . CinderHelper ( osc = self . osc ) <NEWLINE> self . nova_util = nova_helper . NovaHelper ( osc = self . osc ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["fdecfb0b16e1e02a9f3453048acea3b4", {"code_string": "def _ouc(x, y):\n    out = np.empty_like(x, dtype = bool)\n    xzero = (x == 0)\n    yzero = (y == 0)\n    out[xzero & yzero] = False\n    out[~ xzero & yzero] = True\n    out[~ yzero] = (abs(x[~ yzero] / y[~ yzero]) > 1.0)\n    return out\n", "code_toks_joined": "def _ouc ( x , y ) : <NEWLINE> <INDENT> out = np . empty_like ( x , dtype = bool ) <NEWLINE> xzero = ( x == 0 ) <NEWLINE> yzero = ( y == 0 ) <NEWLINE> out [ xzero & yzero ] = False <NEWLINE> out [ ~ xzero & yzero ] = True <NEWLINE> out [ ~ yzero ] = ( abs ( x [ ~ yzero ] / y [ ~ yzero ] ) > 1.0 ) <NEWLINE> return out <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["71de1cc10a0bd46f0cc8d583b43b540c", {"code_string": "def __init__(self, arr, offset_x, offset_y, scale = 1):\n    self.arr = arr\n    self.offset_x = offset_x\n    self.offset_y = offset_y\n    self.scale = scale\n", "code_toks_joined": "def __init__ ( self , arr , offset_x , offset_y , scale = 1 ) : <NEWLINE> <INDENT> self . arr = arr <NEWLINE> self . offset_x = offset_x <NEWLINE> self . offset_y = offset_y <NEWLINE> self . scale = scale <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["1630075f16aaf283f01771e41b43914b", {"code_string": "def SetBrightnes(self, brightnes):\n    if(brightnes > 7):\n        brightnes = 7;\n    elif(brightnes < 0):\n        brightnes = 0;\n    if(self.__brightnes != brightnes):\n        self.__brightnes = brightnes;\n        self.Show(self.__currentData);\n", "code_toks_joined": "def SetBrightnes ( self , brightnes ) : <NEWLINE> <INDENT> if ( brightnes > 7 ) : <NEWLINE> <INDENT> brightnes = 7 ; <NEWLINE> <DEDENT> elif ( brightnes < 0 ) : <NEWLINE> <INDENT> brightnes = 0 ; <NEWLINE> <DEDENT> if ( self . __brightnes != brightnes ) : <NEWLINE> <INDENT> self . __brightnes = brightnes ; <NEWLINE> self . Show ( self . __currentData ) ; <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["44ee5420680775b9cedd7ff4366b4026", {"code_string": "def p_param(p):\n    \"\"\"param : NAME EQUALS DECIMAL\"\"\"\n    print(p)\n", "code_toks_joined": "def p_param ( p ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> print ( p ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"param : NAME EQUALS DECIMAL\"\"\""]}}], ["9489e8967083875422964f904b0b3628", {"code_string": "\"\"\"Eventify Persistance Configuration\"\"\"\nimport os\nEVENT_DB_HOST = os.getenv('EVENT_DB_HOST', None)\nEVENT_DB_USER = os.getenv('EVENT_DB_USER', None)\nEVENT_DB_PASS = os.getenv('EVENT_DB_PASS', None)\nEVENT_DB_NAME = os.getenv('EVENT_DB_NAME', 'event_history')\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> EVENT_DB_HOST = os . getenv ( <STRING> , None ) <NEWLINE> EVENT_DB_USER = os . getenv ( <STRING> , None ) <NEWLINE> EVENT_DB_PASS = os . getenv ( <STRING> , None ) <NEWLINE> EVENT_DB_NAME = os . getenv ( <STRING> , <STRING> ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Eventify Persistance Configuration\"\"\"", "'EVENT_DB_HOST'", "'EVENT_DB_USER'", "'EVENT_DB_PASS'", "'EVENT_DB_NAME'", "'event_history'"]}}], ["a7e0ad4981c9fb958976fe373ce18dd1", {"code_string": "try:\n    from.ldap_auth import ldap_auth_backend\nexcept SystemError:\n    from ldap_auth import ldap_auth_backend\n", "code_toks_joined": "try : <NEWLINE> <INDENT> from . ldap_auth import ldap_auth_backend <NEWLINE> <DEDENT> except SystemError : <NEWLINE> <INDENT> from ldap_auth import ldap_auth_backend <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["ee464c3fafe4070eaabf6d4fc99a125d", {"code_string": "import functools\nimport os, os.path\nimport re\nimport threading\nimport urllib\nimport core\n", "code_toks_joined": "import functools <NEWLINE> import os , os . path <NEWLINE> import re <NEWLINE> import threading <NEWLINE> import urllib <NEWLINE> import core <NEWLINE>", "anonymize_dict": {}}], ["2eda2ba757c1621d91e309048d8f5043", {"code_string": "class Post(models.Model):\n    title = models.CharField(max_length = 100)\n    date_time = models.DateTimeField(auto_now_add = True)\n    content = models.TextField(blank = True, null = True)\n    created_time = models.DateTimeField(auto_now_add = True)\n    modified_time = models.DateTimeField(auto_now = True)\n    category = models.ForeignKey(Category)\n    author = models.ForeignKey(User)\n    def __str__(self):\n        return self.title\n    class Meta:\n        ordering = ['-created_time']\n", "code_toks_joined": "class Post ( models . Model ) : <NEWLINE> <INDENT> title = models . CharField ( max_length = 100 ) <NEWLINE> date_time = models . DateTimeField ( auto_now_add = True ) <NEWLINE> content = models . TextField ( blank = True , null = True ) <NEWLINE> created_time = models . DateTimeField ( auto_now_add = True ) <NEWLINE> modified_time = models . DateTimeField ( auto_now = True ) <NEWLINE> category = models . ForeignKey ( Category ) <NEWLINE> author = models . ForeignKey ( User ) <NEWLINE> def __str__ ( self ) : <NEWLINE> <INDENT> return self . title <NEWLINE> <DEDENT> class Meta : <NEWLINE> <INDENT> ordering = [ <STRING> ] <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'-created_time'"]}}], ["f21d007c953fa7402351f4a018dd580f", {"code_string": "from __future__ import(absolute_import, division, generators, nested_scopes, print_function,\n    unicode_literals, with_statement)\nimport os\nfrom collections import defaultdict\nfrom twitter.common.collections import OrderedSet\nfrom pants.backend.jvm.targets.jar_dependency import JarDependency\nfrom pants.backend.jvm.tasks.coverage.base import Coverage, CoverageTaskSettings\nfrom pants.base.build_environment import get_buildroot\nfrom pants.base.exceptions import TaskError\nfrom pants.binaries import binary_util\nfrom pants.util.contextutil import temporary_file\nfrom pants.util.dirutil import relativize_paths, safe_delete, safe_mkdir, touch\n", "code_toks_joined": "from __future__ import ( absolute_import , division , generators , nested_scopes , print_function , <NEWLINE> <INDENT> unicode_literals , with_statement ) <NEWLINE> <DEDENT> import os <NEWLINE> from collections import defaultdict <NEWLINE> from twitter . common . collections import OrderedSet <NEWLINE> from pants . backend . jvm . targets . jar_dependency import JarDependency <NEWLINE> from pants . backend . jvm . tasks . coverage . base import Coverage , CoverageTaskSettings <NEWLINE> from pants . base . build_environment import get_buildroot <NEWLINE> from pants . base . exceptions import TaskError <NEWLINE> from pants . binaries import binary_util <NEWLINE> from pants . util . contextutil import temporary_file <NEWLINE> from pants . util . dirutil import relativize_paths , safe_delete , safe_mkdir , touch <NEWLINE>", "anonymize_dict": {}}], ["646d598c760501f107d32e05d66de24c", {"code_string": "def __repr__(self):\n    if self.name:\n        return '<SimpleProcedure %s>' % self.name\n    return object.__repr__(self)\n", "code_toks_joined": "def __repr__ ( self ) : <NEWLINE> <INDENT> if self . name : <NEWLINE> <INDENT> return <STRING> % self . name <NEWLINE> <DEDENT> return object . __repr__ ( self ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'<SimpleProcedure %s>'"]}}], ["bd59f48d976c1a7ce69341d8900ae824", {"code_string": "def getWriters(self):\n    \"\"\"Return a list of the writers.\"\"\"\n    return list(self._writers)\n", "code_toks_joined": "def getWriters ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return list ( self . _writers ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Return a list of the writers.\"\"\""]}}], ["64bb55a04b661f6382638ab7055daf1c", {"code_string": "def test_install_from_wheel_gui_entrypoint(script, data):\n    \"\"\"Test installing scripts (gui entry points are generated)\"\"\"\n    result = script.pip(\n        'install', 'script.wheel3==0.1', '--no-index',\n        '--find-links=' + data.find_links,\n        expect_error = False,\n    )\n    if os.name == 'nt':\n        wrapper_file = script.bin / 't1.exe'\n    else:\n        wrapper_file = script.bin / 't1'\n    assert wrapper_file in result.files_created\n", "code_toks_joined": "def test_install_from_wheel_gui_entrypoint ( script , data ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> result = script . pip ( <NEWLINE> <INDENT> <STRING> , <STRING> , <STRING> , <NEWLINE> <STRING> + data . find_links , <NEWLINE> expect_error = False , <NEWLINE> <DEDENT> ) <NEWLINE> if os . name == <STRING> : <NEWLINE> <INDENT> wrapper_file = script . bin / <STRING> <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> wrapper_file = script . bin / <STRING> <NEWLINE> <DEDENT> assert wrapper_file in result . files_created <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test installing scripts (gui entry points are generated)\"\"\"", "'install'", "'script.wheel3==0.1'", "'--no-index'", "'--find-links='", "'nt'", "'t1.exe'", "'t1'"]}}], ["85a9a74430951bb2e2eb8da9c0bf0db1", {"code_string": "class Server(object):\n    def get_interface(self):\n        pass\n    def add_vlan_to_interface(self):\n        pass\n    def ping(self):\n        pass\n    def setup_link(self):\n        pass\n    def check_ports_on_br(self):\n        pass\n    def setup_iperf_server(self):\n        pass\n    def start_iperf_client(self):\n        pass\n    def teardown_iperf_server(self):\n        pass\n    def check_dhcp_on_comp(self):\n        pass\n", "code_toks_joined": "class Server ( object ) : <NEWLINE> <INDENT> def get_interface ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def add_vlan_to_interface ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def ping ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def setup_link ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def check_ports_on_br ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def setup_iperf_server ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def start_iperf_client ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def teardown_iperf_server ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> def check_dhcp_on_comp ( self ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["e7d302283309998bce2fccdc8de44ee6", {"code_string": "def main():\n    args = parser.parse_args()\n    for i, (ff, inputfile) in enumerate(list_tiffs(args.inputfile)):\n        process_file(ff, inputfile)\n        print('Processed %d file(s)' %(i + 1))\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> args = parser . parse_args ( ) <NEWLINE> for i , ( ff , inputfile ) in enumerate ( list_tiffs ( args . inputfile ) ) : <NEWLINE> <INDENT> process_file ( ff , inputfile ) <NEWLINE> print ( <STRING> % ( i + 1 ) ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Processed %d file(s)'"]}}], ["3329c7c0d1cb86850b154dc500f27d5e", {"code_string": "def _decode_val(self, val):\n    [retry_times, timestamp, buff] = val.split(\":\", 2)\n    retry_times = int(retry_times)\n    timestamp = int(timestamp)\n    packet = protocol.Packet.decode(buff)\n    packet.retry_times = retry_times\n    packet.timestamp = timestamp\n    return packet\n", "code_toks_joined": "def _decode_val ( self , val ) : <NEWLINE> <INDENT> [ retry_times , timestamp , buff ] = val . split ( <STRING> , 2 ) <NEWLINE> retry_times = int ( retry_times ) <NEWLINE> timestamp = int ( timestamp ) <NEWLINE> packet = protocol . Packet . decode ( buff ) <NEWLINE> packet . retry_times = retry_times <NEWLINE> packet . timestamp = timestamp <NEWLINE> return packet <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\":\""]}}], ["4854d2f89ad3a3395545416ba3aefc15", {"code_string": "def prepare_search_results(res):\n    \"\"\" Internal function to prepare ElasticSearch search results to send as json.\"\"\"\n    projects = list(res)\n    for project in projects:\n        project['is_bookmark'] = 'true' if project.get('_id') in current_user.bookmarks else 'false'\n        project['is_owner'] = 'true' if current_user['email'] in project.get('authors') else 'false'\n    return projects\n", "code_toks_joined": "def prepare_search_results ( res ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> projects = list ( res ) <NEWLINE> for project in projects : <NEWLINE> <INDENT> project [ <STRING> ] = <STRING> if project . get ( <STRING> ) in current_user . bookmarks else <STRING> <NEWLINE> project [ <STRING> ] = <STRING> if current_user [ <STRING> ] in project . get ( <STRING> ) else <STRING> <NEWLINE> <DEDENT> return projects <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Internal function to prepare ElasticSearch search results to send as json.\"\"\"", "'is_bookmark'", "'true'", "'_id'", "'false'", "'is_owner'", "'true'", "'email'", "'authors'", "'false'"]}}], ["d10f7959238a0742f33df954a841b734", {"code_string": "from __future__ import unicode_literals\nfrom django.utils.translation import ugettext_lazy as _\nfrom shuup.admin.utils.picotable import ChoicesFilter, Column, MPTTFilter\nfrom shuup.admin.utils.views import PicotableListView\nfrom shuup.core.models import Category, CategoryStatus, CategoryVisibility\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> from django . utils . translation import ugettext_lazy as _ <NEWLINE> from shuup . admin . utils . picotable import ChoicesFilter , Column , MPTTFilter <NEWLINE> from shuup . admin . utils . views import PicotableListView <NEWLINE> from shuup . core . models import Category , CategoryStatus , CategoryVisibility <NEWLINE>", "anonymize_dict": {}}], ["16cc817d07ee072d2cc165db2f3690d6", {"code_string": "def new_incoming_message(self, msg_id, producer_dn, msg_data):\n    msg_file = self._inpath + msg_id\n    if self._dup_check(msg_data, msg_file + '\\t' + producer_dn + '\\n'):\n        self._atomic_write_file(msg_file, msg_data)\n        sigfile = open(msg_file + '.sig', 'w')\n        sigfile.write(producer_dn + '\\n')\n        sigfile.close()\n        return True\n    else:\n        return False\n", "code_toks_joined": "def new_incoming_message ( self , msg_id , producer_dn , msg_data ) : <NEWLINE> <INDENT> msg_file = self . _inpath + msg_id <NEWLINE> if self . _dup_check ( msg_data , msg_file + <STRING> + producer_dn + <STRING> ) : <NEWLINE> <INDENT> self . _atomic_write_file ( msg_file , msg_data ) <NEWLINE> sigfile = open ( msg_file + <STRING> , <STRING> ) <NEWLINE> sigfile . write ( producer_dn + <STRING> ) <NEWLINE> sigfile . close ( ) <NEWLINE> return True <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'\\t'", "'\\n'", "'.sig'", "'w'", "'\\n'"]}}], ["efac81d139e6654345db9e25eb6a7982", {"code_string": "def errcheck(result, func, arguments):\n    if result < 0:\n        errno = ctypes.get_errno()\n        raise OSError(errno, os.strerror(errno))\n    return result\n", "code_toks_joined": "def errcheck ( result , func , arguments ) : <NEWLINE> <INDENT> if result < 0 : <NEWLINE> <INDENT> errno = ctypes . get_errno ( ) <NEWLINE> raise OSError ( errno , os . strerror ( errno ) ) <NEWLINE> <DEDENT> return result <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["50f2fafa48271cd9be93a19b57f01377", {"code_string": "def brower(self):\n    if self.LWweb.currentItem():\n        url = self.LWweb.currentItem().text()\n        webbrowser.open(url)\n", "code_toks_joined": "def brower ( self ) : <NEWLINE> <INDENT> if self . LWweb . currentItem ( ) : <NEWLINE> <INDENT> url = self . LWweb . currentItem ( ) . text ( ) <NEWLINE> webbrowser . open ( url ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["285d5947b9a200f6c5e46b08d73db7c5", {"code_string": "'''Created on Jan 17, 2013'''\nimport unittest\nfrom testbundle.bundle import Bundle\nfrom databundles.identity import *\nfrom test_base import TestBase\nfrom osgeo.gdalconst import GDT_Float32\nimport ogr\n", "code_toks_joined": "<STRING> <NEWLINE> import unittest <NEWLINE> from testbundle . bundle import Bundle <NEWLINE> from databundles . identity import * <NEWLINE> from test_base import TestBase <NEWLINE> from osgeo . gdalconst import GDT_Float32 <NEWLINE> import ogr <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''Created on Jan 17, 2013'''"]}}], ["11eaf7c19d717115512e5e8594b79b13", {"code_string": "from django.db import models\nfrom django.contrib.auth.models import User\nfrom django.db.models.signals import post_save, pre_save\nfrom django.core.mail import send_mail\nfrom django.conf import settings\n", "code_toks_joined": "from django . db import models <NEWLINE> from django . contrib . auth . models import User <NEWLINE> from django . db . models . signals import post_save , pre_save <NEWLINE> from django . core . mail import send_mail <NEWLINE> from django . conf import settings <NEWLINE>", "anonymize_dict": {}}], ["7691736ce5da74b3fcf992578f0c91b6", {"code_string": "def test_keys(self):\n    \"\"\"Test the ability to iterate over a repository's keys.\"\"\"\n    i = self.instance.keys()\n    self.get_next(i)\n    self.session.get.assert_called_once_with(\n        url_for('keys'),\n        params = {'per_page': 100},\n        headers = {}\n    )\n", "code_toks_joined": "def test_keys ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> i = self . instance . keys ( ) <NEWLINE> self . get_next ( i ) <NEWLINE> self . session . get . assert_called_once_with ( <NEWLINE> <INDENT> url_for ( <STRING> ) , <NEWLINE> params = { <STRING> : 100 } , <NEWLINE> headers = { } <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Test the ability to iterate over a repository's keys.\"\"\"", "'keys'", "'per_page'"]}}], ["e126bf5603bf15e2a78e80e4f729e2f2", {"code_string": "def tushare_code_2_order_book_id(code):\n    try:\n        return TUSHARE_CODE_MAPPING[code]\n    except KeyError:\n        if code.startswith(\"6\"):\n            return \"{}.XSHG\".format(code)\n        elif code[0] in[\"3\", \"0\"]:\n            return \"{}.XSHE\".format(code)\n        else:\n            raise RuntimeError(\"Unknown code\")\n", "code_toks_joined": "def tushare_code_2_order_book_id ( code ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> return TUSHARE_CODE_MAPPING [ code ] <NEWLINE> <DEDENT> except KeyError : <NEWLINE> <INDENT> if code . startswith ( <STRING> ) : <NEWLINE> <INDENT> return <STRING> . format ( code ) <NEWLINE> <DEDENT> elif code [ 0 ] in [ <STRING> , <STRING> ] : <NEWLINE> <INDENT> return <STRING> . format ( code ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> raise RuntimeError ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"6\"", "\"{}.XSHG\"", "\"3\"", "\"0\"", "\"{}.XSHE\"", "\"Unknown code\""]}}], ["e536e693cc9530703e922a67c4d54b27", {"code_string": "import unittest\nimport tempfile\nfrom openglider.jsonify import load\nfrom openglider.plots import flatten_glider\nfrom openglider.plots.glider.cell import flattened_cell\nfrom openglider.plots.part import create_svg\nfrom openglider.glider.cell_elements import Panel\nfrom openglider.graphics import Line, Graphics2D, Red, Graphics3D\n", "code_toks_joined": "import unittest <NEWLINE> import tempfile <NEWLINE> from openglider . jsonify import load <NEWLINE> from openglider . plots import flatten_glider <NEWLINE> from openglider . plots . glider . cell import flattened_cell <NEWLINE> from openglider . plots . part import create_svg <NEWLINE> from openglider . glider . cell_elements import Panel <NEWLINE> from openglider . graphics import Line , Graphics2D , Red , Graphics3D <NEWLINE>", "anonymize_dict": {}}], ["47412d43d11aed1bea8f7c286bad2dd2", {"code_string": "def section(function):\n    sections.append(function)\n    return function\n", "code_toks_joined": "def section ( function ) : <NEWLINE> <INDENT> sections . append ( function ) <NEWLINE> return function <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["d204ddd16a4c807c6a3f5cf26e8d45a0", {"code_string": "import logging\nfrom threading import local\nfrom django.conf import settings\nfrom django.core import signals\nfrom django.db import models\nfrom django.db.models.signals import pre_delete, post_save, m2m_changed\nfrom django.dispatch import receiver\nfrom elasticutils.contrib.django import MappingType, Indexable, MLT\nfrom elasticsearch.exceptions import NotFoundError\nfrom kitsune.search import es_utils\nfrom kitsune.search.tasks import index_task, unindex_task\nfrom kitsune.sumo.models import ModelBase\nlog = logging.getLogger('k.search.es')\n_search_mapping_types = {}\n", "code_toks_joined": "import logging <NEWLINE> from threading import local <NEWLINE> from django . conf import settings <NEWLINE> from django . core import signals <NEWLINE> from django . db import models <NEWLINE> from django . db . models . signals import pre_delete , post_save , m2m_changed <NEWLINE> from django . dispatch import receiver <NEWLINE> from elasticutils . contrib . django import MappingType , Indexable , MLT <NEWLINE> from elasticsearch . exceptions import NotFoundError <NEWLINE> from kitsune . search import es_utils <NEWLINE> from kitsune . search . tasks import index_task , unindex_task <NEWLINE> from kitsune . sumo . models import ModelBase <NEWLINE> log = logging . getLogger ( <STRING> ) <NEWLINE> _search_mapping_types = { } <NEWLINE>", "anonymize_dict": {"<STRING>": ["'k.search.es'"]}}], ["615447d6ef6b5fbb805e648b2a2ad91c", {"code_string": "def walk(self, oid, host, port, community):\n    ret = {}\n    snmpAuthData = cmdgen.CommunityData(community)\n    snmpTransportData = cmdgen.UdpTransportTarget((host, port))\n    resultTable = self.snmpCmdGen.nextCmd(snmpAuthData,\n        snmpTransportData,\n        oid)\n    varBindTable = resultTable[3]\n    for varBindTableRow in varBindTable:\n        for o, v in varBindTableRow:\n            ret[o.prettyPrint()] = v.prettyPrint()\n    return ret\n", "code_toks_joined": "def walk ( self , oid , host , port , community ) : <NEWLINE> <INDENT> ret = { } <NEWLINE> snmpAuthData = cmdgen . CommunityData ( community ) <NEWLINE> snmpTransportData = cmdgen . UdpTransportTarget ( ( host , port ) ) <NEWLINE> resultTable = self . snmpCmdGen . nextCmd ( snmpAuthData , <NEWLINE> <INDENT> snmpTransportData , <NEWLINE> oid ) <NEWLINE> <DEDENT> varBindTable = resultTable [ 3 ] <NEWLINE> for varBindTableRow in varBindTable : <NEWLINE> <INDENT> for o , v in varBindTableRow : <NEWLINE> <INDENT> ret [ o . prettyPrint ( ) ] = v . prettyPrint ( ) <NEWLINE> <DEDENT> <DEDENT> return ret <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["b3c41f28632208bed0f2ae5eb4ab5ee2", {"code_string": "def rl_complete(self, text, state):\n    \"\"\"Alternate entry point for using the argcomplete completer in a readline-based REPL. See also\"\"\"\n    if state == 0:\n        cword_prequote, cword_prefix, cword_suffix, comp_words, first_colon_pos = split_line(text)\n        comp_words.insert(0, sys.argv[0])\n        matches = self._get_completions(comp_words, cword_prefix, cword_prequote, first_colon_pos)\n        self._rl_matches = [text + match[len(cword_prefix): ] for match in matches]\n    if state < len(self._rl_matches):\n        return self._rl_matches[state]\n    else:\n        return None\n", "code_toks_joined": "def rl_complete ( self , text , state ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if state == 0 : <NEWLINE> <INDENT> cword_prequote , cword_prefix , cword_suffix , comp_words , first_colon_pos = split_line ( text ) <NEWLINE> comp_words . insert ( 0 , sys . argv [ 0 ] ) <NEWLINE> matches = self . _get_completions ( comp_words , cword_prefix , cword_prequote , first_colon_pos ) <NEWLINE> self . _rl_matches = [ text + match [ len ( cword_prefix ) : ] for match in matches ] <NEWLINE> <DEDENT> if state < len ( self . _rl_matches ) : <NEWLINE> <INDENT> return self . _rl_matches [ state ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Alternate entry point for using the argcomplete completer in a readline-based REPL. See also\"\"\""]}}], ["410c30daa8bced754345b21bc00ec4f9", {"code_string": "def phenotips_view_patient_pdf(request, project_guid, patient_id):\n    \"\"\"Requests the PhenoTips PDF for the given patient_id, and forwards PhenoTips' response to the client.\"\"\"\n    url = \"/bin/export/data/%(patient_id)s?format=pdf&pdfcover=0&pdftoc=0&pdftemplate=PhenoTips.PatientSheetCode\" % locals()\n    project = Project.objects.get(guid = project_guid)\n    permissions_level = 'view'\n    auth_tuple = _check_user_permissions(request.user, project, permissions_level)\n    return _send_request_to_phenotips('GET', url, auth_tuple = auth_tuple)\n", "code_toks_joined": "def phenotips_view_patient_pdf ( request , project_guid , patient_id ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> url = <STRING> % locals ( ) <NEWLINE> project = Project . objects . get ( guid = project_guid ) <NEWLINE> permissions_level = <STRING> <NEWLINE> auth_tuple = _check_user_permissions ( request . user , project , permissions_level ) <NEWLINE> return _send_request_to_phenotips ( <STRING> , url , auth_tuple = auth_tuple ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Requests the PhenoTips PDF for the given patient_id, and forwards PhenoTips' response to the client.\"\"\"", "\"/bin/export/data/%(patient_id)s?format=pdf&pdfcover=0&pdftoc=0&pdftemplate=PhenoTips.PatientSheetCode\"", "'view'", "'GET'"]}}], ["acbb597cdc621a5971381896d1dae998", {"code_string": "def test_fstab_baduuid(self):\n    self.addFstabEntry('UUID=1111111-1111-1111-1111-111111111111 /test ext4 defaults 0 0')\n    pdb.set_trace()\n    self.assertNotEqual(self._watcher.handle_fstab(ignoretime = True), 0)\n", "code_toks_joined": "def test_fstab_baduuid ( self ) : <NEWLINE> <INDENT> self . addFstabEntry ( <STRING> ) <NEWLINE> pdb . set_trace ( ) <NEWLINE> self . assertNotEqual ( self . _watcher . handle_fstab ( ignoretime = True ) , 0 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'UUID=1111111-1111-1111-1111-111111111111 /test ext4 defaults 0 0'"]}}], ["da3648b254ef8db19ac64bbd5a7d645a", {"code_string": "class FetchableEntityApiMixin(object):\n    def _fetch(self, id, entity_model = None):\n        response = self.get(endpoint = '/{id}'.format(id = id))\n        if response.status_code == 200:\n            return self.deserialize(response, model = entity_model)\n        self.handle(response)\n", "code_toks_joined": "class FetchableEntityApiMixin ( object ) : <NEWLINE> <INDENT> def _fetch ( self , id , entity_model = None ) : <NEWLINE> <INDENT> response = self . get ( endpoint = <STRING> . format ( id = id ) ) <NEWLINE> if response . status_code == 200 : <NEWLINE> <INDENT> return self . deserialize ( response , model = entity_model ) <NEWLINE> <DEDENT> self . handle ( response ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/{id}'"]}}], ["b3af58c672d901751514a2a2a7a068aa", {"code_string": "class NoneAttrs(object):\n    def __getattr__(self, attr):\n        return None\n", "code_toks_joined": "class NoneAttrs ( object ) : <NEWLINE> <INDENT> def __getattr__ ( self , attr ) : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["1e04c0f76b77f9bb40f64bf34513cc9a", {"code_string": "def get_root_tree_identity(self):\n    \"\"\"Returns a complete tuple that'll be flattened to the path that\"\"\"\n    return(self.__class__.tree_class,\n        self.__workflow.workflow_name,\n        self.__from_invocation.invocation_id,\n        self.__relationship_type)\n", "code_toks_joined": "def get_root_tree_identity ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return ( self . __class__ . tree_class , <NEWLINE> <INDENT> self . __workflow . workflow_name , <NEWLINE> self . __from_invocation . invocation_id , <NEWLINE> self . __relationship_type ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Returns a complete tuple that'll be flattened to the path that\"\"\""]}}], ["bc5cadd815dbc5bf1fb97aac2495477a", {"code_string": "def test_preprint_private_invisible_no_auth(self):\n    res = self.app.get(self.url)\n    assert len(res.json['data']) == 1\n    self.project.is_public = False\n    self.project.save()\n    res = self.app.get(self.url, expect_errors = True)\n    assert_equal(res.status_code, 401)\n", "code_toks_joined": "def test_preprint_private_invisible_no_auth ( self ) : <NEWLINE> <INDENT> res = self . app . get ( self . url ) <NEWLINE> assert len ( res . json [ <STRING> ] ) == 1 <NEWLINE> self . project . is_public = False <NEWLINE> self . project . save ( ) <NEWLINE> res = self . app . get ( self . url , expect_errors = True ) <NEWLINE> assert_equal ( res . status_code , 401 ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'data'"]}}], ["ad3948a690bf4f2cd035bff18de2608c", {"code_string": "'''| Filename    : class_array_init.py'''\nimport gzip\nimport os\nfrom theano import config\nimport numpy as np\n", "code_toks_joined": "<STRING> <NEWLINE> import gzip <NEWLINE> import os <NEWLINE> from theano import config <NEWLINE> import numpy as np <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''| Filename    : class_array_init.py'''"]}}], ["dac96bae48c3026223c03fb091a7b8a9", {"code_string": "def test_L3_Reaction_id(self):\n    id = \"mitochondria\";\n    self.assertEqual(False, self.R.isSetId())\n    self.R.setId(id)\n    self.assert_((id == self.R.getId()))\n    self.assertEqual(True, self.R.isSetId())\n    if(self.R.getId() == id):\n        pass\n    pass\n", "code_toks_joined": "def test_L3_Reaction_id ( self ) : <NEWLINE> <INDENT> id = <STRING> ; <NEWLINE> self . assertEqual ( False , self . R . isSetId ( ) ) <NEWLINE> self . R . setId ( id ) <NEWLINE> self . assert_ ( ( id == self . R . getId ( ) ) ) <NEWLINE> self . assertEqual ( True , self . R . isSetId ( ) ) <NEWLINE> if ( self . R . getId ( ) == id ) : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"mitochondria\""]}}], ["3cefb04efef3c1529c23cbffc9fc1983", {"code_string": "class Role(serializers.ModelSerializer):\n    class Meta:\n        model = RoleModel\n        fields = (\n            'slug',\n            'title',\n            'title_plural',\n            'past_tense',\n        )\n        extra_kwargs = {\n            'title': {\n                'required': False,\n            },\n            'past_tense': {\n                'required': False,\n            },\n        }\n", "code_toks_joined": "class Role ( serializers . ModelSerializer ) : <NEWLINE> <INDENT> class Meta : <NEWLINE> <INDENT> model = RoleModel <NEWLINE> fields = ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <DEDENT> ) <NEWLINE> extra_kwargs = { <NEWLINE> <INDENT> <STRING> : { <NEWLINE> <INDENT> <STRING> : False , <NEWLINE> <DEDENT> } , <NEWLINE> <STRING> : { <NEWLINE> <INDENT> <STRING> : False , <NEWLINE> <DEDENT> } , <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'slug'", "'title'", "'title_plural'", "'past_tense'", "'title'", "'required'", "'past_tense'", "'required'"]}}], ["3b3d0568a9d9b31c70f968921742031e", {"code_string": "def test_one_listener(self):\n    cb = MagicMock()\n    self.l.add_listener(cb)\n    changes = dict(foo = 32)\n    self.l.notify_listeners(changes)\n    cb.assert_called_once_with(self.l, changes)\n    cb.reset_mock()\n    self.l.remove_listener(cb)\n    self.l.notify_listeners(dict(bo = 3))\n    self.assertEqual(cb.call_count, 0)\n", "code_toks_joined": "def test_one_listener ( self ) : <NEWLINE> <INDENT> cb = MagicMock ( ) <NEWLINE> self . l . add_listener ( cb ) <NEWLINE> changes = dict ( foo = 32 ) <NEWLINE> self . l . notify_listeners ( changes ) <NEWLINE> cb . assert_called_once_with ( self . l , changes ) <NEWLINE> cb . reset_mock ( ) <NEWLINE> self . l . remove_listener ( cb ) <NEWLINE> self . l . notify_listeners ( dict ( bo = 3 ) ) <NEWLINE> self . assertEqual ( cb . call_count , 0 ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["f3952537cb1bdeda03ba8a60a61f4936", {"code_string": "class WorkerPoolPaged(Paged):\n    \"\"\"A paging container for iterating over a list of WorkerPool object\"\"\"\n    _attribute_map = {\n        'next_link': {'key': 'nextLink', 'type': 'str'},\n        'current_page': {'key': 'value', 'type': '[WorkerPool]'}\n    }\n    def __init__(self, * args, ** kwargs):\n        super(WorkerPoolPaged, self).__init__(* args, ** kwargs)\n", "code_toks_joined": "class WorkerPoolPaged ( Paged ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> _attribute_map = { <NEWLINE> <INDENT> <STRING> : { <STRING> : <STRING> , <STRING> : <STRING> } , <NEWLINE> <STRING> : { <STRING> : <STRING> , <STRING> : <STRING> } <NEWLINE> <DEDENT> } <NEWLINE> def __init__ ( self , * args , ** kwargs ) : <NEWLINE> <INDENT> super ( WorkerPoolPaged , self ) . __init__ ( * args , ** kwargs ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"A paging container for iterating over a list of WorkerPool object\"\"\"", "'next_link'", "'key'", "'nextLink'", "'type'", "'str'", "'current_page'", "'key'", "'value'", "'type'", "'[WorkerPool]'"]}}], ["37ed06f9f7dc14a20929cbcbf411ce9b", {"code_string": "from ... template.session.participatingSessionsContentGridsData import ParticipatingSessionsContentGridsData\nfrom ... utility import generateRandomString, generateGridTable\nfrom ... template.gridTableData import GridTableData\nfrom ... models import ResponseGrid\n", "code_toks_joined": "from ... template . session . participatingSessionsContentGridsData import ParticipatingSessionsContentGridsData <NEWLINE> from ... utility import generateRandomString , generateGridTable <NEWLINE> from ... template . gridTableData import GridTableData <NEWLINE> from ... models import ResponseGrid <NEWLINE>", "anonymize_dict": {}}], ["05e82ee4b2c38c5ace066ac9b1ba4981", {"code_string": "def FFT_inverse(N, data):\n    n = N / 2\n    norm = 0.0\n    FFT_transform_internal(N, data, + 1)\n    norm = 1 / float(n)\n    for i in xrange(N):\n        data[i] *= norm\n", "code_toks_joined": "def FFT_inverse ( N , data ) : <NEWLINE> <INDENT> n = N / 2 <NEWLINE> norm = 0.0 <NEWLINE> FFT_transform_internal ( N , data , + 1 ) <NEWLINE> norm = 1 / float ( n ) <NEWLINE> for i in xrange ( N ) : <NEWLINE> <INDENT> data [ i ] *= norm <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["f405292b27feda69c202d640539b2ded", {"code_string": "def update(self):\n    \"\"\"Get the latest data and update the states.\"\"\"\n    try:\n        self._state = template.render(self.hass, self._template)\n    except TemplateError as ex:\n        if ex.args and ex.args[0].startswith(\n            \"UndefinedError: 'None' has no attribute\"):\n            _LOGGER.warning(ex)\n            return\n        self._state = None\n        _LOGGER.error(ex)\n", "code_toks_joined": "def update ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> try : <NEWLINE> <INDENT> self . _state = template . render ( self . hass , self . _template ) <NEWLINE> <DEDENT> except TemplateError as ex : <NEWLINE> <INDENT> if ex . args and ex . args [ 0 ] . startswith ( <NEWLINE> <INDENT> <STRING> ) : <NEWLINE> _LOGGER . warning ( ex ) <NEWLINE> return <NEWLINE> <DEDENT> self . _state = None <NEWLINE> _LOGGER . error ( ex ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Get the latest data and update the states.\"\"\"", "\"UndefinedError: 'None' has no attribute\""]}}], ["4245b9fd4cd179d286ca0892102700c3", {"code_string": "import os\nimport argparse\nimport yaml\nimport six\n", "code_toks_joined": "import os <NEWLINE> import argparse <NEWLINE> import yaml <NEWLINE> import six <NEWLINE>", "anonymize_dict": {}}], ["374d19fb48ff78d853587b526e08b7ac", {"code_string": "from django.db import models\nfrom django.contrib.contenttypes.fields import GenericForeignKey\nfrom django.contrib.contenttypes.models import ContentType\n", "code_toks_joined": "from django . db import models <NEWLINE> from django . contrib . contenttypes . fields import GenericForeignKey <NEWLINE> from django . contrib . contenttypes . models import ContentType <NEWLINE>", "anonymize_dict": {}}], ["68314d875730e3d73538deb7e62d6793", {"code_string": "\"\"\"Date :\"\"\"\nfrom string import uppercase\ndatas = ''\nwhile True:\n    try:\n        datas += raw_input()\n    except EOFError:\n        break\nscore = lambda name, pos: sum(uppercase.index(c) + 1 for c in name) * pos\ndatas = [name.strip()[1: - 1] for name in datas.split(',')]\ndatas.sort()\nprint(sum(score(name, pos + 1) for pos, name in enumerate(datas)))\n", "code_toks_joined": "<STRING> <NEWLINE> from string import uppercase <NEWLINE> datas = <STRING> <NEWLINE> while True : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> datas += raw_input ( ) <NEWLINE> <DEDENT> except EOFError : <NEWLINE> <INDENT> break <NEWLINE> <DEDENT> <DEDENT> score = lambda name , pos : sum ( uppercase . index ( c ) + 1 for c in name ) * pos <NEWLINE> datas = [ name . strip ( ) [ 1 : - 1 ] for name in datas . split ( <STRING> ) ] <NEWLINE> datas . sort ( ) <NEWLINE> print ( sum ( score ( name , pos + 1 ) for pos , name in enumerate ( datas ) ) ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Date :\"\"\"", "''", "','"]}}], ["1e1d31dc3b9690afcc390fe087b4087a", {"code_string": "from tde.util.splits import check_intervals, truncate_intervals\nfrom tde.data.corpus import Corpus\nfrom tde.data.interval import Interval, IntervalDB\nfrom tde.data.classes import ClassDict, ClassID\nfrom tde.data.fragment import FragmentToken\nfrom tde.data.segment_annotation import SegmentAnnotation\n", "code_toks_joined": "from tde . util . splits import check_intervals , truncate_intervals <NEWLINE> from tde . data . corpus import Corpus <NEWLINE> from tde . data . interval import Interval , IntervalDB <NEWLINE> from tde . data . classes import ClassDict , ClassID <NEWLINE> from tde . data . fragment import FragmentToken <NEWLINE> from tde . data . segment_annotation import SegmentAnnotation <NEWLINE>", "anonymize_dict": {}}], ["96d68734abe6955680c6878772dfc284", {"code_string": "def create_dataframe_from_files(self, locations, df_format = \"json\", csv_dates = None, index_col = None):\n    local_file = self.work_folder + \"/data\"\n    self._copy_features_locally(locations, local_file, df_format)\n    return self._convert_dataframe(local_file, df_format, csv_dates, index_col)\n", "code_toks_joined": "def create_dataframe_from_files ( self , locations , df_format = <STRING> , csv_dates = None , index_col = None ) : <NEWLINE> <INDENT> local_file = self . work_folder + <STRING> <NEWLINE> self . _copy_features_locally ( locations , local_file , df_format ) <NEWLINE> return self . _convert_dataframe ( local_file , df_format , csv_dates , index_col ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"json\"", "\"/data\""]}}], ["7a510a712da40c6301a45d559377a2a0", {"code_string": "def figures(request):\n    context = RequestContext(request)\n    figure_list = Figure.objects.order_by('title')[: 5]\n    context_dict = {'figures': figure_list}\n    return render_to_response('gigafig/figures.html', context_dict, context)\n", "code_toks_joined": "def figures ( request ) : <NEWLINE> <INDENT> context = RequestContext ( request ) <NEWLINE> figure_list = Figure . objects . order_by ( <STRING> ) [ : 5 ] <NEWLINE> context_dict = { <STRING> : figure_list } <NEWLINE> return render_to_response ( <STRING> , context_dict , context ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'title'", "'figures'", "'gigafig/figures.html'"]}}], ["414b09db73c4927fa1686624711dfd1c", {"code_string": "from resort import Resort\nfrom conditions import Conditions\nfrom ski_pass import SkiPass\n", "code_toks_joined": "from resort import Resort <NEWLINE> from conditions import Conditions <NEWLINE> from ski_pass import SkiPass <NEWLINE>", "anonymize_dict": {}}], ["0045e0970c61d69a31bf59dc6636d60b", {"code_string": "class SmartsnippetAppConfig(django.apps.AppConfig):\n    name = 'smartsnippets'\n    verbose_name = 'Custom Component'\n    verbose_plural_name = 'Custom Components'\n", "code_toks_joined": "class SmartsnippetAppConfig ( django . apps . AppConfig ) : <NEWLINE> <INDENT> name = <STRING> <NEWLINE> verbose_name = <STRING> <NEWLINE> verbose_plural_name = <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'smartsnippets'", "'Custom Component'", "'Custom Components'"]}}], ["5519a608385302d21f4e7bec2a5529d8", {"code_string": "class PostcodeForm(forms.Form):\n    postcode = GBPostcodeField(\n        widget = forms.TextInput(\n            attrs = {\"class\": \"form-control form-control-1-4\"}\n        )\n    )\n", "code_toks_joined": "class PostcodeForm ( forms . Form ) : <NEWLINE> <INDENT> postcode = GBPostcodeField ( <NEWLINE> <INDENT> widget = forms . TextInput ( <NEWLINE> <INDENT> attrs = { <STRING> : <STRING> } <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"class\"", "\"form-control form-control-1-4\""]}}], ["3bb31d134b921df4c65d36e90f152487", {"code_string": "def clear_done_flag(self):\n    for stukje in self.puzzelstukjes:\n        self.puzzelstukjes[stukje].done = False\n", "code_toks_joined": "def clear_done_flag ( self ) : <NEWLINE> <INDENT> for stukje in self . puzzelstukjes : <NEWLINE> <INDENT> self . puzzelstukjes [ stukje ] . done = False <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["20b7b2ba9900ddf58dba94812a9fb744", {"code_string": "def tracking_collection(self):\n    \"\"\"Return current tracking collection, or None if it does not exist.\"\"\"\n    return self._track\n", "code_toks_joined": "def tracking_collection ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return self . _track <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Return current tracking collection, or None if it does not exist.\"\"\""]}}], ["787b84bc4037849fcaa66dc1dc9ddbb4", {"code_string": "def is_prime(p):\n    if p <= SMALL_PRIMES[- 1]:\n        return p in SMALL_PRIMES\n    if not all(p % q for q in SMALL_PRIMES):\n        return False\n    if p < 1373653:\n        return miller_rabin(p, 2) and miller_rabin(p, 3)\n    elif p < 9080191:\n        return miller_rabin(p, 31) and miller_rabin(p, 73)\n    else:\n        return miller_rabin(p, 2) and miller_rabin(p, 7) and miller_rabin(p, 61)\n", "code_toks_joined": "def is_prime ( p ) : <NEWLINE> <INDENT> if p <= SMALL_PRIMES [ - 1 ] : <NEWLINE> <INDENT> return p in SMALL_PRIMES <NEWLINE> <DEDENT> if not all ( p % q for q in SMALL_PRIMES ) : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> if p < 1373653 : <NEWLINE> <INDENT> return miller_rabin ( p , 2 ) and miller_rabin ( p , 3 ) <NEWLINE> <DEDENT> elif p < 9080191 : <NEWLINE> <INDENT> return miller_rabin ( p , 31 ) and miller_rabin ( p , 73 ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return miller_rabin ( p , 2 ) and miller_rabin ( p , 7 ) and miller_rabin ( p , 61 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["243deb269524254ed71b5cf60b3ca406", {"code_string": "class IOWarning(UserWarning):\n    \"\"\"Warn about devices of input and/or output, including files and directories.\"\"\"\n    pass\n", "code_toks_joined": "class IOWarning ( UserWarning ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> pass <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Warn about devices of input and/or output, including files and directories.\"\"\""]}}], ["502acea699b26b9730b0b482d90325ad", {"code_string": "class SaleOrder(models.Model):\n    _inherit = 'sale.order'\n    def _prepare_order_line_procurement(self, cr, uid, order, line, group_id = False, context = None):\n        vals = super(SaleOrder, self)._prepare_order_line_procurement(cr, uid, order, line, group_id, context)\n        if line and line.address_allotment_id:\n            vals['partner_dest_id'] = line.address_allotment_id.id\n        return vals\n", "code_toks_joined": "class SaleOrder ( models . Model ) : <NEWLINE> <INDENT> _inherit = <STRING> <NEWLINE> def _prepare_order_line_procurement ( self , cr , uid , order , line , group_id = False , context = None ) : <NEWLINE> <INDENT> vals = super ( SaleOrder , self ) . _prepare_order_line_procurement ( cr , uid , order , line , group_id , context ) <NEWLINE> if line and line . address_allotment_id : <NEWLINE> <INDENT> vals [ <STRING> ] = line . address_allotment_id . id <NEWLINE> <DEDENT> return vals <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'sale.order'", "'partner_dest_id'"]}}], ["2531d37367865437ae12d0e8e9ce41f7", {"code_string": "def __eq__(self, other):\n    \"\"\" Equality using the == operator.\"\"\"\n    return comparison.float_equal(self.x, other.x) and comparison.float_equal(self.y, other.y)\n", "code_toks_joined": "def __eq__ ( self , other ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> return comparison . float_equal ( self . x , other . x ) and comparison . float_equal ( self . y , other . y ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\" Equality using the == operator.\"\"\""]}}], ["4587f673d638a990acc56cfd3c9f20b7", {"code_string": "from collections import OrderedDict\nfrom django.contrib import admin\nfrom edc_export.actions import export_as_csv_action\nfrom edc_consent.actions import flag_as_verified_against_paper, unflag_as_verified_against_paper\nfrom edc_registration.models import RegisteredSubject\nfrom tshilo_dikotla.base_model_admin import MembershipBaseModelAdmin\nfrom..forms import SpecimenConsentForm\nfrom..models import SpecimenConsent\n", "code_toks_joined": "from collections import OrderedDict <NEWLINE> from django . contrib import admin <NEWLINE> from edc_export . actions import export_as_csv_action <NEWLINE> from edc_consent . actions import flag_as_verified_against_paper , unflag_as_verified_against_paper <NEWLINE> from edc_registration . models import RegisteredSubject <NEWLINE> from tshilo_dikotla . base_model_admin import MembershipBaseModelAdmin <NEWLINE> from . . forms import SpecimenConsentForm <NEWLINE> from . . models import SpecimenConsent <NEWLINE>", "anonymize_dict": {}}], ["497e5bf2252eeb750081a8075907309c", {"code_string": "def test_getFitsWithShip_RifterFit(DB, RifterFit):\n    DB['db'].save(RifterFit)\n    assert Fit.getFitsWithShip(587)[0][1] == 'My Rifter Fit'\n    DB['db'].remove(RifterFit)\n", "code_toks_joined": "def test_getFitsWithShip_RifterFit ( DB , RifterFit ) : <NEWLINE> <INDENT> DB [ <STRING> ] . save ( RifterFit ) <NEWLINE> assert Fit . getFitsWithShip ( 587 ) [ 0 ] [ 1 ] == <STRING> <NEWLINE> DB [ <STRING> ] . remove ( RifterFit ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'db'", "'My Rifter Fit'", "'db'"]}}], ["1dcf17130b79d57398ac6a82672f2b1e", {"code_string": "from __future__ import unicode_literals\nfrom thetvdb.exceptions import tvdb_attributenotfound, tvdb_episodenotfound, tvdb_error, tvdb_exception, tvdb_seasonnotfound, tvdb_showincomplete, tvdb_shownotfound, tvdb_userabort\n__author__ = \"echel0n\"\n__version__ = \"1.0\"\nindexerExcepts = [\"indexer_exception\", \"indexer_error\", \"indexer_userabort\", \"indexer_shownotfound\",\n    \"indexer_showincomplete\",\n    \"indexer_seasonnotfound\", \"indexer_episodenotfound\", \"indexer_attributenotfound\"]\ntvdbExcepts = [\"tvdb_exception\", \"tvdb_error\", \"tvdb_userabort\", \"tvdb_shownotfound\", \"tvdb_showincomplete\",\n    \"tvdb_seasonnotfound\", \"tvdb_episodenotfound\", \"tvdb_attributenotfound\"]\nindexer_exception = tvdb_exception\nindexer_error = tvdb_error\nindexer_userabort = tvdb_userabort\nindexer_attributenotfound = tvdb_attributenotfound\nindexer_episodenotfound = tvdb_episodenotfound\nindexer_seasonnotfound = tvdb_seasonnotfound\nindexer_shownotfound = tvdb_shownotfound\nindexer_showincomplete = tvdb_showincomplete\n", "code_toks_joined": "from __future__ import unicode_literals <NEWLINE> from thetvdb . exceptions import tvdb_attributenotfound , tvdb_episodenotfound , tvdb_error , tvdb_exception , tvdb_seasonnotfound , tvdb_showincomplete , tvdb_shownotfound , tvdb_userabort <NEWLINE> __author__ = <STRING> <NEWLINE> __version__ = <STRING> <NEWLINE> indexerExcepts = [ <STRING> , <STRING> , <STRING> , <STRING> , <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <STRING> , <STRING> ] <NEWLINE> <DEDENT> tvdbExcepts = [ <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <NEWLINE> <INDENT> <STRING> , <STRING> , <STRING> ] <NEWLINE> <DEDENT> indexer_exception = tvdb_exception <NEWLINE> indexer_error = tvdb_error <NEWLINE> indexer_userabort = tvdb_userabort <NEWLINE> indexer_attributenotfound = tvdb_attributenotfound <NEWLINE> indexer_episodenotfound = tvdb_episodenotfound <NEWLINE> indexer_seasonnotfound = tvdb_seasonnotfound <NEWLINE> indexer_shownotfound = tvdb_shownotfound <NEWLINE> indexer_showincomplete = tvdb_showincomplete <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"echel0n\"", "\"1.0\"", "\"indexer_exception\"", "\"indexer_error\"", "\"indexer_userabort\"", "\"indexer_shownotfound\"", "\"indexer_showincomplete\"", "\"indexer_seasonnotfound\"", "\"indexer_episodenotfound\"", "\"indexer_attributenotfound\"", "\"tvdb_exception\"", "\"tvdb_error\"", "\"tvdb_userabort\"", "\"tvdb_shownotfound\"", "\"tvdb_showincomplete\"", "\"tvdb_seasonnotfound\"", "\"tvdb_episodenotfound\"", "\"tvdb_attributenotfound\""]}}], ["ba86dcff71e4699ad9c28aeefde66988", {"code_string": "\"\"\"Custom Weblate signals\"\"\"\nfrom django.dispatch import Signal\nvcs_post_push = Signal(providing_args = ['subproject'])\nvcs_post_update = Signal(providing_args = ['subproject', 'previous_head'])\nvcs_pre_commit = Signal(providing_args = ['translation'])\nvcs_post_commit = Signal(providing_args = ['translation'])\ntranslation_post_add = Signal(providing_args = ['translation'])\nuser_pre_delete = Signal()\n", "code_toks_joined": "<STRING> <NEWLINE> from django . dispatch import Signal <NEWLINE> vcs_post_push = Signal ( providing_args = [ <STRING> ] ) <NEWLINE> vcs_post_update = Signal ( providing_args = [ <STRING> , <STRING> ] ) <NEWLINE> vcs_pre_commit = Signal ( providing_args = [ <STRING> ] ) <NEWLINE> vcs_post_commit = Signal ( providing_args = [ <STRING> ] ) <NEWLINE> translation_post_add = Signal ( providing_args = [ <STRING> ] ) <NEWLINE> user_pre_delete = Signal ( ) <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Custom Weblate signals\"\"\"", "'subproject'", "'subproject'", "'previous_head'", "'translation'", "'translation'", "'translation'"]}}], ["9310cdc859f9c1830de03ef45b7f422e", {"code_string": "from gi.repository import Gtk\nfrom gi.repository.GdkPixbuf import Pixbuf\nfrom gi.repository import Gio\nimport urllib2\n", "code_toks_joined": "from gi . repository import Gtk <NEWLINE> from gi . repository . GdkPixbuf import Pixbuf <NEWLINE> from gi . repository import Gio <NEWLINE> import urllib2 <NEWLINE>", "anonymize_dict": {}}], ["f77fa80e1b2a69fae0e3fbab42d83396", {"code_string": "from django.conf.urls import url\nfrom django.contrib.auth.views import login, logout\nfrom charcoallog.accounts.views import register\nurlpatterns = [\n    url(r'^entrar/', login,\n        {'template_name': 'accounts/login.html'}, name = 'login'),\n    url(r'^sair/', logout,\n        {'next_page': 'core:home'}, name = 'logout'),\n    url(r'^cadastre-se/', register, name = 'register'),\n]\n", "code_toks_joined": "from django . conf . urls import url <NEWLINE> from django . contrib . auth . views import login , logout <NEWLINE> from charcoallog . accounts . views import register <NEWLINE> urlpatterns = [ <NEWLINE> <INDENT> url ( <STRING> , login , <NEWLINE> <INDENT> { <STRING> : <STRING> } , name = <STRING> ) , <NEWLINE> <DEDENT> url ( <STRING> , logout , <NEWLINE> <INDENT> { <STRING> : <STRING> } , name = <STRING> ) , <NEWLINE> <DEDENT> url ( <STRING> , register , name = <STRING> ) , <NEWLINE> <DEDENT> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["r'^entrar/'", "'template_name'", "'accounts/login.html'", "'login'", "r'^sair/'", "'next_page'", "'core:home'", "'logout'", "r'^cadastre-se/'", "'register'"]}}], ["4159cbb3c2d1eeb2eacc678b8d603728", {"code_string": "def cull(self):\n    for k, v in self.iteritems_older_than(self.ttl):\n        self.data.popitem(last = False)\n", "code_toks_joined": "def cull ( self ) : <NEWLINE> <INDENT> for k , v in self . iteritems_older_than ( self . ttl ) : <NEWLINE> <INDENT> self . data . popitem ( last = False ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["581bd3b45082034dace7eb48b770f7df", {"code_string": "\"\"\"This file is part of Urban Mediator software.\"\"\"\nimport config\nimport code\nimport mobile, widget, feed, util\nimport webinstall\n", "code_toks_joined": "<STRING> <NEWLINE> import config <NEWLINE> import code <NEWLINE> import mobile , widget , feed , util <NEWLINE> import webinstall <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"This file is part of Urban Mediator software.\"\"\""]}}], ["74d26d8a23884f8a873eaf017ed58f01", {"code_string": "def saw_test(self):\n    \"\"\"Record when a test line was seen.\"\"\"\n    self._lines_seen['test'] += 1\n", "code_toks_joined": "def saw_test ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . _lines_seen [ <STRING> ] += 1 <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Record when a test line was seen.\"\"\"", "'test'"]}}], ["fa3c343a613b997098eeb4a003acc39f", {"code_string": "def test_returns_a_403_error_if_no_journal_can_be_associated_with_the_current_user(self):\n    class MyView(JournalScopeMixin, TemplateView):\n        template_name = 'dummy.html'\n    user = UserFactory.create()\n    journal = JournalFactory.create(collection = self.collection)\n    url = reverse(\n        'userspace:journal:information:update', kwargs = {'journal_pk': journal.pk})\n    request = self.get_request(url)\n    request.user = user\n    my_view = MyView.as_view()\n    with self.assertRaises(PermissionDenied):\n        my_view(request, journal_pk = self.journal.pk)\n", "code_toks_joined": "def test_returns_a_403_error_if_no_journal_can_be_associated_with_the_current_user ( self ) : <NEWLINE> <INDENT> class MyView ( JournalScopeMixin , TemplateView ) : <NEWLINE> <INDENT> template_name = <STRING> <NEWLINE> <DEDENT> user = UserFactory . create ( ) <NEWLINE> journal = JournalFactory . create ( collection = self . collection ) <NEWLINE> url = reverse ( <NEWLINE> <INDENT> <STRING> , kwargs = { <STRING> : journal . pk } ) <NEWLINE> <DEDENT> request = self . get_request ( url ) <NEWLINE> request . user = user <NEWLINE> my_view = MyView . as_view ( ) <NEWLINE> with self . assertRaises ( PermissionDenied ) : <NEWLINE> <INDENT> my_view ( request , journal_pk = self . journal . pk ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'dummy.html'", "'userspace:journal:information:update'", "'journal_pk'"]}}], ["e4cdcfd89d22e492be388029d99b7643", {"code_string": "class CompassSensor(sensor.DigitalSensor):\n    __metaclass__ = _MetaCMPS_Nx\n    def __init__(self, brick, port):\n        super(CompassSensor, self).__init__(brick, port)\n        self.sensor_type = Type.LOW_SPEED_9V\n        self.mode = Mode.RAW\n        self.set_input_mode()\n        sleep(0.1)\n", "code_toks_joined": "class CompassSensor ( sensor . DigitalSensor ) : <NEWLINE> <INDENT> __metaclass__ = _MetaCMPS_Nx <NEWLINE> def __init__ ( self , brick , port ) : <NEWLINE> <INDENT> super ( CompassSensor , self ) . __init__ ( brick , port ) <NEWLINE> self . sensor_type = Type . LOW_SPEED_9V <NEWLINE> self . mode = Mode . RAW <NEWLINE> self . set_input_mode ( ) <NEWLINE> sleep ( 0.1 ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["57f0727553cfc1bff7ee93c7cd293f48", {"code_string": "class SkipHours:\n    \"\"\"Publish the skipHours\"\"\"\n    element_attrs = {}\n    def __init__(self, hours):\n        self.hours = hours\n    def publish(self, handler):\n        if self.hours:\n            handler.startElement(\"skipHours\", self.element_attrs)\n            for hour in self.hours:\n                _element(handler, \"hour\", str(hour))\n            handler.endElement(\"skipHours\")\n", "code_toks_joined": "class SkipHours : <NEWLINE> <INDENT> <STRING> <NEWLINE> element_attrs = { } <NEWLINE> def __init__ ( self , hours ) : <NEWLINE> <INDENT> self . hours = hours <NEWLINE> <DEDENT> def publish ( self , handler ) : <NEWLINE> <INDENT> if self . hours : <NEWLINE> <INDENT> handler . startElement ( <STRING> , self . element_attrs ) <NEWLINE> for hour in self . hours : <NEWLINE> <INDENT> _element ( handler , <STRING> , str ( hour ) ) <NEWLINE> <DEDENT> handler . endElement ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Publish the skipHours\"\"\"", "\"skipHours\"", "\"hour\"", "\"skipHours\""]}}], ["9fe258b1ad152e67c6a2bf4f15b443f5", {"code_string": "def skew(v):\n    return sympy.Matrix([[0, - v[2], v[1]],\n        [v[2], 0, - v[0]],\n        [- v[1], v[0], 0]])\n", "code_toks_joined": "def skew ( v ) : <NEWLINE> <INDENT> return sympy . Matrix ( [ [ 0 , - v [ 2 ] , v [ 1 ] ] , <NEWLINE> <INDENT> [ v [ 2 ] , 0 , - v [ 0 ] ] , <NEWLINE> [ - v [ 1 ] , v [ 0 ] , 0 ] ] ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["d03fa96e92fee3f3b2bd9a0704b8023b", {"code_string": "def get_object(self):\n    if not hasattr(self, \"_object\"):\n        ipam_id = filters.get_int_or_uuid(self.kwargs['ipam_id'])\n        try:\n            self._object = ipam_show(self.request, ipam_id)\n        except Exception:\n            msg = _('Unable to retrieve network ipam.')\n            url = reverse('horizon:project:networking:index')\n            exceptions.handle(self.request, msg, redirect = url)\n    return self._object\n", "code_toks_joined": "def get_object ( self ) : <NEWLINE> <INDENT> if not hasattr ( self , <STRING> ) : <NEWLINE> <INDENT> ipam_id = filters . get_int_or_uuid ( self . kwargs [ <STRING> ] ) <NEWLINE> try : <NEWLINE> <INDENT> self . _object = ipam_show ( self . request , ipam_id ) <NEWLINE> <DEDENT> except Exception : <NEWLINE> <INDENT> msg = _ ( <STRING> ) <NEWLINE> url = reverse ( <STRING> ) <NEWLINE> exceptions . handle ( self . request , msg , redirect = url ) <NEWLINE> <DEDENT> <DEDENT> return self . _object <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"_object\"", "'ipam_id'", "'Unable to retrieve network ipam.'", "'horizon:project:networking:index'"]}}], ["02023c6e8c786040f9b953a9c800b893", {"code_string": "class FavCreateSerializer(serializers.ModelSerializer):\n    user = serializers.ReadOnlyField(source = 'user.email')\n    foodtruck = serializers.PrimaryKeyRelatedField(\n        queryset = Foodtruck.objects.all(),\n        )\n    class Meta:\n        model = Fav\n        fields = ('id', 'user', 'foodtruck')\n", "code_toks_joined": "class FavCreateSerializer ( serializers . ModelSerializer ) : <NEWLINE> <INDENT> user = serializers . ReadOnlyField ( source = <STRING> ) <NEWLINE> foodtruck = serializers . PrimaryKeyRelatedField ( <NEWLINE> <INDENT> queryset = Foodtruck . objects . all ( ) , <NEWLINE> ) <NEWLINE> <DEDENT> class Meta : <NEWLINE> <INDENT> model = Fav <NEWLINE> fields = ( <STRING> , <STRING> , <STRING> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'user.email'", "'id'", "'user'", "'foodtruck'"]}}], ["ea5f11ee8250d6b474a5a60bd88a3c36", {"code_string": "def validateRegexp(regexp):\n    import re\n    def inner(user):\n        if not re.match(regexp, user):\n            raise argparse.ArgumentTypeError(\"Invalid format\")\n        return user\n    return inner\n", "code_toks_joined": "def validateRegexp ( regexp ) : <NEWLINE> <INDENT> import re <NEWLINE> def inner ( user ) : <NEWLINE> <INDENT> if not re . match ( regexp , user ) : <NEWLINE> <INDENT> raise argparse . ArgumentTypeError ( <STRING> ) <NEWLINE> <DEDENT> return user <NEWLINE> <DEDENT> return inner <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"Invalid format\""]}}], ["7c6bfa4664677161372ba9dfdaaa538e", {"code_string": "def error(* strings):\n    \"\"\"Print errors to stderr and update the error count.\"\"\"\n    global errors\n    errors += 1\n    message = \" \".join(str(x) for x in strings)\n    logging.error(message)\n    return message\n", "code_toks_joined": "def error ( * strings ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> global errors <NEWLINE> errors += 1 <NEWLINE> message = <STRING> . join ( str ( x ) for x in strings ) <NEWLINE> logging . error ( message ) <NEWLINE> return message <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Print errors to stderr and update the error count.\"\"\"", "\" \""]}}], ["5d1d2b2d498d5357db25d37ba72d5c38", {"code_string": "class QuestionApp(CMSApp):\n    name = _('Question App')\n    urls = ['question.urls']\n", "code_toks_joined": "class QuestionApp ( CMSApp ) : <NEWLINE> <INDENT> name = _ ( <STRING> ) <NEWLINE> urls = [ <STRING> ] <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Question App'", "'question.urls'"]}}], ["9bf036698155ce1b3ea596ef51433c6a", {"code_string": "from __future__ import print_function\nfrom openturns import *\nfrom math import *\nTESTPREAMBLE()\ntry:\n    b = Basis()\n    print(\"basis =\", b)\nexcept:\n    import sys\n    print(\"t_Basis_std.py\", sys.exc_info()[0], sys.exc_info()[1])\n", "code_toks_joined": "from __future__ import print_function <NEWLINE> from openturns import * <NEWLINE> from math import * <NEWLINE> TESTPREAMBLE ( ) <NEWLINE> try : <NEWLINE> <INDENT> b = Basis ( ) <NEWLINE> print ( <STRING> , b ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> import sys <NEWLINE> print ( <STRING> , sys . exc_info ( ) [ 0 ] , sys . exc_info ( ) [ 1 ] ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"basis =\"", "\"t_Basis_std.py\""]}}], ["86a8e8360b085c5d3723237f5c4a5223", {"code_string": "def add_node(self, node, parent = None):\n    '''Add a new node in the tree.'''\n    if not isinstance(node, TreeViewNode):\n        raise TreeViewException(\n            'The node must be a subclass of TreeViewNode')\n    if parent is None and self._root:\n        parent = self._root\n    if parent:\n        parent.is_leaf = False\n        parent.nodes.append(node)\n        node.parent_node = parent\n        node.level = parent.level + 1\n    node.bind(size = self._trigger_layout)\n    self._trigger_layout()\n    return node\n", "code_toks_joined": "def add_node ( self , node , parent = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if not isinstance ( node , TreeViewNode ) : <NEWLINE> <INDENT> raise TreeViewException ( <NEWLINE> <INDENT> <STRING> ) <NEWLINE> <DEDENT> <DEDENT> if parent is None and self . _root : <NEWLINE> <INDENT> parent = self . _root <NEWLINE> <DEDENT> if parent : <NEWLINE> <INDENT> parent . is_leaf = False <NEWLINE> parent . nodes . append ( node ) <NEWLINE> node . parent_node = parent <NEWLINE> node . level = parent . level + 1 <NEWLINE> <DEDENT> node . bind ( size = self . _trigger_layout ) <NEWLINE> self . _trigger_layout ( ) <NEWLINE> return node <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Add a new node in the tree.'''", "'The node must be a subclass of TreeViewNode'"]}}], ["1a0a4fe41728227366b89bac9c372c4f", {"code_string": "def set_context(self, serializer):\n    \"\"\"This hook is called by the serializer instance,\"\"\"\n    self.instance = getattr(serializer, 'instance', None)\n", "code_toks_joined": "def set_context ( self , serializer ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . instance = getattr ( serializer , <STRING> , None ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"This hook is called by the serializer instance,\"\"\"", "'instance'"]}}], ["80c99b6cff12f75d755fd2cc3b87bad6", {"code_string": "def createAuthQuery(self):\n    query = self.API_QUERY\n    query[\"username\"] = self._usr\n    query[\"password\"] = self._pwd\n    return query\n", "code_toks_joined": "def createAuthQuery ( self ) : <NEWLINE> <INDENT> query = self . API_QUERY <NEWLINE> query [ <STRING> ] = self . _usr <NEWLINE> query [ <STRING> ] = self . _pwd <NEWLINE> return query <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"username\"", "\"password\""]}}], ["c0f39eecf5f3a22a0d6c982410aae3e0", {"code_string": "\"\"\"This file reads in the stepdata.csv file and performs some\"\"\"\nimport numpy as np\nimport pandas as pd\nsteps_df = pd.read_csv(\"../data/stepdata.csv\",\n    index_col = 0, parse_dates = True)\n", "code_toks_joined": "<STRING> <NEWLINE> import numpy as np <NEWLINE> import pandas as pd <NEWLINE> steps_df = pd . read_csv ( <STRING> , <NEWLINE> <INDENT> index_col = 0 , parse_dates = True ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"This file reads in the stepdata.csv file and performs some\"\"\"", "\"../data/stepdata.csv\""]}}], ["33ef1279106f1a7e8b4a9c93b8949d2c", {"code_string": "class IssueQuerySet(QuerySet):\n    def published(self):\n        return self.filter(is_published = True)\n", "code_toks_joined": "class IssueQuerySet ( QuerySet ) : <NEWLINE> <INDENT> def published ( self ) : <NEWLINE> <INDENT> return self . filter ( is_published = True ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["507e02e91eb68302a9e2bef6dcaefa28", {"code_string": "import unittest\nfrom ubuntutweak.settings.gsettings import Schema\nfrom ubuntutweak.settings.gconfsettings import GconfSetting\n", "code_toks_joined": "import unittest <NEWLINE> from ubuntutweak . settings . gsettings import Schema <NEWLINE> from ubuntutweak . settings . gconfsettings import GconfSetting <NEWLINE>", "anonymize_dict": {}}], ["9e5c09bccc2d5395ffca1633655b5661", {"code_string": "'''DNA strand is composed of 4 different nucleotides A,C,G,T. This task will'''\nimport os\nos.chdir('/home/vu/Downloads')\nf = open('rosalind_dna (1).txt', 'r').read()[: - 1]\nd = {}\nfor i in f:\n    if i not in d:\n        d[i] = 1\n    else:\n        d[i] = d[i] + 1\nfor items in d:\n    print(items, d[items])\n''' Result'''\n", "code_toks_joined": "<STRING> <NEWLINE> import os <NEWLINE> os . chdir ( <STRING> ) <NEWLINE> f = open ( <STRING> , <STRING> ) . read ( ) [ : - 1 ] <NEWLINE> d = { } <NEWLINE> for i in f : <NEWLINE> <INDENT> if i not in d : <NEWLINE> <INDENT> d [ i ] = 1 <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> d [ i ] = d [ i ] + 1 <NEWLINE> <DEDENT> <DEDENT> for items in d : <NEWLINE> <INDENT> print ( items , d [ items ] ) <NEWLINE> <DEDENT> <STRING> <NEWLINE>", "anonymize_dict": {"<STRING>": ["'''DNA strand is composed of 4 different nucleotides A,C,G,T. This task will'''", "'/home/vu/Downloads'", "'rosalind_dna (1).txt'", "'r'", "''' Result'''"]}}], ["c9e9ca880b74c2117b36d8c6a617dae3", {"code_string": "def erepl(t):\n    bad = [\",\", \";\", \".\", \"(\", \")\", \"/\", \"beim\", \"Adv\", \"Akk\", \"Abl\", \"?\", \"Konj\"]\n    for i in bad:\n        t = t.replace(i, \" \")\n    return t.split(\" \")\n", "code_toks_joined": "def erepl ( t ) : <NEWLINE> <INDENT> bad = [ <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE> for i in bad : <NEWLINE> <INDENT> t = t . replace ( i , <STRING> ) <NEWLINE> <DEDENT> return t . split ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\",\"", "\";\"", "\".\"", "\"(\"", "\")\"", "\"/\"", "\"beim\"", "\"Adv\"", "\"Akk\"", "\"Abl\"", "\"?\"", "\"Konj\"", "\" \"", "\" \""]}}], ["3096363ccfb23fceaeb9f5426ecab673", {"code_string": "def getConfig():\n    confFile = open('config.yaml', 'r')\n    conf = yaml.load(confFile)\n    confFile.close\n    return conf\n", "code_toks_joined": "def getConfig ( ) : <NEWLINE> <INDENT> confFile = open ( <STRING> , <STRING> ) <NEWLINE> conf = yaml . load ( confFile ) <NEWLINE> confFile . close <NEWLINE> return conf <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'config.yaml'", "'r'"]}}], ["b3d2349bb63eaebb77feda7f856dfb22", {"code_string": "class VolumePerturbAugmentor(AugmentorBase):\n    \"\"\"Augmentation model for adding random volume perturbation.\"\"\"\n    def __init__(self, rng, min_gain_dBFS, max_gain_dBFS):\n        self._min_gain_dBFS = min_gain_dBFS\n        self._max_gain_dBFS = max_gain_dBFS\n        self._rng = rng\n    def transform_audio(self, audio_segment):\n        \"\"\"Change audio loadness.\"\"\"\n        gain = self._rng.uniform(min_gain_dBFS, max_gain_dBFS)\n        audio_segment.apply_gain(gain)\n", "code_toks_joined": "class VolumePerturbAugmentor ( AugmentorBase ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , rng , min_gain_dBFS , max_gain_dBFS ) : <NEWLINE> <INDENT> self . _min_gain_dBFS = min_gain_dBFS <NEWLINE> self . _max_gain_dBFS = max_gain_dBFS <NEWLINE> self . _rng = rng <NEWLINE> <DEDENT> def transform_audio ( self , audio_segment ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> gain = self . _rng . uniform ( min_gain_dBFS , max_gain_dBFS ) <NEWLINE> audio_segment . apply_gain ( gain ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Augmentation model for adding random volume perturbation.\"\"\"", "\"\"\"Change audio loadness.\"\"\""]}}], ["299bf7298f195d8d4da2f33845a1ab9d", {"code_string": "from __future__ import absolute_import, division, print_function\nfrom.form import Form, TornadoInputWrapper\n__author__ = 'ipfans <ipfanscn@gmail.com>'\n__since__ = '2015-08-28'\n__version__ = '1.0.0'\n__all__ = ['Form', 'TornadoInputWrapper']\n", "code_toks_joined": "from __future__ import absolute_import , division , print_function <NEWLINE> from . form import Form , TornadoInputWrapper <NEWLINE> __author__ = <STRING> <NEWLINE> __since__ = <STRING> <NEWLINE> __version__ = <STRING> <NEWLINE> __all__ = [ <STRING> , <STRING> ] <NEWLINE>", "anonymize_dict": {"<STRING>": ["'ipfans <ipfanscn@gmail.com>'", "'2015-08-28'", "'1.0.0'", "'Form'", "'TornadoInputWrapper'"]}}], ["6a1a005a3a726b55f61b1589f23a0ca3", {"code_string": "import glob\nimport os\nimport re\nimport shutil\nimport cleanttl\nfrom ttlhead import ttlhead\n", "code_toks_joined": "import glob <NEWLINE> import os <NEWLINE> import re <NEWLINE> import shutil <NEWLINE> import cleanttl <NEWLINE> from ttlhead import ttlhead <NEWLINE>", "anonymize_dict": {}}], ["d694d5e95dc76637808e217474460069", {"code_string": "from flask import Blueprint\nindex = Blueprint('index', __name__, template_folder = 'templates')\nfrom.import view\n", "code_toks_joined": "from flask import Blueprint <NEWLINE> index = Blueprint ( <STRING> , __name__ , template_folder = <STRING> ) <NEWLINE> from . import view <NEWLINE>", "anonymize_dict": {"<STRING>": ["'index'", "'templates'"]}}], ["2989c794f432bad5d9a9ac05590c6a90", {"code_string": "\"\"\"Copyright (c) 2014, Regents of the University of California\"\"\"\n\"\"\"@author Anthony Sutardja <anthonysutardja@berkeley.edu>\"\"\"\nimport urllib2\nfrom BeautifulSoup import BeautifulSoup\nfrom smap.driver import SmapDriver\nfrom smap.util import periodicSequentialCall\nfrom twisted.python import log\n", "code_toks_joined": "<STRING> <NEWLINE> <STRING> <NEWLINE> import urllib2 <NEWLINE> from BeautifulSoup import BeautifulSoup <NEWLINE> from smap . driver import SmapDriver <NEWLINE> from smap . util import periodicSequentialCall <NEWLINE> from twisted . python import log <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Copyright (c) 2014, Regents of the University of California\"\"\"", "\"\"\"@author Anthony Sutardja <anthonysutardja@berkeley.edu>\"\"\""]}}], ["622068c9b88bfb8b584b160efdf608ba", {"code_string": "def handler(fit, skill, context):\n    fit.modules.filteredItemBoost(lambda mod: mod.item.requiresSkill(skill), \"consumptionQuantity\",\n        skill.getModifiedItemAttr(\"consumptionQuantityBonusPercent\") * skill.level)\n", "code_toks_joined": "def handler ( fit , skill , context ) : <NEWLINE> <INDENT> fit . modules . filteredItemBoost ( lambda mod : mod . item . requiresSkill ( skill ) , <STRING> , <NEWLINE> <INDENT> skill . getModifiedItemAttr ( <STRING> ) * skill . level ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"consumptionQuantity\"", "\"consumptionQuantityBonusPercent\""]}}], ["c4e4d6a7de20dddaeeb24795bbc7aca5", {"code_string": "def get_config():\n    config = {'model': PronounPrediction,\n        'n_hiddens': [50],\n        'embedding_dimensionality': 50,\n        'activation_function': T.tanh,\n        'cost_function': cross_entropy,\n        'min_iterations': 100000,\n        'n_epochs': 1000,\n        'batch_size': 100,\n        'no_embeddings': 23,\n        'window_size': (4, 4),\n        'classes_filepath': 'resources/train/iwslt14/classes.csv',\n        'training_filepath': ['resources/train/iwslt14/data-with-doc.csv'],\n        'development_filepath': 'resources/test/teddev/data-with-doc.csv',\n        'test_filepath': 'resources/test/discomt/data-with-doc.csv',\n        'n_tags': 3}\n    return config\n", "code_toks_joined": "def get_config ( ) : <NEWLINE> <INDENT> config = { <STRING> : PronounPrediction , <NEWLINE> <INDENT> <STRING> : [ 50 ] , <NEWLINE> <STRING> : 50 , <NEWLINE> <STRING> : T . tanh , <NEWLINE> <STRING> : cross_entropy , <NEWLINE> <STRING> : 100000 , <NEWLINE> <STRING> : 1000 , <NEWLINE> <STRING> : 100 , <NEWLINE> <STRING> : 23 , <NEWLINE> <STRING> : ( 4 , 4 ) , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : [ <STRING> ] , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : 3 } <NEWLINE> <DEDENT> return config <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'model'", "'n_hiddens'", "'embedding_dimensionality'", "'activation_function'", "'cost_function'", "'min_iterations'", "'n_epochs'", "'batch_size'", "'no_embeddings'", "'window_size'", "'classes_filepath'", "'resources/train/iwslt14/classes.csv'", "'training_filepath'", "'resources/train/iwslt14/data-with-doc.csv'", "'development_filepath'", "'resources/test/teddev/data-with-doc.csv'", "'test_filepath'", "'resources/test/discomt/data-with-doc.csv'", "'n_tags'"]}}], ["3ce00118b6a20b3bae325ace63e484dc", {"code_string": "def delete_frame(self, key, ignoreMissingKey = True, timeoutSecs = 60, ** kwargs):\n    assert key is not None, 'FAIL: \"key\" parameter is null'\n    result = self.__do_json_request('/3/Frames.json/' + key, cmd = 'delete', timeout = timeoutSecs)\n    if not ignoreMissingKey and 'f00b4r' in result:\n        raise ValueError('Frame key not found: ' + key)\n    return result\n", "code_toks_joined": "def delete_frame ( self , key , ignoreMissingKey = True , timeoutSecs = 60 , ** kwargs ) : <NEWLINE> <INDENT> assert key is not None , <STRING> <NEWLINE> result = self . __do_json_request ( <STRING> + key , cmd = <STRING> , timeout = timeoutSecs ) <NEWLINE> if not ignoreMissingKey and <STRING> in result : <NEWLINE> <INDENT> raise ValueError ( <STRING> + key ) <NEWLINE> <DEDENT> return result <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'FAIL: \"key\" parameter is null'", "'/3/Frames.json/'", "'delete'", "'f00b4r'", "'Frame key not found: '"]}}], ["c3e3b4fd0c93316f093f78dabb57957a", {"code_string": "\"\"\"To run these tests against a live database:\"\"\"\nimport copy\nimport json\nimport uuid\nfrom migrate.versioning import api as versioning_api\nimport sqlalchemy\nfrom keystone.common import sql\nfrom keystone.common.sql import migration\nfrom keystone import config\nfrom keystone import test\nimport default_fixtures\nCONF = config.CONF\nDEFAULT_DOMAIN_ID = CONF.identity.default_domain_id\n", "code_toks_joined": "<STRING> <NEWLINE> import copy <NEWLINE> import json <NEWLINE> import uuid <NEWLINE> from migrate . versioning import api as versioning_api <NEWLINE> import sqlalchemy <NEWLINE> from keystone . common import sql <NEWLINE> from keystone . common . sql import migration <NEWLINE> from keystone import config <NEWLINE> from keystone import test <NEWLINE> import default_fixtures <NEWLINE> CONF = config . CONF <NEWLINE> DEFAULT_DOMAIN_ID = CONF . identity . default_domain_id <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"To run these tests against a live database:\"\"\""]}}], ["07f42969253df47c1a70755c402ab747", {"code_string": "class CustomUserCreationForm(UserCreationForm):\n    '''Copy Django's UserCreationForm over'''\n    class Meta(UserCreationForm.Meta):\n        model = User\n    def clean_username(self):\n        username = self.cleaned_data[\"username\"]\n        try:\n            User._default_manager.get(username = username)\n        except User.DoesNotExist:\n            return username\n        raise forms.ValidationError(\n            self.error_messages['duplicate_username'],\n            code = 'duplicate_username',\n        )\n", "code_toks_joined": "class CustomUserCreationForm ( UserCreationForm ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> class Meta ( UserCreationForm . Meta ) : <NEWLINE> <INDENT> model = User <NEWLINE> <DEDENT> def clean_username ( self ) : <NEWLINE> <INDENT> username = self . cleaned_data [ <STRING> ] <NEWLINE> try : <NEWLINE> <INDENT> User . _default_manager . get ( username = username ) <NEWLINE> <DEDENT> except User . DoesNotExist : <NEWLINE> <INDENT> return username <NEWLINE> <DEDENT> raise forms . ValidationError ( <NEWLINE> <INDENT> self . error_messages [ <STRING> ] , <NEWLINE> code = <STRING> , <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Copy Django's UserCreationForm over'''", "\"username\"", "'duplicate_username'", "'duplicate_username'"]}}], ["3febbf113893701f0fbddd548d46c4f4", {"code_string": "class Pentium(Machine):\n    '''Intel 32-bit architecture processors.'''\n    def load(self, factory, fp):\n        from lang.asm.att_lexer import Lexer\n        from lang.asm.att_parser import Parser\n        lexer = Lexer(fp)\n        parser = Parser(lexer, factory = factory)\n        term = parser.start()\n        return term\n    def translate(self, term):\n        from machine.pentium import translator\n        from transf.context import Context\n        term = translator.doModule.apply(term, Context())\n        return term\n", "code_toks_joined": "class Pentium ( Machine ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def load ( self , factory , fp ) : <NEWLINE> <INDENT> from lang . asm . att_lexer import Lexer <NEWLINE> from lang . asm . att_parser import Parser <NEWLINE> lexer = Lexer ( fp ) <NEWLINE> parser = Parser ( lexer , factory = factory ) <NEWLINE> term = parser . start ( ) <NEWLINE> return term <NEWLINE> <DEDENT> def translate ( self , term ) : <NEWLINE> <INDENT> from machine . pentium import translator <NEWLINE> from transf . context import Context <NEWLINE> term = translator . doModule . apply ( term , Context ( ) ) <NEWLINE> return term <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''Intel 32-bit architecture processors.'''"]}}], ["6868a9c8a4a14819cc1dbf9fac66ae1e", {"code_string": "\"\"\"Test for end-to-end with external server.\"\"\"\nimport optparse\nimport sys\nimport test.test_endtoend\nimport unittest\n_DEFAULT_WEB_SOCKET_PORT = 80\n", "code_toks_joined": "<STRING> <NEWLINE> import optparse <NEWLINE> import sys <NEWLINE> import test . test_endtoend <NEWLINE> import unittest <NEWLINE> _DEFAULT_WEB_SOCKET_PORT = 80 <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"Test for end-to-end with external server.\"\"\""]}}], ["30e14aa72f93a5692f1b2f4e1c08688f", {"code_string": "def read_cat_facts_file(self):\n    \"\"\"Read the cat facts file into a list so we can retrieve at random later\"\"\"\n    try:\n        dir = os.path.dirname(__file__)\n        fact_file_path = os.path.join(dir, \"./facts.txt\")\n        for line in open(fact_file_path):\n            self.cat_facts.append(line.rstrip(\"\\n\"))\n    except:\n        self.log.error(\"Cayenne: error reading cat facts file: %s\" % fact_file_path)\n", "code_toks_joined": "def read_cat_facts_file ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> try : <NEWLINE> <INDENT> dir = os . path . dirname ( __file__ ) <NEWLINE> fact_file_path = os . path . join ( dir , <STRING> ) <NEWLINE> for line in open ( fact_file_path ) : <NEWLINE> <INDENT> self . cat_facts . append ( line . rstrip ( <STRING> ) ) <NEWLINE> <DEDENT> <DEDENT> except : <NEWLINE> <INDENT> self . log . error ( <STRING> % fact_file_path ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Read the cat facts file into a list so we can retrieve at random later\"\"\"", "\"./facts.txt\"", "\"\\n\"", "\"Cayenne: error reading cat facts file: %s\""]}}], ["475132bfea774d4f7b26f7f1d1f8b64f", {"code_string": "from sqlalchemy import Boolean, Column, DateTime\nfrom sqlalchemy import MetaData, Integer, String, Table\nfrom nova.openstack.common import log as logging\nLOG = logging.getLogger(__name__)\n", "code_toks_joined": "from sqlalchemy import Boolean , Column , DateTime <NEWLINE> from sqlalchemy import MetaData , Integer , String , Table <NEWLINE> from nova . openstack . common import log as logging <NEWLINE> LOG = logging . getLogger ( __name__ ) <NEWLINE>", "anonymize_dict": {}}], ["22e1a30654e3031aab1a288e13764255", {"code_string": "def test_endpoint(self):\n    customer = invoiced.Customer(self.client, 123)\n    self.assertEqual('/customers/123', customer.endpoint())\n    customer.set_endpoint_base('/blah')\n    self.assertEqual('/blah', customer.endpoint_base())\n    self.assertEqual('/blah/customers/123', customer.endpoint())\n", "code_toks_joined": "def test_endpoint ( self ) : <NEWLINE> <INDENT> customer = invoiced . Customer ( self . client , 123 ) <NEWLINE> self . assertEqual ( <STRING> , customer . endpoint ( ) ) <NEWLINE> customer . set_endpoint_base ( <STRING> ) <NEWLINE> self . assertEqual ( <STRING> , customer . endpoint_base ( ) ) <NEWLINE> self . assertEqual ( <STRING> , customer . endpoint ( ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'/customers/123'", "'/blah'", "'/blah'", "'/blah/customers/123'"]}}], ["f74e4aa3fae40c625584ccfddf3db9bb", {"code_string": "import json\nimport requests\nTIMEOUT = 30\n", "code_toks_joined": "import json <NEWLINE> import requests <NEWLINE> TIMEOUT = 30 <NEWLINE>", "anonymize_dict": {}}], ["6ff6e3fad83a93e00e89d01f54c13324", {"code_string": "import os\nimport shutil\nimport logging\nimport tarfile\nimport tempfile\nimport subprocess\nimport distutils.spawn\nfrom threading import Thread\nif not distutils.spawn.find_executable('ffmpeg'):\n    raise ImportError('ffmpeg executable not found')\n", "code_toks_joined": "import os <NEWLINE> import shutil <NEWLINE> import logging <NEWLINE> import tarfile <NEWLINE> import tempfile <NEWLINE> import subprocess <NEWLINE> import distutils . spawn <NEWLINE> from threading import Thread <NEWLINE> if not distutils . spawn . find_executable ( <STRING> ) : <NEWLINE> <INDENT> raise ImportError ( <STRING> ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'ffmpeg'", "'ffmpeg executable not found'"]}}], ["a8e680e444a5003f3e5e8688a1100b03", {"code_string": "def logadd(self, a, b):\n    g = T.maximum(a, b)\n    l = T.minimum(a, b)\n    return g + T.log(1 + T.exp(l - g))\n", "code_toks_joined": "def logadd ( self , a , b ) : <NEWLINE> <INDENT> g = T . maximum ( a , b ) <NEWLINE> l = T . minimum ( a , b ) <NEWLINE> return g + T . log ( 1 + T . exp ( l - g ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["c1fe85120f6530c874a7a901cb8c7555", {"code_string": "def _compare_periods(self, first: Period, second: Period):\n    self.assertEqual(first.start, second.start)\n    self.assertEqual(first.duration, second.duration)\n    return True\n", "code_toks_joined": "def _compare_periods ( self , first : Period , second : Period ) : <NEWLINE> <INDENT> self . assertEqual ( first . start , second . start ) <NEWLINE> self . assertEqual ( first . duration , second . duration ) <NEWLINE> return True <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["e2cdd586e1d2ab2123b651c4e0f601fa", {"code_string": "helptable = {\n    \"dates|Date Formats\":\n    r'''Some commands allow the user to specify a date:''',\n    'environment|env|Environment Variables':\n    r'''HG::''',\n    \"patterns|File Name Patterns\": r'''Mercurial accepts several notations for identifying one or more''',\n}\n", "code_toks_joined": "helptable = { <NEWLINE> <INDENT> <STRING> : <NEWLINE> <STRING> , <NEWLINE> <STRING> : <NEWLINE> <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <DEDENT> } <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"dates|Date Formats\"", "r'''Some commands allow the user to specify a date:'''", "'environment|env|Environment Variables'", "r'''HG::'''", "\"patterns|File Name Patterns\"", "r'''Mercurial accepts several notations for identifying one or more'''"]}}], ["42bf057bfa3492e4e61f66be21bda032", {"code_string": "def plot_dista_distrib_autocor(self):\n    '''plots dista_distrib_autocor'''\n    plt.plot(np.arange(self._min_hop_shift, self._max_hop_shift) * self.gcd / float(self.sampling_rate), self.dista_distrib_autocor)\n    plt.title('autocorrelation of distribution of onset distances')\n    plt.xlabel('lags (s)')\n    plt.ylabel('autocor')\n    plt.show()\n", "code_toks_joined": "def plot_dista_distrib_autocor ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> plt . plot ( np . arange ( self . _min_hop_shift , self . _max_hop_shift ) * self . gcd / float ( self . sampling_rate ) , self . dista_distrib_autocor ) <NEWLINE> plt . title ( <STRING> ) <NEWLINE> plt . xlabel ( <STRING> ) <NEWLINE> plt . ylabel ( <STRING> ) <NEWLINE> plt . show ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'''plots dista_distrib_autocor'''", "'autocorrelation of distribution of onset distances'", "'lags (s)'", "'autocor'"]}}], ["e6f4a82573ed889ea7a96a50d08bdfed", {"code_string": "def evaluateModuleMSE(self, module, averageOver = 1, ** args):\n    \"\"\"Evaluate the predictions of a module on a dataset and return the MSE\"\"\"\n    res = 0.\n    for dummy in range(averageOver):\n        module.reset()\n        res += self.evaluateMSE(module.activate, ** args)\n    return res / averageOver\n", "code_toks_joined": "def evaluateModuleMSE ( self , module , averageOver = 1 , ** args ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> res = 0. <NEWLINE> for dummy in range ( averageOver ) : <NEWLINE> <INDENT> module . reset ( ) <NEWLINE> res += self . evaluateMSE ( module . activate , ** args ) <NEWLINE> <DEDENT> return res / averageOver <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"\"\"Evaluate the predictions of a module on a dataset and return the MSE\"\"\""]}}], ["0274e6ff5d7cde3e667646e4ed891aae", {"code_string": "def web_delete_authzs_bucket(key_name, bucket):\n    with db_trans() as c:\n        c.execute(\"delete from authz where key_name=:key_name and \"\n            \"bucket=:bucket\", locals())\n    return 'ok'\n", "code_toks_joined": "def web_delete_authzs_bucket ( key_name , bucket ) : <NEWLINE> <INDENT> with db_trans ( ) as c : <NEWLINE> <INDENT> c . execute ( <STRING> <NEWLINE> <INDENT> <STRING> , locals ( ) ) <NEWLINE> <DEDENT> <DEDENT> return <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"delete from authz where key_name=:key_name and \"", "\"bucket=:bucket\"", "'ok'"]}}], ["73fe46e4685efb83d53048928157475e", {"code_string": "class Tfg_Asig(models.Model):\n    tfg = models.ForeignKey(Tfg, default = None)\n    alumno_1 = models.ForeignKey(Alumno, related_name = 'alumno_1', default = None)\n    alumno_2 = models.ForeignKey(Alumno, related_name = 'alumno_2', default = None, null = True)\n    alumno_3 = models.ForeignKey(Alumno, related_name = 'alumno_3', default = None, null = True)\n", "code_toks_joined": "class Tfg_Asig ( models . Model ) : <NEWLINE> <INDENT> tfg = models . ForeignKey ( Tfg , default = None ) <NEWLINE> alumno_1 = models . ForeignKey ( Alumno , related_name = <STRING> , default = None ) <NEWLINE> alumno_2 = models . ForeignKey ( Alumno , related_name = <STRING> , default = None , null = True ) <NEWLINE> alumno_3 = models . ForeignKey ( Alumno , related_name = <STRING> , default = None , null = True ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'alumno_1'", "'alumno_2'", "'alumno_3'"]}}], ["e378d782a0fcbb184f91e3c01d5dd328", {"code_string": "def WritePotentialLeaks(graph_dumps):\n    for graph in graph_dumps:\n        if graph.leaks:\n            filename = 'process_%d_%s-leaks.json' %(graph.pid, graph.heap)\n            output_filename = os.path.join(_OUTPUT_DIR, filename)\n            with open(output_filename, 'w') as output:\n                json.dump(graph.leaks, output)\n", "code_toks_joined": "def WritePotentialLeaks ( graph_dumps ) : <NEWLINE> <INDENT> for graph in graph_dumps : <NEWLINE> <INDENT> if graph . leaks : <NEWLINE> <INDENT> filename = <STRING> % ( graph . pid , graph . heap ) <NEWLINE> output_filename = os . path . join ( _OUTPUT_DIR , filename ) <NEWLINE> with open ( output_filename , <STRING> ) as output : <NEWLINE> <INDENT> json . dump ( graph . leaks , output ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["'process_%d_%s-leaks.json'", "'w'"]}}], ["58b567c98c8fb9ab1575ccc7f5fa86b8", {"code_string": "def main():\n    form = cgi.FieldStorage()\n    if(form.has_key(\"action\") and form.has_key(\"name\") and form.has_key(\"age\")):\n        if(form[\"action\"].value == \"display\"):\n            display_data(form[\"name\"].value, form[\"age\"].value)\n    else:\n        generate_form()\n", "code_toks_joined": "def main ( ) : <NEWLINE> <INDENT> form = cgi . FieldStorage ( ) <NEWLINE> if ( form . has_key ( <STRING> ) and form . has_key ( <STRING> ) and form . has_key ( <STRING> ) ) : <NEWLINE> <INDENT> if ( form [ <STRING> ] . value == <STRING> ) : <NEWLINE> <INDENT> display_data ( form [ <STRING> ] . value , form [ <STRING> ] . value ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> generate_form ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {"<STRING>": ["\"action\"", "\"name\"", "\"age\"", "\"action\"", "\"display\"", "\"name\"", "\"age\""]}}], ["b2bb0d6227b5b31c28a7d50ad5c145bc", {"code_string": "\"\"\"usage:\"\"\"\nfrom __future__ import division\nimport docopt\nimport os\nimport pandas as pd\nimport propyte\nimport sklearn.preprocessing\nname = \"ttHbb_preprocess_CSV_file\"\nversion = \"2017-04-05T1141Z\"\nlogo = name\n", "code_toks_joined": "<STRING> <NEWLINE> from __future__ import division <NEWLINE> import docopt <NEWLINE> import os <NEWLINE> import pandas as pd <NEWLINE> import propyte <NEWLINE> import sklearn . preprocessing <NEWLINE> name = <STRING> <NEWLINE> version = <STRING> <NEWLINE> logo = name <NEWLINE>", "anonymize_dict": {"<STRING>": ["\"\"\"usage:\"\"\"", "\"ttHbb_preprocess_CSV_file\"", "\"2017-04-05T1141Z\""]}}], ["712df16db0b591770f507183c8e2ba53", {"code_string": "class test_Potential_1d(object):\n    def test_single_run(self):\n        P = Potential_1d_single_run()\n    def test_many_runs(self):\n        P = Potential_1d_many_runs()\n", "code_toks_joined": "class test_Potential_1d ( object ) : <NEWLINE> <INDENT> def test_single_run ( self ) : <NEWLINE> <INDENT> P = Potential_1d_single_run ( ) <NEWLINE> <DEDENT> def test_many_runs ( self ) : <NEWLINE> <INDENT> P = Potential_1d_many_runs ( ) <NEWLINE> <DEDENT> <DEDENT>", "anonymize_dict": {}}], ["b3e1234c8c654b67516775c0a711a84f", {"code_string": "from django.contrib import admin\nfrom django.contrib.admin import AdminSite\nfrom.models import Figure\nfrom.models import Animation\n", "code_toks_joined": "from django . contrib import admin <NEWLINE> from django . contrib . admin import AdminSite <NEWLINE> from . models import Figure <NEWLINE> from . models import Animation <NEWLINE>", "anonymize_dict": {}}], ["6cffc97005e544682f5efc49afb72305", {"code_string": "class CartItemInline(admin.TabularInline):\n    model = CartItem\n    extra = 0\n    exclude = ('product', )\n    readonly_fields = ('quantity', )\n", "code_toks_joined": "class CartItemInline ( admin . TabularInline ) : <NEWLINE> <INDENT> model = CartItem <NEWLINE> extra = 0 <NEWLINE> exclude = ( <STRING> , ) <NEWLINE> readonly_fields = ( <STRING> , ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'product'", "'quantity'"]}}], ["a639ebc324dc67d8ed6c30b268caaa9e", {"code_string": "class DiskCommand(ConstantBase):\n    FUA = ()\n    AHEAD = ()\n    SYNC = ()\n    META = ()\n    FLUSH = ()\n", "code_toks_joined": "class DiskCommand ( ConstantBase ) : <NEWLINE> <INDENT> FUA = ( ) <NEWLINE> AHEAD = ( ) <NEWLINE> SYNC = ( ) <NEWLINE> META = ( ) <NEWLINE> FLUSH = ( ) <NEWLINE> <DEDENT>", "anonymize_dict": {}}], ["4a1781953937f50061e7f3878b4c580d", {"code_string": "def thread_run():\n    Log.logger.debug('Processing webui_run')\n    return 'Processed webui_run'\n", "code_toks_joined": "def thread_run ( ) : <NEWLINE> <INDENT> Log . logger . debug ( <STRING> ) <NEWLINE> return <STRING> <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'Processing webui_run'", "'Processed webui_run'"]}}], ["8d24aa5562264cf97f71c8ca7db8073c", {"code_string": "def test_with_many_matching_ignore_channel_patterns(self):\n    self.destalinator = destalinator.Destalinator(self.slacker, self.slackbot, activated = True)\n    self.destalinator.config.config['ignore_channel_patterns'] = ['^len', 'lin', '^st']\n    self.assertTrue(self.destalinator.ignore_channel('stalinists'))\n", "code_toks_joined": "def test_with_many_matching_ignore_channel_patterns ( self ) : <NEWLINE> <INDENT> self . destalinator = destalinator . Destalinator ( self . slacker , self . slackbot , activated = True ) <NEWLINE> self . destalinator . config . config [ <STRING> ] = [ <STRING> , <STRING> , <STRING> ] <NEWLINE> self . assertTrue ( self . destalinator . ignore_channel ( <STRING> ) ) <NEWLINE> <DEDENT>", "anonymize_dict": {"<STRING>": ["'ignore_channel_patterns'", "'^len'", "'lin'", "'^st'", "'stalinists'"]}}]]